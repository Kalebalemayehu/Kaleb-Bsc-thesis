Authors,Title,DOI,Link,Abstract,Author Keywords,Index Keywords
"Abbas A., Baek S., Silvera N., Soulileuth B., Pachepsky Y., Ribolzi O., Boithias L., Cho K.H.","In-stream Escherichia coli modeling using high-temporal-resolution data with deep learning and process-based models","10.5194/hess-25-6185-2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121001663&doi=10.5194%2fhess-25-6185-2021&partnerID=40&md5=decf59f31ce247bf01a7d22de439d032","Contamination of surface waters with microbiological pollutants is a major concern to public health. Although long-term and high-frequency Escherichia coli (E. coli) monitoring can help prevent diseases from fecal pathogenic microorganisms, such monitoring is time-consuming and expensive. Process-driven models are an alternative means for estimating concentrations of fecal pathogens. However, process-based modeling still has limitations in improving the model accuracy because of the complexity of relationships among hydrological and environmental variables. With the rise of data availability and computation power, the use of data-driven models is increasing. In this study, we simulated fate and transport of E. coli in a 0.6gkm2 tropical headwater catchment located in the Lao People's Democratic Republic (Lao PDR) using a deep-learning model and a process-based model. The deep learning model was built using the long short-term memory (LSTM) methodology, whereas the process-based model was constructed using the Hydrological Simulation Program-FORTRAN (HSPF). First, we calibrated both models for surface as well as for subsurface flow. Then, we simulated the E. coli transport with 6gmin time steps with both the HSPF and LSTM models. The LSTM provided accurate results for surface and subsurface flow with 0.51 and 0.64 of the Nash-Sutcliffe efficiency (NSE) values, respectively. In contrast, the NSE values yielded by the HSPF were -0.7 and 0.59 for surface and subsurface flow. The simulated E. coli concentrations from LSTM provided the NSE of 0.35, whereas the HSPF gave an unacceptable performance with an NSE value of -3.01 due to the limitations of HSPF in capturing the dynamics of E. coli with land-use change. The simulated E. coli concentration showed the rise and drop patterns corresponding to annual changes in land use. This study showcases the application of deep-learning-based models as an efficient alternative to process-based models for E. coli fate and transport simulation at the catchment scale. © 2021 The Author(s).",,"Catchments; Land use; Long short-term memory; Runoff; Water pollution; Escherichia coli model; Fate and transport; High temporal resolution; Hydrological simulations; Learning Based Models; Learning models; Process-based modeling; Simulation projects; Surface and subsurface flow; Term Frequency; Escherichia coli; accuracy assessment; catchment; coliform bacterium; concentration (composition); hydrological modeling; machine learning; numerical model; stream; subsurface flow; temporal analysis; Escherichia coli"
"Abbas A., Baek S., Kim M., Ligaray M., Ribolzi O., Silvera N., Min J.-H., Boithias L., Cho K.H.","Surface and sub-surface flow estimation at high temporal resolution using deep neural networks","10.1016/j.jhydrol.2020.125370","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089223073&doi=10.1016%2fj.jhydrol.2020.125370&partnerID=40&md5=a37926348997e5fd2ad6f970efd1ee32","Recent intensification in climate change have resulted in the rise of hydrological extreme events. This demands modeling of hydrological processes at high temporal resolution to better understand flow patterns in catchments. To model surface and sub-surface flows in a catchment we utilized a physically based model called Hydrological Simulated Program-FORTRAN and two deep learning-based models. One deep learning model consisted of only one long short-term memory (simple LSTM), whereas the other model simulated processes in each hydrological response unit (HRU) by defining one separate LSTM for each HRU (HRU-based LSTM). The models use environmental time-series data and two-dimensional spatial data to predict surface and sub-surface flows at 6-minute time step simultaneously. We tested our models in a tropical humid headwater catchment in northern Lao PDR and compared their performances. Our results showed that the simple LSTM model outperformed the other models on surface runoff prediction with the lowest MSE (7.4e−5 m3 s−1), whereas HRU-based LSTM model better predicted patterns and slopes in sub-surface flow in comparison with the other models by having the smallest MSE value (3.2e−4 m3 s−1). This study demonstrated the performance of a deep learning model when simulating hydrological cycle with high temporal resolution. © 2020 Elsevier B.V.","Deep learning model; Hydrological Simulated Program-FORTRAN; Long short-term memory (LSTM); Sub-surface flow; Surface runoff","Catchments; Climate change; Deep learning; Deep neural networks; Learning systems; Runoff; Headwater catchment; High temporal resolution; Hydrological cycles; Hydrological extremes; Hydrological process; Hydrological response unit; Learning Based Models; Physically based modeling; Long short-term memory; artificial neural network; catchment; climate change; estimation method; extreme event; hydrological cycle; hydrological modeling; hydrological response; prediction; subsurface flow; temporal analysis"
"Abdollahi A., Pradhan B.","Urban vegetation mapping from aerial imagery using explainable AI (XAI)","10.3390/s21144738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109297211&doi=10.3390%2fs21144738&partnerID=40&md5=433abc268b8efa2ed7d71f7c8e707bee","Urban vegetation mapping is critical in many applications, i.e., preserving biodiversity, maintaining ecological balance, and minimizing the urban heat island effect. It is still challenging to extract accurate vegetation covers from aerial imagery using traditional classification approaches, because urban vegetation categories have complex spatial structures and similar spectral properties. Deep neural networks (DNNs) have shown a significant improvement in remote sensing image classification outcomes during the last few years. These methods are promising in this domain, yet unreliable for various reasons, such as the use of irrelevant descriptor features in the building of the models and lack of quality in the labeled image. Explainable AI (XAI) can help us gain insight into these limits and, as a result, adjust the training dataset and model as needed. Thus, in this work, we explain how an explanation model called Shapley additive explanations (SHAP) can be utilized for interpreting the output of the DNN model that is designed for classifying vegetation covers. We want to not only produce high-quality vegetation maps, but also rank the input parameters and select appropriate features for classification. Therefore, we test our method on vegetation mapping from aerial imagery based on spectral and textural features. Texture features can help overcome the limitations of poor spectral resolution in aerial imagery for vegetation mapping. The model was capable of obtaining an overall accuracy (OA) of 94.44% for vegetation cover mapping. The conclusions derived from SHAP plots demonstrate the high contribution of features, such as Hue, Brightness, GLCM_Dissimilarity, GLCM_Homogeneity, and GLCM_Mean to the output of the proposed model for vegetation mapping. Therefore, the study indicates that existing vegetation mapping strategies based only on spectral characteristics are insufficient to appropriately classify vegetation covers. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep neural network; Remote sensing; SHAP; Vegetation mapping; XAI","Aerial photography; Antennas; Biodiversity; Deep neural networks; Image classification; Image enhancement; Photomapping; Remote sensing; Textures; Classification approach; Ecological balance; Overall accuracies; Remote sensing image classification; Spectral characteristics; Spectral properties; Urban Heat Island Effects; Vegetation mapping; Vegetation; city; heat; Cities; Hot Temperature; Neural Networks, Computer"
"Abdullah K.H., Sofyan D.","Machine Learning in Safety and Health Research: A Scientometric Analysis","10.22034/ijism.2022.1977763.0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146668545&doi=10.22034%2fijism.2022.1977763.0&partnerID=40&md5=74a1e39bc533a47d353142abd01b92d7","Safety and health are intricately interwoven and have become indispensable to the thriving business world and anthropology. It is concerned with ensuring employees’ physical, emotional, and mental well-being. Based on the Scopus and Web of Science databases, the current study intends to analyse the global research output on machine learning in safety and health. This study utilized ScientoPy and VOSviewer to delve into the annual growth, patterns of research communication on source titles, international collaboration among countries, and authors’ keyword analysis. This study found that the Web of Science database tracks the evolution of publications throughout time. PLoS One has surpassed all other source titles in terms of publishing activity. Also, this study indicated that US researchers are constantly working on machine learning in safety and health research and have developed significant collaborations with China and Australia. Between 2020 and 2021, the University of Toronto published 86% of all papers, outpacing other institutions. The keywords “machine learning”, “artificial intelligence”, “electronic health records”, “deep learning”, and “mental health” were the most popular and trending keywords in 2020 and 2021, and “artificial intelligence” appeared in most publications among others. Future researchers should conduct scoping or systematic literature reviews to elucidate the relationships between these terms. This study may entice the curiosity of practitioners and researchers to advance new knowledge in this field by being devoted to cutting-edge research in the contemporary philosophy of science, cognitive, and cultural anthropology on machine learning in safety and health research. In conclusion, this scientometric analysis demonstrates that machine learning in safety and health is a study domain that requires further refinement in future research, as this technology has the potential to significantly improve workplace safety and health through targeted applications with clear benefits © 2023,International Journal of Information Science and Management.All Rights Reserved.","Health; Machine learning; Publication trajectories.; Safety; Scientometric; Scopus; Web of science",
"Abdullahi M., Baashar Y., Alhussian H., Alwadain A., Aziz N., Capretz L.F., Abdulkadir S.J.","Detecting Cybersecurity Attacks in Internet of Things Using Artificial Intelligence Methods: A Systematic Literature Review","10.3390/electronics11020198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122387869&doi=10.3390%2felectronics11020198&partnerID=40&md5=935d3274b03cc9808c51084d26143c60","In recent years, technology has advanced to the fourth industrial revolution (Industry 4.0), where the Internet of things (IoTs), fog computing, computer security, and cyberattacks have evolved exponentially on a large scale. The rapid development of IoT devices and networks in various forms generate enormous amounts of data which in turn demand careful authentication and security. Artificial intelligence (AI) is considered one of the most promising methods for addressing cybersecurity threats and providing security. In this study, we present a systematic literature review (SLR) that categorize, map and survey the existing literature on AI methods used to detect cybersecurity attacks in the IoT environment. The scope of this SLR includes an in-depth investigation on most AI trending techniques in cybersecurity and state-of-art solutions. A systematic search was performed on various electronic databases (SCOPUS, Science Direct, IEEE Xplore, Web of Science, ACM, and MDPI). Out of the identified records, 80 studies published between 2016 and 2021 were selected, surveyed and carefully assessed. This review has explored deep learning (DL) and machine learning (ML) techniques used in IoT security, and their effectiveness in detecting attacks. However, several studies have proposed smart intrusion detection systems (IDS) with intelligent architectural frameworks using AI to overcome the existing security and privacy challenges. It is found that support vector machines (SVM) and random forest (RF) are among the most used methods, due to high accuracy detection another reason may be efficient memory. In addition, other methods also provide better performance such as extreme gradient boosting (XGBoost), neural networks (NN) and recurrent neural networks (RNN). This analysis also provides an insight into the AI roadmap to detect threats based on attack categories. Finally, we present recommendations for potential future investigations. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; Cyberattacks; Cybersecurity; Deep learning; Internet of things; Intrusion detection systems; Machine learning; Systematic literature review",
"Abubakar I.S., Akadiri S.S.","Revisiting oil rents-output growth nexus in Nigeria: evidence from dynamic autoregressive distributive lag model and kernel-based regularized least squares approach","10.1007/s11356-022-19034-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124581993&doi=10.1007%2fs11356-022-19034-z&partnerID=40&md5=f00b4b7d9c415287cb51e9b28dd0a7a4","Given the dominant role of oil in terms of foreign exchange earnings in Nigeria, this study revisits the oil rents and output growth nexus, using the novel dynamic autoregressive distributive lag (DYNARDL) model and kernel-based regularized least squares (KRLS) approach over the period 1973–2020. The major finding from this study is that oil rents are less significant for output and also exhibit decreasing marginal effect on output growth in Nigeria. However, our robustness result shows that oil revenue is positive and significantly affects output growth, while corruption dampens output growth. Result from the oil revenue model with a minimum root square mean error, when compared with the oil rents model, corroborate the finding. We are thus of the opinion that oil revenue is more important for output growth in Nigeria than oil rents. Having established this fact, it is recommended that policymakers and the government should accord utmost attention to boosting oil revenue via transparency and accountability. They should also ensure a lasting solution to the nation’s high dependency on refined crude oil products importation for a sustainable economic growth and development. Also, more efforts should be directed at developing the seven identified strategic solid minerals to further enhance the revenue base of the government. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","C22; Corruption index; Dynamic ARDL; F43; KRLS; Nigeria; Oil rents; Oil revenue; Output growth; Q41","crude oil; economic growth; government; vector autoregression; Nigeria; carbon dioxide; petroleum; economic development; government; least square analysis; Nigeria; Carbon Dioxide; Economic Development; Government; Least-Squares Analysis; Nigeria; Petroleum"
"Adel A.","Future of industry 5.0 in society: human-centric solutions, challenges and prospective research areas","10.1186/s13677-022-00314-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137846801&doi=10.1186%2fs13677-022-00314-5&partnerID=40&md5=088ca1f5005c90af0ca33ae2a2d1b81b","Industry 4.0 has been provided for the last 10 years to benefit the industry and the shortcomings; finally, the time for industry 5.0 has arrived. Smart factories are increasing the business productivity; therefore, industry 4.0 has limitations. In this paper, there is a discussion of the industry 5.0 opportunities as well as limitations and the future research prospects. Industry 5.0 is changing paradigm and brings the resolution since it will decrease emphasis on the technology and assume that the potential for progress is based on collaboration among the humans and machines. The industrial revolution is improving customer satisfaction by utilizing personalized products. In modern business with the paid technological developments, industry 5.0 is required for gaining competitive advantages as well as economic growth for the factory. The paper is aimed to analyze the potential applications of industry 5.0. At first, there is a discussion of the definitions of industry 5.0 and advanced technologies required in this industry revolution. There is also discussion of the applications enabled in industry 5.0 like healthcare, supply chain, production in manufacturing, cloud manufacturing, etc. The technologies discussed in this paper are big data analytics, Internet of Things, collaborative robots, Blockchain, digital twins and future 6G systems. The study also included difficulties and issues examined in this paper head to comprehend the issues caused by organizations among the robots and people in the assembly line. © 2022, The Author(s).","Cognitive systems; Disaster recovery; Green manufacturing; Human machine collaboration; Industry 5.0; Smart healthcare; Supply chain","Cloud analytics; Cognitive systems; Competition; Customer satisfaction; Data Analytics; Health care; Industry 4.0; Business productivity; Disaster recovery; Green manufacturing; Human-centric; Human-machine collaboration; Industrial revolutions; Industry 5.0; Prospectives; Research areas; Smart healthcare; Supply chains"
"Adem K., Ozguven M.M., Altas Z.","A sugar beet leaf disease classification method based on image processing and deep learning","10.1007/s11042-022-13925-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138631291&doi=10.1007%2fs11042-022-13925-6&partnerID=40&md5=30f699d6fe7c85d280a5941bdba737ed","Leaf spot disease, which causes 10 − 50% loss in sugar beet yield, causes great damage on the leaves. This disease physiologically appears as individual circular spots on the sugar beet leaves and over time spreads to the entire leaf, resulting in complete death of the leaf. Therefore, in our study, Faster R-CNN, SSD, VGG16, Yolov4 deep learning models were used directly, and Yolov4 deep learning model with image processing was used in a hybrid way for automatic determination of leaf spot disease on sugar beet and classification of severity. The proposed hybrid method for the diagnosis of diseases and identifying the severity were trained and tested using 1040 images, and the classification accuracy rate of the most successful method was found to be 96.47%. The proposed hybrid approach showed that the combined use of image processing and deep learning models yield more successful results than the analysis made using only deep learning models. In this way, both the time spent for the diagnosis of leaf spot disease on sugar beet will be reduced and human error will be eliminated, and the relevant pesticides will be sprayed to the plant at the right time. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Faster RCNN; Leaf spot disease; SSD; Sugar Beet; VGG16; Yolov4","Computer aided diagnosis; Deep learning; Learning systems; Plants (botany); Sugar beets; Classification methods; Disease classification; Fast RCNN; Images processing; Leaf disease; Leaf spot disease; Learning models; SSD; VGG16; Yolov4; Image classification"
"Adjuik T.A., Davis S.C.","Machine Learning Approach to Simulate Soil CO2 Fluxes under Cropping Systems","10.3390/agronomy12010197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123167797&doi=10.3390%2fagronomy12010197&partnerID=40&md5=8ef9c9c1a3b22f7687240733acb6b957","With the growing number of datasets to describe greenhouse gas (GHG) emissions, there is an opportunity to develop novel predictive models that require neither the expense nor time required to make direct field measurements. This study evaluates the potential for machine learning (ML) approaches to predict soil GHG emissions without the biogeochemical expertise that is required to use many current models for simulating soil GHGs. There are ample data from field measurements now publicly available to test new modeling approaches. The objective of this paper was to develop and evaluate machine learning (ML) models using field data (soil temperature, soil moisture, soil classification, crop type, fertilization type, and air temperature) available in the Greenhouse gas Reduction through Agricultural Carbon Enhancement network (GRACEnet) database to simulate soil CO2 fluxes with different fertilization methods. Four machine learning algorithms—K nearest neighbor regression (KNN), support vector regression (SVR), random forest (RF) regression, and gradient boosted (GB) regression—were used to develop the models. The GB regression model out-performed all the other models on the training dataset with R2 = 0.88, MAE = 2177.89 g C ha−1 day−1, and RMSE 4405.43 g C ha−1 day−1 . However, the RF and GB regression models both performed optimally on the unseen test dataset with R2 = 0.82. Machine learning tools were useful for developing predictors based on soil classification, soil temperature and air temperature when a large database like GRACEnet is available, but these were not highly predictive variables in correlation analysis. This study demonstrates the suitability of using tree-based ML algorithms for predictive modeling of CO2 fluxes, but no biogeochemical processes can be described with such models. © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:// creativecommons.org/licenses/by/ 4.0/).","GRACEnet; Gradient boosted regression; Greenhouse gases fluxes; KNN regression; Prediction; Random forest regression; Support vector regression",
"Afaq Y., Manocha A.","Blockchain and Deep Learning Integration for Various Application: A Review","10.1080/08874417.2023.2173330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147772619&doi=10.1080%2f08874417.2023.2173330&partnerID=40&md5=73b4256c0dff8cd9eb0b05fc55e159cf","Recently, deep learning and blockchain technologies have gained successful attention due to the high potential of generating accurate decisions and data security, respectively. The data provenances characteristics such as transparency, traceability, and trustworthiness are provided by the vast majority of centralized server-based deep learning approaches. This article examines the advantages of combining deep learning algorithms with blockchain technology. In addition, the most effective strategy for combining these two technologies to achieve the best result is identified through the most recent state-of-the-art literature. In this manner, the article is divided into seven thematic taxonomies based on the literature review: applications of deep learning and blockchain, deep learning techniques, protocols, domains, types of blockchain, and datasets. We have outlined the advantages and disadvantages of blockchain-based deep learning frameworks to facilitate insightful discussions. © 2023 International Association for Computer Information Systems.","blockchain; consensus protocol; Deep learning; machine learning; security","Deep learning; Learning algorithms; Learning systems; Network security; Block-chain; Centralized server; Consensus protocols; Data provenance; Deep learning; High potential; Learning approach; Machine-learning; Security; Server-based; Blockchain"
"Afshan N., Rout R.K.","Machine Learning Techniques for IoT Data Analytics","10.1002/9781119740780.ch3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133080677&doi=10.1002%2f9781119740780.ch3&partnerID=40&md5=054e3a030dd63c4c1803c578a49725d3","Tremendous advancements and innovations in hardware and software together with developments in different communication technologies and computational advancements have encouraged the advent of an ecosystem of highly interconnected and smart devices known as the Internet of Things (IoT). This IoT is getting outstandingly universal and ubiquitous in today's society with a transformative and constructive impact on different application domains like smart and sustainable living, smart healthcare, smart agriculture, smart cities, manufacturing, and more. Consequently, there has been escalating quantitative expansion in the devices connected to IoT leading to the generation of massive volumes of data, depicting a perfect overlap of big data generation with that of IoT. These voluminous data are totally useless without any proper analytic procedure and is much more than humans will be able to process and analyze. In addition to being huge in terms of size and volume, the big data generated by IoT are of highly veracious and variable nature with a variety of data forms and quality. Further, it is highly distinguished by its velocity in terms of creation, time, processing, location dependency, and accessibility. As a result, smart analysis of such data for obtaining valuable insights is a challenging task. Intelligent data analytics is an important prerequisite to maximize the business value of IoT and realize its hyped market potential. Machine learning has the power to handle different challenges associated with IoT data and can be deployed effectively as they require minimal human intervention. In this chapter, different machine learning algorithms will be discussed along with their potential and challenges for IoT data analytics. The central goal of this chapter is to present a taxonomy of various machine learning approaches and demonstrate the implementation of different techniques so as to do higher level analysis using IoT data. © 2021 John Wiley & Sons, Inc. All rights reserved.","data analytics; Internet of Things; machine learning; smart data",
"Ahishakiye E., Mwangi W., Muthoni P., Nderu L., Wario R.","Comparative performance of machine leaning algorithms in prediction of cervical cancer",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118954486&partnerID=40&md5=dda5ea50df17fbbf8010ad4562430aed","Cervical cancer is among the most common types of cancer affecting women around the world despite the advances in prevention, screening, diagnosis, and treatment during the past decade. Cervical cancer can be treated if diagnosed in its early stages. Machine learning algorithms like multi-layer perceptron, decision trees, random forest, K-Nearest Neighbor, and Naïve-Bayes have been used for the prediction of cervical cancer to aid in its early diagnoses. In this study, we compare the performance of ensemble methods (AdaBoost, Stochastic Gradient Boosting, Random Forests, and Extra Trees), and classification algorithms (K-Nearest Neighbor and Support Vector Machine) in the prediction of cervical cancer basin g risk factors. Ensemble methods and classification algorithms were used during this study. Ensemble methods were selected because they combine several machine learning techniques into one model to decrease variance, bias, or improve performance while the classification methods were selected because our dataset was generally categorical and therefore could work well with our problem domain. Experimental results revealed that all the algorithms did not perform well on the 'imbalanced' dataset. Experiments on balanced revealed an improved performance. The performance metrics used include Fl-score, Area Under Curve (AUC), and Recall. Extra Trees performed better than the rest when using the Fl-score metric, Stochastic Gradient Boosting and Random Forest performed better than the rest when using the AUC metric, K-Nearest Neighbors outperformed the rest using the recall metric, and Extra Trees had the best accuracy 0.96. The application of machine learning methods in the prediction of cervical cancer using risk factors may lead to early detection of the disease which can be treated if diagnosed early. Six algorithms have been considered in this study. The general performance reveals that ensemble methods performed better than classification methods using both imbalanced and balanced datasets. © 2021 IST-Africa Institute and Authors.","Cervical Cancer; Classification Algorithms; Ensemble Methods; Machine Learning","Adaptive boosting; Chemical detection; Classification (of information); Decision trees; Diagnosis; Diseases; Forestry; Motion compensation; Nearest neighbor search; Stochastic systems; Support vector machines; Cervical cancers; Classification algorithm; Ensemble methods; Extra-trees; Machine-learning; Nearest-neighbour; Performance; Random forests; Risk factors; Stochastic gradient boosting; Forecasting"
"Ahishakiye E., Wario R., Mwangi W., Taremwa D.","Prediction of Cervical Cancer Basing on Risk Factors using Ensemble Learning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094324742&partnerID=40&md5=7fcec09bc1891ec915e6dcdae01884f1","Cervical cancer is among the most common types of cancer affecting women around the world despite the advances in prevention, screening, diagnosis, and treatment during the past decade. Cervical cancer can be treated if diagnosed in its early stages. Machine learning algorithms like multi-layer perceptron, decision trees, random forest, K-Nearest Neighbor, and Naïve-Bayes have been used for the prediction of cervical cancer to aid in its early diagnoses. In this study, we used an ensemble learning technique in the prediction of cervical cancer using risk factors. This technique was selected because it combines several machine learning techniques into one model to decrease variance, bias, and improvement in performance. K-Nearest Neighbor, Classification and Regression Trees, Naïve Bayes Classifier, and Support Vector Machine. Classification methods were selected because the interest of this study was to solve a classification problem. Therefore these algorithms could work well within our problem domain. The final prediction model was trained and validated, and our experimental results revealed that our model had an accuracy of 87.21%. © 2020 IST-Africa Institute and Authors.","Cervical Cancer; Classification Algorithms; Ensemble learning; Machine Learning","Decision trees; Diseases; Forecasting; Forestry; Learning systems; Motion compensation; Multilayer neural networks; Nearest neighbor search; Predictive analytics; Support vector machines; Support vector regression; Bayes Classifier; Classification and regression tree; Classification methods; Ensemble learning; K-nearest neighbors; Machine learning techniques; Multi layer perceptron; Prediction model; Learning algorithms"
"Ahmad W., Muhammad K., Glass H.J., Chatterjee S., Khan A., Hussain A.","Novel MLR-RF-Based Geospatial Techniques: A Comparison with OK","10.3390/ijgi11070371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133637692&doi=10.3390%2fijgi11070371&partnerID=40&md5=12165c965c57a547d2307a5cb8406aad","Geostatistical estimation methods rely on experimental variograms that are mostly erratic, leading to subjective model fitting and assuming normal distribution during conditional simula-tions. In contrast, Machine Learning Algorithms (MLA) are (1) free of such limitations, (2) can in-corporate information from multiple sources and therefore emerge with increasing interest in real-time resource estimation and automation. However, MLAs need to be explored for robust learning of phenomena, better accuracy, and computational efficiency. This paper compares MLAs, i.e., Multiple Linear Regression (MLR) and Random Forest (RF), with Ordinary Kriging (OK). The techniques were applied to the publicly available Walkerlake dataset, while the exhaustive Walker Lake dataset was validated. The results of MLR were significant (p &lt; 10 × 10−5), with correlation coeffi-cients of 0.81 (R-square = 0.65) compared to 0.79 (R-square = 0.62) from the RF and OK methods. Additionally, MLR was automated (free from an intermediary step of variogram modelling as in OK), produced unbiased estimates, identified key samples representing different zones, and had higher computational efficiency. © 2022 by the authors. Li-censee MDPI, Basel, Switzerland.","geostatistics; interpretable machine learning; Machine Learning Algorithms (MLA); Ordinary Kriging (OK); random forest (RF); SHAP; spatial estimation",
"Ahmed F., Straub J.","Initial Work on the Development of a Hardware-Based Gradient Descent Trained Expert System","10.3390/systems10050160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140625616&doi=10.3390%2fsystems10050160&partnerID=40&md5=6ff92095b2fede6865cccb54f8eaef71","Prior work has introduced a form of explainable artificial intelligence that is able to precisely explain, in a human-understandable form, why it makes decisions. It is also able to learn to make better decisions without potentially learning illegal or invalid considerations. This defensible system is based on fractional value rule-fact expert systems and the use of gradient descent training to optimize rule weightings. This software system has demonstrated efficacy for many applications; however, it utilizes iterative processing and thus does not have a deterministic completion time. It also requires comparatively expensive general-purpose computing hardware to run on. This paper builds on prior work in the development of hardware-based expert systems and presents and assesses the efficacy of a hardware implementation of this system. It characterizes its performance and discusses its utility and trade-offs for several application domains. © 2022 by the authors.","artificial intelligence; electronic; expert system; gradient descent; hardware-based; rule-fact network",
"Ahmed I., Kumara I., Reshadat V., Kayes A.S.M., van den Heuvel W.-J., Tamburri D.A.","Travel time prediction and explanation with spatio-temporal features: A comparative study","10.3390/electronics11010106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121822454&doi=10.3390%2felectronics11010106&partnerID=40&md5=8813a157c0f06a68123e63ed1dd3882f","Travel time information is used as input or auxiliary data for tasks such as dynamic navigation, infrastructure planning, congestion control, and accident detection. Various data-driven Travel Time Prediction (TTP) methods have been proposed in recent years. One of the most challenging tasks in TTP is developing and selecting the most appropriate prediction algorithm. The existing studies that empirically compare different TTP models only use a few models with specific features. More-over, there is a lack of research on explaining TTPs made by black-box models. Such explanations can help to tune and apply TTP methods successfully. To fill these gaps in the current TTP literature, using three data sets, we compare three types of TTP methods (ensemble tree-based learning, deep neural networks, and hybrid models) and ten different prediction algorithms overall. Furthermore, we apply XAI (Explainable Artificial Intelligence) methods (SHAP and LIME) to understand and interpret models’ predictions. The prediction accuracy and reliability for all models are evaluated and compared. We observed that the ensemble learning methods, i.e., XGBoost and LightGBM, are the best performing models over the three data sets, and XAI methods can adequately explain how various spatial and temporal features influence travel time. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Explainable AI; Hybrid models; LightGBM; LSTM; SHAP and LIME; Spatio-temporal; Travel time prediction; XAI; XGBoost",
"Ahmed M.O., Khalef R., Ali G.G., El-Adaway I.H.","Evaluating Deterioration of Tunnels Using Computational Machine Learning Algorithms","10.1061/(ASCE)CO.1943-7862.0002162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112064167&doi=10.1061%2f%28ASCE%29CO.1943-7862.0002162&partnerID=40&md5=934b85e2cf4c9c384d783221551b5322","Tunnels are an integrated part of the transportation infrastructure. Structural evaluation and inspection of tunnels are vital tasks to assess the deterioration of tunnels and maintain their level of service. Researchers have developed many predictive models that describe the deterioration of various infrastructure systems using data from formal inspections. However, there is a lack of research that developed predictive models of deterioration of tunnels in the US. Therefore, this paper investigated the feasibility of using various machine learning techniques to develop a computational data-driven decision support tool that predicts the deterioration of tunnels in the US. An ex ante framework for predicting the deterioration of tunnels in the US was developed. The research methodology comprised (1) collecting, cleaning, and standardizing data for tunnels in the US from the Federal Highway Administration (FHWA); (2) identifying the best subset of variables that allow predicting the deterioration of tunnels; (3) utilizing existing machine learning algorithms, namely k-nearest neighbors (KNN), random forest (RF), artificial neural networks (ANNs), and support vector machine (SVM), to develop classification models that predict the deterioration of tunnels; (4) optimizing the accuracy of the developed models by determining the best set of hyperparameters that result in the most accurate performance; (5) comparing the performance of the developed models and selecting the best performing model to be used as a decision support tool; and (6) evaluating and validating the performance of the selected model. The results identified 18 variables that greatly affect the deterioration of tunnels, with the tunnel width having the greatest impact on the prediction of deterioration of tunnels. Results indicated that the RF algorithm reached an accuracy of 85.38%, which was the highest accuracy, compared with KNN, ANN, and SVM, which reached an accuracy of 80.12%, 56.14%, and 56.73%, respectively. In addition, the entropy criterion function with a maximum of five features and 500 estimators successfully constructed the best hyperparameters for the selected RF model. Therefore, the developed decision support tool can be used by transportation entities to estimate the overall condition of tunnels based on specific tunnel parameters with reasonable prediction accuracy. It also can aid decision makers in developing, optimizing, and prioritizing maintenance plans and allocation of funding. © 2021 American Society of Civil Engineers.","Deterioration modeling; Infrastructure management; Machine learning; Tunnels","Boring machines (machine tools); Decision making; Decision support systems; Decision trees; Deterioration; Forecasting; Highway administration; Learning systems; Nearest neighbor search; Neural networks; Predictive analytics; Support vector machines; Decision support tools; Federal Highway Administration; Infrastructure systems; K nearest neighbor (KNN); Machine learning techniques; Research methodologies; Structural evaluation; Transportation infrastructures; Learning algorithms"
"Ahmed M.S., Tazwar M.T., Khan H., Roy S., Iqbal J., Rabiul Alam M.G., Hassan M.R., Hassan M.M.","Yield Response of Different Rice Ecotypes to Meteorological, Agro-Chemical, and Soil Physiographic Factors for Interpretable Precision Agriculture Using Extreme Gradient Boosting and Support Vector Regression","10.1155/2022/5305353","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139490887&doi=10.1155%2f2022%2f5305353&partnerID=40&md5=91ebeaa7d8d3c6f433b56bbc7949f169","The food security of more than half of the world's population depends on rice production which is one of the key objectives of precision agriculture. The traditional rice almanac used astronomical and climate factors to estimate yield response. However, this research integrated meteorological, agro-chemical, and soil physiographic factors for yield response prediction. Besides, the impact of those factors on the production of three major rice ecotypes has also been studied in this research. Moreover, this study found a different set of those factors with respect to the yield response of different rice ecotypes. Machine learning algorithms named Extreme Gradient Boosting (XGBoost) and Support Vector Regression (SVR) have been used for predicting the yield response. The SVR shows better results than XGBoost for predicting the yield of the Aus rice ecotype, whereas XGBoost performs better for forecasting the yield of the Aman and Boro rice ecotypes. The result shows that the root mean squared error (RMSE) of three different ecotypes are in between 9.38% and 24.37% and that of R-squared values are between 89.74% and 99.13% on two different machine learning algorithms. Moreover, the explainability of the models is also shown in this study with the help of the explainable artificial intelligence (XAI) model called Local Interpretable Model-Agnostic Explanations (LIME). © 2022 Md. Sabbir Ahmed et al.",,"Adaptive boosting; Food supply; Forecasting; Lime; Machine learning; Mean square error; Agro-chemicals; Food security; Gradient boosting; Key objective; Machine learning algorithms; Precision Agriculture; Rice production; Support vector regressions; World population; Yield response; Precision agriculture"
"Ahmed S.E., San O., Kara K., Younis R., Rasheed A.","Multifidelity computing for coupling full and reduced order models","10.1371/journal.pone.0246092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101309377&doi=10.1371%2fjournal.pone.0246092&partnerID=40&md5=058494e78e9d2fd46934e8f0d4798540","Hybrid physics-machine learning models are increasingly being used in simulations of transport processes. Many complex multiphysics systems relevant to scientific and engineering applications include multiple spatiotemporal scales and comprise a multifidelity problem sharing an interface between various formulations or heterogeneous computational entities. To this end, we present a robust hybrid analysis and modeling approach combining a physics-based full order model (FOM) and a data-driven reduced order model (ROM) to form the building blocks of an integrated approach among mixed fidelity descriptions toward predictive digital twin technologies. At the interface, we introduce a long short-term memory network to bridge these high and low-fidelity models in various forms of interfacial error correction or prolongation. The proposed interface learning approaches are tested as a new way to address ROM-FOM coupling problems solving nonlinear advection-diffusion flow situations with a bifidelity setup that captures the essence of a broad class of transport processes. © 2021 Ahmed et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; advection; article; diffusion; digital twin; learning; long short term memory network; physics; problem solving; algorithm; computer simulation; machine learning; physical phenomena; theoretical model; Algorithms; Big Data; Computer Simulation; Machine Learning; Models, Theoretical; Physical Phenomena"
"Ahsan M.M., Uddin M.R., Ali M.S., Islam M.K., Farjana M., Sakib A.N., Momin K.A., Luna S.A.","Deep transfer learning approaches for Monkeypox disease diagnosis","10.1016/j.eswa.2022.119483","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145978246&doi=10.1016%2fj.eswa.2022.119483&partnerID=40&md5=2d0a1c43ad1ed4c1aac605e22020c9e7","Monkeypox has become a significant global challenge as the number of cases increases daily. Those infected with the disease often display various skin symptoms and can spread the infection through contamination. Recently, Machine Learning (ML) has shown potential in image-based diagnoses, such as detecting cancer, identifying tumor cells, and identifying coronavirus disease (COVID)-19 patients. Thus, ML could potentially be used to diagnose Monkeypox as well. In this study, we developed a Monkeypox diagnosis model using Generalization and Regularization-based Transfer Learning approaches (GRA-TLA) for binary and multiclass classification. We tested our proposed approach on ten different convolutional Neural Network (CNN) models in three separate studies. The preliminary computational results showed that our proposed approach, combined with Extreme Inception (Xception), was able to distinguish between individuals with and without Monkeypox with an accuracy ranging from 77% to 88% in Studies One and Two, while Residual Network (ResNet)-101 had the best performance for multiclass classification in Study Three, with an accuracy ranging from 84% to 99%. In addition, we found that our proposed approach was computationally efficient compared to existing TL approaches in terms of the number of parameters (NP) and Floating-Point Operations per Second (FLOPs) required. We also used Local Interpretable Model-Agnostic Explanations (LIME) to explain our model's predictions and feature extractions, providing a deeper understanding of the specific features that may indicate the onset of Monkeypox. © 2023 Elsevier Ltd","Deep learning; Disease diagnosis; Image processing; Machine learning; Monkeypox virus","Convolutional neural networks; Image processing; Learning systems; Lime; Transfer learning; Viruses; Deep learning; Disease diagnosis; Global challenges; Image-based diagnosis; Images processing; Learning approach; Machine-learning; Monkeypox virus; Multi-class classification; Transfer learning; Deep learning"
"Aiba M., Shibata R., Oguro M., Nakashizuka T.","Variable effects of vegetation characteristics on a recreation service depending on natural and social environment","10.1038/s41598-023-27799-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146289018&doi=10.1038%2fs41598-023-27799-7&partnerID=40&md5=5f44654e4c18dbdf1a7a08801d45e14d","In this study, we examined roles of three vegetation characteristics in provisioning of a recreation service by applying a machine-learning method to 4,708,229 spatially-explicit records of hiking activity in Japan. Then, expected impacts of land-use changes assessed and mapped based on the model. Associations between a recreation service and three vegetation characteristics were considerably variable depending on the social and natural environment such as accessibility and altitude. As a consequence, expected impacts of unit changes in vegetation characteristics on the service flow were considerably heterogeneous throughout the study area. The signs (positive or negative) of the impact can be reversed depending on the contexts even among nearby sites. Such notable but variable contributions of vegetation on a recreation service should be carefully reflected in landscape management. Even moderate changes in either the quantity or quality of vegetation can have a considerable impact on the frequency of hiking activity. Landscape management for promotion of the recreation service should be carefully designed for each locality on the grounds of the context-dependent effects of vegetation. © 2023, The Author(s).",,"altitude; article; human; Japan; land use; machine learning; recreation; social environment; vegetation; ecosystem; environmental protection; recreation; social environment; sport; Altitude; Conservation of Natural Resources; Ecosystem; Recreation; Social Environment; Sports"
"Akbarzadeh S., Ahderom S., Alameh K.","A statistical approach to provide explainable convolutional neural network parameter optimization","10.2991/ijcis.d.191219.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078248102&doi=10.2991%2fijcis.d.191219.001&partnerID=40&md5=e13e3d0feafbc6e63e442e68604ec599","Algorithms based on convolutional neural networks (CNNs) have been great attention in image processing due to their ability to find patterns and recognize objects in a wide range of scientific and industrial applications. Finding the best network and optimizing its hyperparameters for a specific application are central challenges for CNNs. Most state-of-the-art CNNs are manually designed, while techniques for automatically finding the best architecture and hyperparameters are computationally intensive, and hence, there is a need to severely limit their search space. This paper proposes a fast statistical method for CNN parameter optimization, which can be applied in many CNN applications and provides more explainable results. The authors specifically applied Taguchi based experimental designs for network optimization in a basic network, a simplified Inception network and a simplified Resnet network, and conducted a comparison analysis to assess their respective performance and then to select the hyperparameters and networks that facilitate faster training and provide better accuracy. The results show that up to a 6% increase in classification accuracy can be achieved after parameter optimization. © 2019 The Authors. Published by Atlantis Press SARL.","Convolutional neural network; Deep learning; Design of experiment; Hyperparameter; Optimization; Taguchi","Deep learning; Deep neural networks; Design of experiments; Image processing; Neural networks; Optimization; Taguchi methods; Classification accuracy; Comparison analysis; Convolutional neural network; Hyper-parameter; Network optimization; Parameter optimization; State of the art; Statistical approach; Convolution"
"Alagumalai A., Shou W., Mahian O., Aghbashlo M., Tabatabaei M., Wongwises S., Liu Y., Zhan J., Torralba A., Chen J., Wang Z., Matusik W.","Self-powered sensing systems with learning capability","10.1016/j.joule.2022.06.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134731780&doi=10.1016%2fj.joule.2022.06.001&partnerID=40&md5=c4b99a464465a035d3482a19e65a8916","Self-powered sensing systems augmented with machine learning (ML) represent a path toward the large-scale deployment of the internet of things (IoT). With autonomous energy-harvesting techniques, intelligent systems can continuously generate data and process them to make informed decisions. The development of self-powered intelligent sensing systems will revolutionize the design and fabrication of sensors and pave the way for intelligent robots, digital health, and sustainable energy. However, challenges remain regarding stable power harvesting, seamless integration of ML, privacy, and ethical implications. In this review, we first present three self-powering principles for sensors and systems, including triboelectric, piezoelectric, and pyroelectric mechanisms. Then, we discuss the recent progress in applied ML techniques on self-powered sensors followed by a new paradigm of self-powered sensing systems with learning capability and their applications in different sectors. Finally, we share our outlook of potential research needs and challenges presented in ML-enabled self-powered sensing systems and conclude with a road map for future directions. © 2022 Elsevier Inc.","energy harvesting; internet of things; machine learning; nanogenerator; self-powered; sensor","Intelligent robots; Intelligent systems; Learning systems; Machine design; Machine learning; Nanogenerators; Informed decision; Intelligent sensing; Large-scale deployment; Learning capabilities; Machine-learning; Nanogenerators; Self-powered; Self-powered sensing; Sensing systems; Sustainable energy; Internet of things; machine learning; robotics; sensor"
"Albattah W., Nawaz M., Javed A., Masood M., Albahli S.","A novel deep learning method for detection and classification of plant diseases","10.1007/s40747-021-00536-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134073451&doi=10.1007%2fs40747-021-00536-1&partnerID=40&md5=b3593dcd35434bca100afdedb65dcb76","The agricultural production rate plays a pivotal role in the economic development of a country. However, plant diseases are the most significant impediment to the production and quality of food. The identification of plant diseases at an early stage is crucial for global health and wellbeing. The traditional diagnosis process involves visual assessment of an individual plant by a pathologist through on-site visits. However, manual examination for crop diseases is restricted because of less accuracy and the small accessibility of human resources. To tackle such issues, there is a demand to design automated approaches capable of efficiently detecting and categorizing numerous plant diseases. Precise identification and classification of plant diseases is a tedious job due because of the occurrence of low-intensity information in the image background and foreground, the huge color resemblance in the healthy and diseased plant areas, the occurrence of noise in the samples, and changes in the position, chrominance, structure, and size of plant leaves. To tackle the above-mentioned problems, we have introduced a robust plant disease classification system by introducing a Custom CenterNet framework with DenseNet-77 as a base network. The presented method follows three steps. In the first step, annotations are developed to get the region of interest. Secondly, an improved CenterNet is introduced in which DenseNet-77 is proposed for deep keypoints extraction. Finally, the one-stage detector CenterNet is used to detect and categorize several plant diseases. To conduct the performance analysis, we have used the PlantVillage Kaggle database, which is the standard dataset for plant diseases and challenges in terms of intensity variations, color changes, and differences found in the shapes and sizes of leaves. Both the qualitative and quantitative analysis confirms that the presented method is more proficient and reliable to identify and classify plant diseases than other latest approaches. © 2021, The Author(s).","Agriculture; CenterNet; Deep learning; DenseNet; Plant disease",
"Albinet F., Peng Y., Eguchi T., Smolders E., Dercon G.","Prediction of exchangeable potassium in soil through mid-infrared spectroscopy and deep learning: From prediction to explainability","10.1016/j.aiia.2022.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140931886&doi=10.1016%2fj.aiia.2022.10.001&partnerID=40&md5=38e60d488c83a0a0f2d555dade330824","The ability to characterize rapidly and repeatedly exchangeable potassium (Kex) content in the soil is essential for optimizing remediation of radiocaesium contamination in agriculture. In this paper, we show how this can be now achieved using a Convolutional Neural Network (CNN) model trained on a large Mid-Infrared (MIR) soil spectral library (40,000 samples with Kex determined with 1 M NH4OAc, pH 7), compiled by the National Soil Survey Center of the United States Department of Agriculture. Using Partial Least Squares Regression as a baseline, we found that our implemented CNN leads to a significantly higher prediction performance of Kex when a large amount of data is available (10000), increasing the coefficient of determination from 0.64 to 0.79, and reducing the Mean Absolute Percentage Error from 135% to 31%. Furthermore, in order to provide end-users with required interpretive keys, we implemented the GradientShap algorithm to identify the spectral regions considered important by the model for predicting Kex. Used in the context of the implemented CNN on various Soil Taxonomy Orders, it allowed (i) to relate the important spectral features to domain knowledge and (ii) to demonstrate that including all Soil Taxonomy Orders in CNN-based modeling is beneficial as spectral features learned can be reused across different, sometimes underrepresented orders. © 2022 The Authors","Agriculture; Convolutional neural network; High-throughput soil characterization; Interpretability; Machine learning; Nuclear emergency response; Remediation",
"Alexander J.C., Romito B.T., Çobanoǧlu M.C.","The present and future role of artificial intelligence and machine learning in anesthesiology","10.1097/AIA.0000000000000294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092332102&doi=10.1097%2fAIA.0000000000000294&partnerID=40&md5=b108f1e5ef00cf37d8142396fa200a18",[No abstract available],,"anesthesiology; Article; artificial intelligence; automation; computer model; convolutional neural network; futurology; health care industry; health care utilization; human; intensive care unit; intraoperative period; machine learning; medical ethics; priority journal; sepsis; software; statistical reasoning; treatment outcome; machine learning; Anesthesiology; Artificial Intelligence; Humans; Machine Learning"
"Alghamdi M., Angelov P., Gimenez R., Rufino M., Soares E.","Self-Organising and Self-Learning Model for Soybean Yield Prediction","10.1109/SNAMS.2019.8931888","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077810022&doi=10.1109%2fSNAMS.2019.8931888&partnerID=40&md5=914cbc55d97138721e462c899a919815","Machine learning has arisen with advanced data analytics. Many factors influence crop yield, such as soil, amount of water, climate, and genotype. Determining factors that significantly influence yield prediction and identify the most appropriate predictive methods are important in yield management. It is critical to consider and study the combination of different crop factors and their impact on the yield. The objectives of this paper are: (1) to use advanced data analytic techniques to precisely predict the soybean crop yields, (2) to identify the most influential features that impact soybean predictions, (3) to illustrate the ability of Fuzzy Rule-Based (FRB) sub-systems, which are self-organizing, self-learning, and data-driven, by using the recently developed Autonomous Learning Multiple-Model First-order (ALMMo-1) system, and (4) to compare the performance with other well-known methods. The ALMMo-1 system is a transparent model, which stakeholders can easily read and interpret. The model is a data-driven and composed of prototypes selected from the actual data. Many factors affect the yield, and data clouds can be formed in the feature/data space based on the data density. The data cloud is the key to the IF part of FRB sub-systems, while the THEN part (the consequences of the IF condition) illustrates the yield prediction in the form of a linear regression model, which consists of the yield features or factors. In addition, the model can determine the most influential features of the yield prediction online. The model shows an excellent prediction accuracy with a Root Mean Square Error (RMSE) of 0.0883, and Non-Dimensional Error Index (NDEI) of 0.0611, which is competitive with state-of-the-art methods. © 2019 IEEE.","Autonomous Learning; Fuzzy Rule-Based; Linear regression; Multi-Modal; Soybean yield prediction","Advanced Analytics; Crops; Data Analytics; Forecasting; Fuzzy inference; Fuzzy rules; Linear regression; Mean square error; Regression analysis; Autonomous learning; Fuzzy rule based; Linear regression models; Multi-modal; Root mean square errors; Self-learning models; State-of-the-art methods; Yield prediction; Learning systems"
"Ali A., Khan Ghouri K.F., Naseem H., Soomro T.R., Mansoor W., Momani A.M.","Battle of Deep Fakes: Artificial Intelligence Set to Become a Major Threat to the Individual and National Security","10.1109/ICCR56254.2022.9995821","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146494447&doi=10.1109%2fICCR56254.2022.9995821&partnerID=40&md5=928a0b91de3eb57072ea68b67fe666aa","The article discusses the possibility of political organizations utilizing deepfake technologies. It is observed that deepfakes can affect all levels of public and political life and contribute to the development of several problems, including reputational risks for celebrities and ordinary citizens, the growth of organized crime, and social stability and national security concerns. The sophistication of deepfake technology (DT) has increased significantly. Cybercriminals can now modify sounds, images, and movies to scam individuals and organizations. This growing threat to international institutions and individuals demands our attention. This article discusses deepfakes, their societal benefits, and how deception technology works. The hazards deepfakes pose to enterprises, governments, and legal systems worldwide are highlighted. In addition, the paper will examine potential solutions for deepfakes and end with future research goals. The authors conclude by discussing potential threats, prospects, and key pathsfor state regulation of this content within the framework of broader political and legal instruments to combat the spread of disinformation and fake news. © 2022 IEEE.","AI; deepfake; information security; political technology; public policy","Artificial intelligence; Cybersecurity; Cybercriminals; Deepfake; Enterprise system; Government systems; Legal system; Organised crime; Political technology; Social stability; Societal benefits; Sound image; National security"
"Ali S., Abdullah, Armand T.P.T., Athar A., Hussain A., Ali M., Yaseen M., Joo M.-I., Kim H.-C.","Metaverse in Healthcare Integrated with Explainable AI and Blockchain: Enabling Immersiveness, Ensuring Trust, and Providing Patient Data Security","10.3390/s23020565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146718701&doi=10.3390%2fs23020565&partnerID=40&md5=b6388ed54edcb85142133fa1d7fcc794","Digitization and automation have always had an immense impact on healthcare. It embraces every new and advanced technology. Recently the world has witnessed the prominence of the metaverse which is an emerging technology in digital space. The metaverse has huge potential to provide a plethora of health services seamlessly to patients and medical professionals with an immersive experience. This paper proposes the amalgamation of artificial intelligence and blockchain in the metaverse to provide better, faster, and more secure healthcare facilities in digital space with a realistic experience. Our proposed architecture can be summarized as follows. It consists of three environments, namely the doctor’s environment, the patient’s environment, and the metaverse environment. The doctors and patients interact in a metaverse environment assisted by blockchain technology which ensures the safety, security, and privacy of data. The metaverse environment is the main part of our proposed architecture. The doctors, patients, and nurses enter this environment by registering on the blockchain and they are represented by avatars in the metaverse environment. All the consultation activities between the doctor and the patient will be recorded and the data, i.e., images, speech, text, videos, clinical data, etc., will be gathered, transferred, and stored on the blockchain. These data are used for disease prediction and diagnosis by explainable artificial intelligence (XAI) models. The GradCAM and LIME approaches of XAI provide logical reasoning for the prediction of diseases and ensure trust, explainability, interpretability, and transparency regarding the diagnosis and prediction of diseases. Blockchain technology provides data security for patients while enabling transparency, traceability, and immutability regarding their data. These features of blockchain ensure trust among the patients regarding their data. Consequently, this proposed architecture ensures transparency and trust regarding both the diagnosis of diseases and the data security of the patient. We also explored the building block technologies of the metaverse. Furthermore, we also investigated the advantages and challenges of a metaverse in healthcare. © 2023 by the authors.","blockchain; digital twins; explainable AI; healthcare; healthcare metaverse; immersive technologies; immersive technologies in healthcare; metaverse; mixed reality; NLP","Architecture; Artificial intelligence; Data privacy; Diagnosis; Forecasting; Health care; Hospital data processing; Lime; Mixed reality; Transparency; Block-chain; Explainable AI; Healthcare; Healthcare metaverse; Immersive technologies; Immersive technology in healthcare; Metaverses; Mixed reality; Blockchain; artificial intelligence; computer security; health care delivery; human; trust; Artificial Intelligence; Blockchain; Computer Security; Delivery of Health Care; Humans; Trust"
"Alim M.A., Repon M.R., Islam T., Mishfa K.F., Jalil M.A., Aljabri M.D., Rahman M.M.","Mapping the Progress in Natural Dye-Sensitized Solar Cells: Materials, Parameters and Durability","10.1002/slct.202201557","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132733098&doi=10.1002%2fslct.202201557&partnerID=40&md5=4d3f5a510ab2f6f100132cb5747cc7e6","The rapid growth of the population severely influences the supply of energy, accordingly ensuring clean energy has become a big challenge now and will be in the future. Fossil fuels have been satisfying the energy demand until now, but fossil fuels, being non-renewable sources, will not be able to satisfy the energy demand in the future and will have a negative impact on the environment. Renewable energy sources have become the most demanding topic for researchers in this crisis. The solar cell, which is an abundant renewable energy resource, converts solar power into electrical energy without any environmental damage. Silicon solar cells have higher efficiency, but their high manufacturing cost, complicated procedures and environmental issues restrict their usage. Then dye-sensitized solar cells (DSSCs) have been introduced as an alternative to silicon solar cells. In DSSC, both natural and synthetic dyes are used. Though synthetic dyes provide higher efficiency, they are environmentally harmful. Afterward, the concept of natural dye-sensitized solar cells (NDSSC) have been materialized where only natural dyes are used. Researchers and environmentalists are looking for natural dyes as a replacement for synthetic dyes in recent times, as natural dyes are plentiful, can be collected naturally and have no environmental effects. Natural dyes in the form of anthocyanins, carotenoids, flavonoids, chlorophylls, tannins and betalains are extracted from various portions of plants that include leaves, roots, flowers, fruits, seeds, barks, etc. In this review, we investigate natural sources of dyes, natural sensitizers (dyes), shortcomings and remedies, improvements in efficiency and stability, developments, and commercialization. In addition, recent advances and the comparison of natural and synthetic dyes have been discussed in this review. © 2022 Wiley-VCH GmbH.","Dye-sensitized solar cell; Metal complexes; Natural dye-sensitized solar cells; Renewable energy; Sensitizers",
"Alissa K.A., Maray M., Malibari A.A., Alazwari S., Alqahtani H., Nour M.K., Obbaya M., Shamseldin M.A., Al Duhayyim M.","Optimal Deep Learning Model Enabled Secure UAV Classification for Industry 4.0","10.32604/cmc.2023.033532","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145353087&doi=10.32604%2fcmc.2023.033532&partnerID=40&md5=90631ce23344367db24cdee27607ea08","Emerging technologies such as edge computing, Internet of Things (IoT), 5G networks, big data, Artificial Intelligence (AI), and Unmanned Aerial Vehicles (UAVs) empower, Industry 4.0, with a progressive production methodology that shows attention to the interaction between machine and human beings. In the literature, various authors have focused on resolving security problems in UAV communication to provide safety for vital applications. The current research article presents a Circle Search Optimization with Deep Learning Enabled Secure UAV Classification (CSODL-SUAVC) model for Industry 4.0 environment. The suggested CSODL-SUAVC methodology is aimed at accomplishing two core objectives such as secure communication via image steganography and image classification. Primarily, the proposed CSODL-SUAVC method involves the following methods such as Multi- Level Discrete Wavelet Transformation (ML-DWT), CSO-related Optimal Pixel Selection (CSO-OPS), and signcryption-based encryption. The proposed model deploys the CSO-OPS technique to select the optimal pixel points in cover images. The secret images, encrypted by signcryption technique, are embedded into cover images. Besides, the image classification process includes three components namely, Super-Resolution using Convolution Neural Network (SRCNN), Adam optimizer, and softmax classifier. The integration of the CSO-OPS algorithm and Adam optimizer helps in achieving the maximum performance upon UAV communication. The proposed CSODLSUAVC model was experimentally validated using benchmark datasets and the outcomes were evaluated under distinct aspects. The simulation outcomes established the supreme better performance of the CSODL-SUAVC model over recent approaches. © 2023 Tech Science Press. All rights reserved.","Artificial Intelligence; Deep Learning; emerging technologies; image steganography; Industry 4.0; Unmanned Aerial Vehicles","5G mobile communication systems; Antennas; Cryptography; Deep learning; Discrete wavelet transforms; Image classification; Industry 4.0; Internet of things; Learning systems; Pixels; Steganography; Aerial vehicle; Classification models; Deep learning; Emerging technologies; Image steganography; Pixel selection; Search optimization; Unmanned aerial vehicle; Vehicle classification; Vehicle communications; Unmanned aerial vehicles (UAV)"
"Alladi T., Chamola V., Sahu N., Guizani M.","Applications of blockchain in unmanned aerial vehicles: A review","10.1016/j.vehcom.2020.100249","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079858521&doi=10.1016%2fj.vehcom.2020.100249&partnerID=40&md5=c5a1265c56a2469cf3f8b29ba6d17a8a","The recent advancement in Unmanned Aerial Vehicles (UAVs) in terms of manufacturing processes, and communication and networking technology has led to a rise in their usage in civilian and commercial applications. The regulations of the Federal Aviation Administration (FAA) in the US had earlier limited the usage of UAVs to military applications. However more recently, the FAA has outlined new enforcement that will also expand the usage of UAVs in civilian and commercial applications. Due to being deployed in open atmosphere, UAVs are vulnerable to being lost, destroyed or physically hijacked. With the UAV technology becoming ubiquitous, various issues in UAV networks such as intra-UAV communication, UAV security, air data security, data storage and management, etc. need to be addressed. Blockchain being a distributed ledger protects the shared data using cryptography techniques such as hash functions and public key encryption. It can also be used for assuring the truthfulness of the information stored and for improving the security and transparency of the UAVs. In this paper, we review various applications of blockchain in UAV networks such as network security, decentralized storage, inventory management, surveillance, etc., and discuss some broader perspectives in this regard. We also discuss various challenges to be addressed in the integration of blockchain and UAVs and suggest some future research directions. © 2020 Elsevier Inc.","Blockchain technology; Internet of Things (IoT); Security and privacy; Unmanned Aerial Vehicle (UAV) network",
"Alnawayseh S.E.A., Al-Sit W.T., Alrababah H., Yasin N.S., Fatima M., Mehmood N.","Classification of White Blood Cells Empowered with Auto Encoder and CNN","10.1109/ICCR56254.2022.9996048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146487356&doi=10.1109%2fICCR56254.2022.9996048&partnerID=40&md5=56d0c8029017f770446793034c3239f2","Differential counting of white blood cells (WBCs) is a well-established clinical practice for assessing a patient's immune system state. Information about our health state may be gained by determining the amount and type of white blood cells (WBCs). The quantity of white blood cells (WBCs) may be used to identify disorders such as leukemia, AIDS, autoimmune diseases, immunological deficiencies, and blood diseases. Convolutional Neural Networks (CNNs), in particular, have a tremendous impact on the medical industry, where a large quantity of pictures must be processed and studied. Images and objects may be categorized and identified using ACNN in this research. Input is provided in the form of raw pixels, and the algorithm outputs an indication of how likely it is that the pixels fall into one of many different categories. Convolution and pooling are added to each layer to minimize the parameter magnitude by a significant amount. The proposed approach will take images automatically from data set and reduce the size of images with auto approach for working faster. It is time-consuming and exhausting to manually locate, identify, and count the many WBC subclasses. Accuracy in classification and counting is directly related to the skill and knowledge of the workers © 2022 IEEE.","classification; cnn; image; wbc","Blood; Cells; Convolution; Convolutional neural networks; Cytology; Image classification; Signal encoding; Auto encoders; Cell-be; Cell/B.E; Cell/BE; Clinical practices; Cnn; Convolutional neural network; Image; Wbc; White blood cells; Pixels"
"Alnowaiser K.K., Ahmed M.A.","Digital Twin: Current Research Trends and Future Directions","10.1007/s13369-022-07459-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142896868&doi=10.1007%2fs13369-022-07459-0&partnerID=40&md5=f9bedcaa130094af7ecd33e28c88ef94","Cyber physical systems, as a backbone of the Fourth Industrial Revolution (IR 4.0), and all their enabling technologies introduced a relatively newer concept named the digital twin. The interest in the digital twin technology has been growing in academia and industry. This is evident in the increasing number of published research and patents concerning digital twin development along with their various industrial applications. However, there is no framework that could be used to evaluate current digital twin development techniques available in the literature and, Using the proposed framework, identify corresponding strengths and shortfalls. In this paper, prominent approaches related to the development of digital twin were analyzed. Accordingly, a framework was built to compare between the digital twin approaches in terms of research domains, technologies, and models employed in the digital twin, and validation methods used. Using the proposed framework, gaps and future directions for digital twin research are identified from five aspects: digital twin definitions, applications, integration, modeling, and data. © 2022, King Fahd University of Petroleum & Minerals.","Adaptive models; Closed-loop control systems; Data-driven models; Digital twin; Literature review",
"Alonso R.S.","Deep symbolic learning and semantics for an explainable and ethical artificial intelligence","10.1007/978-3-030-58356-9_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091480696&doi=10.1007%2f978-3-030-58356-9_30&partnerID=40&md5=672234b1e7c2ef4a70311d0e0ac8dff6","The main objective of this research is to investigate new hybrid neuro-symbolic algorithms for the construction of an open-source Deep Symbolic Learning framework that allows the training and application of explainable and ethical Deep Learning models. This framework will be supported by an ontology and a layer model in which it is taken into account which user is responsible for interpreting each of the output results according to his or her role, considering, also, the ethical implications of those results. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.","Deep Learning; Deep Symbolic Learning; Ethical artificial intelligence; Explainable artificial intelligence; Interpretable machine learning","Application programs; Deep learning; Open source software; Philosophical aspects; Semantics; Ethical implications; Layer model; Learning models; Open sources; Symbolic algorithms; Symbolic learning; Ambient intelligence"
"Alqurashi F.A., Alsolami F., Abdel-Khalek S., Sayed Ali E., Saeed R.A.","Machine learning techniques in internet of UAVs for smart cities applications","10.3233/JIFS-211009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127451313&doi=10.3233%2fJIFS-211009&partnerID=40&md5=9b3151d4c91fe7fa277148dbe338c722","Recently, there were much interest in technology which has emerged greatly to the development of smart unmanned systems. Internet of UAV (IoUAV) enables an unmanned aerial vehicle (UAV) to connect with public network, and cooperate with the neighboring environment. It also enables UAV to argument information and gather data about others UAV and infrastructures. Applications related to smart UAV and IoUAV systems are facing many impairments issues. The challenges are related to UAV cloud network, big data processing, energy efficiency in IoUAV, and efficient communication between a large amount of different UAV types, in addition to optimum decisions for intelligence. Artificial Intelligence (AI) technologies such as Machine Learning (ML) mechanisms enable to archives intelligent behavior for unmanned systems. Moreover, it provides a smart solution to enhance IoUAV network efficiency. Decisions in data processing are considered one of the most problematic issues related to UAV especially for the operations related to cloud and fog based network levels. ML enables to resolve some of these issues and optimize the Quality of UAV network experience (QoE). The paper provides theoretical fundamentals for ML models and algorithms for IoUAV applications and recently related works, in addition to future trends. © 2022 - IOS Press. All rights reserved.","deep learning; IoUAV; machine learning; network optimization; QoE; smart unmanned systems","Antennas; Data handling; Deep learning; Energy efficiency; Smart city; Deep learning; Internet of UAV; Machine learning techniques; Network optimization; Public networks; QoE; Smart unmanned system; UAV systems; Unmanned system; Vehicle clouds; Unmanned aerial vehicles (UAV)"
"Alrousan R.Z., Alnemrawi B.R.","Punching shear behavior of FRP reinforced concrete slabs under different opening configurations and loading conditions","10.1016/j.cscm.2022.e01508","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139049132&doi=10.1016%2fj.cscm.2022.e01508&partnerID=40&md5=357080353e60099a5bfcf0486e79c37f","This study investigates the punching shear behavior of reinforced concrete (RC) flat slabs using theoretical and non-linear finite element analysis techniques (NLFEA). The internal slab-column connection was studied under the combined effect of openings and loading eccentricity. No additional reinforcement was introduced after the opening was made to simulate the effect of opening in an existing structure. Thirty-six slabs were simulated (1800 mm × 1800 mm × 120) mm3 for the length, width, and depth, respectively. The investigated parameters were: (i) reinforcement type (basalt FRP, carbon FRP, and steel); (ii) the existence of opening and its location (with or opposite to the eccentricity side); and (iii) eccentricity value (0, 75, 150, and 225 mm). The slabs were supported at 1500 mm in both directions using eight high-strength bolts and were analyzed up to failure under square column loading of 150 mm side. All simulated slabs failed in punching shear. It was concluded that both the opening and loading eccentricity adversely affected the behavior of the slab, where using FRP bars as an internal reinforcement causes the slab's ductility index to be significantly reduced. Moreover, Increasing the loading eccentricity value adversely affects the slab's behavior. It reduces its ultimate capacity, ultimate deflection, cracking deflection, plastic stiffness, and energy absorption. The type of reinforcement affects the general behavior of the flat slabs. Slabs reinforced with steel reinforcement have the highest cracking and ultimate load, followed by slabs with CFRP, and BFRP reinforcements, respectively. Meanwhile, the relationship is inversed for the ultimate deflection. Simulation results were compared to those obtained from different international design codes (ACI 318–19, EC2, MC 2010, ACI 440, CSA/S806–12, and JSCE), and all overestimated the punching shear capacity of the tested slabs with the JSCE and the ACI 318 the JSCE have approximately the same predictions. © 2022 The Authors","BFRP rods; CFRP rods; Eccentricity; Location; NLFEA; Openings; Punching Shear; RC Slabs","Columns (structural); Concrete slabs; Analysis techniques; BFRP rod; CFRP rod; Eccentricity; Loading eccentricity; Non-linear finite element analyse technique; Nonlinear finite element analyses (FEA); Opening; Punching shear; Reinforced concrete slabs; Reinforced concrete"
"Al-Saedi A.A., Boeva V., Casalicchio E., Exner P.","Context-Aware Edge-Based AI Models for Wireless Sensor Networks—An Overview","10.3390/s22155544","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135202158&doi=10.3390%2fs22155544&partnerID=40&md5=26b9ec59ba270c7c9537d01747c69ffb","Recent advances in sensor technology are expected to lead to a greater use of wireless sensor networks (WSNs) in industry, logistics, healthcare, etc. On the other hand, advances in artificial intelligence (AI), machine learning (ML), and deep learning (DL) are becoming dominant solutions for processing large amounts of data from edge-synthesized heterogeneous sensors and drawing accurate conclusions with better understanding of the situation. Integration of the two areas WSN and AI has resulted in more accurate measurements, context-aware analysis and prediction useful for smart sensing applications. In this paper, a comprehensive overview of the latest developments in context-aware intelligent systems using sensor technology is provided. In addition, it also discusses the areas in which they are used, related challenges, motivations for adopting AI solutions, focusing on edge computing, i.e., sensor and AI techniques, along with analysis of existing research gaps. Another contribution of this study is the use of a semantic-aware approach to extract survey-relevant subjects. The latter specifically identifies eleven main research topics supported by the articles included in the work. These are analyzed from various angles to answer five main research questions. Finally, potential future research directions are also discussed. © 2022 by the authors.","artificial intelligence; context-awareness; edge computing; wireless sensor network","Deep learning; Edge computing; Intelligent systems; Semantics; Context- awareness; Context-Aware; Edge computing; Edge-based; Heterogeneous sensors; Intelligence models; Large amounts of data; Machine-learning; Sensor technologies; Synthesised; Wireless sensor networks; artificial intelligence; computer network; human; wireless communication; Artificial Intelligence; Computer Communication Networks; Humans; Wireless Technology"
"Alsahaf A., Azzopardi G., Ducro B., Hanenberg E., Veerkamp R.F., Petkov N.","Prediction of slaughter age in pigs and assessment of the predictive value of phenotypic and genetic information using random forest","10.1093/jas/sky359","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058155224&doi=10.1093%2fjas%2fsky359&partnerID=40&md5=98d5c1683070eb8b27244dfc5e56f666","The weight of a pig and the rate of its growth are key elements in pig production. In particular, predicting future growth is extremely useful, since it can help in determining feed costs, pen space requirements, and the age at which a pig reaches a desired slaughter weight. However, making these predictions is challenging, due to the natural variation in how individual pigs grow, and the different causes of this variation. In this paper, we used machine learning, namely random forest (RF) regression, for predicting the age at which the slaughter weight of 120 kg is reached. Additionally, we used the variable importance score from RF to quantify the importance of different types of input data for that prediction. Data of 32,979 purebred Large White pigs were provided by Topigs Norsvin, consisting of phenotypic data, estimated breeding values (EBVs), along with pedigree and pedigree-genetic relationships. Moreover, we presented a 2-step data reduction procedure, based on random projections (RPs) and principal component analysis (PCA), to extract features from the pedigree and genetic similarity matrices for use as inputs in the prediction models. Our results showed that relevant phenotypic features were the most effective in predicting the output (age at 120 kg), explaining approximately 62% of its variance (i.e., R 2 = 0.62). Estimated breeding value, pedigree, or pedigree-genetic features interchangeably explain 2% of additional variance when added to the phenotypic features, while explaining, respectively, 38%, 39%, and 34% of the variance when used separately. © The Author(s) 2018. Published by Oxford University Press on behalf of the American Society of Animal Science. All rights reserved.","Breeding; Grouping strategies; Machine learning; Pigs; Random forest; Regression","animal; biological model; body weight; breeding; genetics; growth, development and aging; pig; Animals; Body Weight; Breeding; Models, Biological; Swine"
"Al-Samaree M.Y., Nader M.I., Gorial F.I., Al-Tuama J.A., Yaseen M.H.","Design and Synthesis of inhibitors of tumor necrosis factor-alpha (TNFα) activity of patients with Rheumatoid arthritis (RA)","10.31838/hiv23.01.55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146440657&doi=10.31838%2fhiv23.01.55&partnerID=40&md5=8974acb04111131cb452e16d4e2dde43","Tumor necrosis factor-alpha (TNF-α) is a pro-inflammatory cytokine. It acts as a biological regulator of immune function, but its dysregulation is associated with a number of diseases, especially autoimmune diseases. The strategy of inhibiting TNF-α is an excellent treatment option for autoimmune diseases. This study uses computational methods to design potential inhibitors against TNF-α. The Lipinski rule, molecular docking, and ADMET studies identified the results as active agents. They were evaluated to gain insight into the potential binding interaction with the target protein. Based on that, three compounds (MY1, MY2 and MY3) were selected for synthesizing and studying their activity in the laboratory. The molecules were examined for their purity and identity and confirmed by their melting points, FT-IR and H1 NMR-spectra. The laboratory evaluation results showed the three compounds classified within the medium toxicity compounds, on the other hand, the values of Kd were (0.129 μM, 10.19 μM, 0.389 μM) and IC50 were (4.34 nM, 4.50 nM and 4.60 nMJ respectively. AG has also calculated the values (-9.44 Kcal/ mole), (-6.8 Kcal/ mole) and (8.35 Kcal/ mole). The bonding efficiency scores showed (LE ≤ 0.3), which indicates that all compounds capable of inhibiting TNF-alpha significantly. © 2023, ResearchTrentz Academy Publishing Education Services. All rights reserved.",,
"Alshehri M.","Fuzzy Logic Based Explainable AI Approach for the Easy Calibration of AI Models in IoT Environments","10.1007/978-3-030-98404-5_57","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127090328&doi=10.1007%2f978-3-030-98404-5_57&partnerID=40&md5=4fa6ce1fef9a6e5ed63bba2287053faa","The Internet of Things (IoT) permeates all aspects of human existence shortly. As a result of the IoT, it can now construct a smart world. For this to happen, however, extracting meaningful information from raw sensory input functioning in loud and complicated settings must be addressed to achieve it. For example, bandwidth, processing power, and power consumption must be addressed while building a possible IoT system. Due to the current epidemic, the need for contactless solutions has risen. Possible solutions include a gesture-based control system that protects user privacy and can operate several different appliances simultaneously. When implementing such gesture-based control systems, opaque box artificial intelligence (AI) models are used. This opaque box AI model has shown good performance metrics on in-distribution data when tested in a lab. However, their complexity and opaqueness make them prone to failure when exposed to real-world out-of-distribution input. In contrast to opaque box models, explainable AI models based on fuzzy logic (EAI-FL) demonstrate comparable performance on lab data distributions. The type-2 fuzzy models, on the other hand, are readily calibrated and modified to offer equivalent performance to those attained on the lab in-distribution data in the real world. © 2022, Springer Nature Switzerland AG.","AI; Calibration; Fuzzy logic; IoT","Artificial intelligence; Computer circuits; Control systems; Fuzzy logic; Internet of things; Laboratories; 'current; Contact less; Fuzzy-Logic; Intelligence models; Performance; Processing power; Real-world; Sensory input; Smart world; User privacy; Calibration"
"Al-Tahmeesschi A., Umebayashi K., Iwata H., Lehtomäki J., Lopez-Benitez M.","Feature-Based Deep Neural Networks for Short-Term Prediction of WiFi Channel Occupancy Rate","10.1109/ACCESS.2021.3088423","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112378721&doi=10.1109%2fACCESS.2021.3088423&partnerID=40&md5=98c5f377fd1c3c8534c36b1b5353940f","Spectrum occupancy prediction is a key enabling technology to facilitate a proactive resource allocation for dynamic spectrum management systems. This work focuses on the prediction of duty cycle (DC) metric that reflects spectrum usage (in the time domain). The spectrum usage is typically measured on a shorter time scale than needed for prediction. Hence, data thinning is required and we apply block averaging. However, averaging operation results in flattening the DC data and losing essential features to assist deep neural network (DNN) to predict the spectrum usage. To improve DC prediction after block averaging, a feature-based deep learning framework is proposed. Namely, long short-term memory (LSTM) and gated recurrent unit (GRU) are selected and enhanced by using features of the data, such as the variance of DC data in addition to DC data themself. The proposed model is capable of proactively predicting the spectrum usage by capturing complex relationships among various input features for the measured spectrum, thus providing higher prediction accuracy with an average improvement of 5% in RMSE compared with traditional models. Moreover, to have a better understanding of the proposed model, we quantify the effect of input features on the predicted spectrum usage values. Based on the most significant input features, a simpler and more efficient model is proposed to estimate DC with similar accuracy to when using all features. © 2013 IEEE.","5G; deep neural networks; explainable AI; GRU; LSTM; occupancy rate; SHAP; short-term prediction; spectrum awareness; WiFi","Deep learning; Deep neural networks; Forecasting; Wi-Fi; Wireless local area networks (WLAN); Complex relationships; Dynamic spectrum management; Enabling technologies; Essential features; Learning frameworks; Prediction accuracy; Short term prediction; Spectrum occupancies; Long short-term memory"
"Altarez R.D.D., Apan A., Maraseni T.","Deep learning U-Net classification of Sentinel-1 and 2 fusions effectively demarcates tropical montane forest's deforestation","10.1016/j.rsase.2022.100887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142736921&doi=10.1016%2fj.rsase.2022.100887&partnerID=40&md5=28f6f46e1214ce45724916b791958257","Tropical montane forests (TMF) play a vital role in providing numerous ecosystem services. This ecosystem is characterized by towering mountains, cold weather, tall trees such as pine, and dwarfed plants. Although the combination of optical and radar imagery has shown promise in land use and land cover (LULC) mapping, only a handful of studies have attempted to study the dynamics of land changes in tropical montasne forests by combining the two. In this study, we examined the usage of Sentinel-1 (S-1) and Sentinel-2 (S-2) and their fusion as input for LULC mapping with three modeling classifiers: traditional (maximum likelihood classification - MLC), machine learning techniques (random forest, k-nearest neighbor, and kd-tree nearest neighbor), and a deep learning approach (U-Net) in a TMF in the Philippines. Also, the deforestation was characterized in terms of proximity and topographic factors. The findings revealed that the combination of S-1 and S-2 provides LULC with high accuracy of image classification. In binary classification, traditional MLC supersedes other classifiers in correctly classifying the pixels of the input imagery (average overall accuracy (OA) = 95.22; Kappa index (KI) = 90.39). Random Forest (RF) stands out in machine learning classifiers (average OA = 94.49; KI = 88.8). However, U-Net deep learning loses in binary classification but proven more robust when LULC were classified into six complex classes with an OA of 86.77 and KI of 78.89. In addition, using deep learning modeling for LULC mapping of the research site, it was determined that from 2015 to early 2022, 417.93 km2 of the study area had been deforested. Further, this research reveals that the greater the proximity of a forest to a human settlement or agricultural zone, the greater the likelihood that it will be cleared for human habitation or agriculture. Deforestation also occurred in rural locations, far from roads and bodies of water. This analysis also supports the hypothesis that deforestation can occur even in high-elevation areas. The results of this study can be utilized by policy and law makers in order to better communicate the critical nature of implementing evidence- and science-based policies to strengthen protections, as well as developing conservation and management plan for tropical montane forests. © 2022 Elsevier B.V.","Deep learning; Optical; Radar; Tropical montane forest; U-Net",
"Althoff D., Rodrigues L.N., Silva D.D.D.","Addressing hydrological modeling in watersheds under land cover change with deep learning","10.1016/j.advwatres.2021.103965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108120792&doi=10.1016%2fj.advwatres.2021.103965&partnerID=40&md5=62feedb40ade31322ba296283667709c","The impacts of land cover change have traditionally been assessed in hydrological modeling with a priori knowledge, e.g., using methods based on the curve number, or by calibrating hydrological models over different time periods. However, how hydrological processes respond to such changes is extremely context-dependent. Thus, there is an opportunity for the development of hydrological models that can learn from large hydrological data sets under the context of severe environmental changes. In this study, a single regional hydrological model is developed based on long short-term memory (LSTM) neural networks using different input configurations. One model considers only meteorological forcings as inputs (I1), another model considers meteorological forcings and static catchment attributes (I2), and a third model also considers meteorological forcings and catchment attributes but where the land cover characteristics are dynamic (I3). The models are trained using information from 411 catchments in the Brazilian Cerrado biome. The data set includes, for each catchment, the daily streamflow observations (target), daily precipitation and reference evapotranspiration (meteorological forcings), and 21 catchment attributes including topography, climate indices, soil characteristics, and land cover characteristics. Considering catchment attributes increases the performance of the LSTM model (I2 and I3 median KGE: 0.69). Considering the land use cover characteristics as dynamic improves the predictions under low-flow conditions (I3 median rNSE: 0.62) when compared to the model considering such characteristics as static (I2 median rNSE: 0.53). This study also uses the deep network with the integrated gradients technique to explore the contribution of the catchment characteristics to streamflow and the number of time steps of influence for the deep network in different regions. © 2021 Elsevier Ltd","Cerrado; Data-driven; Explainable artificial intelligence; Regional hydrological model","Catchments; Land use; Long short-term memory; Runoff; Stream flow; Topography; Cerrado; Data driven; Data set; Explainable artificial intelligence; Hydrological models; Land cover; Land-cover change; Meteorological forcing; Regional hydrological model; Short term memory; Climate models; artificial intelligence; catchment; environmental change; flow modeling; hydrological modeling; numerical model; streamflow; watershed"
"Althoff D., Bazameb H.C., Nascimentob J.G.","Untangling hybrid hydrological models with explainable artificial intelligence","10.2166/H2OJ.2021.066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104407891&doi=10.2166%2fH2OJ.2021.066&partnerID=40&md5=4383b2d0afdac777d9e09b3abc2a96a3","Hydrological models are valuable tools for developing streamflow predictions in unmonitored catchments to increase our understanding of hydrological processes. A recent effort has been made in the development of hybrid (conceptual/machine learning) models that can preserve some of the hydrological processes represented by conceptual models and can improve streamflow predictions. However, these studies have not explored how the data-driven component of hybrid models resolved runoff routing. In this study, explainable artificial intelligence (XAI) techniques are used to turn a black-box model into a glass box model. The hybrid models reduced the root mean-square error of the simulated streamflow values by approximately 27, 50, and 24% for stations 17120000, 27380000, and 33680000, respectively, relative to the traditional method. XAI techniques helped unveil the impor tance of accounting for soil moisture in hydrological models. Differing from purely data-driven hydrological models, the inclusion of the production storage in the proposed hybrid model, which is responsible for estimating the water balance, reduced the short-and long-Term dependencies of input variables for streamflow prediction. In addition, soil moisture controlled water percolation, which was the main predictor of streamflow. This finding is because soil moisture controls the underlying mechanisms of groundwater flow into river streams. © 2021 The Authors.","Gr4j; Individual conditional explanations; Lime; Partial dependence profiles; Regression trees",
"Al-Wesabi F.N., Malibari A.A., Mustafa Hilal A., NEMRI N., Kumar A., Gupta D.","Intelligent ensemble of voting based solid fuel classification model for energy harvesting from agricultural residues","10.1016/j.seta.2022.102040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124409751&doi=10.1016%2fj.seta.2022.102040&partnerID=40&md5=8495334038992980664b6c58494773f3","In recent times, utilization of renewable energy resources for transportation and electric power generation can be the sustainable way that reduces the risk of environmental, climatic, economic, political, and security concerns related to fossil fuel combustion. Among the several renewable energy sources, biomass is commonly used due to the fulfilment of ecological compatibility due to the fact that it is attained from plant and animal waste. At the same time, the classification of fuel materials becomes difficult when the material is previously processed or gathered from an environment that makes it challenging to discern. Therefore, with the constant development and diversification of energy harvesting from agricultural residues, there is a requirement to design a model for the classification of solid fuels. The recent developments of machine learning (ML) and deep learning (DL) techniques can be used for the solid fuel classification. The ML and DL models comprise many interdisciplinary areas, such as statistics, mathematics, artificial neural networks, data mining, optimization, and artificial intelligence. With this motivation, this paper designs a new intelligent ensemble of voting based solid fuel classification (IEVB-SFC) model for energy harvesting from agricultural residue. The proposed IEVB-SFC technique involves different stages of operations such as data acquisition, data preprocessing, classification, and ensemble process. At the primary stage, the data preprocessing is carried out in three different ways such as data transformation, class labeling, and data normalization. Besides, the IEVB-SFC technique comprises three different DL models as long short term memory (LSTM), gated recurrent unit (GRU), and convolutional neural network based LSTM (CNN-LSTM). Finally, an ensemble of three DL models takes place by the use of voting technique and thereby determines the appropriate solid fuel class labels, show the novelty of the work. The experimental results showcased the betterment of the IEVB-SFC technique over the recent state of art techniques with the maximum accuracy of 0.97. © 2022 Elsevier Ltd","Agricultural residue; Biomass; Deep learning; Energy harvesting; Machine learning; Renewable energy source; Solid fuel classification","Agriculture; Data acquisition; Data mining; Electric power generation; Energy harvesting; Fossil fuels; Long short-term memory; Metadata; Waste incineration; Classification models; Classification technique; Data preprocessing; Deep learning; Fossil fuel combustion; Learning models; Renewable energy source; Renewable energy sources (biomass); Solid fuel classification; Solid fuels; Agricultural wastes; accuracy assessment; alternative energy; biomass power; ensemble forecasting; fossil fuel; harvesting; machine learning; renewable resource"
"Ambore B., Gupta A.D., Rafi S.M., Yadav S., Joshi K., Sivakumar R.D.","A Conceptual Investigation on the Image Processing using Artificial Intelligence and Tensor Flow Models through Correlation Analysis","10.1109/ICACITE53722.2022.9823649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135482462&doi=10.1109%2fICACITE53722.2022.9823649&partnerID=40&md5=eb115ee9a120ef158ec1472517a25419","Artificial intelligence plays a vital role in image processing and tensor flow models. Due to increasing demand of generating data from image as well as to make distinction between images the necessity and relevance of these two topics are also growing. Image classification and processing is a recent trend where traffic lights and other objects are identified by Machine Learning (ML) and Deep Learning (DL) technologies. These technologies are further implemented inside self-driven vehicles for developing autonomous processing's and information transfer. However, an accuracy and speed of detection process is a concern in today's world. Thus, this study paper provides an insight into image processing accuracy by 'single-stage object detection model' or SSD MobileNetV2 and 'Regional-based Convolutional Neural Network' or RCNN. Pearson correlation analysis and mean was obtained using the input data. The output data were further analysed and discussed. Findings suggested that RCNN is 80.90% accurate when it is allowed to detect traffic lights present at 11.9 metres apart; whereas SSD MobileNet V2 has shown 71.8% of accuracy when the traffic light was detected present at the same distance. On average, the RCNN shows higher accuracy than SSD MobileNet V2. The discussion found that RCNN is more accurate and slower than SSD MobileNetV2. © 2022 IEEE.","correlation analysis; image processing; RCCN; SSD MobileNet; tensor flow model","Convolutional neural networks; Correlation methods; Object detection; Tensors; Correlation analysis; Flow modelling; Image tensors; Images classification; Images processing; RCCN; Recent trends; SSD mobilenet; Tensor flow model; Traffic light; Deep learning"
"Amponsah A.A., Adekoya A.F., Weyori B.A.","A novel fraud detection and prevention method for healthcare claim processing using machine learning and blockchain technology","10.1016/j.dajour.2022.100122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137728319&doi=10.1016%2fj.dajour.2022.100122&partnerID=40&md5=6899ed2e15a3da1d5c23b6d1ebb60907","Healthcare fraud is a global problem affecting both developing and developed countries. It is the deliberate attempt of the perpetrators to take undue advantage of the inefficiencies in current healthcare systems. Fraud tends to deny legitimate beneficiaries of universal health coverage, especially those under health insurance protection. In this work, we propose using machine learning techniques and blockchain technology to detect and prevent fraud in healthcare, especially in claims processing. A decision tree classification algorithm is adopted to classify the original claims dataset. The extracted knowledge is programmed in the Ethereum blockchain smart contract to detect and prevent healthcare fraud. The comparative experimental results show that the best performing tool achieves a classification accuracy of 97.96% and a sensitivity of 98.09%. This means that the proposed system enhances the blockchain smart contract's ability to detect fraud with an accuracy of 97.96%. © 2022 The Author(s)","Blockchain technology; Fraud detection; Healthcare fraud; Machine learning; Smart contract",
"An D., Chen Y.","A Digital Twin Enabled Internet of Living Things (IoLT) Framework for Soil Carbon Management","10.1109/MESA55290.2022.10004406","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146899504&doi=10.1109%2fMESA55290.2022.10004406&partnerID=40&md5=ea41996c5521cf0a404052d00ff2e16c","Due to the lack of cost-effective methods for soil carbon content accounting, soil carbon emissions cannot be managed properly for a long time. The traditional methods are labor intensive which usually need tedious preprocessing and expensive analyzers to quantify the total soil carbon content. In this paper, we propose that a Digital Twin with AIoLT framework could perfectly solve the challenge mentioned above. By using an AIoLT-enabled proximity radar sensor to measure soil carbon content in real-time, our proposed soil carbon management digital twin (SCMDT) has the ability to deal with these soil carbon data to be 'smart' big data, which are from missionaware sampling strategies. We also provide an evaluation metric for our proposed SCMDT in order to quantify its performance. © 2022 IEEE.","Artificial Intelligent Internet of Living Things (AIoLT); Artificial Intelligent Internet of Things (AIoT); Digital Twin; Internet of Living Things (IoT); Proximity Radar Sensor; Soil Carbon Accounting","Artificial intelligence; Carbon; Cost effectiveness; Radar equipment; Soils; Artificial intelligent; Artificial intelligent internet of living thing; Artificial intelligent internet of thing; Carbon accounting; Internet of living thing; Living things; Proximity radar sensor; Radar sensors; Soil carbon; Soil carbon accounting; Internet of things"
"Andrade Cruz I., Chuenchart W., Long F., Surendra K.C., Renata Santos Andrade L., Bilal M., Liu H., Tavares Figueiredo R., Khanal S.K., Fernando Romanholo Ferreira L.","Application of machine learning in anaerobic digestion: Perspectives and challenges","10.1016/j.biortech.2021.126433","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120475936&doi=10.1016%2fj.biortech.2021.126433&partnerID=40&md5=71ec200e236d989a92b084f211d28d0e","Anaerobic digestion (AD) is widely adopted for remediating diverse organic wastes with simultaneous production of renewable energy and nutrient-rich digestate. AD process, however, suffers from instability, thereby adversely affecting biogas production. There have been significant efforts in developing strategies to control the AD process to maintain process stability and predict AD performance. Among these strategies, machine learning (ML) has gained significant interest in recent years in AD process optimization, prediction of uncertain parameters, detection of perturbations, and real-time monitoring. ML uses inductive inference to generalize correlations between input and output data, subsequently used to make informed decisions in new circumstances. This review aims to critically examine ML as applied to the AD process and provides an in-depth assessment of important algorithms (ANN, ANFIS, SVM, RF, GA, and PSO) and their applications in AD modeling. The review also outlines some challenges and perspectives of ML, and highlights future research directions. © 2021 Elsevier Ltd","Anaerobic digestion; Machine learning; Modeling; Process instability; Process optimization","Machine learning; Particle swarm optimization (PSO); Process control; Uncertainty analysis; Anaerobic digestion process; Biogas production; Developing strategy; Digestate; Digestion performance; Modeling; Organic wastes; Process instabilities; Process stability; Renewable energies; Anaerobic digestion; biofuel; methane; anaerobic growth; bioreactor; machine learning; Anaerobiosis; Biofuels; Bioreactors; Machine Learning; Methane"
"Angarita-Zapata J.S., Alonso-Vicario A., Masegosa A.D., Legarda J.","A taxonomy of food supply chain problems from a computational intelligence perspective","10.3390/s21206910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117710418&doi=10.3390%2fs21206910&partnerID=40&md5=e3bd935f09705110f3c43b0f0ee05974","In the last few years, the Internet of Things, and other enabling technologies, have been progressively used for digitizing Food Supply Chains (FSC). These and other digitalization-enabling technologies are generating a massive amount of data with enormous potential to manage supply chains more efficiently and sustainably. Nevertheless, the intricate patterns and complexity embedded in large volumes of data present a challenge for systematic human expert analysis. In such a datadriven context, Computational Intelligence (CI) has achieved significant momentum to analyze, mine, and extract the underlying data information, or solve complex optimization problems, striking a balance between productive efficiency and sustainability of food supply systems. Although some recent studies have sorted the CI literature in this field, they are mainly oriented towards a single family of CI methods (a group of methods that share common characteristics) and review their application in specific FSC stages. As such, there is a gap in identifying and classifying FSC problems from a broader perspective, encompassing the various families of CI methods that can be applied in different stages (from production to retailing) and identifying the problems that arise in these stages from a CI perspective. This paper presents a new and comprehensive taxonomy of FSC problems (associated with agriculture, fish farming, and livestock) from a CI approach; that is, it defines FSC problems (from production to retail) and categorizes them based on how they can be modeled from a CI point of view. Furthermore, we review the CI approaches that are more commonly used in each stage of the FSC and in their corresponding categories of problems. We also introduce a set of guidelines to help FSC researchers and practitioners to decide on suitable families of methods when addressing any particular problems they might encounter. Finally, based on the proposed taxonomy, we identify and discuss challenges and research opportunities that the community should explore to enhance the contributions that CI can bring to the digitization of the FSC. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Agriculture; Computational intelligence; Deep learning; Fish farming; Food supply chain; Fuzzy systems; Livestock; Machine learning; Meta-heuristics; Neural networks; Probabilistic methods","Complex networks; Deep learning; Fish; Food supply; Fuzzy systems; Heuristic methods; Supply chains; Taxonomies; Computational intelligence methods; Deep learning; Enabling technologies; Fish farming; Food supply chain; Human expert; Large volumes; Metaheuristic; Neural-networks; Probabilistic methods; Agriculture; agriculture; animal; artificial intelligence; catering service; food; human; technology; Agriculture; Animals; Artificial Intelligence; Food; Food Supply; Humans; Technology"
"Ao S.-I., Gelman L., Karimi H.R., Tiboni M.","Advances in Machine Learning for Sensing and Condition Monitoring","10.3390/app122312392","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143841037&doi=10.3390%2fapp122312392&partnerID=40&md5=731819493e446554148550ad16c85323","In order to overcome the complexities encountered in sensing devices with data collection, transmission, storage and analysis toward condition monitoring, estimation and control system purposes, machine learning algorithms have gained popularity to analyze and interpret big sensory data in modern industry. This paper put forward a comprehensive survey on the advances in the technology of machine learning algorithms and their most recent applications in the sensing and condition monitoring fields. Current case studies of developing tailor-made data mining and deep learning algorithms from practical aspects are carefully selected and discussed. The characteristics and contributions of these algorithms to the sensing and monitoring fields are elaborated. © 2022 by the authors.","condition monitoring; machine learning deep learning; sensing",
"Apostolopoulos I.D., Athanasoula I., Tzani M., Groumpos P.P.","An Explainable Deep Learning Framework for Detecting and Localising Smoke and Fire Incidents: Evaluation of Grad-CAM++ and LIME","10.3390/make4040057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144455738&doi=10.3390%2fmake4040057&partnerID=40&md5=48b0b40dd9f25710180ef3f24a4044c3","Climate change is expected to increase fire events and activity with multiple impacts on human lives. Large grids of forest and city monitoring devices can assist in incident detection, accelerating human intervention in extinguishing fires before they get out of control. Artificial Intelligence promises to automate the detection of fire-related incidents. This study enrols 53,585 fire/smoke and normal images and benchmarks seventeen state-of-the-art Convolutional Neural Networks for distinguishing between the two classes. The Xception network proves to be superior to the rest of the CNNs, obtaining very high accuracy. Grad-CAM++ and LIME algorithms improve the post hoc explainability of Xception and verify that it is learning features found in the critical locations of the image. Both methods agree on the suggested locations, strengthening the abovementioned outcome. © 2022 by the authors.","convolutional neural networks; deep learning; explainable artificial intelligence; fire detection; interpretability; smoke detection",
"Araya S.N., Fryjoff-Hung A., Anderson A., Viers J.H., Ghezzehei T.A.","Advances in soil moisture retrieval from multispectral remote sensing using unoccupied aircraft systems and machine learning techniques","10.5194/hess-25-2739-2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106937685&doi=10.5194%2fhess-25-2739-2021&partnerID=40&md5=9e61224aeb821463783b63129f3f2c9f","This study investigates the ability of machine learning models to retrieve the surface soil moisture of a grassland area from multispectral remote sensing carried out using an unoccupied aircraft system (UAS). In addition to multispectral images, we use terrain attributes derived from a digital elevation model and hydrological variables of precipitation and potential evapotranspiration as covariates to predict surface soil moisture. We tested four different machine learning algorithms and interrogated the models to rank the importance of different variables and to understand their relationship with surface soil moisture. All the machine learning algorithms we tested were able to predict soil moisture with good accuracy. The boosted regression tree algorithm was marginally the best, with a mean absolute error of 3.8 % volumetric moisture content. Variable importance analysis revealed that the four most important variables were precipitation, reflectance in the red wavelengths, potential evapotranspiration, and topographic position indices (TPI). Our results demonstrate that the dynamics of soil water status across heterogeneous terrain may be adequately described and predicted by UAS remote sensing and machine learning. Our modeling approach and the variable importance and relationships we have assessed in this study should be useful for management and environmental modeling tasks where spatially explicit soil moisture information is important. © 2021 Author(s) (or their employer(s)).",,"Evapotranspiration; Forestry; Geomorphology; Learning systems; Learning to rank; Remote sensing; Soil moisture; Trees (mathematics); Unmanned aerial vehicles (UAV); Boosted regression trees; Digital elevation model; Machine learning models; Machine learning techniques; Multispectral remote sensing; Potential evapotranspiration; Soil moisture retrievals; Volumetric moisture content; Learning algorithms; aircraft; algorithm; digital elevation model; environmental modeling; evapotranspiration; grassland; image analysis; machine learning; remote sensing; soil moisture; spectral analysis"
"Ariza A., Lengaigne M., Menkes C., Lebourges-Dhaussy A., Receveur A., Gorgues T., Habasque J., Gutiérrez M., Maury O., Bertrand A.","Global decline of pelagic fauna in a warmer ocean","10.1038/s41558-022-01479-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139055124&doi=10.1038%2fs41558-022-01479-2&partnerID=40&md5=488aa33f4b094b32dca11f383f951cdd","Pelagic fauna is expected to be impacted under climate change according to ecosystem simulations. However, the direction and magnitude of the impact is still uncertain and still not corroborated by observation-based statistical studies. Here we compile a global underwater sonar database and 20 ocean climate projections to predict the future distribution of sound-scattering fauna around the world’s oceans. We show that global pelagic fauna will be seriously compromised by the end of the twenty-first century if we continue under the current greenhouse emission scenario. Low and mid latitudes are expected to lose from 3% to 22% of animal biomass due to the expansion of low-productive systems, while higher latitudes would be populated by present-day temperate fauna, supporting results from ecosystem simulations. We further show that strong mitigation measures to contain global warming below 2 °C would reduce these impacts to less than half. © 2022, The Author(s), under exclusive licence to Springer Nature Limited.",,"biomass; climate change; fauna; global warming; simulation"
"Arkhipova M.Yu.","Modelling Crop Yield in Agricultural Regions Using Computer Vision Technology [Моделирование урожайности зерновых культур сельскохозяйственных регионов c использованием технологий компьютерного зрения]","10.17059/ekon.reg.2022-2-20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134235709&doi=10.17059%2fekon.reg.2022-2-20&partnerID=40&md5=23796796f9695552ecc2fec0f11a5356","The article examines new methodologies for modelling crop yield in agricultural regions of Russia based on the use of remote capabilities to get information on the field state. The proposed approach can be applied to develop indicator systems and create methodological platforms and models necessary to obtain more accurate estimates. In comparison with the traditional regression model, this method uses computer vision technology to gather additional data. Statistical hypothesis testing confirmed the significance of satellite photographs of fields for improving the accuracy of crop yield forecasting models. Traditional econometric tools were compared with various neural networks in order to discover the optimal model. The proposed tools were tested using data from 100 agricultural fields located in municipalities of 43 Russian regions, selected in proportion to the volume of crop production in this region. The conducted analysis showed the advantage of the mixed data neural network in comparison with other neural (multilayer perceptron and convolutional neural network) and regression models. In conditions of uncertainty and a large amount of data, the mixed data neural network can help obtain more accurate estimates. Additionally, while environmental factors have different effects on crop yields, they must be considered along with socio-economic characteristics. The use of new models and data types differing from table information can significantly improve the forecasting accuracy and interpretation. The analysis results can be used for examining and monitoring agricultural production in regional municipalities, determining farm resource requirements, as well as for creating sectoral and comprehensive projects and programmes for the development of the agricultural industry. © 2022 Institute of Economics, Ural Branch of the Russian Academy of Sciences. All rights reserved.","agricultural statistical analysis; computer vision; econometric modelling; econometric models; neural networks; satellite photos; yield forecasting",
"Arun P.V., Karnieli A.","Learning of physically significant features from earth observation data: an illustration for crop classification and irrigation scheme detection","10.1007/s00521-022-07019-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126222781&doi=10.1007%2fs00521-022-07019-5&partnerID=40&md5=7082dfb11012a0b9b44df96501e4be30","Earth observation data processing requires interpretable deep learning (DL) models that learn physically significant and meaningful features. The current study proposes approaches to make the network to learn meaningful features. In addition, a set of interpretability- and explanation-based evaluation strategies are proposed to evaluate the DL models. Adversarial variational encoding along with constraints to regulate latent representations and embed label information are employed to learn interpretable manifold. The proposed architecture, called interpretable adversarial encoding network (IAENet), significantly improves the results compared to other main existing DL models. The proposed IAENet learns the features which are essential in distinguishing the different classes thereby improving the interpretability of the model. The explanations for the different models are generated through analysis of the concepts learned by each model using activation maximization. Besides, the relevance assigned by the model to input features is also estimated using the layer-wise relevance propagation approach. Experiments on the phenological curve-based crop classification illustrate that IAENet learn relevant features (giving importance to the non-rainy season) to distinguish different irrigation schemes. The performance can be attributed to the learned interpretable manifold, and the refinement of architectural units and convolutions considering the point-nature and irregular sampling of the input data. Experiments on learning crop-specific features from multispectral images for crop-type classification indicate that IAENet learns red and green edge features crucial in distinguishing the studied crops. The improvement in interpretability of the DL models is found to reduce the sensitivity toward network parameters. The proposed evaluation measures facilitate ascertaining the physical significance of the learned manifold. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Classification; Crop-specific features; Deep learning; Interpretability; Phenological curves; VENµS","Activation analysis; Classification (of information); Data handling; Deep learning; Encoding (symbols); Irrigation; Signal encoding; Crop classification; Crop-specific feature; Deep learning; Earth observation data; Interpretability; Irrigation schemes; Learn+; Learning models; Phenological curve; VENµS; Crops"
"Arun P.V., Karnieli A.","Deep learning-based phenological event modeling for classification of crops","10.3390/rs13132477","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109271348&doi=10.3390%2frs13132477&partnerID=40&md5=67aa27a000674480466ef4faf1ecadc7","Classification of crops using time-series vegetation index (VI) curves requires appropriate modeling of phenological events and their characteristics. The current study explores the use of capsules, a group of neurons having an activation vector, to learn the characteristic features of the phenological curves. In addition, joint optimization of denoising and classification is adopted to improve the generalizability of the approach and to make it resilient to noise. The proposed approach employs reconstruction loss as a regularizer for classification, whereas the crop-type label is used as prior information for denoising. The activity vector of the class capsule is applied to sample the latent space conditioned on the cell state of a Long Short-Term Memory (LSTM) that integrates the sequences of the phenological events. Learning of significant phenological characteristics is facilitated by adversarial variational encoding in conjunction with constraints to regulate latent representations and embed label information. The proposed architecture, called the variational capsule network (VCapsNet), significantly improves the classification and denoising results. The performance of VCapsNet can be attributed to the suitable modeling of phenological events and the resilience to outliers and noise. The maxpooling-based capsule implementation yields better results, particularly with limited training samples, compared to the conventional implementations. In addition to the confusion matrix-based accuracy measures, this study illustrates the use of interpretability-based evaluation measures. Moreover, the proposed approach is less sensitive to noise and yields good results, even at shallower depths, compared to the main existing approaches. The performance of VCapsNet in accurately classifying wheat and barley crops indicates that the approach addresses the issues in crop-type classification. The approach is generic and effectively models the crop-specific phenological features and events. The interpretability-based evaluation measures further indicate that the approach successfully identifies the crop transitions, in addition to the planting, heading, and harvesting dates. Due to its effectiveness in crop-type classification, the proposed approach is applicable to acreage estimation and other applications in different scales. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Classification; Deep learning; Denoising; Phenological curves; VENµS","Biology; Classification (of information); Crops; Long short-term memory; Vector spaces; Accuracy measures; Activation vectors; Appropriate models; Confusion matrices; Crop type classification; Evaluation measures; Joint optimization; Proposed architectures; Deep learning"
"Arvind C.S., Aditya K., Keerthan H.S., Farhan M., Asha K.N., Patil S.S.","Non-Invasive Multistage Fruit Grading Application with User Recommendation system","10.1109/CONECCT55679.2022.9865785","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138260071&doi=10.1109%2fCONECCT55679.2022.9865785&partnerID=40&md5=4c43c7ee7342686c475310bb3a8d0e77","In recent years, fruit sellers, consumers, and mid-lower income farmers have faced difficulty grading the fruits as it is laborious and needs massive investment. Artificial intelligence and vision sensors on mobile devices have led to non-invasive ways to grade the fruits. Hence, using deep learning, fruit grading applications with recommendation features were developed to handle multiple fruits. YoloV3 will detect the fruit type, followed by sub-categories classification using inceptionNet V3 and MobileNet V2 classifiers. Finally, Neural network classifier will predict the fruit grade based on handcrafted features. Deep neural network models were trained using two different data sets (i) fruit360 and (ii) our own (custom fruit dataset) in a transfer learning approach. The proposed application has client interface was developed using the angular framework, which communicates with the server using flask microservices. Where end-users can upload fruit images via mobile phones or web browsers to obtain (i) Fruit Sub Categories, and it grades with user recommendations such as (i) finding the nearest fruit shop (ii) Present retail market price of the fruit (iii) Recipe recommendation. The developed mobile application will remove bias and improve the perception of non-invasive fruit grading. © 2022 IEEE.","Angular; Deep learning; Deployment; Grading; Recommendation; Validation","Deep neural networks; Fruits; Learning systems; Web browsers; Angular; Deep learning; Deployment; Fruit grading; Intelligence sensors; Low incomes; Multi-stages; Recommendation; User recommendations; Validation; Grading"
"Arvind C.S., Totla A., Jain T., Sinha N., Jyothi R., Aditya K., Keerthan, Farhan M., Sumukh G., Ak G.","Deep Learning Based Plant Disease Classification with Explainable AI and Mitigation Recommendation","10.1109/SSCI50451.2021.9659869","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125790384&doi=10.1109%2fSSCI50451.2021.9659869&partnerID=40&md5=f5143a3bee6f73a05fbd0ef85c71ddc0","Plants show visible symptoms of getting infected with a disease. Presently an experienced plant pathologist can diagnose the condition through visual inspection of disease-affected plants. However, manual visualization is time-consuming and depends on the plant pathologist's expertise in identifying plant disease. Hence this problem can be solved by a computer-aided diagnostic system with artificial intelligence (CADS-AI). This system will aid in improving and protecting the yield of the plant, but it lacks trust as the existing system is not flawless. Hence, in this research work, a plant disease classification with an explainable AI pipeline is developed which ensures trust in the CADS solution. Furthermore, an expert recommendation system will act as an alternative to expert plant pathologists. Tomato leaf diseases data from the PlantVillage dataset is used in the proposed solution. Transfer learning technique was adopted in training deep neural network models with original and augmented data of 16, 684 and 53, 476 images respectively. The best model for the dataset was efficientNet B5 with best F1 score accuracy of 0.9842 and 0.9930. The predicted output of B5 was interpreted with explainable AI techniques and validated using YOLOv4. Inference of the proposed solution was a client-server interface where end-users can upload infected leaf images via mobile phones or web browsers. This entire system was tested in real-time with 250 volunteers with 4G mobile network or 100 MBPS wifi. The average throughput time of the system is around 4.3 seconds. © 2021 IEEE.","Deeplearning; Deployment; Explainable AI; Plant Disease; Recommendation; Validation","Deep neural networks; Web browsers; Computer aided diagnostics; Condition; Deeplearning; Deployment; Disease classification; Explainable AI; Plant disease; Recommendation; Validation; Visual inspection; Diagnosis"
"Ashok K., Gopikrishnan S.","Statistical Analysis of Remote Health Monitoring Based IoT Security Models & Deployments From a Pragmatic Perspective","10.1109/ACCESS.2023.3234632","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147203315&doi=10.1109%2fACCESS.2023.3234632&partnerID=40&md5=383ea174876df648aa8a38d9be752a3c","Remote health monitoring-based Internet of Things (IoT) network security is a multi-domain task, that involves identification of network attack, evaluation of mitigation strategies, design of performance aware data security models, integration of privacy models, and modeling of device-level security methods. Internal designs for each of these models is highly complex, and varies in terms of quantitative & qualitative performance measures. This is due to their variation in terms of design nuances, functional advantages, context-based limitations, and possible deployment-specific future scopes. Due to this variation, it is highly ambiguous to select these models for performance-specific IoT deployments. Moreover, these models also vary in terms of security level, Quality of Service (QoS) parameters, scalability performance, computational complexity, deployment costs, and other performance metrics. Thus, to identify optimum models, researchers & network designers are required to test & validate multiple security models for their deployments. Due to which, the cost & time to market for IoT devices is increased, thereby affecting viability of IoT products. To overcome these selection issues, an empirical survey of different IoT security models including block-chains, encryption techniques, hashing models, privacy preservation techniques, machine learning based security methods, etc. are discussed in this text. This text also discusses various attack mitigation models that provide node-level security, network-level security, physical security, & route-level security. This discussion will assist in initially evaluating different operating characteristics of these models, which will allow readers to identify most suited models for their application-specific use cases. This article also assesses the models' performance in terms of computational latency, energy consumption, security levels, deployment complexity, and scalability measures. These metrics are compared between different security models, which will further assist readers to identify optimum models for their performance-specific use cases. To further assist in model selection, this text proposes evaluation of a novel IoT Security Performance Rank (ISRP), that combines various performance metrics to form a singular rank which can be used to describe overall performance of these models. Readers will be able to consider optimal security approaches for new and current IoT installations based on this ranking. © 2013 IEEE.","attacks; blockchain; data; energy; IoT; medical signal detection; physical; privacy; QoS; route; security","Blockchain; Complex networks; Cryptography; Data privacy; Energy utilization; Health care; Internet of things; Learning systems; Network security; Quality control; Scalability; Signal detection; Attack; Block-chain; Computational modelling; Data; Energy; Medical services; Medical signal detection; Physical; Privacy; Quality-of-service; Remote monitoring; Route; Security; Signal's detections; Quality of service"
"Ashwini B.P., Savithramma R.M., Sumathi R.","Artificial Intelligence in Smart City Applications: An overview","10.1109/ICICCS53718.2022.9788152","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133160245&doi=10.1109%2fICICCS53718.2022.9788152&partnerID=40&md5=371206f1d024385b82b98edf8543d429","Recently, the smart city has evolved as a global model and several institutions have adopted this concept to facilitate the citizens with the comfort and quality of life exploiting the progress in the capabilities of computing, networking, and data management. All probable aspects of a smart city are modeled as different components such as governance, transportation, waste and energy management, and so on. Artificial Intelligence (AI) based technology is widely applied in the development of most of the components of a smart city. In this context, the current article presents a detailed survey of the latest AI-based solutions in smart city implementation. The following inferences are made through this review: (a) AI-based applications for a smart city have been adopted by various developing and developed countries worldwide. (b) The components such as town planning, governance, and education are less explored as compared to other components. (c) Network-based models including deep learning models are the most popular as compared to other models like trees, genetic, linear, and naive models. Finally, it is observed from the review that AI is an indispensable part of a smart city currently and will continue to be in the future. © 2022 IEEE.","Artificial Intelligence; Information and Communication Technology; Smart city components; Smart education; Smart governance; Smart grid; Smart transportation","Deep learning; Electric power transmission networks; Information management; Smart power grids; Waste management; 'current; Developed countries; Global models; Information and Communication Technologies; Quality of life; Smart city component; Smart education; Smart governance; Smart grid; Smart transportation; Smart city"
"Asif M.R.A., Hasan K.F., Islam M.Z., Khondoker R.","STRIDE-based Cyber Security Threat Modeling for IoT-enabled Precision Agriculture Systems","10.1109/STI53101.2021.9732597","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127443053&doi=10.1109%2fSTI53101.2021.9732597&partnerID=40&md5=63aa3b399e5169e96f354334aa647eb1","The concept of traditional farming is changing rapidly with the introduction of smart technologies like the Internet of Things (IoT). Under the concept of smart agriculture, precision agriculture is gaining popularity to enable Decision Support System (DSS)-based farming management that utilizes widespread IoT sensors and wireless connectivity to enable automated detection and optimization of resources. Undoubtedly the success of the system would be impacted on crop productivity, where failure would impact severely. Like many other cyber-physical systems, one of the growing challenges to avoid system adversity is to ensure the system's security, privacy, and trust. But what are the vulnerabilities, threats, and security issues we should consider while deploying precision agriculture? This paper has conducted a holistic threat modeling on component levels of precision agriculture's standard infrastructure using popular threat intelligence tools STRIDE to identify common security issues. Our modeling identifies a noticing of fifty-eight potential security threats to consider. This presentation systematically presented them and advised general mitigation suggestions to support cyber security in precision agriculture. © 2021 IEEE.","Cyber security; Internet of Things (IoT); Precision Agriculture; STRIDE; Threat Modeling","Artificial intelligence; Decision support systems; Embedded systems; Internet of things; Precision agriculture; Security systems; Agriculture systems; Cyber security; Internet of thing; Precision Agriculture; Security issues; Security threat modeling; Smart agricultures; Smart technology; STRIDE; Threat modeling; Cybersecurity"
"Askar N.A., Habbal A., Mohammed A.H., Sajat M.S., Yusupov Z., Kodirov D.","Architecture, Protocols, and Applications of the Internet of Medical Things (IoMT)","10.12720/jcm.17.11.900-918","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140914177&doi=10.12720%2fjcm.17.11.900-918&partnerID=40&md5=e2d5479c84900a059b273a044a386bd1","The Internet of Things (IoT) refers to the interconnected framework of web-connected objects that can collect and transfer information over a remote network without requiring any human intervention. The rapid progression in the development of IoT-based devices and their expansion towards making the medical care facility financially more savvy, proactive, and customized, has given rise to the development of the ""Internet of Medical Things (IoMT)"" that are assumed to function proactively in all domains of the healthcare industry. Within this framework, the IoMT-based healthcare system delivers various advantages, such as quick and unfailing treatment, enhanced communication, cost minimization, etc., through the exploitation of several new technologies. For instance, machine learning has significantly helped with the exploitation of various healthcare systems; fog computing not only minimises the cost of communication but also provides low latency; blockchain delivers its users a much better way of protecting sensitive and confidential information and data they possess. In this survey, a comprehensive elaboration of the IoMT-based healthcare systems based on modern technologies was conducted. This article describes various techniques and solutions of IoMT healthcare systems in the context of emerging technologies, and the related future trends and applications for a better understanding of how IoMT can enhance the healthcare industry now and in future. © 2022 Journal of Communications and 2022 by the authors.","Blockchain; edge computing; fog computing; H-IoT; internet of medical things; IoMT healthcare; machine learning",
"Aslan S., Zennaro F., Furlan E., Critto A.","Recurrent neural networks for water quality assessment in complex coastal lagoon environments: A case study on the Venice Lagoon","10.1016/j.envsoft.2022.105403","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131599532&doi=10.1016%2fj.envsoft.2022.105403&partnerID=40&md5=0511e39da7d6474312dcf576675a546d","Eutrophication represents an important ecological and environmental issue in coastal lagoons. This paper presents an extensive study of recurrent cell and network architectures to model eutrophication processes in the Venice lagoon, a very complex and fragile ecosystem that has been strongly altered by anthropic activities over years. Experimental results showed that recurrent models outperformed Random Forests (RF) significantly on two datasets, performing similarly to CNNs on one of the datasets, while outperforming CNNs on the other one. Additionally, the transferability potential of the trained models was investigated. The empirical analysis has shown that recurrent neural network models with lower computational complexity provide the highest eutrophication prediction accuracy when their trained models were tested on a new dataset. Designed models represent effective tools for early-warning eutrophication prediction that can support the implementation of relevant EU acquis (EU Marine Strategy and Water Framework Directives) and achievement of their environmental targets. © 2022 Elsevier Ltd","Eutrophication prediction and modeling; Machine learning; Neural networks; Recurrent neural networks; Venice lagoon; Water quality assessment","Complex networks; Decision trees; Environmental regulations; Eutrophication; Lakes; Network architecture; Recurrent neural networks; Rivers; Water conservation; Water quality; Anthropic activity; Case-studies; Coastal lagoons; Environmental issues; Eutrophication prediction and modeling; Lagoon environments; Neural-networks; Recurrent models; Venice lagoon; Water quality assessments; Forecasting; artificial neural network; assessment method; coastal lagoon; environmental issue; eutrophication; machine learning; prediction; water quality; Italy; Veneto; Venezia [Veneto]; Venice Lagoon"
"Asteris P.G., Lemonis M.E., Nguyen T.-A., Van Le H., Pham B.T.","Soft computing-based estimation of ultimate axial load of rectangular concrete-filled steel tubes","10.12989/scs.2021.39.4.471","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105616526&doi=10.12989%2fscs.2021.39.4.471&partnerID=40&md5=1b6ae18a78d70e57d640b464dde6f223","In this study, we estimate the ultimate load of rectangular concrete-filled steel tubes (CFST) by developing a novel hybrid predictive model (ANN-BCMO) which is a combination of balancing composite motion optimization (BCMO) - a very new optimization technique and artificial neural network (ANN). For this aim, an experimental database consisting of 422 datasets is used for the development and validation of the ANN-BCMO model. Variables in the database are related with the geometrical characteristics of the structural members, and the mechanical properties of the constituent materials (steel and concrete). Validation of the hybrid ANN-BCMO model is carried out by applying standard statistical criteria such as root mean square error (RMSE), coefficient of determination (R2), and mean absolute error (MAE). In addition, the selection of appropriate values for parameters of the hybrid ANN-BCMO is conducted and its robustness is evaluated and compared with the conventional ANN techniques. The results reveal that the new hybrid ANN-BCMO model is a promising tool for prediction of the ultimate load of rectangular CFST, and prove the effective role of BCMO as a powerful algorithm in optimizing and improving the capability of the ANN predictor. © 2021 Techno Press. All rights reserved.","Artificial neural network; Balancing composite motion optimization; CFST column; Ultimate axial load","Balancing; Mean square error; Neural networks; Predictive analytics; Soft computing; Tubes (components); Tubular steel structures; Coefficient of determination; Constituent materials; Experimental database; Geometrical characteristics; Optimization techniques; Rectangular concrete-filled steel tubes; Root mean square errors; Statistical criterion; Concretes"
"Aswad F.M., Kareem A.N., Khudhur A.M., Khalaf B.A., Mostafa S.A.","Tree-based machine learning algorithms in the Internet of Things environment for multivariate flood status prediction","10.1515/jisys-2021-0179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120880023&doi=10.1515%2fjisys-2021-0179&partnerID=40&md5=474fc700d88440fbf984de317e8bbaaf","Floods are one of the most common natural disasters in the world that affect all aspects of life, including human beings, agriculture, industry, and education. Research for developing models of flood predictions has been ongoing for the past few years. These models are proposed and built-in proportion for risk reduction, policy proposition, loss of human lives, and property damages associated with floods. However, flood status prediction is a complex process and demands extensive analyses on the factors leading to the occurrence of flooding. Consequently, this research proposes an Internet of Things-based flood status prediction (IoT-FSP) model that is used to facilitate the prediction of the rivers flood situation. The IoT-FSP model applies the Internet of Things architecture to facilitate the flood data acquisition process and three machine learning (ML) algorithms, which are Decision Tree (DT), Decision Jungle, and Random Forest, for the flood prediction process. The IoT-FSP model is implemented in MATLAB and Simulink as development platforms. The results show that the IoT-FSP model successfully performs the data acquisition and prediction tasks and achieves an average accuracy of 85.72% for the three-fold cross-validation results. The research finding shows that the DT scores the highest accuracy of 93.22%, precision of 92.85, and recall of 92.81 among the three ML algorithms. The ability of the ML algorithm to handle multivariate outputs of 13 different flood textual statuses provides the means of manifesting explainable artificial intelligence and enables the IoT-FSP model to act as an early warning and flood monitoring system. © 2022 Firas Mohammed Aswad et al., published by De Gruyter.","explainable artificial intelligence; flood prediction; Internet of Things; machine learning; multivariate classification","Data acquisition; Decision trees; Disasters; Floods; Forecasting; Learning algorithms; Machine learning; Agriculture industries; Explainable artificial intelligence; Flood prediction; Human being; Machine learning algorithms; Multivariate classification; Natural disasters; Prediction modelling; Risks reduction; Tree-based; Internet of things"
"Ateeq K., Ramlal P., Thawabeh O.A., Arsalan A., Burhan M., Nasir M.U.","NABA: Novel Adaptive Broadcast Storm Avoidance in NDN and SDN based FANET","10.1109/ICCR56254.2022.9995825","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146496970&doi=10.1109%2fICCR56254.2022.9995825&partnerID=40&md5=74a566fce37d0d37ffea468ff2044119","The proposed Internet paradigm The Flying Ad Hoc Network (FANET), Named Data Network (NDN), and Software Defined Network (SDN) have attracted the interest of the scientific community. The TCP/IP protocol is the present Internet standard, while NDN is the future internet architecture that builds on it. Data availability is improved via NDN, which substitutes named data for the nodes' addresses. SDN is a good option for communicating effectively, utilizing resources effectively, and supporting developing technologies. The SDN has attracted interest because of its high-level programmability and flexibility. Numerous applications in the military, business, and civil sectors make extensive use of FANE T. The broadcast characteristic of NDN causes an issue known as a broadcast storm in dense FANET environments. The issue is caused by duplicate packets, which raises the overall amount of traffic and retransmissions. FANET has a problem with the timely and quick transmission of essential packets. In this paper, we suggested a new scheme named 'Novel Adaptive Broadcast Storm Avoidance (NABA)' for SDN and NDN-enabled FANET, which uses a controller to lessen the broadcast issue. Our scheme made use of the SDN controller's effective flow management to regulate the broadcast storm and facilitate packet transfers. Additionally, we divided up the packet into categories based on priority. The priority of the packet is determined by the naming criterion. In terms of the overall number of Interests and content retrieval time, the findings show that NAB A performs better than native NDN floods. © 2022 IEEE.","FANET; IoT; NDN; SDN; UAV","Ad hoc networks; Internet of things; Military applications; Network architecture; Storms; Ad-hoc networks; Broadcast storm; Flying ad hoc network; Internet Standard; IoT; Named data networks; Network-based; Scientific community; Software-defined networks; TCP/IP protocol; Unmanned aerial vehicles (UAV)"
"Attkan A., Ranga V.","Cyber-physical security for IoT networks: a comprehensive review on traditional, blockchain and artificial intelligence based key-security","10.1007/s40747-022-00667-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130967343&doi=10.1007%2fs40747-022-00667-z&partnerID=40&md5=58dc42823d0c6c1e6749a7b01f312f9e","The recent years have garnered huge attention towards the Internet of Things (IoT) because it enables its consumers to improve their lifestyles and professionally keep up with the technological advancements in the cyber-physical world. The IoT edge devices are heterogeneous in terms of the technology they are built on and the storage file formats used. These devices require highly secure modes of mutual authentication to authenticate each other before actually sending the data. Mutual authentication is a very important aspect of peer-to-peer communication. Secure session keys enable these resource-constrained devices to authenticate each other. After successful authentication, a device can be authorized and can be granted access to shared resources. The need for validating a device requesting data transfer to avoid data privacy breaches that may compromise confidentiality and integrity. Blockchain and artificial intelligence (AI) both are extensively being used as an integrated part of IoT networks for security enhancements. Blockchain provides a decentralized mechanism to store validated session keys that can be allotted to the network devices. Blockchain is also used to load balance the stressing edge devices during low battery levels. AI on the other hand provides better learning and adaptiveness towards IoT attacks. The integration of newer technologies in IoT key management yields enhanced security features. In this article, we systematically survey recent trending technologies from an IoT security point of view and discuss traditional key security mechanisms. This article delivers a comprehensive quality study for researchers on authentication and session keys, integrating IoT with blockchain and AI-based authentication in cybersecurity. © 2022, The Author(s).","Artificial intelligence; Authentication; Authorization; Blockchain; Cyber-physical systems; IoT security; Key distribution; Key management system; Sensor networks; Session key",
"Ávila M.M., Durán M.L., Caballero D., Antequera T., Palacios-Pérez T., Cernadas E., Fernández-Delgado M.","Magnetic Resonance Imaging, texture analysis and regression techniques to non-destructively predict the quality characteristics of meat pieces","10.1016/j.engappai.2019.03.026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063961208&doi=10.1016%2fj.engappai.2019.03.026&partnerID=40&md5=f3fbd5b85d4793421a6fdc92e41e67bb","The quality of meat products is traditionally assessed by chemical or sensorial analysis, which are time consuming, need specialized technicians and destroy the products. The development of new technologies to monitor meat pieces using non-destructive methods in order to establish their quality is earning importance in the last years. An increasing number of studies have been carried out on meat pieces combining Magnetic Resonance Imaging (MRI), texture descriptors and regression techniques to predict several physico-chemical or sensorial attributes of the meat, mainly different types of pig ham and loins. In spite of the importance of the problem, the conclusions of these works are still preliminary because they only use the most classical texture descriptors and regressors instead of stronger methods, and because the methodology used to measure the performance is optimistic. In this work, we test a wide range of texture analysis techniques and regression methods using a realistic methodology to predict several physico-chemical and sensorial attributes of different meat pieces of Iberian pigs. The texture descriptors include statistical techniques, like Haralick descriptors, local binary patterns, fractal features and frequential descriptors, like Gabor or wavelet features. The regression techniques include linear regressors, neural networks, deep learning, support vector machines, regression trees, ensembles, boosting machines and random forests, among others. We developed experiments using 15 texture feature vectors, 28 regressors over 4 datasets of Iberian pig meat pieces to predict 39 physico-chemical and sensorial attributes, summarizing 16,380 experiments. There is not any combination of texture vector and regressor which provides the best result for all attributes tested. Nevertheless, all these experiments provided the following conclusions: (1) the regressor performance, measured using the squared correlation (R 2 ), is from good to excellent (above 0.5625) for 29 out of 39 attributes tested; (2) the WAPE (Weighted Absolute Percent Error) is lower than 2% for 32 out of 37 attributes; (3) the dispersion in computer predictions around the true attributes is lower or similar than the dispersion in the labeling expert's for the majority of attributes (85%); and (4) differences between predicted and true values are not statistically significant for 29 out of 37 attributes using the Wilcoxon ranksum statistical test. We can conclude that these results provide a high reliability for an automatic system to predict the quality of meat pieces, which may operate on-line in the meat industries in the future. © 2019 Elsevier Ltd","Fractal descriptors; Gabor filters; Local binary patterns; Magnetic resonance imaging; Meat products; Regression methods; Texture classification; Wavelet transform","Chemical analysis; Decision trees; Deep learning; Forecasting; Fractals; Gabor filters; Magnetic resonance imaging; Magnetism; Mammals; Meats; Nondestructive examination; Regression analysis; Resonance; Textures; Wavelet transforms; Descriptors; Local binary patterns; Meat products; Regression method; Texture classification; Quality control"
"Awan K.A., Din I.U., Almogren A., Almajed H.","Agritrust—a trust management approach for smart agriculture in cloud-based internet of agriculture things","10.3390/s20216174","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094827036&doi=10.3390%2fs20216174&partnerID=40&md5=adad1c45557aa5394a98ec28346c528d","Internet of Things (IoT) provides a diverse platform to automate things where smart agriculture is one of the most promising concepts in the field of Internet of Agriculture Things (IoAT). Due to the requirements of more processing power for computations and predictions, the concept of Cloud-based smart agriculture is proposed for autonomic systems. This is where digital innovation and technology helps to improve the quality of life in the area of urbanization expansion. For the integration of cloud in smart agriculture, the system is shown to have security and privacy challenges, and most significantly, the identification of malicious and compromised nodes along with a secure transmission of information between sensors, cloud, and base station (BS). The identification of malicious and compromised node among soil sensors communicating with the BS is a notable challenge in the BS to cloud communications. The trust management mechanism is proposed as one of the solutions providing a lightweight approach to identify these nodes. In this article, we have proposed a novel trust management mechanism to identify malicious and compromised nodes by utilizing trust parameters. The trust mechanism is an event-driven process that computes trust based on the pre-defined time interval and utilizes the previous trust degree to develop an absolute trust degree. The system also maintains the trust degree of a BS and cloud service providers using distinct approaches. We have also performed extensive simulations to evaluate the performance of the proposed mechanism against several potential attacks. In addition, this research helps to create friendlier environments and efficient agricultural productions for the migration of people to the cities. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Digital innovation; Internet of Agriculture Things; Privacy; Smart irrigation system; Trust management; Urbanization","Agricultural robots; Agriculture; Internet of things; Network security; Privacy by design; Agricultural productions; Cloud communications; Cloud service providers; Digital innovations; Extensive simulations; Internet of Things (IOT); Secure transmission; Security and privacy; Trusted computing"
"Ayres L.B., Gomez F.J.V., Linton J.R., Silva M.F., Garcia C.D.","Taking the leap between analytical chemistry and artificial intelligence: A tutorial review","10.1016/j.aca.2021.338403","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103009115&doi=10.1016%2fj.aca.2021.338403&partnerID=40&md5=136adc6e7007ebfb207d2c090473a2cb","The last 10 years have witnessed the growth of artificial intelligence into different research areas, emerging as a vibrant discipline with the capacity to process large amounts of information and even intuitively interact with humans. In the chemical world, these innovations in both hardware and algorithms have allowed the development of revolutionary approaches in organic synthesis, drug discovery, and materials’ design. Despite these advances, the use of AI to support analytical purposes has been mostly limited to data-intensive methodologies linked to image recognition, vibrational spectroscopy, and mass spectrometry but not to other technologies that, albeit simpler, offer promise of greatly enhanced analytics now that AI is becoming mature enough to take advantage of them. To address the imminent opportunity of analytical chemists to use AI, this tutorial review aims to serve as a first step for junior researchers considering integrating AI into their programs. Thus, basic concepts related to AI are first discussed followed by a critical assessment of representative reports integrating AI with various sensors, spectroscopies, and separation techniques. For those with the courage (and the time) needed to get started, the review also provides a general sequence of steps to begin integrating AI into their programs. © 2021 Elsevier B.V.","Analytical; Artificial intelligence; Deep learning; Sensors; Spectroscopy","Chemical analysis; Deep learning; Image enhancement; Image recognition; Mass spectrometry; Amount of information; Analytical; Data intensive; Deep learning; Drug discovery; Drug materials; Large amounts; Materials design; Organic synthesis; Research areas; Spectroscopy; algorithm; artificial intelligence; artificial neural network; boosting algorithm; chemistry; colorimetry; k nearest neighbor; mass spectrometry; priority journal; random forest; reinforcement learning (machine learning); Review; separation technique; supervised machine learning; support vector machine; unsupervised machine learning; vibrational spectroscopy"
"Babu K.-E.-K.","Artificial intelligence in Bangladesh, its applications in different sectors and relevant challenges for the government: An analysis","10.1504/IJPLAP.2021.118891","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119486010&doi=10.1504%2fIJPLAP.2021.118891&partnerID=40&md5=6303b9415f1ed50679feb2a0bf178baa","Once upon a time, Bangladesh was dependent only on agriculture but with the change of time, the advent of advanced technology has taken place in every field of this country. Automation and control technology is being applied in various industries and artificial intelligence, IoT, big data, blockchain, etc. has become very popular here. For the effective implementation of AI, several specific sectors have been identified here where we see extensive use of AI technologies. For implementing AI technology, Bangladesh government should have to undertake huge preparation where there will be many challenges if the technology is adopted without any proper preparation. The paper briefly discusses the current technological situations in Bangladesh, the concept of AI, its applications in different sectors, and the relevant challenges. The paper also suggests the steps to be taken in the use of AI technology to maintain certain aspects i.e., policy, information privacy, security, and regulations. Copyright © 2021 Inderscience Enterprises Ltd.","4IR; Artificial intelligence; Bangladesh; Economic growth; Education; Fourth industrial revolution; Information technology; Smart mobility",
"Bachmann N., Tripathi S., Brunner M., Jodlbauer H.","The Contribution of Data-Driven Technologies in Achieving the Sustainable Development Goals","10.3390/su14052497","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125320818&doi=10.3390%2fsu14052497&partnerID=40&md5=a602d12c2614270690909f422e2a97e2","The United Nations’ Sustainable Development Goals (SDGs) set out to improve the quality of life of people in developed, emerging, and developing countries by covering social and economic aspects, with a focus on environmental sustainability. At the same time, data-driven technologies influence our lives in all areas and have caused fundamental economical and societal changes. This study presents a comprehensive literature review on how data-driven approaches have enabled or inhibited the successful achievement of the 17 SDGs to date. Our findings show that data-driven analytics and tools contribute to achieving the 17 SDGs, e.g., by making information more reliable, supporting better-informed decision-making, implementing data-based policies, prioritizing actions, and optimizing the allocation of resources. Based on a qualitative content analysis, results were aggregated into a conceptual framework, including the following categories: (1) uses of data-driven methods (e.g., monitoring, measurement, mapping or modeling, forecasting, risk assessment, and planning purposes), (2) resulting positive effects, (3) arising challenges, and (4) recommendations for action to overcome these challenges. Despite positive effects and versatile applications, problems such as data gaps, data biases, high energy consumption of computational resources, ethical concerns, privacy, ownership, and security issues stand in the way of achieving the 17 SDGs. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence (AI); Big data; Data-driven; Deep learning (DL); Internet of Things (IoT); Machine learning (ML); Sustainable development goals (SDG)","advanced technology; artificial intelligence; Internet; machine learning; Sustainable Development Goal"
"Backholer K., Baum F., Finlay S.M., Friel S., Giles-Corti B., Jones A., Patrick R., Shill J., Townsend B., Armstrong F., Baker P., Bowen K., Browne J., Büsst C., Butt A., Canuto K., Canuto K., Capon A., Corben K., Daube M., Goldfeld S., Grenfell R., Gunn L., Harris P., Horton K., Keane L., Lacy-Nichols J., Lo S.N., Lovett R.W., Lowe M., Martin J.E., Neal N., Peeters A., Pettman T., Thoms A., Thow A.M.T., Timperio A., Williams C., Wright A., Zapata-Diomedi B., Demaio S.","Australia in 2030: what is our path to health for all?","10.5694/mja2.51020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105030886&doi=10.5694%2fmja2.51020&partnerID=40&md5=b0e8f243e5557cdab73f9165d726c401","Chapter 1: How Australia improved health equity through action on the social determinants of health: Do not think that the social determinants of health equity are old hat. In reality, Australia is very far away from addressing the societal level drivers of health inequity. There is little progressive policy that touches on the conditions of daily life that matter for health, and action to redress inequities in power, money and resources is almost non-existent. In this chapter we ask you to pause this reality and come on a fantastic journey where we envisage how COVID-19 was a great disruptor and accelerator of positive progressive action. We offer glimmers of what life could be like if there was committed and real policy action on the social determinants of health equity. It is vital that the health sector assists in convening the multisectoral stakeholders necessary to turn this fantasy into reality. Chapter 2: Aboriginal and Torres Strait Islander connection to culture: building stronger individual and collective wellbeing: Aboriginal and Torres Strait Islander peoples have long maintained that culture (ie, practising, maintaining and reclaiming it) is vital to good health and wellbeing. However, this knowledge and understanding has been dismissed or described as anecdotal or intangible by Western research methods and science. As a result, Aboriginal and Torres Strait Islander culture is a poorly acknowledged determinant of health and wellbeing, despite its significant role in shaping individuals, communities and societies. By extension, the cultural determinants of health have been poorly defined until recently. However, an increasing amount of scientific evidence supports what Aboriginal and Torres Strait Islander people have always said — that strong culture plays a significant and positive role in improved health and wellbeing. Owing to known gaps in knowledge, we aim to define the cultural determinants of health and describe their relationship with the social determinants of health, to provide a full understanding of Aboriginal and Torres Strait Islander wellbeing. We provide examples of evidence on cultural determinants of health and links to improved Aboriginal and Torres Strait Islander health and wellbeing. We also discuss future research directions that will enable a deeper understanding of the cultural determinants of health for Aboriginal and Torres Strait Islander people. Chapter 3: Physical determinants of health: healthy, liveable and sustainable communities: Good city planning is essential for protecting and improving human and planetary health. Until recently, however, collaboration between city planners and the public health sector has languished. We review the evidence on the health benefits of good city planning and propose an agenda for public health advocacy relating to health-promoting city planning for all by 2030. Over the next 10 years, there is an urgent need for public health leaders to collaborate with city planners — to advocate for evidence-informed policy, and to evaluate the health effects of city planning efforts. Importantly, we need integrated planning across and between all levels of government and sectors, to create healthy, liveable and sustainable cities for all. Chapter 4: Health promotion in the Anthropocene: the ecological determinants of health: Human health is inextricably linked to the health of the natural environment. In this chapter, we focus on ecological determinants of health, including the urgent and critical threats to the natural environment, and opportunities for health promotion arising from the human health co-benefits of actions to protect the health of the planet. We characterise ecological determinants in the Anthropocene and provide a sobering snapshot of planetary health science, particularly the momentous climate change health impacts in Australia. We highlight Australia’s position as a major fossil fuel producer and exporter, and a country lacking cohesive and timely emissions reduction policy. We offer a roadmap for action, with four priority directions, and point to a scaffold of guiding approaches — planetary health, Indigenous people’s knowledge systems, ecological economics, health co-benefits and climate-resilient development. Our situation requires a paradigm shift, and this demands a recalibration of health promotion education, research and practice in Australia over the coming decade. Chapter 5: Disrupting the commercial determinants of health: Our vision for 2030 is an Australian economy that promotes optimal human and planetary health for current and future generations. To achieve this, current patterns of corporate practice and consumption of harmful commodities and services need to change. In this chapter, we suggest ways forward for Australia, focusing on pragmatic actions that can be taken now to redress the power imbalances between corporations and Australian governments and citizens. We begin by exploring how the terms of health policy making must change to protect it from conflicted commercial interests. We also examine how marketing unhealthy products and services can be more effectively regulated, and how healthier business practices can be incentivised. Finally, we make recommendations on how various public health stakeholders can hold corporations to account, to ensure that people come before profits in a healthy and prosperous future Australia. Chapter 6: Digital determinants of health: the digital transformation: We live in an age of rapid and exponential technological change. Extraordinary digital advancements and the fusion of technologies, such as artificial intelligence, robotics, the Internet of Things and quantum computing constitute what is often referred to as the digital revolution or the Fourth Industrial Revolution (Industry 4.0). Reflections on the future of public health and health promotion require thorough consideration of the role of digital technologies and the systems they influence. Just how the digital revolution will unfold is unknown, but it is clear that advancements and integrations of technologies will fundamentally influence our health and wellbeing in the future. The public health response must be proactive, involving many stakeholders, and thoughtfully considered to ensure equitable and ethical applications and use. Chapter 7: Governance for health and equity: a vision for our future: Coronavirus disease 2019 has caused many people and communities to take stock on Australia’s direction in relation to health, community, jobs, environmental sustainability, income and wealth. A desire for change is in the air. This chapter imagines how changes in the way we govern our lives and what we value as a society could solve many of the issues Australia is facing — most pressingly, the climate crisis and growing economic and health inequities. We present an imagined future for 2030 where governance structures are designed to ensure transparent and fair behaviour from those in power and to increase the involvement of citizens in these decisions, including a constitutional voice for Indigenous peoples. We imagine that these changes were made by measuring social progress in new ways, ensuring taxation for public good, enshrining human rights (including to health) in legislation, and protecting and encouraging an independent media. Measures to overcome the climate crisis were adopted and democratic processes introduced in the provision of housing, education and community development. © 2021 AMPCo Pty Ltd",,"Australia; commercial phenomena; environmental health; forecasting; health care planning; health equity; health promotion; human; indigenous health care; Oceanic ancestry group; social determinants of health; Australia; Commerce; Community Health Planning; Digital Technology; Environmental Health; Forecasting; Health Equity; Health Promotion; Health Services, Indigenous; Humans; Oceanic Ancestry Group; Social Determinants of Health"
"Badruddoja S., Dantu R., He Y., Thompson M., Salau A., Upadhyay K.","Trusted AI with Blockchain to Empower Metaverse","10.1109/BCCA55292.2022.9922027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142101823&doi=10.1109%2fBCCA55292.2022.9922027&partnerID=40&md5=2b50eb87381ddb17c44587fc22b454f7","The digital experience emerging in the virtual world is a reality with the advent of the metaverse. Augmented reality(AR), virtual reality(VR), extended reality(XR), and artificial intelligence(AI) algorithms would pave the way for an immersive experience for the users in the virtual space. However, the explosion of these technologies broaches new challenges to threaten the success of metaverse due to security risks. The blockchain technology augmented with AI promises to deliver a trusted metaverse for everyone. Nevertheless, smart contracts fail to produce a cognitive prediction, dissuading users from confiding in the metaverse. We arm smart contracts with intelligence to predict using AI algorithms. Moreover, we deploy the smart contracts on the Ethereum blockchain platform and produce a prediction accuracy of 95% compared to Python scikit-learn-based predictions. Our results show that the prediction delay can obstruct the growth of metaverse applications to accept blockchain technologies. Furthermore, the limitation of blockchain technology can make integration unreasonable. Therefore, we discuss possible scalability solutions that can be part of our future work to help more metaverse applications adopt blockchain solutions. © 2022 IEEE.","Artificial Intelligence; Blockchain; Decentralization; Digital Twin; Metaverse; Security; Smart Contracts; Trust","Artificial intelligence; Augmented reality; Blockchain; Forecasting; Virtual reality; Artificial intelligence algorithms; Block-chain; Decentralisation; Immersive; Metaverses; Security; Security risks; Trust; Virtual spaces; Virtual worlds; Smart contract"
"Baghel R., Sharma P.","Historical wheat yield mapping using time-series satellite data and district-wise yield statistics over Uttar Pradesh state, India","10.1016/j.rsase.2022.100808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133913241&doi=10.1016%2fj.rsase.2022.100808&partnerID=40&md5=80ac2884afb0e1af2eece95817af9fe7","Crop productivity has often been affected by undesirable climatic events such as heat stress, flood, unseasonal rainfall, drought, etc. Historical crop yield estimation and mapping shall provide a pivotal input for food security measures and planning purposes. The present study deployed various satellite (i.e., normalized difference vegetation index) and gridded (i.e., precipitation, temperature, evapotranspiration) products to portray the historical wheat yield at satellite pixel-level during 2001–2019 over the Uttar Pradesh state of India. Directorate of Economics and Statistics (DES) based district-wise wheat yield dataset was also used with satellite variables to develop the historical wheat yield model based on the multiple regression analysis. Spatially, higher, lower, and lower to moderate wheat yields are observed in the western and northwest parts, southern and southeast parts, and lower-middle to the lower right parts of the state respectively throughout the study years. Remarkably, the years 2017,2018, and 2019 witnessed higher yields, while 2004, 2006, 2007, 2008, and 2015 witnessed lower yield. The developed wheat yield models performed well, as R2 values were observed between 0.3 and 0.76 between the satellite-derived and DES-based district-wise mean yield. The mean absolute error was found to be considerable and ranged between 0.22 and 1.7 t/ha during the study years. The adopted methodology can be used across the different parts of the globe at the local to country scale for a quantitative crop yield depiction and mapping at the satellite pixel level. Such historical crop yield mapping can assist in understanding the long-term crop yield pattern in response to the climate change activity, and hence food security measures can be formulated and implemented. © 2022 Elsevier B.V.","Crop yield; MODIS; Multiple regression; NDVI; Satellite data",
"Balcombe L., De Leo D.","The Potential Impact of Adjunct Digital Tools and Technology to Help Distressed and Suicidal Men: An Integrative Review","10.3389/fpsyg.2021.796371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123766836&doi=10.3389%2ffpsyg.2021.796371&partnerID=40&md5=fd7484e0363c619553fb483ec27d6ec2","Suicidal men feel the need to be self-reliant and that they cannot find another way out of relationship or socioeconomic issues. Suicide prevention is of crucial importance worldwide. The much higher rate of suicide in men engenders action. The prelude is a subjective experience that can be very isolating and severely distressing. Men may not realize a change in their thinking and behaviors, which makes it more difficult to seek and get help, thereby interrupting a “downward spiral”. Stoicism often prevents men from admitting to their personal struggle. The lack of “quality” connections and “non-tailored” therapies has led to a high number of men “walking out” on traditional clinical approaches. But there are complicated relationships in motivations and formative behaviors of suicide with regards to emotional state, psychiatric disorders, interpersonal life events and suicidal behavior method selection. Middle-aged and older men have alternated as the most at-risk of suicide. There is no one solution that applies to all men, but digital tools may be of assistance (e.g., video conferences, social networks, telephone calls, and emails). Digital interventions require higher levels of effectiveness for distress and suicidality but self-guided approaches may be the most suitable for men especially where linked with an integrated online suicide prevention platform (e.g., quick response with online chats, phone calls, and emails). Furthermore, technology-enabled models of care offer promise to advance appropriate linking to mental health services through better and faster understanding of the specific needs of individuals (e.g., socio-cultural) and the type and level of suicidality experienced. Long-term evidence for suicidality and its evaluation may benefit from progressing human computer-interaction and providing impetus for an eminent integrated digital platform. Copyright © 2022 Balcombe and De Leo.","digital mental health interventions; digital tools and technology; high-risk and vulnerable men; human-computer interaction; integrated digital platform; self-help; suicide prevention; technology-enabled care",
"Balti H., Ben Abbes A., Mellouli N., Farah I.R., Sang Y., Lamolle M.","A review of drought monitoring with big data: Issues, methods, challenges and research directions","10.1016/j.ecoinf.2020.101136","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090328146&doi=10.1016%2fj.ecoinf.2020.101136&partnerID=40&md5=91c01dc6ee53f55937973b1dc742f5b3","Over recent years, the frequency and intensity of droughts have increased and there has been a large drying trend over many parts of the world. Consequently, drought monitoring using big data analytic has gained an explosive interest. Droughts stand among the most damaging natural disasters. It threatens agricultural production, ecological environment, and socio-economic development. For this reason, early warning, accurate evaluation, and efficient prediction are an emergency especially for the nations that are the most menaced by this danger. There are numerous emerging studies addressing big data and its applications in drought monitoring. In fact, big data handle data heterogeneity which is an additive value for the prediction of drought, it offers a view of the different dimensions such as the spatial distribution, the temporal distribution and the severity detection of this phenomenon. Big data analytic and drought are introduced and reviewed in this paper. Besides, this review includes different studies, researches and applications of big data to drought monitoring. Challenges related to data life cycle such as data challenges, data processing challenges and data infrastructure management challenges are also discussed. Finally, we conclude that big data analytic can be beneficial in drought monitoring but there is a need for statistical and artificial intelligence-based approaches. © 2020","Artificial intelligence; Big data; Drought monitoring; Machine learning; Remote sensing; Statistical approach","agricultural production; drought; early warning system; natural disaster; socioeconomic survey; spatial distribution"
"Banerjee P., Banerjee S., Barnwal R.P.","Explaining deep-learning models using gradient-based localization for reliable tea-leaves classifications","10.1109/ICAECC54045.2022.9716699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126732023&doi=10.1109%2fICAECC54045.2022.9716699&partnerID=40&md5=e9a985a76199fbd9612353be84a50ff2","In deep learning solutions there has been a lot of ambiguity about how to make explainability inclusive of a machine learning pipeline. Recently, several deep learning techniques have been introduced to solve increasingly complicated problems with higher predictive capacity. However, this predictive power comes at the cost of high computational complexity and difficult to interpret. While these models often produce very accurate predictions, we need to be able to explain the path followed by such models for decision making. Deep learning models, in general, predict with no or very less interpretable explanations. This lack of explainability makes such models blackbox. Explainable Artificial Intelligence (XAI) aims at transforming this black box approach into a more interpretable one. In this paper, we apply the well known Grad-CAM technique for the explainability of tea-leaf classification problem. The proposed method classifies tea-leaf-bud combinations using pre-trained deep learning models. We add classification explainability in our tea-leaf dataset using the pre-trained model as an input to the Grad-CAM technique to produce class-specific heatmap. We analyzed the results and working of the classification models for their reliability and effectiveness. © 2022 IEEE.","deep learning; explainable artificial intelligence; interpretability; reliability; tea-leaf","Cams; Decision making; Deep learning; Deep learning; Explainable artificial intelligence; Gradient based; Interpretability; Leaf classification; Learning models; Learning techniques; Localisation; Predictive capacity; Tea-leaves; Classification (of information)"
"Bankins S., Formosa P.","The Ethical Implications of Artificial Intelligence (AI) For Meaningful Work","10.1007/s10551-023-05339-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147769817&doi=10.1007%2fs10551-023-05339-7&partnerID=40&md5=ad4482b31f29a9f334dacf7f87165642","The increasing workplace use of artificially intelligent (AI) technologies has implications for the experience of meaningful human work. Meaningful work refers to the perception that one’s work has worth, significance, or a higher purpose. The development and organisational deployment of AI is accelerating, but the ways in which this will support or diminish opportunities for meaningful work and the ethical implications of these changes remain under-explored. This conceptual paper is positioned at the intersection of the meaningful work and ethical AI literatures and offers a detailed assessment of the ways in which the deployment of AI can enhance or diminish employees’ experiences of meaningful work. We first outline the nature of meaningful work and draw on philosophical and business ethics accounts to establish its ethical importance. We then explore the impacts of three paths of AI deployment (replacing some tasks, ‘tending the machine’, and amplifying human skills) across five dimensions constituting a holistic account of meaningful work, and finally assess the ethical implications. In doing so we help to contextualise the meaningful work literature for the era of AI, extend the ethical AI literature into the workplace, and conclude with a range of practical implications and future research directions. © 2023, The Author(s).","Artificial intelligence (AI); Ethical AI; Future of work; Meaningful work; Technology and work",
"Baouya A., Chehida S., Ouchani S., Bensalem S., Bozga M.","Generation and verification of learned stochastic automata using k-NN and statistical model checking","10.1007/s10489-021-02884-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118675894&doi=10.1007%2fs10489-021-02884-4&partnerID=40&md5=fb6916622ed900ef9b51dc9e3fe951bc","Deriving an accurate behavior model from historical data of a black box for verification and feature forecasting is seen by industry as a challenging issue especially for a large featured dataset. This paper focuses on an alternative approach where stochastic automata can be learned from time-series observations captured from a set of deployed sensors. The main advantage offered by such techniques is that they enable analysis and forecasting from a formal model instead of traditional learning methods. We perform statistical model checking to analyze the learned automata by expressing temporal properties. For this purpose, we consider a critical water infrastructure that provides a scenario based on a set of input and output values of heterogeneous sensors to regulate the dam spill gates. The method derives a consistent approximate model with traces collected over thirty years. The experiments show that the model provides not only an approximation of the desired output of a feature value but, also, forecasts the ebb and flow of the sensed data. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Learning automata; Sensors; Statistical model checking; Stochastic automata; Temporal logic","Automata theory; Large dataset; Learning systems; Model checking; Nearest neighbor search; Stochastic models; Stochastic systems; Behaviour models; Black boxes; Formal modeling; Historical data; Learning Automata; Learning methods; Statistical model checking; Stochastic Automata; Times series; Traditional learning; Forecasting"
"Baraldi A., Sapia L.D., Tiede D., Sudmanns M., Augustin H.L., Lang S.","Innovative Analysis Ready Data (ARD) product and process requirements, software system design, algorithms and implementation at the midstream as necessary-but-not-sufficient precondition of the downstream in a new notion of Space Economy 4.0 - Part 1: Problem background in Artificial General Intelligence (AGI)","10.1080/20964471.2021.2017549","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139868089&doi=10.1080%2f20964471.2021.2017549&partnerID=40&md5=28695c7a015fbb833091c49a8fed1f58","Aiming at the convergence between Earth observation (EO) Big Data and Artificial General Intelligence (AGI), this two-part paper identifies an innovative, but realistic EO optical sensory image-derived semantics-enriched Analysis Ready Data (ARD) product-pair and process gold standard as linchpin for success of a new notion of Space Economy 4.0. To be implemented in operational mode at the space segment and/or midstream segment by both public and private EO big data providers, it is regarded as necessary-but-not-sufficient “horizontal” (enabling) precondition for: (I) Transforming existing EO big raster-based data cubes at the midstream segment, typically affected by the so-called data-rich information-poor syndrome, into a new generation of semantics-enabled EO big raster-based numerical data and vector-based categorical (symbolic, semi-symbolic or subsymbolic) information cube management systems, eligible for semantic content-based image retrieval and semantics-enabled information/knowledge discovery. (II) Boosting the downstream segment in the development of an ever-increasing ensemble of “vertical” (deep and narrow, user-specific and domain-dependent) value–adding information products and services, suitable for a potentially huge worldwide market of institutional and private end-users of space technology. For the sake of readability, this paper consists of two parts. In the present Part 1, first, background notions in the remote sensing metascience domain are critically revised for harmonization across the multi-disciplinary domain of cognitive science. In short, keyword “information” is disambiguated into the two complementary notions of quantitative/unequivocal information-as-thing and qualitative/equivocal/inherently ill-posed information-as-data-interpretation. Moreover, buzzword “artificial intelligence” is disambiguated into the two better-constrained notions of Artificial Narrow Intelligence as part-without-inheritance-of AGI. Second, based on a better-defined and better-understood vocabulary of multidisciplinary terms, existing EO optical sensory image-derived Level 2/ARD products and processes are investigated at the Marr five levels of understanding of an information processing system. To overcome their drawbacks, an innovative, but realistic EO optical sensory image-derived semantics-enriched ARD product-pair and process gold standard is proposed in the subsequent Part 2. © 2022 The Author(s). Published by Taylor & Francis Group and Science Press on behalf of the International Society for Digital Earth, supported by the International Research Center of Big Data for Sustainable Development Goals, and CASEarth Strategic Priority Research Programme.","2D spatial topology-preserving/retinotopic image mapping; Analysis Ready Data; Artificial General Intelligence; Artificial Narrow Intelligence; big data; cognitive science; computer vision; Earth observation; essential climate variables; Global Earth Observation System of (component) Systems; inductive/ deductive/ hybrid inference; radiometric corrections of optical imagery from atmospheric, topographic, adjacency and bidirectional reflectance distribution function effects; Scene Classification Map; semantic content-based image retrieval; Space Economy 4.0; world ontology (synonym for conceptual/ mental/ perceptual model of the world)","Climate change; Computer vision; Conceptual design; Distribution functions; Earth (planet); Image analysis; Information management; Metadata; Observatories; Optical remote sensing; Product design; Search engines; Semantics; 2d spatial topology-preserving/retinotopic image mapping; Analyse ready data; Artificial general intelligences; Artificial narrow intelligence; Bidirectional reflectance distribution function effects; Classification maps; Climate variables; Cognitive science; Component systems; Earth observations; Essential climate variable; Global earth observation system of (component) system; Global Earth Observation Systems; Hybrid inference; Image mapping; Inductive/ deductive/ hybrid inference; Ontology's; Optical imagery; Perceptual modelling; Radiometric correction of optical imagery from atmospheric, topographic, adjacency and bidirectional reflectance distribution function effect; Radiometric corrections; Scene classification; Scene classification map; Semantic content-based image retrieval; Space economy 4.0; Spatial topologies; Topology preserving; World ontology (synonym for conceptual/ mental/ perceptual model of the world); Big data"
"Baraldi A., Sapia L.D., Tiede D., Sudmanns M., Augustin H., Lang S.","Innovative Analysis Ready Data (ARD) product and process requirements, software system design, algorithms and implementation at the midstream as necessary-but-not-sufficient precondition of the downstream in a new notion of Space Economy 4.0 - Part 2: Software developments","10.1080/20964471.2021.2017582","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139839040&doi=10.1080%2f20964471.2021.2017582&partnerID=40&md5=a0411c2e0e75091e1edc0c11c487b509","Aiming at the convergence between Earth observation (EO) Big Data and Artificial General Intelligence (AGI), this paper consists of two parts. In the previous Part 1, existing EO optical sensory image-derived Level 2/Analysis Ready Data (ARD) products and processes are critically compared, to overcome their lack of harmonization/ standardization/ interoperability and suitability in a new notion of Space Economy 4.0. In the present Part 2, original contributions comprise, at the Marr five levels of system understanding: (1) an innovative, but realistic EO optical sensory image-derived semantics-enriched ARD co-product pair requirements specification. First, in the pursuit of third-level semantic/ontological interoperability, a novel ARD symbolic (categorical and semantic) co-product, known as Scene Classification Map (SCM), adopts an augmented Cloud versus Not-Cloud taxonomy, whose Not-Cloud class legend complies with the standard fully-nested Land Cover Classification System’s Dichotomous Phase taxonomy proposed by the United Nations Food and Agriculture Organization. Second, a novel ARD subsymbolic numerical co-product, specifically, a panchromatic or multi-spectral EO image whose dimensionless digital numbers are radiometrically calibrated into a physical unit of radiometric measure, ranging from top-of-atmosphere reflectance to surface reflectance and surface albedo values, in a five-stage radiometric correction sequence. (2) An original ARD process requirements specification. (3) An innovative ARD processing system design (architecture), where stepwi se SCM generation and stepwise SCM-conditional EO optical image radiometric correction are alternated in sequence. (4) An original modular hierarchical hybrid (combined deductive and inductive) computer vision subsystem design, provided with feedback loops, where software solutions at the Marr two shallowest levels of system understanding, specifically, algorithm and implementation, are selected from the scientific literature, to benefit from their technology readiness level as proof of feasibility, required in addition to proven suitability. To be implemented in operational mode at the space segment and/or midstream segment by both public and private EO big data providers, the proposed EO optical sensory image-derived semantics-enriched ARD product-pair and process reference standard is highlighted as linchpin for success of a new notion of Space Economy 4.0. © 2022 The Author(s). Published by Taylor & Francis Group and Science Press on behalf of the International Society for Digital Earth, supported by the International Research Center of Big Data for Sustainable Development Goals, and CASEarth Strategic Priority Research Programme.","2D spatial topology-preserving/retinotopic image mapping; Analysis Ready Data; Artificial General Intelligence; Artificial Narrow Intelligence; big data; cognitive science; computer vision; Earth observation; essential climate variables; Global Earth Observation System of (component) Systems; inductive/ deductive/ hybrid inference; radiometric corrections of optical imagery from atmospheric, topographic, adjacency and bidirectional reflectance distribution function effects; Scene Classification Map; semantic content-based image retrieval; Space Economy 4.0; world ontology (synonym for conceptual/ mental/ perceptual model of the world)","Big data; Computer vision; Distribution functions; Earth (planet); Image analysis; Product design; Reflection; Search engines; Specifications; Systems analysis; Taxonomies; 2d spatial topology-preserving/retinotopic image mapping; Analyse ready data; Artificial general intelligences; Artificial narrow intelligence; Bidirectional reflectance distribution function effects; Classification maps; Climate variables; Cognitive science; Component systems; Earth observations; Essential climate variable; Global earth observation system of (component) system; Global Earth Observation Systems; Hybrid inference; Image mapping; Inductive/ deductive/ hybrid inference; Ontology's; Optical imagery; Perceptual modelling; Radiometric correction of optical imagery from atmospheric, topographic, adjacency and bidirectional reflectance distribution function effect; Radiometric corrections; Scene classification; Scene classification map; Semantic content-based image retrieval; Space economy 4.0; Spatial topologies; Topology preserving; World ontology (synonym for conceptual/ mental/ perceptual model of the world); Semantics"
"Barbaresi A., Ceccarelli M., Menichetti G., Torreggiani D., Tassinari P., Bovo M.","Application of Machine Learning Models for Fast and Accurate Predictions of Building Energy Need","10.3390/en15041266","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124545222&doi=10.3390%2fen15041266&partnerID=40&md5=a42369ff35470098db12afb5a46bcfc1","Accurate prediction of building energy need plays a fundamental role in building design, despite the high computational cost to search for optimal energy saving solutions. An important advancement in the reduction of computational time could come from the application of machine learning models to circumvent energy simulations. With the goal of drastically limiting the number of simulations, in this paper we investigate the regression performance of different machine learning models, i.e., Support Vector Machine, Random Forest, and Extreme Gradient Boosting, trained on a small data-set of energy simulations performed on a case study building. Among the XX algorithms, the tree-based Extreme Gradient Boosting showed the best performance. Overall, we find that machine learning methods offer efficient and interpretable solutions, that could help academics and professionals in shaping better design strategies, informed by feature importance. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Building energy saving solutions; Building energy simulation; Machine learning; Optimisation algorithms","Adaptive boosting; Architectural design; Energy conservation; Support vector machines; Accurate prediction; Building energy; Building energy saving; Building energy saving solution; Building energy simulations; Energy needs; Energy simulation; Machine learning models; Optimization algorithms; Performance; Decision trees"
"Barbosa L.A.P., Gerke H.H.","Structural heterogeneity of soil clods: Correlating Weibull parameters to fracture surface topography","10.1016/j.geoderma.2022.116161","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138108119&doi=10.1016%2fj.geoderma.2022.116161&partnerID=40&md5=d535304adc597878611dc312348e3fab","Planes of weakness (i.e. cracks) existing in the soil matrix propagate, creating fracture surfaces and fragmenting the clod into smaller clods. The cracking process defines the fracture topography (i.e., roughness) that control many processes from flow exchange between macropore and matrix to local carbon storage and turnover. To date, useful relations between the surface topography of fractures and hydro-mechanical soil properties are missing because of technical and conceptual limitations. The objective was to test the assumption that the Weibull modulus of clod tensile strength can be related to the surface topography of fractures that resulted from the breakage of standardized soil clods. For carrying out standardized indirect tensile strength tests, a tension testing machine was constructed to prompt and monitor aggregate rupture. A total of 280 clods of 4 size-classes from two contrasting soils were considered. Clods were from the finer-textured Bt horizon of a Haplic Luvisol and the coarser-textured C horizon with lower amount of organic compounds of a Haplic Regosol. The natural clods were standardized in a cylindrical shape, in order to capture differences in the structural heterogeneity in terms of particle binding forces and porosity quantified by the Weibull modulus (m) of tensile strength. The stronger hierarchical organisation of the structure was quantified by smaller values of m (Bt: 3.1 vs C: 3.6) and the mass fractal dimension (Bt: 2.93 vs C: 2.98), and by higher values of the friability (m−1) (Bt: 0.14 vs C: 0.06). From these results, the random forest ensemble learning algorithm showed that the spatial heterogeneity of the organo-mineral pore coating (O-M) (shape factor of frequency distribution Bt: 0.58 vs C: 0.69), and not the organic carbon content (OC) (Bt: 0.48 vs C: 0.1 %), was the most important variable for predicting tensile strength (importance O-M: 0.21 vs OC: 0.09). Furthermore, the greater the spatial heterogeneity of the clod (m values ca. 1.4 for Bt) the lower the fracture surface roughness (ca. 1.8 µm2 µm−2) when compared to a more homogeneous clod (m values ca. 3.6, fracture surface roughness ca. 2.7 µm2 µm−2 for C). According to the random forest ensemble learning algorithm, porosity was the most important variable (variable importance 0.95) for predicting the rupture surface roughness followed by the spatial heterogeneity of the organo-mineral pore coatings, water content, and soil texture. Fracture surface roughness decreased when increasing porosity or decreasing the shape factor of the frequency distribution of organo-mineral coatings. Results confirmed that the Weibull modulus of clod tensile strength can be related with clod fracture surface roughness resulting from standardized clod breakage tests. This sheds light on the Weibull modulus as a distinct macro property for linking soil hydraulic and mechanical properties. This is of special importance in the parameterization of coupled models that combine the spatial heterogeneity of soil physical properties with the effects of hydrostatic forces on the soil structure. © 2022 Elsevier B.V.","Clod fragmentation; Crack roughness; Fracture surface; Organo-mineral binding agents","Aggregates; Decision trees; Fractal dimension; Fracture; Organic carbon; Soil testing; Soils; Surface roughness; Tensile strength; Tensile testing; Textures; Topography; Clod fragmentation; Crack roughness; Fracture surfaces; Mineral binding agents; Organo-mineral binding agent; Random forests; Soil clods; Spatial heterogeneity; Structural heterogeneity; Weibull modulus; Cracks; carbon storage; fracture; heterogeneity; organic carbon; parameterization; tensile strength"
"Barman U., Choudhury R.D.","Smartphone image based digital chlorophyll meter to estimate the value of citrus leaves chlorophyll using Linear Regression, LMBP-ANN and SCGBP-ANN","10.1016/j.jksuci.2020.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079039621&doi=10.1016%2fj.jksuci.2020.01.005&partnerID=40&md5=251771942ff41632188b6ad3562c81e3","The chlorophyll of leaf can be determined using soil plant analysis development meter or spectrophometer by agriculture scientists, agriculture experts, and farmers. Usually, these methods are very costly and may not be available to all the farmers and experts. Low greenness of leaf indicates low photosynthesis in the plant and it creates many problems in the plant. This paper forwards a low-cost smartphone image-based digital chlorophyll meter to predict the chlorophyll of citrus leaf. The chlorophyll of citrus leaf is predicted using Linear Regression (LR) and Artificial Neural Network (ANN). Here, ANN provides more accuracy as compared to LR in citrus chlorophyll prediction. Both methods are validated with the actual chlorophyll of the citrus leaf. The proposed method can be used as a reasonable method for chlorophyll prediction of citrus. © 2020 The Authors","ANN; Chlorophyll; Image processing; Linear Regression; SPAD; Spectrophotometer",
"Barredo-Arrieta A., Del Ser J.","Plausible Counterfactuals: Auditing Deep Learning Classifiers with Realistic Adversarial Examples","10.1109/IJCNN48605.2020.9206728","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093831442&doi=10.1109%2fIJCNN48605.2020.9206728&partnerID=40&md5=9f853cfc3395e8118548c6e16f13ebe1","The last decade has witnessed the proliferation of Deep Learning models in many applications, achieving unrivaled levels of predictive performance. Unfortunately, the black-box nature of Deep Learning models has posed unanswered questions about what they learn from data. Certain application scenarios have highlighted the importance of assessing the bounds under which Deep Learning models operate, a problem addressed by using assorted approaches aimed at audiences from different domains. However, as the focus of the application is placed more on non-expert users, it results mandatory to provide the means for him/her to trust the model, just like a human gets familiar with a system or process: by understanding the hypothetical circumstances under which it fails. This is indeed the angular stone for this research work: to undertake an adversarial analysis of a Deep Learning model. The proposed framework constructs counterfactual examples by ensuring their plausibility, e.g. there is a reasonable probability that a human could generate them without resorting to a computer program. Therefore, this work must be regarded as valuable auditing exercise of the usable bounds a certain model is constrained within, thereby allowing for a much greater understanding of the capabilities and pitfalls of a model used in a real application. To this end, a Generative Adversarial Network (GAN) and multi-objective heuristics are used to furnish a plausible attack to the audited model, efficiently trading between the confusion of this model, the intensity and plausibility of the generated counterfactual. Its utility is showcased within a human face classification task, unveiling the enormous potential of the proposed framework. © 2020 IEEE.","Counterfactuals; Deep Learning; Explainable Artificial Intelligence; Generative Adversarial Networks; Meta-heuristics; Multiobjective Optimization","Learning systems; Neural networks; Adversarial networks; Application scenario; Counterfactuals; Different domains; Learning classifiers; Multi objective; Predictive performance; Real applications; Deep learning"
"Barua L., Zou B., Zhou Y., Liu Y.","Modeling household online shopping demand in the U.S.: a machine learning approach and comparative investigation between 2009 and 2017","10.1007/s11116-021-10250-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120451766&doi=10.1007%2fs11116-021-10250-z&partnerID=40&md5=73cd8063732744bf87200ab57b55c142","Despite the rapid growth of online shopping and research interest in the relationship between online and in-store shopping, national-level modeling and investigation of the demand for online shopping with a prediction focus remain limited in the literature. This paper differs from prior work and leverages two recent releases of the U.S. National Household Travel Survey (NHTS) data for 2009 and 2017 to develop machine learning (ML) models, specifically gradient boosting machine (GBM), for predicting household-level online shopping purchases. The NHTS data allow for not only conducting nationwide investigation but also at the level of households, which is more appropriate than at the individual level given the connected consumption and shopping needs of members in a household. We follow a systematic procedure for model development including employing Recursive Feature Elimination algorithm to select input variables (features) in order to reduce the risk of model overfitting and increase model explainability. Among several ML models, GBM is found to yield the best prediction accuracy. Extensive post-modeling investigation is conducted in a comparative manner between 2009 and 2017, including quantifying the importance of each input variable in predicting online shopping demand, and characterizing value-dependent relationships between demand and the input variables. In doing so, two latest advances in machine learning techniques, namely Shapley value-based feature importance and Accumulated Local Effects plots, are adopted to overcome inherent drawbacks of the popular techniques in current ML modeling. The modeling and investigation are performed at the national level, with a number of findings obtained. The models developed and insights gained can be used for online shopping-related freight demand generation and may also be considered for evaluating the potential impact of relevant policies on online shopping demand. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Accumulated local effects; Gradient boosting machine; National Household Travel Survey; Online shopping demand; Prediction; Shapley value-based feature importance","Adaptive boosting; Electronic commerce; Game theory; Machine learning; Surveys; Accumulated local effect; Gradient boosting; Gradient boosting machine; Local effects; National household travel surveys; Online shopping; Online shopping demand; Shapley value; Shapley value-based feature importance; Value-based; Forecasting"
"Barua P.D., Tuncer I., Aydemir E., Faust O., Chakraborty S., Subbhuraam V., Tuncer T., Dogan S., Acharya U.R.","L-Tetrolet Pattern-Based Sleep Stage Classification Model Using Balanced EEG Datasets","10.3390/diagnostics12102510","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140576823&doi=10.3390%2fdiagnostics12102510&partnerID=40&md5=2e471ed413f04562fcc5072b24f2227d","Background: Sleep stage classification is a crucial process for the diagnosis of sleep or sleep-related diseases. Currently, this process is based on manual electroencephalogram (EEG) analysis, which is resource-intensive and error-prone. Various machine learning models have been recommended to standardize and automate the analysis process to address these problems. Materials and methods: The well-known cyclic alternating pattern (CAP) sleep dataset is used to train and test an L-tetrolet pattern-based sleep stage classification model in this research. By using this dataset, the following three cases are created, and they are: Insomnia, Normal, and Fused cases. For each of these cases, the machine learning model is tasked with identifying six sleep stages. The model is structured in terms of feature generation, feature selection, and classification. Feature generation is established with a new L-tetrolet (Tetris letter) function and multiple pooling decomposition for level creation. We fuse ReliefF and iterative neighborhood component analysis (INCA) feature selection using a threshold value. The hybrid and iterative feature selectors are named threshold selection-based ReliefF and INCA (TSRFINCA). The selected features are classified using a cubic support vector machine. Results: The presented L-tetrolet pattern and TSRFINCA-based sleep stage classification model yield 95.43%, 91.05%, and 92.31% accuracies for Insomnia, Normal dataset, and Fused cases, respectively. Conclusion: The recommended L-tetrolet pattern and TSRFINCA-based model push the envelope of current knowledge engineering by accurately classifying sleep stages even in the presence of sleep disorders. © 2022 by the authors.","EEG signal classification; insomnia; L-tetrolet pattern; multiple pooling decomposition; sleep stage expert system","adolescent; adult; aged; algorithm; analytic method; Article; classification algorithm; clinical decision support system; controlled study; diagnostic accuracy; electroencephalography; feature selection; female; histogram; human; information processing; insomnia; l tetrolet pattern; machine learning; major clinical study; male; mathematical analysis; nonREM sleep; polysomnography; sensitivity and specificity; sleep pattern; sleep stage; support vector machine; threshold selection based relieff and iterative neighborhood component analysis"
"Baryannis G., Dani S., Antoniou G.","Predicting supply chain risks using machine learning: The trade-off between performance and interpretability","10.1016/j.future.2019.07.059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069864648&doi=10.1016%2fj.future.2019.07.059&partnerID=40&md5=3a2030d6a447fd5f2297f7f664836273","Managing supply chain risks has received increased attention in recent years, aiming to shield supply chains from disruptions by predicting their occurrence and mitigating their adverse effects. At the same time, the resurgence of Artificial Intelligence (AI) has led to the investigation of machine learning techniques and their applicability in supply chain risk management. However, most works focus on prediction performance and neglect the importance of interpretability so that results can be understood by supply chain practitioners, helping them make decisions that can mitigate or prevent risks from occurring. In this work, we first propose a supply chain risk prediction framework using data-driven AI techniques and relying on the synergy between AI and supply chain experts. We then explore the trade-off between prediction performance and interpretability by implementing and applying the framework on the case of predicting delivery delays in a real-world multi-tier manufacturing supply chain. Experiment results show that prioritising interpretability over performance may require a level of compromise, especially with regard to average precision scores. © 2019 Elsevier B.V.","Interpretability; Machine learning; Risk analysis; Risk prediction; Supply chain risk management","Economic and social effects; Forecasting; Learning systems; Machine learning; Risk analysis; Risk assessment; Risk management; Supply chains; Adverse effect; Delivery delay; Interpretability; Machine learning techniques; Prediction performance; Risk predictions; Supply chain risk; Supply chain risk management; Supply chain management"
"Başağaoğlu H., Chakraborty D., Do Lago C., Gutierrez L., Şahinli M.A., Giacomoni M., Furl C., Mirchi A., Moriasi D., Şengör S.S.","A Review on Interpretable and Explainable Artificial Intelligence in Hydroclimatic Applications","10.3390/w14081230","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128853137&doi=10.3390%2fw14081230&partnerID=40&md5=a5cd1381c022db28fbd7931d2375db07","This review focuses on the use of Interpretable Artificial Intelligence (IAI) and eXplainable Artificial Intelligence (XAI) models for data imputations and numerical or categorical hydroclimatic predictions from nonlinearly combined multidimensional predictors. The AI models considered in this paper involve Extreme Gradient Boosting, Light Gradient Boosting, Categorical Boosting, Extremely Randomized Trees, and Random Forest. These AI models can transform into XAI models when they are coupled with the explanatory methods such as the Shapley additive explanations and local interpretable model-agnostic explanations. The review highlights that the IAI models are capable of unveiling the rationale behind the predictions while XAI models are capable of discovering new knowledge and justifying AI-based results, which are critical for enhanced accountability of AI-driven predictions. The review also elaborates the importance of domain knowledge and interventional IAI modeling, potential advantages and disadvantages of hybrid IAI and non-IAI predictive modeling, unequivocal importance of balanced data in categorical decisions, and the choice and performance of IAI versus physics-based modeling. The review concludes with a proposed XAI framework to enhance the interpretability and explainability of AI models for hydroclimatic applications. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","explainable artificial intelligence; explanatory methods; hydroclimatic applications; multidimensional data; nonlinearity","Decision trees; Domain Knowledge; Data imputation; Explainable artificial intelligence; Explanatory method; Gradient boosting; Hydroclimatic; Hydroclimatic application; Intelligence models; Light gradients; Multidimensional data; Nonlinearity; Forecasting; additive; artificial intelligence; data set; hydrometeorology; nonlinearity"
"Başağaoğlu H., Chakraborty D., Winterle J.","Reliable evapotranspiration predictions with a probabilistic machine learning framework","10.3390/w13040557","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101756246&doi=10.3390%2fw13040557&partnerID=40&md5=27b406d7630603dcd9fe09dd55750cc6","Evapotranspiration is often expressed in terms of reference crop evapotranspiration (), actual evapotranspiration (), or surface water evaporation (), and their reliable predictions are critical for groundwater, irrigation, and aquatic ecosystem management in semi-arid regions. We demonstrated that a newly developed probabilistic machine learning (ML) model, using a hybridized ‘boosting’ framework, can simultaneously predict the daily,, & from local hydroclimate data with high accuracy. The probabilistic approach exhibited great potential to overcome data uncertainties, in which of the, of the, and of the test data at three watersheds were within the models’ prediction intervals. The modeling results revealed that the hybrid boosting framework can be used as a reliable computational tool to predict while bypassing net solar radiation calculations, estimate while overcoming uncertainties associated with pan evaporation & pan coefficients, and predict while offsetting high capital & operational costs of EC towers. In addition, using the Shapley analysis built on a coalition game theory, we identified the order of importance and interactions between the hydroclimatic variables to enhance the models’ transparency and trustworthiness. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Evapotranspiration; Machine learning; Probabilistic model; Shapley analysis","Adaptive boosting; Aquatic ecosystems; Computation theory; Evaporation; Forecasting; Game theory; Groundwater; Machine learning; Predictive analytics; Surface waters; Uncertainty analysis; Actual evapotranspiration; Computational tools; Ecosystem management; Hydroclimatic variables; Probabilistic approaches; Probabilistic machines; Radiation calculations; Reference crop evapotranspirations; Evapotranspiration; accuracy assessment; evapotranspiration; machine learning; prediction; probability; reliability analysis; surface water; uncertainty analysis; watershed"
"Basak A., Schmidt K.M., Mengshoel O.J.","From data to interpretable models: machine learning for soil moisture forecasting","10.1007/s41060-022-00347-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137235392&doi=10.1007%2fs41060-022-00347-8&partnerID=40&md5=40051dd54a36b5d5122e5887b7cd4ec1","Soil moisture is critical to agricultural business, ecosystem health, and certain hydrologically driven natural disasters. Monitoring data, though, is prone to instrumental noise, wide ranging extrema, and nonstationary response to rainfall where ground conditions change. Furthermore, existing soil moisture models generally forecast poorly for time periods greater than a few hours. To improve such forecasts, we introduce two data-driven models, the Naive Accumulative Representation (NAR) and the Additive Exponential Accumulative Representation (AEAR). Both of these models are rooted in deterministic, physically based hydrology, and we study their capabilities in forecasting soil moisture over time periods longer than a few hours. Learned model parameters represent the physically based unsaturated hydrological redistribution processes of gravity and suction. We validate our models using soil moisture and rainfall time series data collected from a steep gradient, post-wildfire site in southern California. Data analysis is complicated by rapid landscape change observed in steep, burned hillslopes in response to even small to moderate rain events. The proposed NAR and AEAR models are, in forecasting experiments, shown to be competitive with several established and state-of-the-art baselines. The AEAR model fits the data well for three distinct soil textures at variable depths below the ground surface (5, 15, and 30 cm). Similar robust results are demonstrated in controlled, laboratory-based experiments. Our AEAR model includes readily interpretable hydrologic parameters and provides more accurate forecasts than existing models for time horizons of 10–24 h. Such extended periods of warning for natural disasters, such as floods and landslides, provide actionable knowledge to reduce loss of life and property. © 2022, The Author(s).","Data analysis; Interpretable machine learning; Model optimization and fitting; Monitoring; Post-fire landslides; Soil moisture forecasting","Data handling; Disasters; Ecosystems; Forecasting; Information analysis; Landslides; Machine learning; Moisture control; Rain; Textures; Exponentials; Interpretable machine learning; Machine-learning; Model fitting; Model optimization; Optimization and fittings; Post-fire; Post-fire landslide; Representation model; Soil moisture forecasting; Soil moisture"
"Başaran E.","Classification of white blood cells with SVM by selecting SqueezeNet and LIME properties by mRMR method","10.1007/s11760-022-02141-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123262481&doi=10.1007%2fs11760-022-02141-2&partnerID=40&md5=d3b105c1710fb83f7933811389756ca4","White blood cells, which have an important role in the human immune system, protect the body against various viruses, harmful bacteria and infections. If there are not enough white blood cells in the blood, it results in leukopenia. When white blood cells are examined under a microscope, their change in structure and shape indicates some diseases. When experts clinically examine these images, various problems may arise due to individual misinterpretations. In this study, a diagnostic model based on convolutional neural network (CNN), local interpretable model agnostic annotations (LIME) and minimum redundancy maximum association (mRMR) methods is proposed for the detection of four different white blood cells. For this purpose, firstly, after the deep features of the images were extracted with SqueezeNet CNN, the important regions of the images for classification purposes were determined by the LIME method and the distinctive features of the images were obtained. The features obtained with the SqueezeNet CNN model were also obtained with the mRMR feature selection algorithm. Various feature sets obtained by combining the features obtained with the LIME algorithm are classified with support vector machines. As a result, the accuracy rate of the proposed model for the diagnosis of white blood cells was 95.88%. Selecting the SqueezeNet features with the mRMR method and supporting them with LIME features positively affected the performance results. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Local interpretable model agnostic explanations; Minimum redundancy maximum relevance; SqueezeNet; Support vector machines; White blood cells","Blood; Cells; Convolutional neural networks; Cytology; Diagnosis; Lime; Redundancy; Viruses; Cell-be; Cell/B.E; Cell/BE; Convolutional neural network; Local interpretable model agnostic explanation; Minimum redundancy-maximum relevances; Property; Squeezenet; Support vectors machine; White blood cells; Support vector machines"
"Bastos L.M., Froes de Borja Reis A., Sharda A., Wright Y., Ciampitti I.A.","Current status and future opportunities for grain protein prediction using on-and off-combine sensors: A synthesis-analysis of the literature","10.3390/rs13245027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121345695&doi=10.3390%2frs13245027&partnerID=40&md5=48a120dc0e92017b779e06a5a513fb18","The spatial information about crop grain protein concentration (GPC) can be an important layer (i.e., a map that can be utilized in a geographic information system) with uses from nutrient management to grain marketing. Recently, on-and off-combine harvester sensors have been developed for creating spatial GPC layers. The quality of these GPC layers, as measured by the coefficient of determination (R2 ) and the root mean squared error (RMSE) of the relationship between measured and predicted GPC, is affected by different sensing characteristics. The objectives of this synthesis analysis were to (i) contrast GPC prediction R2 and RMSE for different sensor types (on-combine, off-combine proximal and remote); (ii) contrast and discuss the best spatial, temporal, and spectral resolutions and features, and the best statistical approach for off-combine sensors; and (iii) review current technology limitations and provide future directions for spatial GPC research and application. On-combine sensors were more accurate than remote sensors in predicting GPC, yet with similar precision. The most optimal conditions for creating reliable GPC predictions from off-combine sensors were sensing near anthesis using multiple spectral features that include the blue and green bands, and that are analyzed by complex statistical approaches. We discussed sensor choice in regard to previously identified uses of a GPC layer, and further proposed new uses with remote sensors including same season fertilizer management for increased GPC, and in advance segregated harvest planning related to field prioritization and farm infrastructure. Limitations of the GPC literature were identified and future directions for GPC research were proposed as (i) performing GPC predictive studies on a larger variety of crops and water regimes; (ii) reporting proper GPC ground-truth calibrations; (iii) conducting proper model training, validation, and testing; (iv) reporting model fit metrics that express greater concordance with the ideal predictive model; and (v) implementing and benchmarking one or more uses for a GPC layer. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Combine harvester sensors; Grain protein sensing; Hand held sensors; Proximal sensing; Remote sensors","Biosynthesis; Crops; Forecasting; Harvesters; Information management; Mean square error; Proteins; Combine harvester sensor; Combine harvesters; Grain protein sensing; Hand-held sensor; Protein concentrations; Protein sensing; Proximal sensing; Remote sensors; Root mean squared errors; Synthesis analysis; Remote sensing"
"Batchuluun G., Nam S.H., Park K.R.","Deep learning-based plant classification and crop disease classification by thermal camera","10.1016/j.jksuci.2022.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142539871&doi=10.1016%2fj.jksuci.2022.11.003&partnerID=40&md5=f56f93bb2f471a14026f4be8b2b56b93","Studies regarding image classification based on plant and crop disease images that were acquired using a visible light camera have been conducted in the past, whereas those based on thermal images are limited. This is because the thermal images are blurry due to the nature of the thermal camera, which makes it extremely difficult to classify objects. Therefore, this study proposes a new plant and crop disease classification method based on thermal images. The proposed method used a convolutional neural network with explainable artificial intelligence (XAI) to improve plant and crop disease classification performance. A new thermal plant image dataset was built for conducting the experiments, which contained 4,720 various images of flowers and leaves. In addition, an open database of crop diseases was also used, such as the Paddy crop dataset. The proposed plant and crop disease classification method demonstrated a 98.55% accuracy for the thermal plant image dataset and a 90.04% accuracy for the Paddy crop dataset, both of which outperformed other existing methods. © 2022 The Author(s)","Convolutional neural network; Crop disease image; Explainable artificial intelligence; Plant image classification; Thermal image",
"Batunacun, Wieland R., Lakes T., Nendel C.","Using Shapley additive explanations to interpret extreme gradient boosting predictions of grassland degradation in Xilingol, China","10.5194/gmd-14-1493-2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102798637&doi=10.5194%2fgmd-14-1493-2021&partnerID=40&md5=ac2ee10f294705c0bcf8ba796fee89fe","Machine learning (ML) and data-driven approaches are increasingly used in many research areas. Extreme gradient boosting (XGBoost) is a tree boosting method that has evolved into a state-of-the-art approach for many ML challenges. However, it has rarely been used in simulations of land use change so far. Xilingol, a typical region for research on serious grassland degradation and its drivers, was selected as a case study to test whether XGBoost can provide alternative insights that conventional land-use models are unable to generate. A set of 20 drivers was analysed using XGBoost, involving four alternative sampling strategies, and SHAP (Shapley additive explanations) to interpret the results of the purely data-driven approach. The results indicated that, with three of the sampling strategies (over-balanced, balanced, and imbalanced), XGBoost achieved similar and robust simulation results. SHAP values were useful for analysing the complex relationship between the different drivers of grassland degradation. Four drivers accounted for 99 % of the grassland degradation dynamics in Xilingol. These four drivers were spatially allocated, and a risk map of further degradation was produced. The limitations of using XGBoost to predict future land-use change are discussed. © Author(s) 2021. This work is distributed under the Creative Commons Attribution 4.0 License.",,"additive; environmental gradient; extreme event; grassland; land degradation; prediction; China; Nei Monggol; Xilingol"
"Bavykina M., Kostina N., Lee C.-R., Schafleitner R., Bishop-von Wettberg E., Nuzhdin S.V., Samsonova M., Gursky V., Kozlov K.","Modeling of Flowering Time in Vigna radiata with Artificial Image Objects, Convolutional Neural Network and Random Forest","10.3390/plants11233327","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143612949&doi=10.3390%2fplants11233327&partnerID=40&md5=f68d387133787cf844dcc0a34f8d6623","Flowering time is an important target for breeders in developing new varieties adapted to changing conditions. In this work, a new approach is proposed in which the SNP markers influencing time to flowering in mung bean are selected as important features in a random forest model. The genotypic and weather data are encoded in artificial image objects, and a model for flowering time prediction is constructed as a convolutional neural network. The model uses weather data for only a limited time period of 5 days before and 20 days after planting and is capable of predicting the time to flowering with high accuracy. The most important factors for model solution were identified using saliency maps and a Score-CAM method. Our approach can help breeding programs harness genotypic and phenotypic diversity to more effectively produce varieties with a desired flowering time. © 2022 by the authors.","artificial image objects; climatic factors; convolutional neural network; flowering time; GWAS; mung bean; random forest",
"Baylis K., Heckelei T., Storm H.","Machine learning in agricultural economics","10.1016/bs.hesagr.2021.10.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123896024&doi=10.1016%2fbs.hesagr.2021.10.007&partnerID=40&md5=0f22ac95347940605b2de5043d27d254","With the substantial growth in novel data sources and computational power, machine learning holds great potential for economic analysis. However, like any new approach, the strengths and weaknesses of these tools need to be considered when deciding where and how they can be successfully applied. In this chapter, we introduce key ML methods, from penalized regressions, to tree-based methods to neural networks, relating these approaches to common econometric practice. We then explore the potential afforded by ML to fill gaps in our current methodological toolbox. We discuss use cases like the need for flexible functional forms, the use of unstructured data, and large numbers of explanatory variables in both prediction and causal analysis. We also highlight the challenges of complex simulation models including calibration, validation and computational demands and identify places where machine learning can help. We highlight these issues drawing from existing examples in agricultural and applied economics. To unpack the “black box” of ML, we present numerous approaches used in computer science and statistics for model interpretability. Finally, we highlight some ethical issues around the use of ML. We argue that economists can play a vital role in adapting ML methods for the use in economics by combining them with our domain knowledge of economic mechanisms, and our approach to causal identification. © 2021 Elsevier B.V.","Agricultural economics; Artificial intelligence; Causal estimation; Deep learning; Machine learning; Neural networks; Random forest; Simulation modeling",
"Beans C.","Crop researchers harness artificial intelligence to breed crops for the changing climate","10.1073/pnas.2018732117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095667966&doi=10.1073%2fpnas.2018732117&partnerID=40&md5=99f99eae50c29a5e0552bcdead21f6e7",[No abstract available],,"algorithm; Article; artificial intelligence; climate change; crop production; drone; drought resistance; environmental decision making; evolutionary adaptation; genetic variation; genotype; nonhuman; papaya; plant breeding; priority journal; scientist; wheat; agriculture; artificial intelligence; climate change; crop; human; plant breeding; procedures; Agriculture; Artificial Intelligence; Climate Change; Crops, Agricultural; Humans; Plant Breeding"
"Bellin N., Tesi G., Marchesani N., Rossi V.","Species distribution modeling and machine learning in assessing the potential distribution of freshwater zooplankton in Northern Italy","10.1016/j.ecoinf.2022.101682","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130428245&doi=10.1016%2fj.ecoinf.2022.101682&partnerID=40&md5=606dfb7acba1b140a7fd9f9a1c8dbf06","Species distribution models (SDM's) are powerful tools used to describe species suitable habitats and spatial occurrences and many statistical methods and algorithms are available to model the spatial distribution of a target species. Here we explore a species distribution model framework combined with machine learning algorithms to describe the distribution of two freshwater zooplankton species Daphnia longispina (Cladocera) and Eucyclops serrulatus (Copepods) in a system of 283 shallow and ephemeral freshwater habitats in the Northern Italian Appennines. For each species, we model the habitat suitability by comparing one regression-based model, one generalized linear model (GLM) and two machine learning algorithms: random forest (RF) and artificial neural network (ANN) with one hidden layer. We used a total of 27 predictor variables. The modeling framework was used considering a scenario of future climate change in order to evaluate potential shifts in spatial distribution of the zooplankton species. For both species, the supervised machine learning algorthn (ANN) produced the highest mean values for all the performance metrics. For D. longispina and E. serrulatus, the two most important variables ranked by the shap analysis and global sensitivity and uncertainty analysis (GSUA) were temperature seasonality and precipitation of the warmest quarter. Both species, in a future climatic change scenario, are expected to shift their distribution mainly toward lower northern altitudes with an overall expansion of 7% with respect to the past/present climatic conditions. However, the spatial expansion of D. longispina and E. serrulatus was qualitatively different. In agricultural and natural areas, the expansion of E. serrulatus was greater than that of D. longispina but, in natural areas, the expansion of E. serrulatus was counterbalanced by a greater spatial contraction than that of D. longispina. As hypothesized, direct and indirect anthropogenic pressures may affect the predicted potential shift and expansion of the zooplankton species. © 2022 Elsevier B.V.","Artificial neural network; Climate change; Daphnia; Eucyclops; Shallow waters","artificial neural network; climate change; crustacean; ecological modeling; freshwater environment; shallow water; spatial distribution; Italy"
"Benarous L., Benarous K., Muhammad G., Ali Z.","Deep learning application detecting SARS-CoV-2 key enzymes inhibitors","10.1007/s10586-022-03656-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134482684&doi=10.1007%2fs10586-022-03656-6&partnerID=40&md5=b6f375cd67b765debfe2b3f38f24b11f","The fast spread of the COVID-19 over the world pressured scientists to find its cures. Especially, with the disastrous results, it engendered from human life losses to long-term impacts on infected people’s health and the huge financial losses. In addition to the massive efforts made by researchers and medicals on finding safe, smart, fast, and efficient methods to accurately make an early diagnosis of the COVID-19. Some researchers focused on finding drugs to treat the disease and its symptoms, others worked on creating effective vaccines, while several concentrated on finding inhibitors for the key enzymes of the virus, to reduce its spreading and reproduction inside the human body. These enzymes’ inhibitors are usually found in aliments, plants, fungi, or even in some drugs. Since these inhibitors slow and halt the replication of the virus in the human body, they can help fight it at an early stage saving the patient from death risk. Moreover, if the human body’s immune system gets rid of the virus at the early stage it can be spared from the disastrous sequels it may leave inside the patient’s body. Our research aims to find aliments and plants that are rich in these inhibitors. In this paper, we developed a deep learning application that is trained with various aliments, plants, and drugs to detect if a component contains SARS-CoV-2 key inhibitor(s) intending to help them find more sources containing these inhibitors. The application is trained to identify various sources rich in thirteen coronavirus-2 key inhibitors. The sources are currently just aliments, plants, and seeds and the identification is done by their names. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Aliments; COVID-19; Deep learning; Identification; Key enzymes inhibitors; Plants","Cell proliferation; Computer aided instruction; Deep learning; Diagnosis; Enzymes; Losses; Plants (botany); Seed; Aliment; Deep learning; Enzyme inhibitors; Human bodies; Human lives; Identification; Key enzyme inhibitor; Key enzymes; Long-term impacts; Plant; Coronavirus; COVID-19"
"Berdugo M., Gaitan J.J., Delgado-Baquerizo M., Crowther T.W., Dakos V.","Prevalence and drivers of abrupt vegetation shifts in global drylands","10.1073/pnas.2123393119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140271448&doi=10.1073%2fpnas.2123393119&partnerID=40&md5=59ab9fee2e8a860aba3231eae750fc80","The constant provision of plant productivity is integral to supporting the liability of ecosystems and human wellbeing in global drylands. Drylands are paradigmatic examples of systems prone to experiencing abrupt changes in their functioning. Indeed, space-for-time substitution approaches suggest that abrupt changes in plant productivity are widespread, but this evidence is less clear using observational time series or experimental data at a large scale. Studying the prevalence and, most importantly, the unknown drivers of abrupt (rather than gradual) dynamical patterns in drylands may help to unveil hotspots of current and future dynamical instabilities in drylands. Using a 20-y global satellite-derived temporal assessment of dryland Normalized Difference Vegetation Index (NDVI), we show that 50% of all dryland ecosystems exhibiting gains or losses of NDVI are characterized by abrupt positive/negative temporal dynamics. We further show that abrupt changes are more common among negative than positive NDVI trends and can be found in global regions suffering recent droughts, particularly around critical aridity thresholds. Positive abrupt dynamics are found most in ecosystems with low seasonal variability or high aridity. Our work unveils the high importance of climate variability on triggering abrupt shifts in vegetation and it provides missing evidence of increasing abruptness in systems intensively managed by humans, with low soil organic carbon contents, or around specific aridity thresholds. These results highlight that abrupt changes in dryland dynamics are very common, especially for productivity losses, pinpoint global hotspots of dryland vulnerability, and identify drivers that could be targeted for effective dryland management. Copyright © 2022 the Author(s). Published by PNAS.","abrupt shifts; dryland ecology; productivity dynamics; remote sensing","organic carbon; carbon; Article; climate change; desertification; drought; dryland; ecosystem restoration; environment; environmental factor; environmental temperature; prevalence; seasonal variation; vegetation; ecosystem; human; plant; prevalence; soil; Carbon; Climate Change; Ecosystem; Humans; Plants; Prevalence; Soil"
"Bertolini R., Finch S.J., Nehm R.H.","Enhancing data pipelines for forecasting student performance: integrating feature selection with cross-validation","10.1186/s41239-021-00279-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112708121&doi=10.1186%2fs41239-021-00279-6&partnerID=40&md5=690ce40abe546e77eab35a892c58ba51","Educators seek to harness knowledge from educational corpora to improve student performance outcomes. Although prior studies have compared the efficacy of data mining methods (DMMs) in pipelines for forecasting student success, less work has focused on identifying a set of relevant features prior to model development and quantifying the stability of feature selection techniques. Pinpointing a subset of pertinent features can (1) reduce the number of variables that need to be managed by stakeholders, (2) make “black-box” algorithms more interpretable, and (3) provide greater guidance for faculty to implement targeted interventions. To that end, we introduce a methodology integrating feature selection with cross-validation and rank each feature on subsets of the training corpus. This modified pipeline was applied to forecast the performance of 3225 students in a baccalaureate science course using a set of 57 features, four DMMs, and four filter feature selection techniques. Correlation Attribute Evaluation (CAE) and Fisher’s Scoring Algorithm (FSA) achieved significantly higher Area Under the Curve (AUC) values for logistic regression (LR) and elastic net regression (GLMNET), compared to when this pipeline step was omitted. Relief Attribute Evaluation (RAE) was highly unstable and produced models with the poorest prediction performance. Borda’s method identified grade point average, number of credits taken, and performance on concept inventory assessments as the primary factors impacting predictions of student performance. We discuss the benefits of this approach when developing data pipelines for predictive modeling in undergraduate settings that are more interpretable and actionable for faculty and stakeholders. © 2021, The Author(s).","Cross-validation; Data mining; Data pipeline; Feature selection; Introductory biology",
"Bessa W.R.B., Barbosa V.N., Leite D.G., Neto F.M.M., Santos V.S., Silva T.G., Araujo G.S., Moreira M.W.L., Braga O.C.","Image Filtering Model Based on Convolutional Neural Networks for Automatic Counting of Post-larvae in Aquaculture","10.1145/3544538.3544642","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142040842&doi=10.1145%2f3544538.3544642&partnerID=40&md5=ada6c03f10342971d5e2a0d72f8318eb","Aquaculture is an important activity for the animal protein global supply. In Brazil, this area is showing significant growth in recent years. Among the activities carried out during the production process, the counting of animals in the initial stages can be highlighted. A large number of Brazilian aquaculture farms are small, turning difficult to acquire novel solutions for the automatic count of post-larvae. To mitigate this issue, this paper intends to develop a solution based on the performance evaluation of a set of counting models for use in embedded structures. In addition, this application can be scalable for counting different species and sizes. Besides, the dataset named Vivarium and its specifications is presented as proof of concept and used in the model evaluation. Results show that the prediction model based on convolutional neural networks is capable of verifying the compliance of images, achieving an accuracy of 99%. © 2022 ACM.","aquaculture.; automatic detection; Mobile Computing and Applications","Animals; Convolution; Convolutional neural networks; Animal proteins; Aquaculture.; Automatic counting; Automatic Detection; Convolutional neural network; Filtering models; Image filtering; Mobile applications; Mobile-computing; Model-based OPC; Aquaculture"
"Bhagat M., Kumar D.","Performance evaluation of PCA based reduced features of leaf images extracted by DWT using random Forest and XGBoost classifier","10.1007/s11042-023-14370-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146797614&doi=10.1007%2fs11042-023-14370-9&partnerID=40&md5=b5127195e0dc0093d143b272c42f7f09","The leaf disease classification is a method for putting diseases into groups based on their properties, like texture, shape, and color. Even though DL features are very good at classifying leaf diseases, some authors focused on handcrafted features for leaf disease classification and got quite good results with similar accuracy. In this paper, we have also focused on handcrafted features and ML based shallow classifier to get comparable accuracy of DL models. Handcrafted features and shallow ML based classifier are used for leaf disease detection and classification mainly for three species such as tomato, bell pepper and potato. Here we have used 3- level decomposition based 2D-DWT for image feature extraction and PCA for dimensionality reduction of features. We have used stratified K-Fold validation because the dataset is small and there is a need to maintain the class ratio for classification. For classification Random Forest and XGBoost are used. The proposed method is made up of 4 steps: image pre-processing, feature extraction, feature reduction, and classification. We evaluate the proposed model’s classification accuracy against the classification accuracy of several scholarly works. When applied to Datasets 1, 2, 3, and 4, RF classifiers achieve accuracies of 98.45%, 100%, 98.33%, and 98.55%, respectively, while XGBoost achieves accuracies of 99.11%, 98.72%, 98.23%, and 97.73%. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","DWT; Feature extraction; Feature reduction; Image classification; K-fold cross validation; Leaf images; PCA; RF; XGBoost","Classification (of information); Discrete wavelet transforms; Extraction; Feature extraction; Signal reconstruction; Textures; DWT; Features extraction; Features reductions; Images classification; K fold cross validations; Leaf disease; Leaf images; PCA; RF; Xgboost; Image classification"
"Bhandari N., Walambe R., Kotecha K., Khare S.P.","A comprehensive survey on computational learning methods for analysis of gene expression data","10.3389/fmolb.2022.907150","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142917274&doi=10.3389%2ffmolb.2022.907150&partnerID=40&md5=fb39547c9ff62c5c6b651913d9410ddc","Computational analysis methods including machine learning have a significant impact in the fields of genomics and medicine. High-throughput gene expression analysis methods such as microarray technology and RNA sequencing produce enormous amounts of data. Traditionally, statistical methods are used for comparative analysis of gene expression data. However, more complex analysis for classification of sample observations, or discovery of feature genes requires sophisticated computational approaches. In this review, we compile various statistical and computational tools used in analysis of expression microarray data. Even though the methods are discussed in the context of expression microarrays, they can also be applied for the analysis of RNA sequencing and quantitative proteomics datasets. We discuss the types of missing values, and the methods and approaches usually employed in their imputation. We also discuss methods of data normalization, feature selection, and feature extraction. Lastly, methods of classification and class discovery along with their evaluation parameters are described in detail. We believe that this detailed review will help the users to select appropriate methods for preprocessing and analysis of their data based on the expected outcome. Copyright © 2022 Bhandari, Walambe, Kotecha and Khare.","deep learning; explainable techniques; feature selection; gene expression; interpretation; machine learning; microarray; missing value imputation",
"Bhardwaj A., Kishore S., Pandey D.K.","Artificial Intelligence in Biological Sciences","10.3390/life12091430","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138736152&doi=10.3390%2flife12091430&partnerID=40&md5=5bcde18485e2a73959f973cb9ebbb0e0","Artificial intelligence (AI), currently a cutting-edge concept, has the potential to improve the quality of life of human beings. The fields of AI and biological research are becoming more intertwined, and methods for extracting and applying the information stored in live organisms are constantly being refined. As the field of AI matures with more trained algorithms, the potential of its application in epidemiology, the study of host–pathogen interactions and drug designing widens. AI is now being applied in several fields of drug discovery, customized medicine, gene editing, radiography, image processing and medication management. More precise diagnosis and cost-effective treatment will be possible in the near future due to the application of AI-based technologies. In the field of agriculture, farmers have reduced waste, increased output and decreased the amount of time it takes to bring their goods to market due to the application of advanced AI-based approaches. Moreover, with the use of AI through machine learning (ML) and deep-learning-based smart programs, one can modify the metabolic pathways of living systems to obtain the best possible outputs with the minimal inputs. Such efforts can improve the industrial strains of microbial species to maximize the yield in the bio-based industrial setup. This article summarizes the potentials of AI and their application to several fields of biology, such as medicine, agriculture, and bio-based industry. © 2022 by the authors.","agriculture; artificial intelligence; biotechnology; crop yield; life science; medicine",
"Bhargava A., Bansal A., Goyal V.","Machine learning-based automatic detection of novel coronavirus (COVID-19) disease","10.1007/s11042-022-12508-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125049971&doi=10.1007%2fs11042-022-12508-9&partnerID=40&md5=c0d4bd15439438150a31b36270a9bb08","Abstract The pandemic was announced by the world health organization coronavirus (COVID-19) universal health dilemma. Any scientific appliance which contributes expeditious detection of coronavirus with a huge recognition rate may be excessively fruitful to doctors. In this environment, innovative automation like deep learning, machine learning, image processing and medical image like chest radiography (CXR), computed tomography (CT) has been refined promising solution contrary to COVID-19. Currently, a reverse transcription-polymerase chain reaction (RT-PCR) test has been used to detect the coronavirus. Due to the moratorium period is high on results tested and huge false negative estimates, substitute solutions are desired. Thus, an automated machine learning-based algorithm is proposed for the detection of COVID-19 and the grading of nine different datasets. This research impacts the grant of image processing and machine learning to expeditious and definite coronavirus detection using CXR and CT medical imaging. This results in early detection, diagnosis, and cure for the accomplishment of COVID-19 as early as possible. Firstly, images are preprocessed by normalization to enhance the quality of the image and removing of noise. Secondly, segmentation of images is done by fuzzy c-means clustering. Then various features namely, statistical, textural, histogram of gradients, and discrete wavelet transform are extracted (92) and selected from the feature vector by principle component analysis. Lastly, k-NN, SRC, ANN, and SVM are used to make decisions for normal, pneumonia, COVID-19 positive patients. The performance of the system has been validated by the k (5) fold cross-validation technique. The proposed algorithm achieves 91.70% (k-Nearest Neighbor), 94.40% (Sparse Representation Classifier), 96.16% (Artificial Neural Network), and 99.14% (Support Vector Machine) for COVID detection. The proposed results show feature combination and selection improves the performance in 14.34 s with machine learning and image processing techniques. Among k-NN, SRC, ANN, and SVM classifiers, SVM shows more efficient results that are promising and comparable with the literature. The proposed approach results in an improved recognition rate as compared to the literature review. Therefore, the algorithm proposed shows immense potential to benefit the radiologist for their findings. Also, fruitful in prior virus diagnosis and discriminate pneumonia between COVID-19 and other pandemics. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Coronavirus; COVID-19; Machine learning; Statistical; Support vector machine; Textural","Computerized tomography; Deep learning; Diagnosis; Discrete wavelet transforms; Grading; Image enhancement; Image segmentation; Nearest neighbor search; Neural networks; Polymerase chain reaction; Principal component analysis; Support vector machines; Automatic Detection; Chest radiography; Coronaviruses; COVID-19; Images processing; Performance; Reverse transcription-polymerase chain reaction; Support vectors machine; Textural; World Health Organization; Coronavirus"
"Bhola A., Verma S., Kumar P.","A comparative analysis of deep learning models for cucumber disease classification using transfer learning","10.14456/jcst.2023.3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147366837&doi=10.14456%2fjcst.2023.3&partnerID=40&md5=1a6f779dc691df7d4718a02a80187105","Increasing agricultural productivity continues to be a major challenge for society due to the rapid growth of the global human population and economic prosperity. However, improving agricultural productivity requires proper identification and minimization of diseases that degrade both the quality and quantity of the crops. The scientific community has stressed that the use of recent technologies such as deep learning, the internet of things, computer vision, etc. are vital to address various challenges in the agriculture sector. Furthermore, the use of computer vision to automatically identify diseases is growing in popularity. This paper provides a comparative analysis of six pre-trained deep learning models, namely VGG16, VGG19, ResNet50, ResNet101, InceptionV3, and Xception, for disease detection in cucumber plants. The pre-trained models are fine-tuned using transfer learning and evaluated using different metrics such as training accuracy, testing accuracy, and the number of epochs. The results obtained demonstrate that VGG16, despite being the smallest model in terms of the number of layers, outperforms the rest of the models in all of the evaluation metrics. The VGG16 models obtain testing accuracy of 98% and training accuracy of 99.91% while being trained for 8 epochs. In addition, it is observed that models with a larger number of layers, such as ResNet50 and ResNet101, exhibit fluctuations in accuracy while training due to the execution of fairly large models on a comparatively small dataset. However, InceptionV3 and Xception, despite having a greater number of layers, perform better than ResNet models due to the presence of Inception modules which are better equipped to detect different-sized targets. The findings of this study may be utilized to optimize the best-performing models for disease classification in other plants, and the fine-tuned VGG16 model can be integrated with mobile devices for real-time disease classification. © 2018-2023, Rangsit University.","cucumber disease classification; deep learning; digital agriculture; plant disease; transfer learning",
"Bhuiyan T., Carney R.M., Chellappan S.","Artificial intelligence versus natural selection: Using computer vision techniques to classify bees and bee mimics","10.1016/j.isci.2022.104924","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138522271&doi=10.1016%2fj.isci.2022.104924&partnerID=40&md5=e81eebb42e7e0894a8b683d0454e2068","Many groups of stingless insects have independently evolved mimicry of bees to fool would-be predators. To investigate this mimicry, we trained artificial intelligence (AI) algorithms—specifically, computer vision—to classify citizen scientist images of bees, bumble bees, and diverse bee mimics. For detecting bees and bumble bees, our models achieved accuracies of 91.71% and 88.86%, respectively. As a proxy for a natural predator, our models were poorest in detecting bee mimics that exhibit both aggressive and defensive mimicry. Using the explainable AI method of class activation maps, we validated that our models learn from appropriate components within the image, which in turn provided anatomical insights. Our t-SNE plot yielded perfect within-group clustering, as well as between-group clustering that grossly replicated the phylogeny. Ultimately, the transdisciplinary approaches herein can enhance global citizen science efforts as well as investigations of mimicry and morphology of bees and other insects. © 2022 The Authors","Artificial intelligence; Bioinformatics; Computing methodology; Entomology; Zoology",
"Bianconi F., Fernández A., Smeraldi F., Pascoletti G.","Colour and texture descriptors for visual recognition: A historical overview","10.3390/jimaging7110245","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121356031&doi=10.3390%2fjimaging7110245&partnerID=40&md5=3216204d9eff5d0037d9de443318804f","Colour and texture are two perceptual stimuli that determine, to a great extent, the appearance of objects, materials and scenes. The ability to process texture and colour is a fundamental skill in humans as well as in animals; therefore, reproducing such capacity in artificial (‘intelligent’) systems has attracted considerable research attention since the early 70s. Whereas the main approach to the problem was essentially theory-driven (‘hand-crafted’) up to not long ago, in recent years the focus has moved towards data-driven solutions (deep learning). In this overview we retrace the key ideas and methods that have accompanied the evolution of colour and texture analysis over the last five decades, from the ‘early years’ to convolutional networks. Specifically, we review geometric, differential, statistical and rank-based approaches. Advantages and disadvantages of traditional methods vs. deep learning are also critically discussed, including a perspective on which traditional methods have already been subsumed by deep learning or would be feasible to integrate in a data-driven approach. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Colour; Deep learning; Texture; Visual recognition","Deep learning; Textures; Artificial intelligent; Color analysis; Color and textures; Color descriptors; Convolutional networks; Data driven; Deep learning; Texture analysis; Texture descriptors; Visual recognition; Color"
"Biass S., Jenkins S.F., Aeberhard W.H., Delmelle P., Wilson T.","Insights into the vulnerability of vegetation to tephra fallouts from interpretable machine learning and big Earth observation data","10.5194/nhess-22-2829-2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140322025&doi=10.5194%2fnhess-22-2829-2022&partnerID=40&md5=77cec81ba07f837a9c12f30b173c48ca","Although the generally high fertility of volcanic soils is often seen as an opportunity, short-term consequences of eruptions on natural and cultivated vegetation are likely to be negative. The empirical knowledge obtained from post-event impact assessments provides crucial insights into the range of parameters controlling impact and recovery of vegetation, but their limited coverage in time and space offers a limited sample of all possible eruptive and environmental conditions. Consequently, vegetation vulnerability remains largely unconstrained, thus impeding quantitative risk analyses. Here, we explore how cloud-based big Earth observation data, remote sensing and interpretable machine learning (ML) can provide a large-scale alternative to identify the nature of, and infer relationships between, drivers controlling vegetation impact and recovery. We present a methodology developed using Google Earth Engine to systematically revisit the impact of past eruptions and constrain critical hazard and vulnerability parameters. Its application to the impact associated with the tephra fallout from the 2011 eruption of Cordón Caulle volcano (Chile) reveals its ability to capture different impact states as a function of hazard and environmental parameters and highlights feedbacks and thresholds controlling impact and recovery of both natural and cultivated vegetation. We therefore conclude that big Earth observation (EO) data and machine learning complement existing impact datasets and open the way to a new type of dynamic and large-scale vulnerability models. Copyright: © 2022 Sébastien Biass et al.",,"computer simulation; data set; machine learning; numerical model; tephra; volcanic eruption; volcanology; vulnerability; Chile"
"Biggs M.B., Craig K., Gachango E., Ingham D., Twizeyimana M.","Genomics-and machine learning-Accelerated discovery of biocontrol bacteria","10.1094/PBIOMES-01-21-0003-R","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123305137&doi=10.1094%2fPBIOMES-01-21-0003-R&partnerID=40&md5=bfa115583fb3b785366ea6a344e960e9","Microorganisms with antimicrobial activity have been used to successfully control various plant pathogens. The discovery of organisms with protective activity depends on empirical screenings to assess microbial activity against pathogens of interest. Machine learning can accelerate the discovery process by making screening and, thus, discovery more efficient. We developed a novel machine-learning workflow to identify genomic features associated with fungicidal activity of bacteria, and leveraged those genomic features to discover additional bacteria with the desired activity. We applied our workflow to discover solutions to two problematic fungal diseases: sorghum anthracnose and black sigatoka of banana. These diseases are problematic worldwide, with a particularly devastating impact on small-holder farmers in Sub-Saharan Africa. We screened a total of 1,227 bacterial isolates for antifungal activity against these pathogens using detached-leaf methods and identified 72 taxonomically diverse isolates with robust activity against one or both of these pathogens. We identified biosynthetic gene clusters associated with activity against each pathogen. Machine learning improved the discovery rate of our screen by threefold, and led to the discovery of a taxonomic group in which fungicidal activity has never been reported. This work highlights the wealth of biocontrol mechanisms available in the microbial world for management of fungal pathogens, generates opportunities for future characterization of novel fungicidal mechanisms, and provides a set of genomic features and models for discovering additional bacterial isolates with activity against these two pathogens. Finally, our workflow generalizes to any discovery effort where genomic information is available to guide candidate selection. © 2021 American Phytopathological Society. All rights reserved.","Bacterial-fungal antagonism; Biological control; Black sigatoka; Genomics; Machine learning; Sorghum anthracnose",
"Bishop R.R., Outkin A.V., Eames B.K., White C.C.","Increasing Trust in Development Processes Using Robust, Data-Driven Markov Games: An Application to PRESTIGE","10.1109/TCSS.2020.3035635","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098792088&doi=10.1109%2fTCSS.2020.3035635&partnerID=40&md5=9cb3a9be018494c25f2ac69ecc31604f","In this article, we consider how to increase trust in development processes in which there is a risk for adversarial manipulation, and the adversary's objectives and resources are either ill-specified, imprecisely specified, or unknown. In such problems, we must hedge against the risk of misapprehension of attacker objectives and resources, which is further complicated in the absence of adversarial training data. We show how to model dynamic agent interaction, on the basis of partially observed or noise-corrupted data, using a partially observable Markov game (POMG) framework. We then propose a threefold heuristic solution procedure that: 1) uses the POMG to generate potential adversarial policies; 2) explicitly incorporates these adversarial policies in the construction of a robust defender policy by solving a robust dynamic program (DP); and 3) employs a probability matching heuristic in partially observable environments. © 2014 IEEE.","Dynamic programming; Markov games; partial observability; robust optimization; trust","Corrupted data; Development process; Dynamic programs; Heuristic solutions; Model dynamics; Partially observable environments; Probability matching; Training data; Heuristic programming"
"Blakseth S.S., Rasheed A., Kvamsdal T., San O.","Deep neural network enabled corrective source term approach to hybrid analysis and modeling","10.1016/j.neunet.2021.11.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120695969&doi=10.1016%2fj.neunet.2021.11.021&partnerID=40&md5=c84e7583fdeb872d74b39b401e1f4807","In this work, we introduce, justify and demonstrate the Corrective Source Term Approach (CoSTA)—a novel approach to Hybrid Analysis and Modeling (HAM). The objective of HAM is to combine physics-based modeling (PBM) and data-driven modeling (DDM) to create generalizable, trustworthy, accurate, computationally efficient and self-evolving models. CoSTA achieves this objective by augmenting the governing equation of a PBM model with a corrective source term generated using a deep neural network. In a series of numerical experiments on one-dimensional heat diffusion, CoSTA is found to outperform comparable DDM and PBM models in terms of accuracy – often reducing predictive errors by several orders of magnitude – while also generalizing better than pure DDM. Due to its flexible but solid theoretical foundation, CoSTA provides a modular framework for leveraging novel developments within both PBM and DDM. Its theoretical foundation also ensures that CoSTA can be used to model any system governed by (deterministic) partial differential equations. Moreover, CoSTA facilitates interpretation of the DNN-generated source term within the context of PBM, which results in improved explainability of the DNN. These factors make CoSTA a potential door-opener for data-driven techniques to enter high-stakes applications previously reserved for pure PBM. © 2021 The Author(s)","Corrective source term approach (CoSTA); Deep neural networks; Digital twins; Explainable AI; Hybrid analysis and modeling; Physics-based modeling","Analysis and models; Corrective source term approach; Data-driven model; Explainable AI; Hybrid analysis; Hybrid model; Model-driven; Physics-based models; Source terms; Theoretical foundations; Deep neural networks; article; deep neural network; digital twin; physics; theoretical study; thermal diffusion; Neural Networks, Computer; Physics"
"Bochie K., Gilbert M.S., Gantert L., Barbosa M.S.M., Medeiros D.S.V., Campista M.E.M.","A survey on deep learning for challenged networks: Applications and trends","10.1016/j.jnca.2021.103213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114944678&doi=10.1016%2fj.jnca.2021.103213&partnerID=40&md5=6649614b6635a2c0e941801bc7c509aa","Computer networks are dealing with growing complexity, given the ever-increasing volume of data produced by all sorts of network nodes. Performance improvements are a non-stop ambition and require tuning fine-grained details of the system operation. Analyzing such data deluge, however, is not straightforward and sometimes not supported by the system. There are often problems regarding scalability and the predisposition of the involved nodes to understand and transfer the data. This issue is at least partially circumvented by knowledge acquisition from past experiences, which is a characteristic of the herein called “challenged networks”. The addition of intelligence in these scenarios is fundamental to extract linear and non-linear relationships from the data collected by multiple sources. This is undoubtedly an invitation to machine learning and, more particularly, to deep learning. This paper identifies five different challenged networks: IoT and sensor, mobile, industrial, and vehicular networks as typical scenarios that may have multiple and heterogeneous data sources and face obstacles concerning connectivity. As a consequence, deep learning solutions can contribute to system performance by adding intelligence and the ability to interpret data. We start the paper by providing an overview of deep learning, further explaining this approach's benefits over the cited scenarios. We propose a workflow based on our observations of deep learning applications over challenged networks, and based on it, we strive to survey the literature on deep-learning-based solutions at an application-oriented level using the PRISMA methodology. Afterward, we also discuss new deep learning techniques that show enormous potential for further improvements as well as transversal issues, such as security. Finally, we provide lessons learned raising trends linking all surveyed papers to deep learning approaches. We are confident that the proposed paper contributes to the state of the art and can be a piece of inspiration for beginners and also for enthusiasts on advanced networking research. © 2021 Elsevier Ltd","Challenged networks; Deep learning; Industrial networks; Internet of Things; Machine learning; Sensor networks; Vehicular networks; Wireless mobile networks","Knowledge acquisition; Learning systems; Surveys; Application-oriented; Challenged networks; Heterogeneous data sources; Learning approach; Learning techniques; Non-linear relationships; System operation; Vehicular networks; Deep learning"
"Boguszewska-Mańkowska D., Ruszczak B., Zarzyńska K.","Classification of Potato Varieties Drought Stress Tolerance Using Supervised Learning","10.3390/app12041939","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124754205&doi=10.3390%2fapp12041939&partnerID=40&md5=f864d1adb9dca52e685dce6594b3804e","The presented study was aimed at investigating the variability for drought tolerance among potato cultivars. To achieve this, the stability of drought tolerance of potato cultivars under different water regime conditions was inspected during 11 years of consecutive experiments. The data on 50 potato cultivars’ responses to drought stress, based on the morphological features of plants, i.e., leaf and stem mass and size of the assimilation area, have been collected. The tuber yield, as well as calculated plant tolerance indexes and Climatic Water Balance for each growing season, were analyzed. The studied cultivars were later assigned into one of three tolerance groups for soil drought. The highest linear relationship was found between the mass of leaves and stems and the tuber yield but was found too weak to raise any conclusions. Thus, the ensemble learning models have been evaluated and returned better performance results, and the final classifier is the implementation of extreme gradient boosting. The final classifier of the 96.7% accuracy, which used several measured potato parameters (Relative yield decrease, Stem mass, Maturity, Assimilation area, Leaves mass, Yield per plant, calculated Climatic water balance, and indices: MSTI and DSI) that could distinguish the different tolerance groups were evaluated in the study. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Drought; Drought stress tolerance; Machine learning; Potato; Yield",
"Borges Monteiro A.C., Padilha França R., Arthur R., Iano Y., Segatti A.C., Carnielli G.P., Pereira J.C., de Godoy H.A., Fernandes E.C.","A Look at IIoT: The Perspective of IoT Technology Applied in the Industrial Field","10.1002/9781119769026.ch1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141273167&doi=10.1002%2f9781119769026.ch1&partnerID=40&md5=b7d9d24022304ff1ff3eb2fc7d58d792","The advent of solutions with AI (Artificial Intelligence) technology means tools and software that integrate resources that automate the process of making algorithmic decisions. Simply put, AI consists of systems or machines that mimic human intelligence to perform tasks improving iteratively over time based on the information collected. Thus, IoT currently matches a series of hardware that works connected to the internet, from a refrigerator to a wearable watch that measures heart rate and sends this data to an application. In this sense, it is possible to interpret what part of these devices uses, even on a small scale, AI technology. This technological innovation connects everyday intelligent devices or even intelligent sensors, to the internet, linking the physical world increasingly closer to the digital world. In this scenario, the world is experiencing a digital transformation, and related to it, the Industrial Internet of Things (IIoT) aims to connect different devices to collect and transmit data present in an industrial environment. Performing this communication through essential industrial variables related to smart devices, effecting communication, data, and data analysis. In this sense, this chapter is motivated to provide an updated overview of IoT and IIoT, addressing its evolution along with AI technology and potential in the industry, approaching its relationship, with a concise bibliographic ackground, synthesizing the potential of technologies. © 2022 Scrivener Publishing LLC. All rights reserved.","IIoT; industrial; IoT; IoT applications; sensors",
"Boulent J., St-Charles P.-L., Foucher S., Théau J.","Automatic Detection of Flavescence Dorée Symptoms Across White Grapevine Varieties Using Deep Learning","10.3389/frai.2020.564878","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109101945&doi=10.3389%2ffrai.2020.564878&partnerID=40&md5=b3d1fca2174ee0fcc0394e474682aca1","Flavescence dorée (FD) is a grapevine disease caused by phytoplasmas and transmitted by leafhoppers that has been spreading in European vineyards despite significant efforts to control it. In this study, we aim to develop a model for the automatic detection of FD-like symptoms (which encompass other grapevine yellows symptoms). The concept is to detect likely FD-affected grapevines so that samples can be removed for FD laboratory identification, followed by uprooting if they test positive, all to be conducted quickly and without omission, thus avoiding further contamination in the fields. Developing FD-like symptoms detection models is not simple, as it requires dealing with the complexity of field conditions and FD symptoms’ expression. To address these challenges, we use deep learning, which has already been proven effective in similar contexts. More specifically, we train a Convolutional Neural Network on image patches, and convert it into a Fully Convolutional Network to perform inference. As a result, we obtain a coarse segmentation of the likely FD-affected areas while having only trained a classifier, which is less demanding in terms of annotations. We evaluate the performance of our model trained on a white grape variety, Chardonnay, across five other grape varieties with varying FD symptoms expressions. Of the two largest test datasets, the true positive rate for Chardonnay reaches 98.48% whereas for Ugni-Blanc it drops to 8.3%, underlining the need for a multi-varietal training dataset to capture the diversity of FD symptoms. To obtain more transparent results and to better understand the model’s sensitivity, we investigate its behavior using two visualization techniques, Guided Gradient-weighted Class Activation Mapping and the Uniform Manifold Approximation and Projection. Such techniques lead to a more comprehensive analysis with greater reliability, which is essential for in-field applications, and more broadly, for all applications impacting humans and the environment. © Copyright © 2020 Boulent, St-Charles, Foucher and Théau.","convolutional neural networks; explainable artificial intelligence; Flavescence dorée; fully convolutional networks; grapevine yellows; plant diseases detection; precision viticulture; smart farming",
"Bouslihim Y., Rochdi A., El Amrani Paaza N.","Machine learning approaches for the prediction of soil aggregate stability","10.1016/j.heliyon.2021.e06480","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102339798&doi=10.1016%2fj.heliyon.2021.e06480&partnerID=40&md5=beb8acd694843e1b4b8d8c87007512ed","Currently, many Pedotransfer Functions (PTFs) are being developed to predict certain soil properties worldwide, especially for difficult and time-consuming parameters to measure. However, very few studies have been done to assess the feasibility of using PTFs (regression or machine learning methods) for predicting soil aggregate stability. Also, the Random Forest (RF) method has never been used before to predict this parameter, and no study was found concerning the use of PTFs methods to estimate soil parameters in Morocco. Therefore, the current study was conducted in the three watersheds of Settat- Ben Ahmed Plateau, located in the center of Morocco and covering approximately 1000 km2. The purpose of this study is to compare the capabilities of the machine learning technique (Random Forest) and Multiple Linear Regression (MLR) to predict the Mean Weight Diameter (MWD) as an index of soil aggregate stability using soil properties from two sources data sets and remote sensing data. The performance of the models was evaluated using a 10-fold cross-validation procedure. The results achieved were acceptable in predicting soil aggregate stability and similar for both models. Thus, the addition of remote sensing indices to soil properties does not improve models. Results also show that organic matter is the most relevant variable for predicting soil aggregate stability for both models. The developed models can be used to predict the soil aggregate stability in this region and avoid waste of time and money deployed for analyses. However, we recommend using the largest and most uniform possible data set to achieve more accurate results. © 2021 The AuthorsPedotransfer functions, soil aggregate stability, mean weight diameter, multiple linear regression, random forest, remote sensing data. © 2021 The Authors","Mean weight diameter; Multiple linear regression; Pedotransfer functions; Random forest; Remote sensing data; Soil aggregate stability",
"Boutahir M.K., Farhaoui Y., Azrour M., Zeroual I., El Allaoui A.","Effect of Feature Selection on the Prediction of Direct Normal Irradiance","10.26599/BDMA.2022.9020003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135258259&doi=10.26599%2fBDMA.2022.9020003&partnerID=40&md5=14480b4cb675bffaa64a741368390151","Solar radiation is capable of producing heat, causing chemical reactions, or generating electricity. Thus, the amount of solar radiation at different times of the day must be determined to design and equip all solar systems. Moreover, it is necessary to have a thorough understanding of different solar radiation components, such as Direct Normal Irradiance (DNI), Diffuse Horizontal Irradiance (DHI), and Global Horizontal Irradiance (GHI). Unfortunately, measurements of solar radiation are not easily accessible for the majority of regions on the globe. This paper aims to develop a set of deep learning models through feature importance algorithms to predict the DNI data. The proposed models are based on historical data of meteorological parameters and solar radiation properties in a specific location of the region of Errachidia, Morocco, from January 1, 2017, to December 31, 2019, with an interval of 60 minutes. The findings demonstrated that feature selection approaches play a crucial role in forecasting of solar radiation accurately when compared with the available data. © 2018 Tsinghua University Press.","deep learning; feature importance; machine learning; renewable energies; solar radiation","Deep learning; Feature extraction; Forecasting; Deep learning; Diffuse horizontal irradiance; Direct normal irradiances; Feature importance; Features selection; Historical data; Learning models; Machine-learning; Measurements of; Renewable energies; Solar radiation"
"Bowler A.L., Ozturk S., Rady A., Watson N.","Domain Adaptation for In-Line Allergen Classification of Agri-Food Powders Using Near-Infrared Spectroscopy","10.3390/s22197239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139943477&doi=10.3390%2fs22197239&partnerID=40&md5=e3bed4acd2a315e22504bd430c5e4ace","The addition of incorrect agri-food powders to a production line due to human error is a large safety concern in food and drink manufacturing, owing to incorporation of allergens in the final product. This work combines near-infrared spectroscopy with machine-learning models for early detection of this problem. Specifically, domain adaptation is used to transfer models from spectra acquired under stationary conditions to moving samples, thereby minimizing the volume of labelled data required to collect on a production line. Two deep-learning domain-adaptation methodologies are used: domain-adversarial neural networks and semisupervised generative adversarial neural networks. Overall, accuracy of up to 96.0% was achieved using no labelled data from the target domain moving spectra, and up to 99.68% was achieved when incorporating a single labelled data instance for each material into model training. Using both domain-adaptation methodologies together achieved the highest prediction accuracies on average, as did combining measurements from two near-infrared spectroscopy sensors with different wavelength ranges. Ensemble methods were used to further increase model accuracy and provide quantification of model uncertainty, and a feature-permutation method was used for global interpretability of the models. © 2022 by the authors.","domain adaptation; food and drink; machine learning; near-infrared spectroscopy; process monitoring; transfer learning","Allergens; Deep learning; Infrared devices; Learning systems; Manufacture; Powders; Uncertainty analysis; Domain adaptation; Food and drink; Food powders; Human errors; Labeled data; Machine-learning; Neural-networks; Production line; Spectra's; Transfer learning; Process monitoring; allergen; human; machine learning; near infrared spectroscopy; powder; Allergens; Humans; Machine Learning; Neural Networks, Computer; Powders; Spectroscopy, Near-Infrared"
"Bracci E., Tallaki M., Ievoli R., Diplotti S.","Knowledge, diffusion and interest in blockchain technology in SMEs","10.1108/JKM-02-2021-0099","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113827771&doi=10.1108%2fJKM-02-2021-0099&partnerID=40&md5=ae10c52eb589272ba3745976ae25a770","Purpose: The paper aims to understand the possible determinants of knowledge of, and interest in using, blockchain, with a particular focus in the future intention to apply this technology. Blockchain technology is deemed to radically change business models and processes. Using this technology in small and medium enterprises (SMEs) is still a novel idea. Moreover, not much is known about the diffusion and level of interest towards blockchain in SMEs. This research adopts a knowledge management perspective, drawing on technology acceptance model to highlight the level of blockchain technology diffusion, and to explore which factors lead SMEs’ to adopt blockchain. Design/methodology/approach: This study distributed a questionnaire to a sample of 300 SMEs in Italy. This study received 96 responses (32% response rate). This study calculated descriptive statistics and undertook a reliability analysis. Finally, this study performed a logistic regression to analyse the determinants of further intention to use blockchain technology. Findings: Results show that blockchain technology is quite well known, but the level of knowledge is limited. Moreover, the research reveals that the rate of adoption is very low. Interest in the future adoption of blockchain is associated with knowledge, perception of usefulness and ease of use of blockchain. Originality/value: This paper is one of the first explorative studies showing which factors lead SMEs to adopt blockchain technologies and shedding some light on the interaction between knowledge management and blockchain adoption and diffusion in SMEs. It highlights how blockchain knowledge could determine future interest in blockchain innovation. This paper is relevant for public and private institutions that aim to promote, through knowledge management, the adoption of blockchain in SMEs. © 2021, Emerald Publishing Limited.","Blockchain diffusion; Blockchain knowledge; Interest in blockchain; Knowledge; Usefulness; Usefulness and ease to use of blockchain",
"Brakefield W.S., Olusanya O.A., Shaban-Nejad A.","Association Between Neighborhood Factors and Adult Obesity in Shelby County, Tennessee: Geospatial Machine Learning Approach","10.2196/37039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135768922&doi=10.2196%2f37039&partnerID=40&md5=ae4e50240ffa5dca40df99b5ea5f279f","Background: Obesity is a global epidemic causing at least 2.8 million deaths per year. This complex disease is associated with significant socioeconomic burden, reduced work productivity, unemployment, and other social determinants of health (SDOH) disparities. Objective: The objective of this study was to investigate the effects of SDOH on obesity prevalence among adults in Shelby County, Tennessee, the United States, using a geospatial machine learning approach. Methods: Obesity prevalence was obtained from the publicly available 500 Cities database of Centers for Disease Control and Prevention, and SDOH indicators were extracted from the US census and the US Department of Agriculture. We examined the geographic distributions of obesity prevalence patterns, using Getis-Ord Gi* statistics and calibrated multiple models to study the association between SDOH and adult obesity. Unsupervised machine learning was used to conduct grouping analysis to investigate the distribution of obesity prevalence and associated SDOH indicators. Results: Results depicted a high percentage of neighborhoods experiencing high adult obesity prevalence within Shelby County. In the census tract, the median household income, as well as the percentage of individuals who were Black, home renters, living below the poverty level, 55 years or older, unmarried, and uninsured, had a significant association with adult obesity prevalence. The grouping analysis revealed disparities in obesity prevalence among disadvantaged neighborhoods. Conclusions: More research is needed to examine links between geographical location, SDOH, and chronic diseases. The findings of this study, which depict a significantly higher prevalence of obesity within disadvantaged neighborhoods, and other geospatial information can be leveraged to offer valuable insights, informing health decision-making and interventions that mitigate risk factors of increasing obesity prevalence. © Whitney S Brakefield, Olufunto A Olusanya, Arash Shaban-Nejad.","disease surveillance; disparities; geographic information systems; machine learning; obesity; obesity surveillance; SDOH; social determinants of health","adult; demography; human; machine learning; obesity; socioeconomics; Tennessee; United States; Adult; Humans; Machine Learning; Obesity; Residence Characteristics; Socioeconomic Factors; Tennessee; United States"
"Brauner P., Dalibor M., Jarke M., Kunze I., Koren I., Lakemeyer G., Liebenberg M., Michael J., Pennekamp J., Quix C., Rumpe B., Van Der Aalst W., Wehrle K., Wortmann A., Ziefle M.","A Computer Science Perspective on Digital Transformation in Production","10.1145/3502265","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121783951&doi=10.1145%2f3502265&partnerID=40&md5=845f657b2749b28088610b8b64995d1c","The Industrial Internet-of-Things (IIoT) promises significant improvements for the manufacturing industry by facilitating the integration of manufacturing systems by Digital Twins. However, ecological and economic demands also require a cross-domain linkage of multiple scientific perspectives from material sciences, engineering, operations, business, and ergonomics, as optimization opportunities can be derived from any of these perspectives. To extend the IIoT to a true Internet of Production, two concepts are required: first, a complex, interrelated network of Digital Shadows which combine domain-specific models with data-driven AI methods; and second, the integration of a large number of research labs, engineering, and production sites as a World Wide Lab which offers controlled exchange of selected, innovation-relevant data even across company boundaries. In this article, we define the underlying Computer Science challenges implied by these novel concepts in four layers: Smart human interfaces provide access to information that has been generated by model-integrated AI. Given the large variety of manufacturing data, new data modeling techniques should enable efficient management of Digital Shadows, which is supported by an interconnected infrastructure. Based on a detailed analysis of these challenges, we derive a systematized research roadmap to make the vision of the Internet of Production a reality. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Digital shadows; Industrial internet of things; Internet of production; World wide lab","Ergonomics; Information management; Internet of things; Manufacture; Cross-domain; Digital shadow; Digital transformation; Ecological and economic; Economic demand; Engineering operation; Internet of production; Manufacturing industries; Material science; World wide lab; Research laboratories"
"Brdar S., Panić M., Hogeveen-van Echtelt E., Mensink M., Grbović Ž., Woltering E., Chauhan A.","Predicting sensitivity of recently harvested tomatoes and tomato sepals to future fungal infections","10.1038/s41598-021-02302-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120175696&doi=10.1038%2fs41598-021-02302-2&partnerID=40&md5=01718448c9610d23cdc73fa708976439","Tomato is an important commercial product which is perishable by nature and highly susceptible to fungal incidence once it is harvested. Not all tomatoes are equally vulnerable to pathogenic fungi, and an early detection of the vulnerable ones can help in taking timely preventive actions, ranging from isolating tomato batches to adjusting storage conditions, but also in making right business decisions like dynamic pricing based on quality or better shelf life estimate. More importantly, early detection of vulnerable produce can help in taking timely actions to minimize potential post-harvest losses. This paper investigates Near-infrared (NIR) hyperspectral imaging (1000–1700 nm) and machine learning to build models to automatically predict the susceptibility of sepals of recently harvested tomatoes to future fungal infections. Hyperspectral images of newly harvested tomatoes (cultivar Brioso) from 5 different growers were acquired before the onset of any visible fungal infection. After imaging, the tomatoes were placed under controlled conditions suited for fungal germination and growth for a 4-day period, and then imaged using normal color cameras. All sepals in the color images were ranked for fungal severity using crowdsourcing, and the final severity of each sepal was fused using principal component analysis. A novel hyperspectral data processing pipeline is presented which was used to automatically segment the tomato sepals from spectral images with multiple tomatoes connected via a truss. The key modelling question addressed in this research is whether there is a correlation between the hyperspectral data captured at harvest and the fungal infection observed 4 days later. Using 10-fold and group k-fold cross-validation, XG-Boost and Random Forest based regression models were trained on the features derived from the hyperspectral data corresponding to each sepal in the training set and tested on hold out test set. The best model found a Pearson correlation of 0.837, showing that there is strong linear correlation between the NIR spectra and the future fungal severity of the sepal. The sepal specific predictions were aggregated to predict the susceptibility of individual tomatoes, and a correlation of 0.92 was found. Besides modelling, focus is also on model interpretation, particularly to understand which spectral features are most relevant to model prediction. Two approaches to model interpretation were explored, feature importance and SHAP (SHapley Additive exPlanations), resulting in similar conclusions that the NIR range between 1390–1420 nm contributes most to the model’s final decision. © 2021, The Author(s).",,"algorithm; automated pattern recognition; calibration; crop; fruit; genetics; machine learning; microbiology; near infrared spectroscopy; plant disease; prevention and control; principal component analysis; procedures; reproducibility; software; tomato; Algorithms; Calibration; Crops, Agricultural; Deep Learning; Fruit; Lycopersicon esculentum; Machine Learning; Microbiology; Pattern Recognition, Automated; Plant Diseases; Principal Component Analysis; Reproducibility of Results; Software; Spectroscopy, Near-Infrared"
"Brenning A.","Spatial machine-learning model diagnostics: a model-agnostic distance-based approach","10.1080/13658816.2022.2131789","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140827329&doi=10.1080%2f13658816.2022.2131789&partnerID=40&md5=e8bb5e001b3f1af11e42c1c04c151355","While significant progress has been made towards explaining black-box machine-learning (ML) models, there is still a distinct lack of diagnostic tools that elucidate the spatial behaviour of ML models in terms of predictive skill and variable importance. This contribution proposes spatial prediction error profiles (SPEPs) and spatial variable importance profiles (SVIPs) as novel model-agnostic assessment and interpretation tools for spatial prediction models with a focus on prediction distance. Their suitability is demonstrated in two case studies representing a regionalization task in an environmental-science context, and a classification task from remotely-sensed land cover classification. In these case studies, the SPEPs and SVIPs of geostatistical methods, linear models, random forest, and hybrid algorithms show striking differences but also relevant similarities. Limitations of related cross-validation techniques are outlined, and the case is made that modelers should focus their model assessment and interpretation on the intended spatial prediction horizon. The range of autocorrelation, in contrast, is not a suitable criterion for defining spatial cross-validation test sets. The novel diagnostic tools enrich the toolkit of spatial data science and may improve ML model interpretation, selection, and design. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Interpretable machine learning; spatial autocorrelation; spatial cross-validation; spatial prediction error; spatial variable importance",
"Brintrup A., Kosasih E.E., MacCarthy B.L., Demirel G.","Digital supply chain surveillance","10.1016/B978-0-323-91614-1.00022-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137877946&doi=10.1016%2fB978-0-323-91614-1.00022-8&partnerID=40&md5=370a6f26e0ca1ee6cdaa58d112d8d0fd","In this chapter, we define and conceptualize the emerging practice of “Digital Supply Chain Surveillance (DSCS)” as the proactive monitoring of digital data that allows firms to track, manage, and analyze information related to a supply chain network using available data and information sources. DSCS has potential applications in risk management, supplier performance management, production planning, inventory optimization, quality management, supplier financing, and cost reduction in supply chains. Artificial Intelligence (AI) is potentially a key enabler and may facilitate a step change in DSCS. We present a framework, SDAR (Surveillance, Detection, Action, Response), to support the design of effective business processes for supply network surveillance. We outline the most important types of AI algorithms and models and discuss their applicability to a range of questions that arise in DSCS. By linking different surveillance data sources and systems, appropriate AI techniques can make surveillance easier, more informative, and scalable. However, AI-based DSCS gives rise to significant technical, ethical, and managerial challenges. These include the decomposition and reintegration of surveillance data and analyses, data imbalances, mitigation of biases in data, algorithms and statistical estimations, and the challenge of embedding DSCS in effective supplier monitoring and auditing processes. © 2022 Elsevier Inc. All rights reserved.","Artificial intelligence; Data analytics; Digital supply chains; Machine learning; Resilience",
"Bukhari H.R., Mumtaz R., Inayat S., Shafi U., Haq I.U., Zaidi S.M.H., Hafeez M.","Assessing the Impact of Segmentation on Wheat Stripe Rust Disease Classification Using Computer Vision and Deep Learning","10.1109/ACCESS.2021.3134196","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121358293&doi=10.1109%2fACCESS.2021.3134196&partnerID=40&md5=249bea7ac89923bc5d67ebfcac6f9595","Wheat is a staple crop that is grown across the world due to its substantial contribution to human nutrition. Its significance is evident as it provides almost 20% of calories and protein required for daily human consumption. However, wheat yield is affected by rust disease that can reduce 30% of wheat production which is a serious threat to food security. In order to minimize the loss, it is crucial to identify precisely and localize the wheat rust disease and its infection types. For this purpose, several classification and segmentation techniques are used which are based on machine/deep learning models. This paper provides a realistic analysis and evaluation of various segmentation techniques including Watershed, Grab Cut, and U2-Net. These techniques are applied to the wheat stripe rust data to generate multiple datasets such as Watershed segmented data, GrabCut segmented data, and U2-Net segmented data. Subsequently, a pre-trained deep learning model, ResNet-18 is applied to these datasets to assess the impact of segmentation on classification accuracy. The highest classification accuracy (96.196%) is achieved on the dataset segmented by U2-Net. This research collates several state-of-the-art segmentation techniques in terms of correctness and their direct impact on classification accuracy which gives a pragmatic analysis for researchers to choose optimal segmentation technique. The research primarily focuses on the direct impact of segmentation on classification accuracy of wheat stripe rust, which has not been given sufficient focus in earlier researches. © 2013 IEEE.","classification; cropping; deep learning; Machine learning; segmentation; wheat stripe rust disease","Biological systems; Classification (of information); Crops; Deep learning; Food supply; Hierarchical systems; Image classification; Watersheds; Biological system modeling; Cropping; Deep learning; Image color analysis; Images segmentations; Machine-learning; Rust disease; Segmentation; Stripe rust; Wheat stripe rust disease; Image segmentation"
"Burkart N., Huber M.F.","A survey on the explainability of supervised machine learning","10.1613/JAIR.1.12228","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100964661&doi=10.1613%2fJAIR.1.12228&partnerID=40&md5=47302df3435a0e4105df250ea1617d6d","Predictions obtained by, e.g., artificial neural networks have a high accuracy but humans often perceive the models as black boxes. Insights about the decision making are mostly opaque for humans. Particularly understanding the decision making in highly sensitive areas such as healthcare or finance, is of paramount importance. The decision-making behind the black boxes requires it to be more transparent, accountable, and understandable for humans. This survey paper provides essential definitions, an overview of the different principles and methodologies of explainable Supervised Machine Learning (SML). We conduct a state-of-the-art survey that reviews past and recent explainable SML approaches and classifies them according to the introduced definitions. Finally, we illustrate principles by means of an explanatory case study and discuss important future directions. © 2021 AI Access Foundation.",,"Decision making; Neural networks; Supervised learning; Surveys; Black boxes; High-accuracy; Sensitive area; State of the art; Supervised machine learning; Learning systems"
"Cai Q., Li F.","Development status and trend of autonomous operation for unmanned surface vehicle","10.1117/12.2637765","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132912687&doi=10.1117%2f12.2637765&partnerID=40&md5=3545667e28c6f1a3e18b03b174159e48","Autonomous operation for unmanned surface vehicle (USV) is the core competence for USV, and an important mean for unmanned and intelligent operation. USVs can be used for multi-mission, so autonomous operation for USV faces a lot of challenges, such as complex and changeable marine environmental factors, limited means of awareness in sea, low degree of automated operational decisions, difficult integration control of sailing and combat equipment. This study summarizes the development status of autonomous operation for USVs from awareness, decision and control. It addresses the difficult issues and current main technologies of autonomous operation for USVs, and points out the deficiencies of the technologies. Finally, based on the analyses of development status, it addresses the development trend of autonomous operation for USV. © The Authors.","autonomous operation; awareness; control; decision-making; Unmanned surface vehicle","Unmanned surface vehicles; Autonomous operations; Awareness; Core competence; Decisions makings; Development status; Development trends; Environmental factors; Intelligent operations; Low degree; Operational decisions; Decision making"
"Cai Z., Liu L., Chen B., Wang Y.","Artificial intelligence: From beginning to date","10.1142/11921","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114982331&doi=10.1142%2f11921&partnerID=40&md5=0ca837e6c0063b0ea5d2d2c74df17982","This English edition monograph is developed and updated from China's best-selling, and award-winning, book on Artificial Intelligence (AI). It covers the foundations as well as the latest developments of AI in a comprehensive and systematic manner. It is a valuable guide for students and researchers on artificial intelligence. A wide range of topics in AI are covered in this book with four distinct features. First of all, the book comprises a comprehensive system, covering the core technology of AI, including the basic theories and techniques of ""traditional"" artificial intelligence, and the basic principles and methods of computational intelligence. Secondly, the book focuses on innovation, covering advanced learning methods for machine learning and deep learning techniques and other artificial intelligence that have been widely used in recent years. Thirdly, the theory and practice of the book are highly integrated. There are theories, techniques and methods, as well as many application examples, which will help readers to understand the artificial intelligence theory and its application development. Fourthly, the content structure of the book is quite characteristic, consisting of three parts: (i) knowledge-based artificial intelligence, (ii) data-based artificial intelligence, and (iii) artificial intelligence applications.It is closely related to the core elements of artificial intelligence, namely knowledge, data, algorithms, and computing powers. This reflects the authors' deep understanding of the artificial intelligence discipline. © 2021 by World Scientific Publishing Co. Pte. Ltd. Under exclusive license by Tsinghua University Press Limited.",,
"Calegari R., Ciatto G., Denti E., Omicini A.","Logic-based technologies for intelligent systems: State of the art and perspectives","10.3390/info11030167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082507008&doi=10.3390%2finfo11030167&partnerID=40&md5=0ffb460d3221ebc31ae6a7314023a412","Together with the disruptive development of modern sub-symbolic approaches to artificial intelligence (AI), symbolic approaches to classical AI are re-gaining momentum, as more and more researchers exploit their potential to make AI more comprehensible, explainable, and therefore trustworthy. Since logic-based approaches lay at the core of symbolic AI, summarizing their state of the art is of paramount importance now more than ever, in order to identify trends, benefits, key features, gaps, and limitations of the techniques proposed so far, as well as to identify promising research perspectives. Along this line, this paper provides an overview of logic-based approaches and technologies by sketching their evolution and pointing out their main application areas. Future perspectives for exploitation of logic-based technologies are discussed aswell, in order to identify those research fields that deserve more attention, considering the areas that already exploit logic-based approaches as well as those that are more likely to adopt logic-based approaches in the future. © 2020 by the authors.","Intelligent systems; Logic-based technologies; Symbolic AI","Intelligent systems; Application area; Future perspectives; Gaining momentum; Logic based technology; Logic-based approach; Research fields; State of the art; Sub-symbolic approach; Computer circuits"
"Camara F., Bellotto N., Cosar S., Weber F., Nathanael D., Althoff M., Wu J., Ruenz J., Dietrich A., Markkula G., Schieben A., Tango F., Merat N., Fox C.","Pedestrian Models for Autonomous Driving Part II: High-Level Models of Human Behavior","10.1109/TITS.2020.3006767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111304323&doi=10.1109%2fTITS.2020.3006767&partnerID=40&md5=4b54911cb72973b9b7e8b57d8d132521","Autonomous vehicles (AVs) must share space with pedestrians, both in carriageway cases such as cars at pedestrian crossings and off-carriageway cases such as delivery vehicles navigating through crowds on pedestrianized high-streets. Unlike static obstacles, pedestrians are active agents with complex, interactive motions. Planning AV actions in the presence of pedestrians thus requires modelling of their probable future behavior as well as detecting and tracking them. This narrative review article is Part II of a pair, together surveying the current technology stack involved in this process, organising recent research into a hierarchical taxonomy ranging from low-level image detection to high-level psychological models, from the perspective of an AV designer. This self-contained Part II covers the higher levels of this stack, consisting of models of pedestrian behavior, from prediction of individual pedestrians' likely destinations and paths, to game-theoretic models of interactions between pedestrians and autonomous vehicles. This survey clearly shows that, although there are good models for optimal walking behavior, high-level psychological and social modelling of pedestrian behavior still remains an open research question that requires many conceptual issues to be clarified. Early work has been done on descriptive and qualitative models of behavior, but much work is still needed to translate them into quantitative algorithms for practical AV control. © 2000-2011 IEEE.","autonomous vehicles; datasets; detection; eHMI; game-theoretic models; microscopic and macroscopic behavior models; pedestrian interaction; pedestrians; Review; sensing; signalling models; survey; tracking; trajectory prediction","Autonomous vehicles; Game theory; Pedestrian safety; Surveys; Autonomous driving; Current technology; Game-theoretic model; Hierarchical taxonomy; Pedestrian behavior; Psychological model; Recent researches; Research questions; Behavioral research"
"Cammarano A., Varriale V., Michelino F., Caputo M.","Open and Crowd-Based Platforms: Impact on Organizational and Market Performance","10.3390/su14042223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124872612&doi=10.3390%2fsu14042223&partnerID=40&md5=b0f1e03604e39c8b0e9560d0cdfc1fd8","The aim of the research was to present the state of the art on the use of open and crowd-based platforms and the advantages in terms of business performance that emerging practices employing such technologies are able to provide. The analysis was performed by extracting information on emerging practices from the repository Business Process Framework for Emerging Technologies developed by the Department of Industrial Engineering of the University of Salerno (Italy). Contingency tables allowed analysis of the association of such practices with industry, business function, business process, and impact on performance. From the analysis of the results, many implementation opportunities emerge, mainly in manufacturing, healthcare, and transportation industries, providing benefits not only in terms of efficiency and productivity, cost reduction, and information management but also in product/service differentiation. Therefore, the research provides an overview of opportunities for organizations employing open and crowd-based platforms in order to improve market and organizational performance. Moreover, the article highlights in what specific business contexts these technologies can be mainly useful. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Crowd science; Crowdfunding; Crowdsourcing; Emerging technologies; Open access; Open data; Open innovation; Open science; Open-source; Platforms","business; cost analysis; information management; market conditions; Campania [Italy]; Italy; Salerno"
"Campos-Taberner M., García-Haro F.J., Martínez B., Gilabert M.A.","Deep learning for agricultural land use classification from sentinel-2 [Deep learning para la clasificación de usos de suelo agrícola con sentinel-2]","10.4995/raet.2020.13337","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097190490&doi=10.4995%2fraet.2020.13337&partnerID=40&md5=772408ad93cbd6911f41f17382ad8587","The use of deep learning techniques for remote sensing applications has recently increased. These algorithms have proven to be successful in estimation of parameters and classification of images. However, little effort has been made to make them understandable, leading to their implementation as “black boxes”. This work aims to evaluate the performance and clarify the operation of a deep learning algorithm, based on a bi-directional recurrent network of long short-term memory (2-BiLSTM). The land use classification in the Valencian Community based on Sentinel-2 image time series in the framework of the common agricultural policy (CAP) is used as an example. It is verified that the accuracy of the deep learning techniques is superior (98.6 % overall success) to that other algorithms such as decision trees (DT), k-nearest neighbors (k-NN), neural networks (NN), support vector machines (SVM) and random forests (RF). The performance of the classifier has been studied as a function of time and of the predictors used. It is concluded that, in the study area, the most relevant information used by the network in the classification are the images corresponding to summer and the spectral and spatial information derived from the red and near infrared bands. These results open the door to new studies in the field of the explainable deep learning in remote sensing applications. © 2020, Universidad Politecnica de Valencia.. All rights reserved.","BiLSTM; Classification; Deep learning; Sentinel-2; Time series",
"Cao M., Tang F., Ji P., Ma F.","Improved Real-Time Semantic Segmentation Network Model for Crop Vision Navigation Line Detection","10.3389/fpls.2022.898131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132831362&doi=10.3389%2ffpls.2022.898131&partnerID=40&md5=3d3e5e53c4c544486c8253682d719981","Field crops are generally planted in rows to improve planting efficiency and facilitate field management. Therefore, automatic detection of crop planting rows is of great significance for achieving autonomous navigation and precise spraying in intelligent agricultural machinery and is an important part of smart agricultural management. To study the visual navigation line extraction technology of unmanned aerial vehicles (UAVs) in farmland environments and realize real-time precise farmland UAV operations, we propose an improved ENet semantic segmentation network model to perform row segmentation of farmland images. Considering the lightweight and low complexity requirements of the network for crop row detection, the traditional network is compressed and replaced by convolution. Based on the residual network, we designed a network structure of the shunting process, in which low-dimensional boundary information in the feature extraction process is passed backward using the residual stream, allowing efficient extraction of low-dimensional information and significantly improving the accuracy of boundary locations and row-to-row segmentation of farmland crops. According to the characteristics of the segmented image, an improved random sampling consensus algorithm is proposed to extract the navigation line, define a new model-scoring index, find the best point set, and use the least-squares method to fit the navigation line. The experimental results showed that the proposed algorithm allows accurate and efficient extraction of farmland navigation lines, and it has the technical advantages of strong robustness and high applicability. The algorithm can provide technical support for the subsequent quasi-flight of agricultural UAVs in farmland operations. Copyright © 2022 Cao, Tang, Ji and Ma.","crop rows detection; navigation path recognition; precision agriculture application; semantic segmentation; visual navigation",
"Cao S., Huang C.-M.","Understanding User Reliance on AI in Assisted Decision-Making","10.1145/3555572","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146372689&doi=10.1145%2f3555572&partnerID=40&md5=1ba8e4f65d722ed20070fb805abc5ff9","Proper calibration of human reliance on AI is fundamental to achieving complementary performance in AI-assisted human decision-making. Most previous works focused on assessing user reliance, and more broadly trust, retrospectively, through user perceptions and task-based measures. In this work, we explore the relationship between eye gaze and reliance under varying task difficulties and AI performance levels in a spatial reasoning task. Our results show a strong positive correlation between percent gaze duration on the AI suggestion and user AI task agreement, as well as user perceived reliance. Moreover, user agency is preserved particularly when the task is easy and when AI performance is low or inconsistent. Our results also reveal nuanced differences between reliance and trust. We discuss the potential of using eye gaze to gauge human reliance on AI in real-time, enabling adaptive AI assistance for optimal human-AI team performance. © 2022 Owner/Author.","decision making; decision support tools; gaze; human-ai interaction; trust","Decision support systems; Decision support tool; Decision supports; Decisions makings; Eye-gaze; Gaze; Human decision-making; Human-ai interaction; Performance; Support tool; Trust; Decision making"
"Cappelli F., Tauro F., Apollonio C., Petroselli A., Borgonovo E., Grimaldi S.","Feature importance measures to dissect the role of sub-basins in shaping the catchment hydrological response: a proof of concept","10.1007/s00477-022-02332-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142256581&doi=10.1007%2fs00477-022-02332-w&partnerID=40&md5=0e45d781e9006aa02279bb4a24d31baf","Understanding the response of a catchment is a crucial problem in hydrology, with a variety of practical and theoretical implications. Dissecting the role of sub-basins is helpful both for advancing current knowledge of physical processes and for improving the implementation of simulation or forecast models. In this context, recent advancements in sensitivity analysis tools could be worthwhile for bringing out hidden dynamics otherwise not easy to distinguish in complex data driven investigations. In the present work seven feature importance measures are described and tested in a specific and simplified proof of concept case study. In practice, simulated runoff time series are generated for a watershed and its inner 15 sub-basins. A machine learning tool is calibrated using the sub-basins time series for forecasting the watershed runoff. Importance measures are applied on such synthetic hydrological scenario with the aim to investigate the role of each sub-basin in shaping the overall catchment response. This proof of concept offers a simplified representation of the complex dynamics of catchment response. The interesting result is that the discharge at the catchment outlet depends mainly on 3 sub-basins that are consistently identified by alternative sensitivity measures. The proposed approach can be extended to real applications, providing useful insights on the role of each sub-basin also analyzing more complex scenarios. © 2022, The Author(s).","Catchment hydrological response; Feature importance measures; Global sensitivity measures; Machine learning; Random Forest","Decision trees; Machine learning; Runoff; Sensitivity analysis; Time series; Watersheds; Catchment hydrological response; Feature importance measure; Global sensitivity; Global sensitivity measure; Hydrological response; Importance measure; Machine-learning; Random forests; Sensitivity measures; Subbasins; Catchments"
"Caravaggio N.","A global empirical re-assessment of the Environmental Kuznets curve for deforestation","10.1016/j.forpol.2020.102282","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089999045&doi=10.1016%2fj.forpol.2020.102282&partnerID=40&md5=d71c5f4bd87232ed32456d6538d4ed7a","This paper investigates an unresolved question in environmental economics: An Environmental Kuznets Curve for deforestation (EKCd). It relies on a 55 year panel of forest cover data reconstructed from the periodic national forest inventories of 114 countries clustered in low, middle, and high income groups—as defined by the World Bank—and examines these clusters within both static and dynamic frameworks. The results are supportive of the inverse U-shaped EKC for deforestation. For low income countries strong effort will be required to avoid further increases in forest loss as these countries develop. Middle income countries, the largest cluster under investigation, display the classic bell-shaped EKCd with the turning point for a decreasing rate of deforestation at US$ 3,790. Deforestation continues thereafter, only at a lower rate until, eventually, for high income countries these rates become negative and these economies begin to show absolute gains in total forest cover. While the combined results from the three clusters confirm the existence of an EKCd, its relatively elevated turning point and the even higher level of development at which forests begin to increase and recover, raise important concern, but also opportunity, for the modern policies and management addressing global forest cover—doubts and opportunities on which the conclusion to this paper reflects further. © 2020 Elsevier B.V.","Deforestation; Environmental Kuznets curve; Forest transition; Panel data; Time series","Deforestation; Dynamic framework; Environmental economics; Environmental Kuznets curves; Income groups; Low income countries; Middle-income countries; National forest inventories; Turning points; Economics; Clumps; Coverings; Data; Deforestation; Displays; Economics; Inventories; Paper"
"Caravaggio N.","Economic growth and the forest development path: A theoretical re-assessment of the environmental Kuznets curve for deforestation","10.1016/j.forpol.2020.102259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088220851&doi=10.1016%2fj.forpol.2020.102259&partnerID=40&md5=2a3bc23adf043fbff170d8f3ed87bc8e","This paper reviews the literature of an unresolved question in environmental economics, the environmental Kuznets curve for deforestation (EKCd). It begins by summarizing the general EKC, the idea that economies draw on their environmental resources during initial growth but, with further growth above some level, their environmental decline attains a turning point. Most investigations of the EKCd are limited to approximately 25 years of FAO forest cover data and most feature sets of developing countries. These are short time series for a resource like forests and the paucity of evidence from developed countries is another weakness. Further discussion of two related concepts, the Forest Transition and a von-Thünen-based forest development pattern, shows a second EKC turning point for deforestation which (unlike environmental resources like, say, CO2) can recover with reforestation and addition to the forest base. Altogether, this background of experience recommends that future examinations of the unresolved EKCd reconsider, among others, the duration and thoroughness of the data, the extent of the cross-sectional international coverage, and the potential of a second turning point occurring for higher levels of development. © 2020 Elsevier B.V.","Deforestation; Environmental Kuznets curve; Forest Transition; Literature review; von Thünen","Deforestation; Developing countries; Reforestation; Developed countries; Economic growths; Environmental economics; Environmental Kuznets curves; Environmental resources; Forest development; Forest transition; Short time series; Economics; Data; Deforestation; Developing Countries; Development; Economics; Growth; Reforestation; Resources"
"Card D., Zhang M., Smith N.A.","Deep weighted averaging classifiers","10.1145/3287560.3287595","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061833178&doi=10.1145%2f3287560.3287595&partnerID=40&md5=92b6e6d9d33d8a4d7e27e12551520819","Recent advances in deep learning have achieved impressive gains in classification accuracy on a variety of types of data, including images and text. Despite these gains, however, concerns have been raised about the calibration, robustness, and interpretability of these models. In this paper we propose a simple way to modify any conventional deep architecture to automatically provide more transparent explanations for classification decisions, as well as an intuitive notion of the credibility of each prediction. Specifically, we draw on ideas from nonparametric kernel regression, and propose to predict labels based on a weighted sum of training instances, where the weights are determined by distance in a learned instance-embedding space. Working within the framework of conformal methods, we propose a new measure of nonconformity suggested by our model, and experimentally validate the accompanying theoretical expectations, demonstrating improved transparency, controlled error rates, and robustness to out-of-domain data, without compromising on accuracy or calibration. © 2019 Association for Computing Machinery.","Conformal methods; Credibility; Interpretability","Calibration; Text processing; Transparency; Classification accuracy; Classification decision; Conformal methods; Credibility; Deep architectures; Interpretability; Nonparametric kernel regressions; Weighted averaging; Deep learning"
"Cardoso Schwindt V., Coletto M.M., Díaz M.F., Ponzoni I.","Could QSOR Modelling and Machine Learning Techniques Be Useful to Predict Wine Aroma?","10.1007/s11947-022-02836-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133246525&doi=10.1007%2fs11947-022-02836-x&partnerID=40&md5=946ffac292b9d6aebb715631e1873fcd","Abstract: Food informatics is having an increasing impact on the food industry and improving the quality of end products, as well as the efficiency of manufacturing processes. In the case of winemaking, a particular application of interest for food informatics is the sensory analysis of wines. This problem can benefit from the strong development that machine learning has achieved in recent decades. However, these data-driven techniques require accurate and sufficient information to generate models capable of predicting the sensory profile of wines. A review of the sensory analysis and volatile composition of wines is presented in this work, along with significant studies on the use of machine learning models to predict wine-related characteristics such as the antioxidant activity of polyphenols of wine and aroma compounds. In this sense, data from a sensory panel and analytical technology were gathered. This literature review reveals the lack of a homogeneous and sufficiently large database of sensory analysis related to the volatile composition of wines to develop machine learning models. However, among artificial intelligence approaches, the application of quantitative structure-odour relationship (QSOR) models is currently gaining importance. Recent studies show that it would be possible to predict quantitatively the sensory analysis of wines by QSOR models, using general volatile composition information. Therefore, the purpose of this review is to identify key aspects and guidelines for the development of this area. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Machine learning; QSOR; Volatile composition; Wine aroma","Forecasting; Machine learning; Odors; Sensory analysis; Informatics; Machine learning models; Machine learning techniques; Machine-learning; Model learning; Quantitative structure-odor relationship; Quantitative structures; Relationship model; Volatile composition; Wine aromas; Wine"
"Carneiro G.A., Padua L., Peres E., Morais R., Sousa J.J., Cunha A.","Segmentation as a Preprocessing Tool for Automatic Grapevine Classification","10.1109/IGARSS46834.2022.9884946","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141598653&doi=10.1109%2fIGARSS46834.2022.9884946&partnerID=40&md5=377f93f351cf232fbea76940c862c5ac","The grapevine variety plays an important role in wine chain production, thus identifying it is crucial for control activities. However, the specialists responsible for identifying the different varieties, mainly through visual analysis, are disappearing. In this scenario, Deep Learning (DL) classification techniques become a possible solution to handle professionals' scarcity. Nevertheless, previous experiments show that trained classification models use the background information to make decisions, which should be avoided. In this paper, we present a study allowing the assessment of removing background regions from the grapevine images in the improvement classification using DL models. The Xception model is trained with a normal dataset and its segmented version. The Local Interpretable Model-Agnostic Explanations (LIME), Grad-CAM, and Grad-CAM++ approaches are used to visualize the segmentation impact in classification decisions. F1-score of 0.92 and 0.94 were achieved, respectively, for segmented-dataset and normal-dataset trained models. Despite the model trained with the segmented-dataset to achieve a worse performance, the Explainable Artificial Intelligence (XAI) approaches showed that it looks into more reliable regions when making decisions. © 2022 IEEE.","convolutional neural networks; explainable artificial intelligence; grapevine species identification; segmentation","Cams; Convolutional neural networks; Deep learning; Image enhancement; Lime; Classification models; Classification technique; Control activities; Convolutional neural network; Explainable artificial intelligence; Grapevine species identification; Preprocessing tools; Segmentation; Species identification; Visual analysis; Classification (of information)"
"Carneiro G.S., Ferreira A., Morais R., Sousa J.J., Cunha A.","Analyzing the Fine Tuning's impact in Grapevine Classification","10.1016/j.procs.2021.12.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122872626&doi=10.1016%2fj.procs.2021.12.025&partnerID=40&md5=559a08d28883c010836c69e874b3694f","Wine is one the most important products from Portugal, being the grapevine variety very important to ensure uniqueness, authenticity and classification. In the Douro Demarcated Region, only certain grapevine varieties are allowed, implying the need for an identification mechanism. The ampelographs, professionals that use visual analysis to classify grapevines, are disappearing. In this situation, one possible replacement for ampelographs can be deep learning models. In previous experiments, we successfully classified 12 grapevines varieties, fine-tuning the Xception model, achieving ~0.9 in F1 score, raising the question, ""what is the impact of the fine-tuning layers' configuration in our results?"". This paper presents an analysis of the impact of different layers' configuration in fine-tuning Xception model to classify 12 grapevine varieties with images acquired in a natural environment. Despite the model achieved F1-score of 0.92 in all configurations, using the Grad-CAM approach, we show that layers' configuration in fine-tuning implies the quality of the models' prediction. As analysis' result, we can see that the model acting as feature extractor and fully fine-tuned obtains similar results in terms of metrics and pixel contribution, and fine-tuning only the last two blocks lead the model to look at more features in the image. © 2021 Elsevier B.V. All rights reserved.","convolutional neural network; explainable artificial intelligence; grad-cam; xception","Cams; Deep learning; Image analysis; Convolutional neural network; Explainable artificial intelligence; F1 scores; Fine tuning; Grad-cam; Identification mechanism; Layer configuration; Portugal; Visual analysis; Xception; Convolutional neural networks"
"Carrington A.M., Fieguth P.W., Qazi H., Holzinger A., Chen H.H., Mayr F., Manuel D.G.","A new concordant partial AUC and partial c statistic for imbalanced data in the evaluation of machine learning algorithms","10.1186/s12911-019-1014-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077570060&doi=10.1186%2fs12911-019-1014-6&partnerID=40&md5=aeb28e9d0eec7393cf1b1c6f950dcd22","Background: In classification and diagnostic testing, the receiver-operator characteristic (ROC) plot and the area under the ROC curve (AUC) describe how an adjustable threshold causes changes in two types of error: false positives and false negatives. Only part of the ROC curve and AUC are informative however when they are used with imbalanced data. Hence, alternatives to the AUC have been proposed, such as the partial AUC and the area under the precision-recall curve. However, these alternatives cannot be as fully interpreted as the AUC, in part because they ignore some information about actual negatives. Methods: We derive and propose a new concordant partial AUC and a new partial c statistic for ROC data - as foundational measures and methods to help understand and explain parts of the ROC plot and AUC. Our partial measures are continuous and discrete versions of the same measure, are derived from the AUC and c statistic respectively, are validated as equal to each other, and validated as equal in summation to whole measures where expected. Our partial measures are tested for validity on a classic ROC example from Fawcett, a variation thereof, and two real-life benchmark data sets in breast cancer: the Wisconsin and Ljubljana data sets. Interpretation of an example is then provided. Results: Results show the expected equalities between our new partial measures and the existing whole measures. The example interpretation illustrates the need for our newly derived partial measures. Conclusions: The concordant partial area under the ROC curve was proposed and unlike previous partial measure alternatives, it maintains the characteristics of the AUC. The first partial c statistic for ROC plots was also proposed as an unbiased interpretation for part of an ROC curve. The expected equalities among and between our newly derived partial measures and their existing full measure counterparts are confirmed. These measures may be used with any data set but this paper focuses on imbalanced data with low prevalence. Future work: Future work with our proposed measures may: demonstrate their value for imbalanced data with high prevalence, compare them to other measures not based on areas; and combine them with other ROC measures and techniques. © 2020 The Author(s).","Area under the ROC curve; C statistic; Classification; Concordance; Diagnostic testing; Explainable artificial intelligence; Imbalanced data; Partial area index; Prevalence; Receiver operating characteristic","area under the curve; diagnostic test; human; machine learning; receiver operating characteristic; Area Under Curve; Diagnostic Tests, Routine; Humans; Machine Learning; ROC Curve"
"CARTER E., HERRERA D.A., STEINSCHNEIDER S.","Feature engineering for subseasonal-to-seasonal warm-season precipitation forecasts in the midwestern united states: Toward a unifying hypothesis of anomalous warm-season hydroclimatic circulation","10.1175/JCLI-D-20-0264.1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115322177&doi=10.1175%2fJCLI-D-20-0264.1&partnerID=40&md5=5472f501dccd4266fe0f4d9bbf06add2","The literature has established dozens of potential predictive indices (PIs) of anomalous warm season precipitation in the Midwestern United States that could have utility in subseasonal to seasonal (S2S) forecasts. This analysis posits that these predictive indices relate to one of three ""modes of action""that work in tandem to drive anomalous hydroclimatic circulation into the continental interior. These include contributions from 1) geostrophic mass flux, 2) ageostrophic mass flux, and 3) atmosphericmoisture supply, and represent semi-independent, interactive forcings on S2S precipitation variability. This study aggregates 24 PIs from the literature that are related to the three modes of action. Using an interpretable machine learning algorithm that accounts for nonlinear and interactive responses in a noisy predictive space, we evaluate the relative importance of PIs in predicting S2S precipitation anomalies fromMarch to September. Physicalmechanisms driving PI skill are confirmed using composite analysis of atmospheric fields related to the three modes of action. In general, PIs associated with ageostrophic mass flux anomalies are important in early summer, while PIs associated with Atlantic-sourced atmospheric moisture supply are important in late summer. At a 2-month lead, PIs associated with continental-scale thermodynamic processes are more important relative to PIs associated with local convective phenomena. PIs representing geostrophic mass flux anomalies are also critical throughout the warm season, in real time and at a 1-2-month lag, but particularly during transitional months (spring/fall). Several new PIs describing zonal and meridional asymmetry in hemispherical thermal gradients emerge as highly important, with implications for both S2S forecasting and climate change. © 2021 American Meteorological Society.","Data science; Mass fluxes/transport; Moisture/moisture budget; Precipitation; Seasonal forecasting; Summer/warm season","Budget control; Climate change; Learning algorithms; Machine learning; Moisture; Weather forecasting; Feature engineerings; Geostrophic mass; Hydroclimatic; Mass fluxes/transport; Mode of action; Moisture/moisture budgets; Seasonal forecasting; Summer/warm season; Warm seasons; Warm-season precipitation forecasts; Digital storage; algorithm; forecasting method; machine learning; mass transport; meridional circulation; moisture transfer; precipitation assessment; seasonal variation; United States"
"Cartolano A., Cuzzocrea A., Pilato G., Grasso G.M.","Explainable AI at Work! What Can It Do for Smart Agriculture?","10.1109/BigMM55396.2022.00020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146498188&doi=10.1109%2fBigMM55396.2022.00020&partnerID=40&md5=1216aab3131145c307bd5e4e4f429cb3","Explainable AI (XAI) is gaining the momentum, at now. While the idea is to apply it in different scenarios, including medicine, business analytics, genomics computing and so forth, in this paper we focus the attention on another emerging case, represented by so called smart agricolture. In this paper, we propose the application of some well-known XAI tools on top of the Crop Recommendation dataset. Our research efforts also involve the sensitivity analysis of retrieved results. © 2022 IEEE.","LIME; SHAP; Smart Agriculture; XAI","Agriculture; Sensitivity analysis; Business analytics; Genomics; Research efforts; SHAP; Smart agricultures; XAI; Lime"
"Cartolano A., Cuzzocrea A., Pilato G.","EXplainable AI for Smart Agriculture","10.18293/DMSVIVA2022-008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138035961&doi=10.18293%2fDMSVIVA2022-008&partnerID=40&md5=8cecd5372a1b69746da34b2fe06b52b8","We analyze a case study in the field of smart agriculture exploiting Explainable AI (XAI) approach. The study regards a multiclass classification problem on the Crop Recommendation dataset. The original task is the prediction of the most adequate crop according to seven features. In addition to the predictions, two of the most well-known XAI approaches have been used in order to obtain explanations and interpretations of the behaviour of the models: SHAP (Shapley Additive ExPlanations), and LIME (Local Interpretable Model-Agnostic Explanations). © 2022 by KSI Research Inc. and Knowledge Systems Institute, USA.","LIME; SHAP; Smart Agriculture; XAI","Classification (of information); Lime; Case-studies; Local interpretable model-agnostic explanation; Multiclass classification problems; Shapley; Shapley additive explanation; Smart agricultures; XAI; Crops"
"Ceccarelli M., Barbaresi A., Menichetti G., Santolini E., Bovo M., Tassinari P., Barreca F., Torreggiani D.","Simulations in agricultural buildings: a machine learning approach to forecast seasonal energy need","10.1109/MetroAgriFor55389.2022.9965083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144597765&doi=10.1109%2fMetroAgriFor55389.2022.9965083&partnerID=40&md5=99eaaf535f2ab2d4fe79fc7239b315b2","A fast and reliable estimation of building energy need is essential in agricultural building design, nonetheless, a large number of simulations is required to obtain better energy saving solutions. The aim of this work is to understand if machine learning can substitute numerical simulations and speed up the building design process and assess the incidence of specific architectural elements. Supervised regression models has been trained and tested in a data-set of thousands simulations performed on a case-study agricultural building. Among the algorithms, the tree-based Extreme Gradient Boosting showed the best performance. A study on model explainability has been carried out using SHAP and features importance, which is fundamental to help academics and professionals devise better design strategies for both new constructions and retrofitting interventions. © 2022 IEEE.","building energy simulation; energy saving; food storage buildings; machine learning; ML explainability","Agriculture; Architectural design; Digital storage; Energy conservation; Food storage; Regression analysis; Structural design; Agricultural buildings; Building energy simulations; Energy savings; Energy needs; Energy-savings; Food storage building; Machine learning approaches; Machine-learning; ML explainability; Storage building; Machine learning"
"Cerutti J., Abi-Zeid I., Lamontagne L., Lavoie R., Rodriguez M.J.","A case-based reasoning system to recommend solutions for source water protection: knowledge acquisition and modelling","10.1080/14778238.2022.2075808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130501442&doi=10.1080%2f14778238.2022.2075808&partnerID=40&md5=80fab13c36eb09a99eb279a441dab134","“How can drinking water sources be protected, and how can one learn from others who have faced similar problems?” These questions are becoming increasingly relevant in a context where anthropogenic activities threaten natural resources. We describe in this paper a knowledge acquisition and modelling process to support complex decision-making related to source water protection. We conducted online surveys, interviews and applied thematic analysis to gather and structure knowledge from documented and undocumented sources. Our process resulted in structured descriptions of cases that consist of past problems and their implemented solutions. Case design was based on know-how and knowledge needs expressed by water stakeholders. The case base forms the backbone of a knowledge-based recommender system prototype that implements case-based reasoning. It is meant to guide decision-makers in developing solutions based on past experiences. It is a successful application of knowledge management and sharing of lessons learned for decision-making in practice. © 2022 The Operational Research Society.","case-based reasoning; decision making; Knowledge acquisition and modelling; knowledge and experience sharing; source water protection",
"Chaibi M., Benghoulam E.M., Tarik L., Berrada M., El Hmaidi A.","Machine Learning Models Based on Random Forest Feature Selection and Bayesian Optimization for Predicting Daily Global Solar Radiation","10.14710/IJRED.2022.41451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123176455&doi=10.14710%2fIJRED.2022.41451&partnerID=40&md5=f02e1446ccfaad5a99a6fb5f18a2de0d","Prediction of daily global solar radiation (H) with simple and highly accurate models would be beneficial for solar energy conversion systems. In this paper, we proposed a hybrid machine learning methodology integrating two feature selection methods and a Bayesian optimization algorithm to predict H in the city of Fez, Morocco. First, we identified the most significant predictors using two Random Forest methods of feature importance: Mean Decrease in Impurity (MDI) and Mean Decrease in Accuracy (MDA). Then, based on the feature selection results, ten models were developed and compared: (1) five standalone machine learning (ML) models including Classification and Regression Trees (CART), Random Forests (RF), Bagged Trees Regression (BTR), Support Vector Regression (SVR), and Multi-Layer Perceptron (MLP); and (2) the same models tuned by the Bayesian optimization (BO) algorithm: CART-BO, RF-BO, BTR-BO, SVR-BO, and MLP-BO. Both MDI and MDA techniques revealed that extraterrestrial solar radiation and sunshine duration fraction were the most influential features. The BO approach improved the predictive accuracy of MLP, CART, SVR, and BTR models and prevented the CART model from overfitting. The best improvements were obtained using the MLP model, where RMSE and MAE were reduced by 17.6% and 17.2%, respectively. Among the studied models, the SVR-BO algorithm provided the best trade-off between prediction accuracy (RMSE=0.4473kWh/m²/day, MAE=0.3381kWh/m²/day, and R²=0.9465), stability (with a 0.0033kWh/m²/day increase in RMSE), and computational cost. © 2022. The Authors.","Bayesian optimization; Feature selection; Mean Decrease in Accuracy; Mean Decrease in Impurity; Solar radiation","Decision trees; Economic and social effects; Feature Selection; Forecasting; Forestry; Regression analysis; Solar energy; Solar energy conversion; Bayesian optimization; Bayesian optimization algorithms; Classification trees; Features selection; Mean decrease in accuracy; Mean decrease in impurity; Multilayers perceptrons; Random forests; Regression trees; Support vector regressions; Solar radiation"
"Chaibi M., Benghoulam E.L.M., Tarik L., Berrada M., El Hmaidi A.","An interpretable machine learning model for daily global solar radiation prediction","10.3390/en14217367","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118676471&doi=10.3390%2fen14217367&partnerID=40&md5=451aa52a62cf8ecd9c13f1ecbc80d84d","Machine learning (ML) models are commonly used in solar modeling due to their high predictive accuracy. However, the predictions of these models are difficult to explain and trust. This paper aims to demonstrate the utility of two interpretation techniques to explain and improve the predictions of ML models. We compared first the predictive performance of Light Gradient Boosting (LightGBM) with three benchmark models, including multilayer perceptron (MLP), multiple linear regression (MLR), and support-vector regression (SVR), for estimating the global solar radiation (H) in the city of Fez, Morocco. Then, the predictions of the most accurate model were explained by two model-agnostic explanation techniques: permutation feature importance (PFI) and Shapley additive explanations (SHAP). The results indicated that LightGBM (R2 = 0.9377, RMSE = 0.4827 kWh/m2, MAE = 0.3614 kWh/m2) provides similar predictive accuracy as SVR, and outperformed MLP and MLR in the testing stage. Both PFI and SHAP methods showed that extraterrestrial solar radiation (H0) and sunshine duration fraction (SF) are the two most important parameters that affect H estimation. Moreover, the SHAP method established how each feature influences the LightGBM estimations. The predictive accuracy of the LightGBM model was further improved slightly after re-examination of features, where the model combining H0, SF, and RH was better than the model with all features. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Light gradient boosting; Multilayer perceptron; Permutation feature importance; Shapley additive explanations; Solar radiation; Support-vector regression","Adaptive boosting; Additives; Benchmarking; Forecasting; Machine learning; Multilayer neural networks; Multilayers; Solar radiation; Gradient boosting; Light gradient boosting; Light gradients; Machine learning models; Multilayers perceptrons; Permutation feature importance; Predictive accuracy; Shapley; Shapley additive explanation; Support vector regressions; Linear regression"
"Chakraborty D., Başağaoğlu H., Alian S., Mirchi A., Moriasi D.N., Starks P.J., Verser J.A.","Multiscale extrapolative learning algorithm for predictive soil moisture modeling & applications","10.1016/j.eswa.2022.119056","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141268640&doi=10.1016%2fj.eswa.2022.119056&partnerID=40&md5=2f1eb9dd79c904c3e067ae34c83db9f7","We present Multiscale Extrapolative Learning Algorithm (MELA) as a novel artificial-intelligence (AI)-based data extrapolator. MELA is capable of extending temporally limited local hydroclimatic measurements at fine spatial resolution to longer periods, using remotely-sensed hydroclimatic data readily available for longer periods but at coarse spatial resolution. We demonstrate the implementation of MELA to extrapolate the monthly local soil moisture measurements at multiple depths from 2015–2021 to 1958–2021 in a semi-arid region. Such data extrapolators are imperative to generate longer historical data needed to adequately train and test AI models while enhancing the chance of capturing the effects of extreme climates on spatially variable soil moisture. The MELA-extrapolated local soil moisture subsequently allowed the construction of monthly time-series of field-scale soil moisture distributions with a normalized accuracy of 72% and prediction of countywide annual winter wheat yields – using MELA-extrapolated soil moisture data and eXplainable AI (XAI) – with a normalized accuracy of 81%. Furthermore, the XAI model ranked the predictors based on their importance in estimating winter wheat yields, in which the soil moisture near the surface and in the root zone and precipitation totals were found to be more influential than temperature on crop yields in the semi-arid region. The XAI model also unveiled the inflection points of the predictors beyond which crop yields would increase or decrease. Moreover, the AI-based analyses in conjunction with climate projections from global climate models suggest potential reductions in rainfed crop yields in the study area by 2050 and 2100 in the absence of climate-resilient mitigation and adaptation plans. © 2022 The Author(s)","Artificial Intelligence; Climate change impacts; Crop yield analysis; Data generator; Soil moisture analysis","Arid regions; Artificial intelligence; Climate change; Climate models; Crops; Extrapolation; Image resolution; Soil moisture; Climate change impact; Crop yield; Crop yield analyse; Data generator; Hydroclimatic; Semi-arid region; Soil moisture analysis; Spatial resolution; Winter wheat yields; Yield analysis; Learning algorithms"
"Chakraborty D., Başağaoğlu H., Winterle J.","Interpretable vs. noninterpretable machine learning models for data-driven hydro-climatological process modeling","10.1016/j.eswa.2020.114498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099180953&doi=10.1016%2fj.eswa.2020.114498&partnerID=40&md5=26f22bd4e86d93b52b9b4e662c2e51d9","Due to their enhanced predictive capabilities, noninterpretable machine learning (ML) models (e.g. deep learning) have recently gained a growing interest in analyzing and modeling earth &amp; planetary science data. However, noninterpretable ML models are often treated as “black boxes” by end-users, which could limit their applicability in critical decision making processes. In this paper, we compared the predictive capabilities of three interpretable ML models with three noninterpretable ML models to answer the overarching question: Is it essential to use noninterpretable ML models for enhanced model predictions from hydro-climatological datasets? The ML model development and comparative analysis were performed using measured climate data and synthetic reference crop evapotranspiration (ETo) data, with varying levels of missing values, from five weather stations across the karstic Edwards aquifer region in semi-arid south-central Texas. Our analysis revealed that interpretable tree-based ensemble models produce comparable results to noninterpretable deep learning models on structured hydro-climatological datasets. We showed that the tree-based ensemble model is also capable of imputing varying levels of missing climate data at the weather stations, employing the newly developed sequential transfer-learning technique. We applied an explainable machine learning (eXML) framework to quantify the global order of importance of hydro-climatic (predictor) variables on ETo, while highlighting the local dependencies and interactions amongst the predictors and ETo. The eXML framework also revealed the inflection points of the climate variables at which the transition from low to high daily ETo rates occur. The ancillary explainability of ML models are expected to increase users’ confidence and support any future decision-making process in water resource management. © 2020 Elsevier Ltd","Boosting; Deep learning; Hydroclimate; Model explainability; Reference crop evapotranspiration; Transfer learning","Aquifers; Climate models; Concrete pavements; Decision making; Deep learning; Transfer learning; Trees (mathematics); Water management; Weather information services; Climatological datasets; Comparative analysis; Decision making process; Machine learning models; Predictive capabilities; Reference crop evapotranspirations; Tree-based ensembles; Waterresource management; Learning systems"
"Chanal P.M., Kakkasageri M.S., Manvi S.K.S.","Security and privacy in the internet of things: Computational intelligent techniques-based approaches","10.1016/B978-0-12-822844-9.00009-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127658245&doi=10.1016%2fB978-0-12-822844-9.00009-8&partnerID=40&md5=c584ca72db511c4b0ec4ef5d54195384","The Internet of Things (IoT) is a network of universally interconnected devices via the Internet. The IoT requires the interconnection between billions or trillions of intelligent objects. IoT devices (nodes) are capable of capturing, preserving, analyzing, and sharing data about themselves and their physical world. Security and privacy are the major challenges in the implementation of IoT technology. Major privacy aspects in the IoT are stealing data, monitoring, and tracking, etc. Authentication, integrity, and confidentiality are major concerns for privacy and security preservation in the IoT. Computational intelligence (CI) focuses on the design and development of intelligent algorithms to solve real-time problems with minimum cost. The main goal of CI is to supplement natural and artificial intelligence to produce human-required competitive results. Computational intelligent mechanisms for providing privacy and security in the IoT include quantum cryptography, artificial intelligence, neural networks, natural computational techniques, bio-inspired computational techniques, fuzzy logic techniques, genetic algorithms, intelligent multiagents, etc. © 2021 Elsevier Inc. All rights reserved.","Authentication; Availability; Computational intelligence; Confidentiality; Integrity; Internet of things; Privacy; Security",
"Chandrasekaran S., Danos N., George U.Z., Han J.-P., Quon G., Müller R., Tsang Y., Wolgemuth C.","The Axes of Life: A Roadmap for Understanding Dynamic Multiscale Systems","10.1093/icb/icab114","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115061399&doi=10.1093%2ficb%2ficab114&partnerID=40&md5=9d47e42ec9deaac9164fe1b47dfdca71","The biological challenges facing humanity are complex, multi-factorial, and are intimately tied to the future of our health, welfare, and stewardship of the Earth. Tackling problems in diverse areas, such as agriculture, ecology, and health care require linking vast datasets that encompass numerous components and spatiooral scales. Here, we provide a new framework and a road map for using experiments and computation to understand dynamic biological systems that span multiple scales. We discuss theories that can help understand complex biological systems and highlight the limitations of existing methodologies and recommend data generation practices. The advent of new technologies such as big data analytics and artificial intelligence can help bridge different scales and data types. We recommend ways to make such models transparent, compatible with existing theories of biological function, and to make biological data sets readable by advanced machine learning algorithms. Overall, the barriers for tackling pressing biological challenges are not only technological, but also sociological. Hence, we also provide recommendations for promoting interdisciplinary interactions between scientists. © The Author(s) 2021. Published by Oxford University Press on behalf of the Society for Integrative and Comparative Biology. All rights reserved.",,"agriculture; algorithm; animal; artificial intelligence; machine learning; technology; Agriculture; Algorithms; Animals; Artificial Intelligence; Machine Learning; Technology"
"Chang Z., Liu S., Xiong X., Cai Z., Tu G.","A Survey of Recent Advances in Edge-Computing-Powered Artificial Intelligence of Things","10.1109/JIOT.2021.3088875","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112178155&doi=10.1109%2fJIOT.2021.3088875&partnerID=40&md5=d1ee0fe72a9181c7db40afb804d749bc","The Internet of Things (IoT) has created a ubiquitously connected world powered by a multitude of wired and wireless sensors generating a variety of heterogeneous data over time in a myriad of fields and applications. To extract complete information from these data, advanced artificial intelligence (AI) technology, especially deep learning (DL), has proved successful in facilitating data analytics, future prediction and decision making. The collective integration of AI and the IoT has greatly promoted the rapid development of AI-of-Things (AIoT) systems that analyze and respond to external stimuli more intelligently without involvement by humans. However, it is challenging or infeasible to process massive amounts of data in the cloud due to the destructive impact of the volume, velocity, and veracity of data and fatal transmission latency on networking infrastructures. These critical challenges can be adequately addressed by introducing edge computing. This article conducts an extensive survey of an end-edge-cloud orchestrated architecture for flexible AIoT systems. Specifically, it begins with articulating fundamental concepts including the IoT, AI and edge computing. Guided by these concepts, it explores the general AIoT architecture, presents a practical AIoT example to illustrate how AI can be applied in real-world applications and summarizes promising AIoT applications. Then, the emerging technologies for AI models regarding inference and training at the edge of the network are reviewed. Finally, the open challenges and future directions in this promising area are outlined. © 2014 IEEE.","Artificial intelligence (AI); deep learning (DL); edge computing; Internet of Things (IoT); machine learning (ML)","Data Analytics; Decision making; Deep learning; Edge computing; Network architecture; Surveys; Artificial intelligence technologies; Complete information; Critical challenges; Emerging technologies; Fundamental concepts; Heterogeneous data; Internet of thing (IOT); Networking infrastructure; Internet of things"
"Charles V., Emrouznejad A., Gherman T.","A critical analysis of the integration of blockchain and artificial intelligence for supply chain","10.1007/s10479-023-05169-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146886493&doi=10.1007%2fs10479-023-05169-w&partnerID=40&md5=98c584de7272bf50e0f526cec52aa117","The integration between blockchain and artificial intelligence (AI) has gained a lot of attention in recent years, especially since such integration can improve security, efficiency, and productivity of applications in business environments characterised by volatility, uncertainty, complexity, and ambiguity. In particular, supply chain is one of the areas that have been shown to benefit tremendously from blockchain and AI, by enhancing information and process resilience, enabling faster and more cost-efficient delivery of products, and augmenting products’ traceability, among others. This paper performs a state-of-the-art review of blockchain and AI in the field of supply chains. More specifically, we sought to answer the following three principal questions: Q1—What are the current studies on the integration of blockchain and AI in supply chain?, Q2—What are the current blockchain and AI use cases in supply chain?, and Q3—What are the potential research directions for future studies involving the integration of blockchain and AI? The analysis performed in this paper has identified relevant research studies that have contributed both conceptually and empirically to the expansion and accumulation of intellectual wealth in the supply chain discipline through the integration of blockchain and AI. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Artificial intelligence; Bibliometric review; Blockchain; Supply chain; Systematic literature review; Thematic analysis",
"Chaterji S., Delay N., Evans J., Mosier N., Engel B., Buckmaster D., Ladisch M.R., Chandra R.","Lattice: A Vision for Machine Learning, Data Engineering, and Policy Considerations for Digital Agriculture at Scale","10.1109/OJCS.2021.3085846","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119298869&doi=10.1109%2fOJCS.2021.3085846&partnerID=40&md5=0cfb037594e7221942a5b47a97361a72","Digital agriculture, with the incorporation of Internet-of-Things (IoT)-based technologies, presents the ability to control a system at multiple levels (individual, local, regional, and global) and generates tools that allow for improved decision making and higher productivity. Recent advances in IoT hardware, e.g., networks of heterogeneous embedded devices, and software, e.g., lightweight computer vision algorithms and cloud optimization solutions, make it possible to efficiently process data from diverse sources in a connected (smart) farm. By interconnecting these IoT devices, often across large geographical distances, it is possible to collect data at different time scales, including in near real-time (i.e., with delays of only a few tens of seconds). This data can then be used for actionable insights, e.g., precise applications of soil supplements and reduced environmental footprint. Through LATTICE, we present an integrated vision for IoT solutions, data processing, and actionable analytics for digital agriculture. We couple this with discussion of economics and policy considerations that will underlie adoption of such IoT and ML technologies. Our paper starts off with the types of datasets in typical field operations, followed by the lifecycle for the data and storage, cloud and edge analytics, and fast information-retrieval solutions. We discuss what algorithms are proving to be most impactful in this space, e.g., approximate data analytics and on-device/in-network processing. We conclude by discussing analytics for alternative agriculture for generation of biofuels and policy challenges in the implementation of digital agriculture in the wild. © 2020 IEEE.","cloud computing; data analysis; Data integration; internet of things; Sensor systems","Agriculture; Cloud analytics; Data Analytics; Data integration; Decision making; Digital storage; E-learning; Engineering education; Life cycle; Machine learning; Cloud-computing; Data engineering; Decisions makings; Digital agriculture; Embedded device; High productivity; Learning data; Machine-learning; Multiple levels; Sensor systems; Internet of things"
"Chaurasiya H.","Cognitive Hexagon-Controlled Intelligent Speech Interaction System","10.1109/TCDS.2022.3168807","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128628110&doi=10.1109%2fTCDS.2022.3168807&partnerID=40&md5=bb25ecc6cfbe693af05b50755b7ecb2d","Several intelligent speech interaction (ISI) systems have emerged over the past four decades that have served the human community. The research papers show that these systems are very well connected to the cognitive hexagon and the six hybrid approaches. Where this hexagon reveals six distinct cognitive areas, one of the six hybrid perspectives gives rise to the dimensions of speech quality. This survey has been undertaken to reveal the dimensions of speech quality and to discuss the role of cognitive hexagonal regions on these dimensions with hybrid approaches. Here, ISI systems support this discussion and follow them as cognitive machines. An overview of the state of the art related to ISI systems is also described here. Techniques, such as processing [natural language (NL)], speech synthesis [speech-to-text (STT) or text-to-speech (TTS)], computing (voice/mobile), and audio mining are presented in this overview. These are contributing well with technologies, such as the Internet of Things (IoT), Voice over Internet Protocol (VoIP), and cloud-based systems (CBSs). In addition, stochastic components, such as reliability, availability, and failure rate were discussed to analyze whether the Quality of Service (QoS) of these ISI systems is described. Additionally, after the discussion, some aspects of the applications are also discussed along with the essential advantages and significant drawbacks. © 2016 IEEE.","Cognitive; hexagon; hybrid; intelligent speech interaction (ISI); system","Cognitive systems; Failure analysis; Philosophical aspects; Speech synthesis; Stochastic systems; Cloud-computing; Cognition; Cognitive; Hexagon; Hybrid; Intelligent speech interaction; Philosophical consideration; Psychology; Quality-of-service; Speech interaction; System.; Quality of service"
"Chen H., Yang C., Zhang X., Liu Z., Sun M., Jin J.","From symbols to embeddings: A tale of two representations in computational social science","10.23919/JSC.2021.0011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121021546&doi=10.23919%2fJSC.2021.0011&partnerID=40&md5=c83493b6c2f8f83987132c4b81abaedd","Computational Social Science (CSS), aiming at utilizing computational methods to address social science problems, is a recent emerging and fast-developing field. The study of CSS is data-driven and significantly benefits from the availability of online user-generated contents and social networks, which contain rich text and network data for investigation. However, these large-scale and multi-modal data also present researchers with a great challenge: how to represent data effectively to mine the meanings we want in CSS? To explore the answer, we give a thorough review of data representations in CSS for both text and network. Specifically, we summarize existing representations into two schemes, namely symbol-based and embedding-based representations, and introduce a series of typical methods for each scheme. Afterwards, we present the applications of the above representations based on the investigation of more than 400 research articles from 6 top venues involved with CSS. From the statistics of these applications, we unearth the strength of each kind of representations and discover the tendency that embedding-based representations are emerging and obtaining increasing attention over the last decade. Finally, we discuss several key challenges and open issues for future directions. This survey aims to provide a deeper understanding and more advisable applications of data representations for CSS researchers. © The author(s) 2021.","Computational Social Science (CSS); Embedding-based representation; Social network; Symbol-based representation","Behavioral research; Modal analysis; Social networking (online); Computational social science; Data driven; Data representations; Embedding-based representation; Embeddings; Online users; Social network; Symbol-based representation; User-generated; Embeddings"
"Chen J., Li X., Wang K., Zhang S., Li J., Sun M.","Assessment of intertidal seaweed biomass based on RGB imagery","10.1371/journal.pone.0263416","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125307220&doi=10.1371%2fjournal.pone.0263416&partnerID=40&md5=76e4b3381af557e126f5cb2243db87c7","The Above Ground Biomass (AGB) of seaweeds is the most fundamental ecological parameter as the material and energy basis of intertidal ecosystems. Therefore, there is a need to develop an efficient survey method that has less impact on the environment. With the advent of technology and the availability of popular filming devices such as smartphones and cameras, intertidal seaweed wet biomass can be surveyed by remote sensing using popular RGB imaging sensors. In this paper, 143 in situ sites of seaweed in the intertidal zone of GouQi Island, ShengSi County, Zhejiang Province, were sampled and biomass inversions were performed. The hyperspectral data of seaweed at different growth stages were analyzed, and it was found that the variation range was small (visible light range &lt; 0.1). Through Principal Component Analysis (PCA), Most of the variance is explained in the first principal component, and the load allocated to the three kinds of seaweed is more than 90%. Through Pearson correlation analysis, 24 parameters of spectral features, 9 parameters of texture features (27 in total for the three RGB bands) and parameters of combined spectral and texture features of the images were selected for screening, and regression prediction was performed using two methods: Random Forest (RF), and Gradient Boosted Decision Tree (GBDT), combined with Pearson correlation coefficients. Compared with the other two models, GBDT has better fitting accuracy in the inversion of seaweed biomass, and the highest R2 was obtained when the top 17, 17 and 11 parameters with strong correlation were selected for the regression prediction by Pearson’s correlation coefficient for Ulva australis, Sargassum thunbergii, and Sargassum fusiforme, and the R2 for Ulva australis was 0.784, RMSE 156.129, MAE 50.691 and MAPE 28.201, the R2 for Sargassum thunbergii was 0.854, RMSE 790.487, MAE 327.108 and MAPE 19.039, and the R2 for Sargassum fusiforme was 0.808, RMSE 445.067 and MAPE 28.822. MAE was 180.172 and MAPE was 28.822. The study combines in situ survey with machine learning methods, which has the advantages of being popular, efficient and environmentally friendly, and can provide technical support for intertidal seaweed surveys. Copyright: © 2022 Chen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"article; biomass; correlation analysis; correlation coefficient; decision tree; growth curve; human; human experiment; imagery; intertidal zone; light; machine learning; nonhuman; prediction; principal component analysis; random forest; Sargassum fusiforme; Sargassum thunbergii; seaweed; ecosystem; growth, development and aging; remote sensing; seaweed; tsunami; Biomass; Ecosystem; Humans; Machine Learning; Principal Component Analysis; Remote Sensing Technology; Seaweed; Tidal Waves"
"Chen N., Yu Y., Chen J., Chen L., Zhang D.","Artificial neural network models for water quality early warning: A review [人工神经网络模型在水质预警中的应用研究进展]","10.13671/j.hjkxxb.2021.0343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121107485&doi=10.13671%2fj.hjkxxb.2021.0343&partnerID=40&md5=dff0be103cbff2f6a07052de459eef1e","Water quality early warning models are a key component of intelligent environmental decision-making and management systems in the era of big data. In recent years, the increasing demand for early warning of water quality deterioration has stimulated researchers to develop new modeling approaches and improve prediction reliability, and artificial neural network (ANN) models are developing rapidly. In this paper we review the development history of three group ANN model and model structure characteristics. The research progress of ANN models for the purpose of soft measurement, data quality control and time series prediction of water quality are summarized. We summarized the general modeling procedure, technical recommendations, and performance indexes that are commonly used. We found that the application of ANN models has been limited by the poor quality of measured data, weak interpretability of model outputs and the substantial requirements in terms of hardware and computing resources. We emphasize that future efforts should be made to develop and apply early warning models in the field of water quality prediction. There is an urgent need to promote the coordinated development of innovative technologies for environmental monitoring and early warning, through constant validation and upgrading of models after their application in a variety of situations. The long-term goal is to form an online water quality monitoring system, incorporating intelligent early warning and emergency management, driven by big data, to support environmental governance. © 2021, Science Press. All right reserved.","Artificial intelligence; Artificial neural network; Big data; Water quality early warning","artificial neural network; data quality; early warning system; environmental monitoring; hardware; innovation; quality control; water quality"
"Chen Q., Wang Y., Wu Y., Li C., Li L., Yang X., Chen S., Zhao Y., Cen J., Yang S., Wang D.","Investigation of fermentation-induced changes in the volatile compounds of Trachinotus ovatus (meixiangyu) based on molecular sensory and interpretable machine-learning techniques: Comparison of different fermentation stages","10.1016/j.foodres.2021.110739","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117920233&doi=10.1016%2fj.foodres.2021.110739&partnerID=40&md5=2b509ae47aa2cba2834d0edc85ac4944","Fermented golden pomfret (Trachinotus ovatus) is appreciated by local consumers owing to its distinct flavor. Electronic nose (E-nose) and gas chromatography-ion mobility spectrometry (GC-IMS) technologies were used to analyze the changes in volatile compounds responsible for evolution of the golden pomfret odor profile during fermentation. Forty-five ion peaks were detected using GC-IMS. Although aldehydes represented the major initial volatile compound group, their levels decreased as fermentation proceeded. Between 3 and 15 days, increased levels of esters contributed to a stable volatile organic compounds profile. After 18 days, high levels of indole and pyrazines were detected. Eleven key volatile compounds were screened based on partial least squares discriminant analysis (PLS-DA). Back propagation artificial neural network (BP-ANN) predicted the fermentation stage enabling the development of better strategies to regulate golden pomfret fermentation. This study provided a theoretical basis for real-time monitoring and quality control of Chinese fermented golden pomfet. © 2021 Elsevier Ltd","Back propagation artificial neural network; Electronic nose; Fermented Trachinotus ovatus; Gas chromatography-ion mobility spectrometry; Quality control; Volatile organic compounds","Backpropagation; Discriminant analysis; Electronic nose; Fermentation; Gas chromatography; Ion chromatography; Ion mobility spectrometers; Ions; Least squares approximations; Neural networks; Quality control; Spectrometry; A-stable; Back Propagation; Back propagation artificial neural network; Fermented trachinotu ovatu; Gas chromatography-ion mobility spectrometry; Ion mobility spectrometry; Ion peaks; Machine learning techniques; Odor profiles; Volatile compounds; Volatile organic compounds; fragrance; volatile organic compound; fermentation; machine learning; mass fragmentography; Fermentation; Gas Chromatography-Mass Spectrometry; Machine Learning; Odorants; Volatile Organic Compounds"
"Chen R., Qi H., Liang Y., Yang M.","Identification of plant leaf diseases by deep learning based on channel attention and channel pruning","10.3389/fpls.2022.1023515","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142640940&doi=10.3389%2ffpls.2022.1023515&partnerID=40&md5=54df98bf93d8ddd0e42ca4ade3202fce","Plant diseases cause significant economic losses and food security in agriculture each year, with the critical path to reducing losses being accurate identification and timely diagnosis of plant diseases. Currently, deep neural networks have been extensively applied in plant disease identification, but such approaches still suffer from low identification accuracy and numerous parameters. Hence, this paper proposes a model combining channel attention and channel pruning called CACPNET, suitable for disease identification of common species. The channel attention mechanism adopts a local cross-channel strategy without dimensionality reduction, which is inserted into a ResNet-18-based model that combines global average pooling with global max pooling to effectively improve the features’ extracting ability of plant leaf diseases. Based on the model’s optimum feature extraction condition, unimportant channels are removed to reduce the model’s parameters and complexity via the L1-norm channel weight and local compression ratio. The accuracy of CACPNET on the public dataset PlantVillage reaches 99.7% and achieves 97.7% on the local peanut leaf disease dataset. Compared with the base ResNet-18 model, the floating point operations (FLOPs) decreased by 30.35%, the parameters by 57.97%, the model size by 57.85%, and the GPU RAM requirements by 8.3%. Additionally, CACPNET outperforms current models considering inference time and throughput, reaching 22.8 ms/frame and 75.5 frames/s, respectively. The results outline that CACPNET is appealing for deployment on edge devices to improve the efficiency of precision agriculture in plant disease detection. Copyright © 2022 Chen, Qi, Liang and Yang.","CACPNET; channel attention; channel pruning; convolutional neural network; deep learning; plant leaf disease",
"Chen S., Zhang Z., Lin J., Huang J.","Machine learning-based estimation of riverine nutrient concentrations and associated uncertainties caused by sampling frequencies","10.1371/journal.pone.0271458","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134267117&doi=10.1371%2fjournal.pone.0271458&partnerID=40&md5=7f3d1435df708b7347692772ee027070","Accurate and sufficient water quality data is essential for watershed management and sustainability. Machine learning models have shown great potentials for estimating water quality with the development of online sensors. However, accurate estimation is challenging because of uncertainties related to models used and data input. In this study, random forest (RF), support vector machine (SVM), and back-propagation neural network (BPNN) models are developed with three sampling frequency datasets (i.e., 4-hourly, daily, and weekly) and five conventional indicators (i.e., water temperature (WT), hydrogen ion concentration (pH), electrical conductivity (EC), dissolved oxygen (DO), and turbidity (TUR)) as surrogates to individually estimate riverine total phosphorus (TP), total nitrogen (TN), and ammonia nitrogen (NH4+-N) in a small-scale coastal watershed. The results show that the RF model outperforms the SVM and BPNN machine learning models in terms of estimative performance, which explains much of the variation in TP (79 ± 1.3%), TN (84 ± 0.9%), and NH4+-N (75 ± 1.3%), when using the 4-hourly sampling frequency dataset. The higher sampling frequency would help the RF obtain a significantly better performance for the three nutrient estimation measures (4-hourly &gt; daily &gt; weekly) for R2 and NSE values. WT, EC, and TUR were the three key input indicators for nutrient estimations in RF. Our study highlights the importance of high-frequency data as input to machine learning model development. The RF model is shown to be viable for riverine nutrient estimation in small-scale watersheds of important local water security. © 2022 Chen et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"ammonia; dissolved oxygen; nitrogen; phosphorus; proton; nitrogen; phosphorus; Article; back propagation neural network; controlled study; electric conductivity; frequency; machine learning; nutrient concentration; random forest; river; sampling; seashore; support vector machine; turbidity; uncertainty; water quality; water temperature; watershed; environmental monitoring; machine learning; procedures; Environmental Monitoring; Machine Learning; Nitrogen; Nutrients; Phosphorus; Rivers"
"Chen Y.-Z., Gu J., Chuang W.-T., Du Y.-F., Zhang L., Lu M.-L., Xu J.-Y., Li H.-Q., Liu Y., Feng H.-T., Li Y.-H., Qin L.-Q.","Slowly Digestible Carbohydrate Diet Ameliorates Hyperglycemia and Hyperlipidemia in High-Fat Diet/Streptozocin-Induced Diabetic Mice","10.3389/fnut.2022.854725","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129340755&doi=10.3389%2ffnut.2022.854725&partnerID=40&md5=ea884f4978b360993c58b2dca0787e78","Objective: Given that the prevalence rate of type 2 diabetes mellitus (T2DM) continues to increase, it is important to find an effective method to prevent or treat this disease. Previous studies have shown that dietary intervention with a slowly digestible carbohydrate (SDC) diet can improve T2DM with almost no side effects. However, the underlying mechanisms of SDC protect against T2DM remains to be elucidated. Methods: The T2DM mice model was established with a high-fat diet and streptozocin injection. Then, SDC was administered for 6 weeks. Bodyweight, food intake, organ indices, fasting blood glucose (FBG), oral glucose tolerance test (OGTT), homeostasis model assessment for insulin resistance (HOMA-IR), and other biochemical parameters were measured. Histopathological and lipid accumulation analyses were performed, and the glucose metabolism-related gene expressions in the liver and skeletal muscle were determined. Lastly, colonic microbiota was also analyzed. Results: SDC intervention alleviated the weight loss in the pancreas, lowered blood glucose and glycosylated hemoglobin levels, and improved glucose tolerance and HOMA-IR. SDC intervention improved serum lipid profile, adipocytokines levels, and lowered the lipid accumulation in the liver, subcutaneous adipose tissue, and epididymal visceral adipose tissue. In addition, SDC intervention increased the expression levels of IRS-2 and GLUT-2 in liver tissues and elevated GLUT-4 expression levels in skeletal muscle tissues. Notably, SDC intervention decreased the Bacteroidetes/Firmicutes ratio, increased Desulfovibrio and Lachnospiraceae genus levels, and inhibited the relative abundance of potentially pathogenic bacteria. Conclusions: SDC intervention can improve hyperglycemia and hyperlipidemia status in diabetic mice, suggesting that this intervention might be beneficial for T2DM. Copyright © 2022 Chen, Gu, Chuang, Du, Zhang, Lu, Xu, Li, Liu, Feng, Li and Qin.","diabetes; high-fat diet; hyperglycemia; hyperlipidemia; slowly digestible carbohydrate; streptozocin",
"Chen Z., Wu R., Lin Y., Li C., Chen S., Yuan Z., Chen S., Zou X.","Plant Disease Recognition Model Based on Improved YOLOv5","10.3390/agronomy12020365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124026874&doi=10.3390%2fagronomy12020365&partnerID=40&md5=64893fb215340d1c9853022d28c1a2c1","To accurately recognize plant diseases under complex natural conditions, an improved plant disease-recognition model based on the original YOLOv5 network model was established. First, a new InvolutionBottleneck module was used to reduce the numbers of parameters and cal-culations, and to capture long-distance information in the space. Second, an SE module was added to improve the sensitivity of the model to channel features. Finally, the loss function ‘Generalized Intersection over Union’ was changed to ‘Efficient Intersection over Union’ to address the former’s degeneration into ‘Intersection over Union’. These proposed methods were used to improve the target recognition effect of the network model. In the experimental phase, to verify the effectiveness of the model, sample images were randomly selected from the constructed rubber tree disease database to form training and test sets. The test results showed that the mean average precision of the improved YOLOv5 network reached 70%, which is 5.4% higher than that of the original YOLOv5 network. The precision values of this model for powdery mildew and anthracnose detection were 86.5% and 86.8%, respectively. The overall detection performance of the improved YOLOv5 network was significantly better compared with those of the original YOLOv5 and the YOLOX_nano network models. The improved model accurately identified plant diseases under natural conditions, and it provides a technical reference for the prevention and control of plant diseases. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","EIOU; InvolutionBottleneck; Plant diseases recognition; SE module; YOLOv5",
"Cheng X., Doosthosseini A., Kunkel J.","Improve the Deep Learning Models in Forestry Based on Explanations and Expertise","10.3389/fpls.2022.902105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131870667&doi=10.3389%2ffpls.2022.902105&partnerID=40&md5=a45ccd003600a0dd48f4f0a080abfc36","In forestry studies, deep learning models have achieved excellent performance in many application scenarios (e.g., detecting forest damage). However, the unclear model decisions (i.e., black-box) undermine the credibility of the results and hinder their practicality. This study intends to obtain explanations of such models through the use of explainable artificial intelligence methods, and then use feature unlearning methods to improve their performance, which is the first such attempt in the field of forestry. Results of three experiments show that the model training can be guided by expertise to gain specific knowledge, which is reflected by explanations. For all three experiments based on synthetic and real leaf images, the improvement of models is quantified in the classification accuracy (up to 4.6%) and three indicators of explanation assessment (i.e., root-mean-square error, cosine similarity, and the proportion of important pixels). Besides, the introduced expertise in annotation matrix form was automatically created in all experiments. This study emphasizes that studies of deep learning in forestry should not only pursue model performance (e.g., higher classification accuracy) but also focus on the explanations and try to improve models according to the expertise. Copyright © 2022 Cheng, Doosthosseini and Kunkel.","classification; deep neural networks; explainable artificial intelligence; feature unlearning; forest care",
"Cheng Y., Bi X., Xu Y., Liu Y., Li J., Du G., Lv X., Liu L.","Artificial intelligence technologies in bioprocess: Opportunities and challenges","10.1016/j.biortech.2022.128451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143711866&doi=10.1016%2fj.biortech.2022.128451&partnerID=40&md5=10b86614e907f3345d0e6e379c55c492","Bioprocess control and optimization are crucial for tapping the metabolic potential of microorganisms, and which have made great progress in the past decades. Combination of the current control and optimization technologies with the latest computer-based strategies will be a worth expecting way to improve bioprocess further. Recently, artificial intelligence (AI) emerged as a data-driven technique independent of the complex interactions used in mathematical models and has been gradually applied in bioprocess. In this review, firstly, AI-guided modeling approaches of bioprocess are discussed, which are widely applied to optimize critical process parameters (CPPs). Then, AI-assisted rapid detection and monitoring technologies employed in bioprocess are summarized. Next, control strategies according to the above two technologies in bioprocess are analyzed. Lastly, current research gaps and future perspectives on AI-guided optimization and control technologies are discussed. This review provides theoretical guidance for developing AI-guided bioprocess optimization and control technologies. © 2022 Elsevier Ltd","Artificial intelligence; Bioprocess modeling; Rapid detection; Real-time monitoring; Smart control","Bioprocess control; Bioprocess modeling; Bioprocess optimization; Bioprocesses; Control and optimization; Control technologies; Optimization technology; Rapid detection; Real time monitoring; Smart control; Artificial intelligence; artificial intelligence; control system; detection method; modeling; monitoring; article; artificial intelligence; bioprocess; control strategy; theoretical study; forecasting; theoretical model; Artificial Intelligence; Evidence Gaps; Forecasting; Models, Theoretical"
"Chia M.Y., Huang Y.F., Koo C.H., Ng J.L., Ahmed A.N., El-Shafie A.","Long-term forecasting of monthly mean reference evapotranspiration using deep neural network: A comparison of training strategies and approaches","10.1016/j.asoc.2022.109221","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133621530&doi=10.1016%2fj.asoc.2022.109221&partnerID=40&md5=3107bcd4c485e4dba973e3caddb5d7ee","Prediction of reference evapotranspiration (ET0) remains a challenge, especially with forward multi-step forecasting. The bottleneck facing current research is the limitation of the span of the forecasting time horizons, which can be rather disappointing, especially when long-term forecasting is desired. In this study, an explainable model structure, represented by a one-dimensional convolutional neural network (CNN-1D) was compared to the long short-term memory network (LSTM) and gated recurrent unit network (GRU), both formulated with black-box model method. The comparison included the application of different forecasting strategies (iterated vs. multiple-input–multiple-output (MIMO)) and approaches (direct vs. indirect). This study was conducted at four stations scattered across the Peninsular Malaysia. From the results of this study, the explainable CNN-1D model generally performed poorer than its black-box counterparts at most of the stations. The type of model and its structure, forecasting strategy and approach formed a complex relationship to indicate that there is no one-for-all solution in the case of the long-term prediction of monthly mean ET0. Despite that, the GRU-based models stood out as the most well-suited option for the task, with the MIMO forecasting strategy being favoured over the iterated strategy. At the four stations, the average mean absolute error (MAE), root mean square error (RMSE), mean percentage error (MAPE) and the Kling–Gupta efficiency (KGE) of the best GRU models were 0.182 mm/day, 0.260 mm/day, 4.972 % and 0.747, respectively. It was found that the prediction residual of the best GRU models did not possess a clear trend as the forecasting horizon was lengthened. The results implied that theoretically, the forecasting time horizon could be extended over to a longer temporal scale without any deterioration in the model performance. This finding is positive as it brings about the possibility of allocating the water budget with higher confidence. Nevertheless, the LSTM and GRU models developed in this study, were believed to have more tremendous potential if they were to be designed with purpose (such as the integration of optimisation algorithm), instead of being a mere black-box structure. © 2022 Elsevier B.V.","Convolutional neural network; Gated recurrent unit; Long short-term memory; Long-term forecasting; Reference evapotranspiration","Brain; Budget control; Convolution; Convolutional neural networks; Deep neural networks; Deterioration; Errors; Evapotranspiration; Forecasting; Mean square error; Multilayer neural networks; Convolutional neural network; Gated recurrent unit; Long-term forecasting; Memory network; Multiple inputs; Multiple outputs; Network models; Reference evapotranspiration; Time horizons; Training strategy; Long short-term memory"
"Chillakuru P., Divya D., Ananthajothi K.","Enhanced Segmentation with Optimized Nine-Layered CNN-Based Classification of Leaf Diseases: An Automatic Approach for Plant Disease Diagnosis","10.1080/01969722.2022.2151173","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144322894&doi=10.1080%2f01969722.2022.2151173&partnerID=40&md5=0bf8a6d2a675405bf1e19f1bf1a2688b","The task of monitoring the plant leaves is considered to be error-prone, inconsistent, and unreliable. Thus, certain deep learning algorithms are developed to detect plant leaf diseases, but most deep learning techniques were designed with restricted-resolution images based on convolutional neural networks (CNNs). Hence, this article decides to develop an optimized nine-layer (ONL)-CNN-based plant leaf disease classification (PLDC) model for ensuring accurate results. The leaf segmented images are given into the abnormality segmentation with the “Adaptive Fuzzy C-Means” (A-FCM) technique for getting the abnormality segmented images. The segmented images are inserted into the classification stage, in which the optimized nine layer-CNN is utilized for leaf disease classification. Here, the parameter optimization takes place in FCM and ONL-CNN for enhancing the performance of the developed PLDC model using the developed hybrid heuristic optimization algorithm with hybrid leader cat swarm optimization (HLCSO). The experimental analysis is conducted with the developed PLDC model with different baseline methods to put forward the effectiveness of the developed model. Throughout the analysis, the given designed method achieved a 96% accuracy rate. Therefore, the proposed model ensures its effective performance regarding accuracy metric and also helps to detect early diagnosis of leaf diseases. © 2022 Taylor & Francis Group, LLC.","Adaptive Fuzzy C-Means; artificial intelligence; hybrid leader cat swarm optimization; optimized nine layer-convolutional neural networks; plant leaf disease classification","Computer aided diagnosis; Convolution; Convolutional neural networks; Deep learning; Fuzzy inference; Fuzzy neural networks; Fuzzy systems; Multilayer neural networks; Network layers; Plants (botany); Adaptive fuzzy C-mean; Adaptive-fuzzy; C-means; Convolutional neural network; Disease classification; Hybrid leader cat swarm optimization; Leaf disease; Optimized nine layer-convolutional neural network; Plant leaf disease classification; Plant leaves; Swarm optimization; Image segmentation"
"Chimatapu R., Hagras H., Kern M., Owusu G.","Hybrid deep learning type-2 fuzzy logic systems for explainable AI","10.1109/FUZZ48607.2020.9177817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090500501&doi=10.1109%2fFUZZ48607.2020.9177817&partnerID=40&md5=81a3cbd08b87f4ffca2002785ea7c079","The recent years have witnessed a rapid rise in the use of Artificial Intelligence (AI) systems, in particular Machine Learning (ML) models. The vast majority of AI systems employ black box models that lack transparency in operation and decision making. This lack of transparency curtails the use of these AI systems in regulated applications (such as medical, financial applications, etc.) where it is important to understand the reasoning behind the predictions of the AI system. In these situations, interpretable models need to be used. However, interpretable models can turn into black-box models for high dimensional inputs. There are a variety of approaches that have been proposed to solve this problem. In this paper, we present a novel hybrid deep learning type-2 fuzzy logic system for explainable AI which addresses these challenges to provide a highly interpretable model that has reasonable performance when compared to the other black box models. © 2020 IEEE.","Deep Learning; Explainable Artificial Intelligence; Interval Type-2 Fuzzy Logic System","Behavioral research; Computer circuits; Decision making; Deep learning; Fuzzy logic; Fuzzy systems; Transparency; AI systems; Black-box model; Financial applications; High-dimensional; Type-2 fuzzy logic system; Learning systems"
"Chiu M.-C., Yan W.-M., Bhat S.A., Huang N.-F.","Development of smart aquaculture farm management system using IoT and AI-based surrogate models","10.1016/j.jafr.2022.100357","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136198786&doi=10.1016%2fj.jafr.2022.100357&partnerID=40&md5=db9567006f028074cdeb3b95a9e3fc08","Due to low labor participation by young adults and an aging agricultural population, Taiwan and the rest of the world are facing labor shortages in agriculture, which will affect aquaculture production. The proposed system is intended primarily for solving the problems faced by the aquaculture farming sector in Taiwan by designing a smart IoT-based fish monitoring and control system equipped with different IoT devices to enable real-time data collection; so that fishpond water-quality conditions and other system parameters can be readily monitored, adjusted, and assessed remotely. To predict the growth of the California Bass fish, this study also develops a deep learning model (DL) that correlates the different parameters of the smart aquaculture system. Bayesian optimization-based hyper-parameter tuning was employed to find the optimal DL model configuration to produce accurate predictions on the given experimental data set. The optimal model produces an R2 value of 0.94 and a mean square error of 0.0015, demonstrating the applicability of the model to predict the desired output. Based on the results of the experiments, the DL model can be incorporated into the autonomous feeding system, reducing the amount of leftover feed. Thus, aquaculture based on the artificial intelligence of things (AIOT) can assist fish farmers in intelligently controlling and managing different fishpond equipment remotely and assist aquaculture operators in performing professional aquaculture, lowering the industry's entry barrier, and promoting aquaculture. © 2022 The Authors","Aquaculture; Bayesian optimization; Big data; Deep neural networks; Internet of things; Smart fish farming",
"Chkoniya V.","Handbook of research on applied data science and artificial intelligence in business and industry","10.4018/9781799869856","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128143850&doi=10.4018%2f9781799869856&partnerID=40&md5=c68135660fe735db4c9025cfefebddd2","The contemporary world lives on the data produced at an unprecedented speed through social networks and the internet of things (IoT). Data has been called the new global currency, and its rise is transforming entire industries, providing a wealth of opportunities. Applied data science research is necessary to derive useful information from big data for the effective and efficient utilization to solve real-world problems. A broad analytical set allied with strong business logic is fundamental in today's corporations. Organizations work to obtain competitive advantage by analyzing the data produced within and outside their organizational limits to support their decision-making processes. This book aims to provide an overview of the concepts, tools, and techniques behind the fields of data science and artificial intelligence (AI) applied to business and industries. The Handbook of Research on Applied Data Science and Artificial Intelligence in Business and Industry discusses all stages of data science to AI and their application to real problems across industries-from science and engineering to academia and commerce. This book brings together practice and science to build successful data solutions, showing how to uncover hidden patterns and leverage them to improve all aspects of business performance by making sense of data from both web and offline environments. Covering topics including applied AI, consumer behavior analytics, and machine learning, this text is essential for data scientists, IT specialists, managers, executives, software and computer engineers, researchers, practitioners, academicians, and students. © 2021 by IGI Global. All rights reserved.",,
"Choi Y., Lee S.","The impact of urban physical environments on cooling rates in summer: Focusing on interaction effects with a kernel-based regularized least squares (KRLS) model","10.1016/j.renene.2019.12.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076702077&doi=10.1016%2fj.renene.2019.12.021&partnerID=40&md5=0522a242885690e41f3e8efb5fa849cb","Rapid urbanization causes changes in land-cover and land-use patterns, and leads to warmer urban temperatures; this is defined as the urban heat island (UHI) effect. The intensity, duration, and frequency of heat waves have increased in recent years, posing a serious threat to urban populations. This study examined the relationships between urban physical elements and the cooling rate (CR) around sunset in the summer of 2016, using high-resolution climate data from 218 automatic weather stations (AWSs) around Seoul, South Korea. To detect possible nonlinearities and interactions among predictors, the Kernel-based regularized least squares (KRLS) estimation approach was adopted for empirical analysis. Along with the KRLS model, traditional ordinary least squares (OLS) analysis was also conducted mainly for comparison purposes. The results showed that urban elements, including both land-cover and three-dimensional built environment characteristics, had a significant influence on CR. In addition, significant interacting behaviors were also found. Our results indicate that a more comprehensive approach to understanding both the singular and compounding effects of various urban characteristics can help ameliorate outdoor thermal environments by enhancing summertime CR. © 2019 Elsevier Ltd","Air temperature; Built environment; Cooling rate; Kernel-based regularized least squares model; Thermal environment; Urban heat island effect","Land use; Landforms; Weather information services; Air temperature; Built environment; Cooling rates; Regularized least squares; Thermal environment; Urban Heat Island Effects; Atmospheric temperature; air temperature; cooling; heat island; heat wave; land cover; land use change; least squares method; numerical model; summer; urban population; South Korea"
"Choudhury A.S., Halder T., Basak A., Chakravarty D.","Implementation of Artificial Intelligence (AI) in Smart Manufacturing: A Status Review","10.1007/978-3-031-22915-2_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144819169&doi=10.1007%2f978-3-031-22915-2_7&partnerID=40&md5=e107144f2483bbabfdbb14e6f8cbfec9","In today's world, artificial intelligence (AI) is widely considered one of the highly innovative technologies. Usage of AI has been implemented nearly in all sectors such as manufacturing, R&D, education, smart cities, agriculture, etc. The new era of the Internet plus AI has resulted in the high-speed evolution of the central technologies, analyzed based on research regarding recent artificial intelligence (AI) applications in smart manufacturing. It is necessary to set up an industry that must be flexible with turbulent changes and adequately manage highly skilled employees and workers to design a more suitable working atmosphere for both men and technology. Google Scholar is widely used to explore several keywords and their combinations and search and examine the relevant articles, papers, journals, and study data for conducting this manuscript. The recent progress in intelligent manufacturing is discussed by observing the outlook of intelligent manufacturing technology and its applications. Lastly, the study talks about the scope of AI and how it is implemented in today's smart manufacturing sector of India, focusing on its present status, limitations, and suggestions for overcoming problems. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Artificial intelligence; CPS; Deep learning; ICT; IIOT; Industry 4.0; Machine learning; RUL; Smart manufacturing","Deep learning; Engineering education; Flow control; Industrial research; CPS; Deep learning; High Speed; Highly skilled employees; ICT; IIOT; Innovative technology; Machine-learning; RUL; Smart manufacturing; Industry 4.0"
"Chu J., Su X., Jiang T., Qi J., Zhang G., Wu H.","Filling the gap between GRACE and GRACE-FO data using a model integrating variational mode decomposition and long short-term memory: a case study of Northwest China","10.1007/s12665-022-10716-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145361435&doi=10.1007%2fs12665-022-10716-y&partnerID=40&md5=c57d63449534ca4ccd993d17821d0de6","Terrestrial water storage anomalies (TWSA) play an important role in the regional and global hydrological cycle. The Gravity Recovery and Climate Experiment (GRACE) (from April 2002 to June 2017) and GRACE-Follow on (GRACE-FO) (from June 2018 to now) provide monthly global TWSA on a large scale, which contributes to the development of hydrology, but there is an 11-month data gap (i.e., from July 2017 to May 2018) between them due to the launch period. Therefore, based on the Center for Space Research (CSR) spherical harmonics (SH) and Mascons solution from April 2002 to June 2017, this study develops a method based on the Variational Mode Decomposition (VMD) with the Long Short-Term Memory (LSTM) model to fill the data gap of GRACE dataset and then tests over Northwest China (NWC). The result shows that integrated VMD–LSTM model achieve significantly higher prediction accuracy as a whole over NWC (NSE = 0.974, CC = 0.989, and RMSE = 0.808 cm) and exhibit higher reliability compared to the single LSTM models. The proposed method outperforms compared to previous similar studies. The current study offers an accurate and effective means of bridging the gap in GRACE-based TWSA data, especially in poor dataset regions like NWC, which may contribute to further understanding of the hydrological cycle and water resources management. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Deep learning; GRACE; Long short-term memory; Northwest China; Terrestrial water storage; Variational mode decomposition","Brain; Digital storage; Information management; Long short-term memory; Space research; Statistical tests; Water resources; Case-studies; Data gap; Deep learning; Gravity recovery and climate experiments; Hydrological cycles; Large-scales; Memory modeling; NorthWest China; Spherical harmonics; Terrestrial water storage; Variational mode decomposition; algorithm; decomposition analysis; GRACE; hydrological cycle; satellite data; spherical harmonics; water storage; China"
"Ciaburro G.","Machine fault detection methods based on machine learning algorithms: A review","10.3934/mbe.2022534","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136219465&doi=10.3934%2fmbe.2022534&partnerID=40&md5=762ad5ef6acf71cca092229d7e00d645","Preventive identification of mechanical parts failures has always played a crucial role in machine maintenance. Over time, as the processing cycles are repeated, the machinery in the production system is subject to wear with a consequent loss of technical efficiency compared to optimal conditions. These conditions can, in some cases, lead to the breakage of the elements with consequent stoppage of the production process pending the replacement of the element. This situation entails a large loss of turnover on the part of the company. For this reason, it is crucial to be able to predict failures in advance to try to replace the element before its wear can cause a reduction in machine performance. Several systems have recently been developed for the preventive faults detection that use a combination of low-cost sensors and algorithms based on machine learning. In this work the different methodologies for the identification of the most common mechanical failures are examined and the most widely applied algorithms based on machine learning are analyzed: Support Vector Machine (SVM) solutions, Artificial Neural Network (ANN) algorithms, Convolutional Neural Network (CNN) model, Recurrent Neural Network (RNN) applications, and Deep Generative Systems. These topics have been described in detail and the works most appreciated by the scientific community have been reviewed to highlight the strengths in identifying faults and to outline the directions for future challenges. © 2022 the Author(s).","classification; deep learning; machine fault diagnosis; machine learning; regression; review","Computer aided diagnosis; Convolutional neural networks; Failure analysis; Learning algorithms; Learning systems; Machinery; Preventive maintenance; Recurrent neural networks; Support vector machines; Wear of materials; Deep learning; Detection methods; Faults detection; Machine fault diagnosis; Machine faults; Machine learning algorithms; Machine-learning; Mechanical parts; On-machines; Regression; Fault detection; algorithm; machine learning; support vector machine; Algorithms; Machine Learning; Neural Networks, Computer; Support Vector Machine"
"Civantos-Gómez I., Rubio Teso M.L., Galeano J., Rubiales D., Iriondo J.M., García-Algarra J.","Climate change conditions the selection of rust-resistant candidate wild lentil populations for in situ conservation","10.3389/fpls.2022.1010799","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142188325&doi=10.3389%2ffpls.2022.1010799&partnerID=40&md5=e50f4289ef5da681eb939f47fe1bce04","Crop Wild Relatives (CWR) are a valuable source of genetic diversity that can be transferred to commercial crops, so their conservation will become a priority in the face of climate change. Bizarrely, in situ conserved CWR populations and the traits one might wish to preserve in them are themselves vulnerable to climate change. In this study, we used a quantitative machine learning predictive approach to project the resistance of CWR populations of lentils to a common disease, lentil rust, caused by fungus Uromyces viciae-fabae. Resistance is measured through a proxy quantitative value, DSr (Disease Severity relative), quite complex and expensive to get. Therefore, machine learning is a convenient tool to predict this magnitude using a well-curated georeferenced calibration set. Previous works have provided a binary outcome (resistant vs. non-resistant), but that approach is not fine enough to answer three practical questions: which variables are key to predict rust resistance, which CWR populations are resistant to rust under current environmental conditions, and which of them are likely to keep this trait under different climate change scenarios. We first predict rust resistance in present time for crop wild relatives that grow up inside protected areas. Then, we use the same models under future climate IPCC (Intergovernmental Panel on Climate Change) scenarios to predict future DSr values. Populations that are rust-resistant by now and under future conditions are optimal candidates for further evaluation and in situ conservation of this valuable trait. We have found that rust-resistance variation as a result of climate change is not uniform across the geographic scope of the study (the Mediterranean basin), and that candidate populations share some interesting common environmental conditions. Copyright © 2022 Civantos-Gómez, Rubio Teso, Galeano, Rubiales, Iriondo and García-Algarra.","climate change; crop wild relatives; in situ conservation; lentils; machine learning; predictive characterization; rust resistance",
"Colak Oz H., Güven Ç., Nápoles G.","School dropout prediction and feature importance exploration in Malawi using household panel data: machine learning approach","10.1007/s42001-022-00195-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143886470&doi=10.1007%2fs42001-022-00195-3&partnerID=40&md5=4e88e0d1e995373e6f1712904f6d793f","Designing early warning systems through machine learning (ML) models to identify students at risk of dropout can improve targeting mechanisms and lead to efficient social policy interventions in education. School dropout is a culmination of various factors that drive children to leave school, and timely policy responses are most needed to address these underlying factors and improve school retention of children over time. However, applying ML approaches to school dropout prediction is an important challenge, especially in low-income countries, where data collection and management systems are relatively more prone to financial and technical constraints. For this reason, this study suggests using already collected household panel data to predict the probability of school dropout and explore feature importance for primary school children in Malawi through ML models. A rich set of variables is obtained in this study from the household data and used to build Random Forest (RF), least absolute shrinkage and selection operator (LASSO), Ridge and multilayer neural network (MNN) models. The study further explores how performance metrics differ when we embed the training samples' weights representing frequency in sampling design into the cost function of these ML models to discuss the implications of using household data in computational social science. LASSO and MNN models trained with sample weights become more prominent due to their higher recall rates of 80.6% and 78.8%. Compared to the baseline model trained with sample weights, the recall rate gained is roughly 56 percentage points using LASSO and 54 percentage points using MNN. Also, comparing LASSO and MNN trained with and without sample weights reveals that training models with sample weights increase the recall rate roughly by 11 percentage points for LASSO and 12 percentage points for MNN. Lastly, the paper provides a comprehensive and unified approach to better interpret the models using a game-theoretic approach – SHapley Additive exPlanations (SHAP) – to quantify feature importance. As a result, socio-economic characteristics of children, such as working in household farming and father's education level, are among the most important features contributing to the probability of school dropout in ML models. This study argues that the weighted sample structure of household data and its wide range of variables explored through the SHAP method for feature importance can enrich the literature and yield valuable results to harness data science for society. © 2022, The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd.","Educational data mining; Feature importance; Machine learning; Sample weights; School dropout prediction",
"Condran S., Bewong M., Islam M.Z., Maphosa L., Zheng L.","Machine Learning in Precision Agriculture: A Survey on Trends, Applications and Evaluations over Two Decades","10.1109/ACCESS.2022.3188649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134207203&doi=10.1109%2fACCESS.2022.3188649&partnerID=40&md5=5e5ac78659724391fb355f529ca03aaa","Precision agriculture represents the new age of conventional agriculture. This is made possible by the advancement of various modern technologies such as the internet of things. The unparalleled potential for data collection and analytics has resulted in an increase in multi-disciplinary research within machine learning and agriculture. However, the application of machine learning techniques to agriculture seems to be out of step with core machine learning research. This gap is further exacerbated by the inherent challenges associated with agricultural data. In this work, we conduct a systematic review of a large body of academic literature published between 2000 and 2022, on the application of machine learning techniques to agriculture. We identify and discuss some of the key data issues such as class imbalance, data sparsity and high dimensionality. Further, we study the impact of these data issues on various machine learning approaches within the context of agriculture. Finally, we identify some of the common pitfalls in the machine learning and agriculture research including the misapplication of machine learning evaluation techniques. To this end, this survey presents a holistic view on the state of affairs in the cross-domain of machine learning and agriculture and proposes some suitable mitigation strategies to address these challenges. © 2013 IEEE.","Agriculture; digital farming; intelligent agriculture; machine learning; precision agriculture; precision farming","Agricultural technology; Artificial intelligence; Biological systems; E-learning; Learning algorithms; Learning systems; Precision agriculture; Surveys; Biological system modeling; Digital farming; Farming; Intelligent agriculture; Machine learning techniques; Machine-learning; Market researches; Precision Agriculture; Precision-farming; Internet of things"
"Cooney R., Wan A.H.L., O'Donncha F., Clifford E.","Designing environmentally efficient aquafeeds through the use of multicriteria decision support tools","10.1016/j.coesh.2021.100276","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108154469&doi=10.1016%2fj.coesh.2021.100276&partnerID=40&md5=9b6d5912e7c6abecbe147132fd121879","Aquaculture is the fastest growing food production system, and the sector accounts for more than half of all fish consumed. Its potential as a sustainable food source has been recognised within the EU Farm to Fork strategy and by the targeting of EU Green Deal research funds. Aquafeed is the primary source of environmental cost in farmed finfish and shrimp life cycle assessments (LCA), and thus, emerging ingredients have a key role to play in increasing its sustainability. This paper proposes that the development and ‘design’ of feed compositions can be disrupted by innovative approaches that simultaneously optimise—via multicriteria analysis—ingredient selection through leveraging economic, nutritional, life cycle cost and environmental datasets. This would be supported by the ongoing collection and curation of these same resources. Further, integration of these disparate resources can enable advanced ingredient traceability. The outcome of such an approach would greatly contribute to increasingly efficient aquafeed production. © 2021 The Author(s)","Aquafeed; Life cycle assessment; Machine learning; Nutrition; Seafood; Sustainable aquaculture",
"Corrado S., Scorza F.","Machine Learning Based Approach to Assess Territorial Marginality","10.1007/978-3-031-10450-3_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135053448&doi=10.1007%2f978-3-031-10450-3_25&partnerID=40&md5=16b849903b072213177c12458537e8d8","The territorial cohesion is one of the primary objectives for the European Union and it affects economic recovery pushing the role of Public Administration in promoting territorial development actions. The National Strategy for Inner Areas (SNAI) is a public policy promoting endogenous development processes in marginal territories with low settlement density. Specific contexts where rules and standards defined for the organization of large metropolitan aggregates lose their effectiveness whose identification represents a critical stage for policy efficacy and the actual map of SNAI target areas appears to be the results of a weak and simplified analytical approach. These considerations are the origin of the research question that underlies this work: identify the typical characteristics of Basilicata's marginal areas through machine learning techniques and, subsequently, reclassify the national territory using the trained model. However, outlining the boundary of this territories is only a preliminary task. The following step is the identification of the dynamics within the different territorial sub-systems that make up the inner peripheries. This paper presents the results of the local model-agnostic method for interpreting the obtained results. It emerges, thought cooperative game theory by Shapley values, the need to refine analytical methods that are sensitive to the measurement of the different context conditions. Future perspectives of the research regard the extensive deepening of the application on the basis of wider datasets able to make explicit spatial components of the distribution of the observed phenomena. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Inner periphery; Interpretable machine learning; Territorial cohesion","Game theory; Public administration; Economic recovery; European union; Inner periphery; Interpretable machine learning; Learning-based approach; Machine-learning; National strategies; Primary objective; Territorial cohesion; Territorial development; Machine learning"
"Costa I., Guarda T.","The Impact of Artificial Intelligence on Portuguese Agriculture","10.1007/978-3-031-17960-0_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144616339&doi=10.1007%2f978-3-031-17960-0_5&partnerID=40&md5=afadbf561a28ae2acccebb6081f7378c","If on the one hand the world population is increasing rapidly, on the other hand, the area of arable land is increasingly smaller, the climatic conditions are increasingly unstable, water resources are scarce, and diseases and pests are less controllable. This research work refers to different techniques for automating agricultural processes based on artificial intelligence (AI). This manuscript analyzes several research works with the objective of obtaining an empirical overview of the latest technological advances in the field of AI, also referring to the main impacts of these solutions on agriculture and their context with Portuguese agriculture. The research carried out demonstrates the existing need to optimize the efficiency of agricultural processes, making them more sustainable, ecological, economic, and healthy. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Artificial intelligence; Deep learning; Machine learning; Neural networks; Precision agriculture","Deep neural networks; Learning systems; Water resources; Agricultural process; Arable land; Climatic conditions; Deep learning; Machine-learning; Neural-networks; Precision Agriculture; Process-based; Waters resources; World population; Precision agriculture"
"Coulibaly S., Kamsu-Foguem B., Kamissoko D., Traore D.","Explainable deep convolutional neural networks for insect pest recognition","10.1016/j.jclepro.2022.133638","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136281253&doi=10.1016%2fj.jclepro.2022.133638&partnerID=40&md5=8377edfd70224c189d5e276c8361d134","Fungal infestation of crops is critical to food security as it affects yield and quality of production. Indeed, one element responsible for this situation is insect pests. Early detection of pests based on parcel images is a real challenge in the context of precision agriculture. Nowadays, technical advances in deep neural networks have led to better results in all areas, including crop health management in agriculture. Despite these satisfactory results of deep neural networks in image classification tasks, one of the drawbacks is that it is difficult to decode what the neural networks have learned. The proposed method consists of identifying and locating insect pests in crops using a Convolutional Neural Network (CNN). The localization of insects from the input data is based on explainability methods. For this, explainability highlights the colors and shapes captured by the CNNs using visualization maps. This provides opportunities for human interaction with the learning system for validation of the results provided by the CNN models. In this study, we used over 75,000 images for 102 different pest categories from the IP102 reference dataset. Various explainability methods are combined to formally interpret insect location. The degree of combination is quantified by the mutual information score. The obtained results allow a better interpretation of the reasoning performed by the deep learning system and identified an optimal number of feature extraction layers. Consequently, we simplified a CNN model by decreasing the number of network parameters by 58.90%. This facilitates their explanation in the field of plant science for the effective application in crop diagnosis. © 2022 Elsevier Ltd","Deep learning; Explainability of neural networks; Image classification; Insect pest detection in crops; Transfer learning","Convolution; Convolutional neural networks; Deep neural networks; Food supply; Image classification; Learning systems; Transfer learning; Convolutional neural network; Deep learning; Explainability of neural network; Food security; Images classification; Insect pest detection in crop; Insects pests; Neural network model; Neural-networks; Transfer learning; Crops"
"Cowton J., Kyriazakis I., Plötz T., Bacardit J.","A combined deep learning GRU-autoencoder for the early detection of respiratory disease in pigs using multiple environmental sensors","10.3390/s18082521","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052148513&doi=10.3390%2fs18082521&partnerID=40&md5=54b2cae67eb46f63a80852dc3807507a","We designed and evaluated an assumption-free, deep learning-based methodology for animal health monitoring, specifically for the early detection of respiratory disease in growing pigs based on environmental sensor data. Two recurrent neural networks (RNNs), each comprising gated recurrent units (GRUs), were used to create an autoencoder (GRU-AE) into which environmental data, collected from a variety of sensors, was processed to detect anomalies. An autoencoder is a type of network trained to reconstruct the patterns it is fed as input. By training the GRU-AE using environmental data that did not lead to an occurrence of respiratory disease, data that did not fit the pattern of “healthy environmental data” had a greater reconstruction error. All reconstruction errors were labelled as either normal or anomalous using threshold-based anomaly detection optimised with particle swarm optimisation (PSO), from which alerts are raised. The results from the GRU-AE method outperformed state-of-the-art techniques, raising alerts when such predictions deviated from the actual observations. The results show that a change in the environment can result in occurrences of pigs showing symptoms of respiratory disease within 1–7 days, meaning that there is a period of time during which their keepers can act to mitigate the negative effect of respiratory diseases, such as porcine reproductive and respiratory syndrome (PRRS), a common and destructive disease endemic in pigs. © 2018 by the authors. Licensee MDPI, Basel, Switzerland.","Anomaly detection; Deep learning; Disease; GRU; Health; Pig; Sensors","Diseases; Health; Mammals; Particle swarm optimization (PSO); Pulmonary diseases; Recurrent neural networks; Sensors; Veterinary medicine; Anomaly detection; Destructive disease; Environmental data; Environmental sensor; Particle swarm optimisation; Reconstruction error; Recurrent neural network (RNNs); State-of-the-art techniques; Deep learning"
"Cugurullo F.","Frankenstein urbanism: Eco, smart and autonomous cities, artificial intelligence and the end of the city","10.4324/9781315652627","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102359147&doi=10.4324%2f9781315652627&partnerID=40&md5=70769df520e497d245ad3427413f505a","This book tells the story of visionary urban experiments, shedding light on the theories that preceded their development and on the monsters that followed and might be the end of our cities. The narrative is threefold and delves first into the eco-city, second the smart city and third the autonomous city intended as a place where existing smart technologies are evolving into artificial intelligences that are taking the management of the city out of the hands of humans. The book empirically explores Masdar City in Abu Dhabi and Hong Kong to provide a critical analysis of eco and smart city experiments and their sustainability, and it draws on numerous real-life examples to illustrate the rise of urban artificial intelligences across different geographical spaces and scales. Theoretically, the book traverses philosophy, urban studies and planning theory to explain the passage from eco and smart cities to the autonomous city, and to reflect on the meaning and purpose of cities in a time when human and non-biological intelligences are irreversibly colliding in the built environment. Iconoclastic and prophetic, Frankenstein Urbanism is both an examination of the evolution of urban experimentation through the lens of Mary Shelley’s Frankenstein, and a warning about an urbanism whose product resembles Frankenstein’s monster: a fragmented entity which escapes human control and human understanding. Academics, students and practitioners will find in this book the knowledge that is necessary to comprehend and engage with the many urban experiments that are now alive, ready to leave the laboratory and enter our cities. © 2021 Federico Cugurullo.",,
"Dai X., Keane M.T., Shalloo L., Ruelle E., Byrne R.M.J.","Counterfactual Explanations for Prediction and Diagnosis in XAI","10.1145/3514094.3534144","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136985233&doi=10.1145%2f3514094.3534144&partnerID=40&md5=bc8b61c378806c8cac6cdce7260f2c26","We compared two sorts of explanations for decisions made by an AI system: counterfactual explanations about how an outcome could have been different in the past, and prefactual explanations about how it could be different in the future. We examined the effects of these alternative explanation strategies on the accuracy of users' judgments about the AI app's predictions about an outcome (inferred from information about the causes), compared to the accuracy of their judgments about the app's diagnoses of a cause (inferred from information about the outcome). The tasks were based on a simulated SmartAgriculture decision support system for grass growth outcomes on dairy farms in Experiment 1, and for an analogous alien planet domain in Experiment 2. The two experiments, with 243 participants, also tested users' confidence in their decisions, and their satisfaction with the explanations. Users made more accurate diagnoses of the presence of causes based on information about their outcome, compared to predictions of an outcome given information about the presence of causes. Their predictions and diagnoses were helped equally by counterfactual explanations and prefactual ones. © 2022 Owner/Author.","counterfactual; diagnosis; explainable ai (xai); explanation; prediction; smart agriculture","Artificial intelligence; Decision support systems; AI systems; App predictions; Counterfactuals; Dairy farms; Explainable ai (xai); Explanation; Smart agricultures; User judgements; Forecasting"
"Damos P., Papathanasiou F., Tsikos E., Kyriakidis T., Louta M.","Bayesian Non-Parametric Thermal Thresholds for Helicoverpa armigera and Their Integration into a Digital Plant Protection System","10.3390/agronomy12102474","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140458944&doi=10.3390%2fagronomy12102474&partnerID=40&md5=9a4ac835e822fc8f6bde967c729f409a","The development of temperature-driven pest risk thresholds is a prerequisite for the buildup and implementation of smart plant protection solutions. However, the challenge is to convert short and abrupt phenology data with limited distributional information into ecological relevant information. In this work, we present a novel approach to analyze phenology data based on non-parametric Bayesian methods and develop degree-day (DD) risk thresholds for Helicoverpa armigera (Hübner) (Lepidoptera: Noctuidae) to be used in a decision support system for dry bean (Phaseolus vulgaris L.) production. The replication of each Bayesian bootstrap generates a posterior probability for each sampling set by considering that the prior unknown distribution of pest phenology is Dirichlet distribution. We computed R = 10,000 temperature-driven pest phenology replicates, to estimate the 2.5%, 50% and 95.5% percentiles (PC) of each flight generation peak in terms of heat summations. The related DD thresholds were: 114.04 (PC 2.5%) 131.8 (PC 50%) and 150.9 (PC 95.5%) for the first, 525.8 (PC 2.5%), 551.7 (PC 50%) and 577.6 (PC 95.5%) for the second and 992.7 (PC 2.5%), 1021.5 (PC 50%) and 1050 (PC 95.5%) for the third flight, respectively. The thresholds were evaluated by estimating the posterior differences between the predicted (2021) and observed (2022) phenology metrics and are in most cases in acceptable levels. The bootstrapped Bayesian risk thresholds have the advantage to be used in modeling short and noisy data sets providing tailored pest forecast without any parametric assumptions. In a second step the above thresholds were integrated to a sub-module of a digital weather-driven real time decision support system for precise pest management for dry bean crops. The system consists of a customized cloud based telemetric meteorological network, established over the border area of the Prespa National Park in Northern Greece, and delivers real time data and pest specific forecast to the end user. © 2022 by the authors.","cotton bollworm; decision support system; pest management; precise plant protection; simulation and forecast",
"Dandolo D., Masiero C., Carletti M., Dalle Pezze D., Susto G.A.","AcME—Accelerated model-agnostic explanations: Fast whitening of the machine-learning black box","10.1016/j.eswa.2022.119115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141498082&doi=10.1016%2fj.eswa.2022.119115&partnerID=40&md5=b00e95b5e01c4312c44f571487f7a584","In the context of human-in-the-loop Machine Learning applications, like Decision Support Systems, interpretability approaches should provide actionable insights without making the users wait. In this paper, we propose Accelerated Model-agnostic Explanations (AcME), an interpretability approach that quickly provides feature importance scores both at the global and the local level. AcME can be applied a posteriori to each regression or classification model based on tabular data. Not only AcME computes feature ranking, but it also provides a what-if analysis tool to assess how changes in features values would affect model predictions. We evaluated the proposed approach on synthetic and real-world datasets, also in comparison with SHapley Additive exPlanations (SHAP), the approach we drew inspiration from, which is currently one of the state-of-the-art model-agnostic interpretability approaches. We achieved comparable results in terms of quality of produced explanations while reducing dramatically the computational time and providing consistent visualization for global and local interpretations. To foster research in this field, and for the sake of reproducibility, we also provide a repository with the code used for the experiments. © 2022 Elsevier Ltd","Decision Support Systems; Explainable artificial intelligence; Machine learning; Machine learning interpretability","Machine learning; Accelerated models; Black boxes; Explainable artificial intelligence; Human-in-the-loop; Interpretability; Machine learning applications; Machine learning interpretability; Machine-learning; Posteriori; Decision support systems"
"Danilevicz M.F., Gill M., Anderson R., Batley J., Bennamoun M., Bayer P.E., Edwards D.","Plant Genotype to Phenotype Prediction Using Machine Learning","10.3389/fgene.2022.822173","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131586703&doi=10.3389%2ffgene.2022.822173&partnerID=40&md5=b2dfd2bf3a8314afa7e101f2f51095a5","Genomic prediction tools support crop breeding based on statistical methods, such as the genomic best linear unbiased prediction (GBLUP). However, these tools are not designed to capture non-linear relationships within multi-dimensional datasets, or deal with high dimension datasets such as imagery collected by unmanned aerial vehicles. Machine learning (ML) algorithms have the potential to surpass the prediction accuracy of current tools used for genotype to phenotype prediction, due to their capacity to autonomously extract data features and represent their relationships at multiple levels of abstraction. This review addresses the challenges of applying statistical and machine learning methods for predicting phenotypic traits based on genetic markers, environment data, and imagery for crop breeding. We present the advantages and disadvantages of explainable model structures, discuss the potential of machine learning models for genotype to phenotype prediction in crop breeding, and the challenges, including the scarcity of high-quality datasets, inconsistent metadata annotation and the requirements of ML models. Copyright © 2022 Danilevicz, Gill, Anderson, Batley, Bennamoun, Bayer and Edwards.","big data; machine learning; phenotype prediction; plant breeding; plant phenotyping","big data; crop; genetic marker; genotype; human; human experiment; imagery; machine learning; metadata; nonhuman; phenotype; plant breeding; prediction; review; unmanned aerial vehicle"
"Danilevicz M.F., Bayer P.E., Boussaid F., Bennamoun M., Edwards D.","Maize yield prediction at an early developmental stage using multispectral images and genotype data for preliminary hybrid selection","10.3390/rs13193976","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116465740&doi=10.3390%2frs13193976&partnerID=40&md5=a9aa15704c73807d2d9bbcb8325c4ecd","Assessing crop production in the field often requires breeders to wait until the end of the season to collect yield-related measurements, limiting the pace of the breeding cycle. Early prediction of crop performance can reduce this constraint by allowing breeders more time to focus on the highest-performing varieties. Here, we present a multimodal deep learning model for predicting the performance of maize (Zea mays) at an early developmental stage, offering the potential to accelerate crop breeding. We employed multispectral images and eight vegetation indices, collected by an uncrewed aerial vehicle approximately 60 days after sowing, over three consecutive growing cycles (2017, 2018 and 2019). The multimodal deep learning approach was used to integrate field management and genotype information with the multispectral data, providing context to the conditions that the plants experienced during the trial. Model performance was assessed using holdout data, in which the model accurately predicted the yield (RMSE 1.07 t/ha, a relative RMSE of 7.60% of 16 t/ha, and R2 score 0.73) and identified the majority of high-yielding varieties, outperforming previously published models for early yield prediction. The inclusion of vegetation indices was important for model performance, with a normalized difference vegetation index and green with normalized difference vegetation index contributing the most to model performance. The model provides a decision support tool, identifying promising lines early in the field trial. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Computer vision; Crop breeding; Explainable artificial intelligence; High-throughput phenotyping; Machine learning; Multimodal learning; Uncrewed aerial vehicles; Vegetation indices; Zea mays","Antennas; Computer vision; Cultivation; Decision support systems; Deep learning; Forecasting; Grain (agricultural product); Unmanned aerial vehicles (UAV); Vegetation; Crop breeding; Developmental stage; Explainable artificial intelligence; High-throughput phenotyping; Modeling performance; Multi-modal learning; Uncrewed aerial vehicles; Vegetation index; Yield prediction; Zea mays; Crops"
"Dara R., Hazrati Fard S.M., Kaur J.","Recommendations for ethical and responsible use of artificial intelligence in digital agriculture","10.3389/frai.2022.884192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135875836&doi=10.3389%2ffrai.2022.884192&partnerID=40&md5=e068b8aae25e66f9713977d0b9fba020","Artificial intelligence (AI) applications are an integral and emerging component of digital agriculture. AI can help ensure sustainable production in agriculture by enhancing agricultural operations and decision-making. Recommendations about soil condition and pesticides or automatic devices for milking and apple picking are examples of AI applications in digital agriculture. Although AI offers many benefits in farming, AI systems may raise ethical issues and risks that should be assessed and proactively managed. Poor design and configuration of intelligent systems may impose harm and unintended consequences on digital agriculture. Invasion of farmers' privacy, damaging animal welfare due to robotic technologies, and lack of accountability for issues resulting from the use of AI tools are only some examples of ethical challenges in digital agriculture. This paper examines the ethical challenges of the use of AI in agriculture in six categories including fairness, transparency, accountability, sustainability, privacy, and robustness. This study further provides recommendations for agriculture technology providers (ATPs) and policymakers on how to proactively mitigate ethical issues that may arise from the use of AI in farming. These recommendations cover a wide range of ethical considerations, such as addressing farmers' privacy concerns, ensuring reliable AI performance, enhancing sustainability in AI systems, and reducing AI bias. Copyright © 2022 Dara, Hazrati Fard and Kaur.","accountability; ethical artificial intelligence; fairness; responsible innovation; transparency; trustable digital agriculture",
"Das A.K., Bera B., Wazid M., Jamal S.S., Park Y.","IGCACS-IoD: An Improved Certificate-Enabled Generic Access Control Scheme for Internet of Drones Deployment","10.1109/ACCESS.2021.3089871","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117548846&doi=10.1109%2fACCESS.2021.3089871&partnerID=40&md5=be5e598b0183f73e540336b7b4644f82","Due to wide-spread use of the Information and Communications Technology (ICT) and Internet of Things (IoT) enabled smart devices, called unmanned aerial vehicles (UAVs) (popularly known as drones), a lot of potential applications of Internet of Drones (IoD) are available ranging from the military to civilian applications. Access control mechanism is an important potential security service that is needed to secure communication among the drones in their respective flying zones, and also among the drones and the Ground Service Station (GSS). In 2021, Chaudhry et al. proposed a certificate based generic access control scheme for IoD environment, called GCACS-IoD. Their claims about the possible security attacks resistant of GCACS-IoD is not justified. In fact, we first prove that GCACS-IoD is unable to protect the disclosure of the private key rCR of the trusted control room (CR) , which is extremely unfortunate careless design flaw and it leads to compromise the entire network. Using the disclosed private key rCR , we further show that GCACS-IoD is completely insecure against other serious attacks, such as malicious drones deployment attack, drone/GSS impersonation attacks and Ephemeral Secret Leakage (ESL) attack, which lead to compromise the session key between any two drones communicating in a particular flying zone. We thus feel that there is a strong need to remedy such serious weaknesses found in Chaudhry et al.'s GCACS-IoD. An improved certificate-enabled generic access control scheme for IoD deployment, called as i GCACS-IoD, has been suggested, which overcomes the weaknesses found in the previous GCACS-IoD. The practical demonstration of i GCACS-IoD has been done through formal security verification and also through NS2 simulation study. © 2013 IEEE.","access control; cryptanalysis; Internet of Drones (IoD); key establishment; NS2 simulation; security","Antennas; Drones; Internet of things; Military applications; Access control schemes; Cryptanalyse; Information and Communication Technologies; Internet of drone; Key establishments; NS2 simulation; Private key; Security; Smart devices; Wide spreads; Access control"
"Das M., Mandal A., Das A., Pereira P.","Land use and land cover change future projection in Kolkata Metropolitan Area, Eastern India","10.1016/B978-0-323-90947-1.00011-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143310542&doi=10.1016%2fB978-0-323-90947-1.00011-9&partnerID=40&md5=d486ddf5edc0c9295f0aa98d2c33e66f","Urbanisation is a global phenomenon that has negative impacts on the environment. This process is especially observed in developing countries where a very high rural exodus is occurring. Most cities in developing countries are not prepared to receive a high number of migrants, and the people who arrive in cities live in precarious conditions. Therefore important land use and land cover (LULC) changes are expected to occur in the future. We study the past and future LULC changes in Kolkata Metropolitan Area (KMA) from 2000 until 2040. Future land use was assessed using the QGIS 18.3.1 MOLUSCE plugin and the Business as Usual scenario. The results showed that the images obtained in 2000 (Kappa=0.77), 2010 (Kappa=0.84), and 2019 (Kappa=0.83) were well classified. From 2000 to 2040, we observed a decreasing trend in the area occupied by agricultural land, especially vegetation. A slightly increasing trend was observed in open land, while the build-up area’s identified trend was very high. Water bodies and agricultural fallow did not show any trend. The most important changes were identified in the area occupied by vegetation and build-up area. The vegetation area covered in 2019 20.66% and 2040 8.51%. The Build-up area occupied 35.85% in 2019 and 51.20% in 2040. The changes expected are drastic and may imply an increase in land degradation, habitat fragmentation, biodiversity loss and a reduction of KMA liveability conditions. © 2022 Elsevier Inc. All rights reserved.","Business as Usual; Kolkata Metropolitan Area; land use and land cover; Urbanisation",
"Das P., Varshney L.R.","Explaining Artificial Intelligence Generation and Creativity: Human interpretability for novel ideas and artifacts","10.1109/MSP.2022.3141365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133732749&doi=10.1109%2fMSP.2022.3141365&partnerID=40&md5=296dbcf371eb5c8640d8ad976a5b1a53","Creativity is often thought of as the pinnacle of human achievement, but artificial intelligence (AI) is now starting to play a central role in creative processes, whether autonomously or in collaboration with people. Widespread deployment is now pushing for explanations on how creative AI is working, whether to engender trust, enable action, provide a basis for evaluation, or for intrinsic reasons. In this article, we review various motivations, algorithms, and methods for explaining either the workings of generative/creative AI algorithms or the generative/creative artifacts they produce. © 1991-2012 IEEE.",,"Software engineering; Artificial intelligence algorithms; Creative process; Creatives; Interpretability; Artificial intelligence"
"Das S., Mullick S.S., Zelinka I.","On Supervised Class-Imbalanced Learning: An Updated Perspective and Some Key Challenges","10.1109/TAI.2022.3160658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135346660&doi=10.1109%2fTAI.2022.3160658&partnerID=40&md5=dc967b1c15c51f699fa0363308b03ea3","The problem of class imbalance has always been considered as a significant challenge to traditional machine learning and the emerging deep learning research communities. A classification problem can be considered as class imbalanced if the training set does not contain an equal number of labeled examples from all the classes. A classifier trained on such an imbalanced training set is likely to favor those classes containing a larger number of training examples than the others. Unfortunately, the classes that contain a small number of labelled instances usually correspond to rare and significant events. Thus, poor classification accuracy on these classes may lead to severe consequences. In this article, we aim to provide a comprehensive summary of the rich pool of research works attempting to combat the adversarial effects of class imbalance efficiently. Specifically, following a formal definition of the problem of class imbalance, we explore the plethora of traditional machine learning approaches aiming to mitigate its adversarial effects. We further discuss the state-of-the-art deep-learning-based approaches for improving a classifier's resilience against class imbalance and highlight the need for techniques tailored for such a paradigm. Moreover, we look at the emerging applications where class imbalance can be a major concern. Finally, we outline a few open problems along with the various challenges emerging with the advent of modern applications, deep learning paradigm, and new sources of data. © 2020 IEEE.","Class-imbalanced classification; deep learning; future challenges; machine learning; open problems; performance evaluation indices","Classification (of information); Deep learning; Support vector machines; Class imbalanced classification; Credit cards; Deep learning; Future challenges; Imbalanced classification; Machine-learning; Objects detection; Open problem; Performance evaluation index; Performances evaluation; Soft sensors; Support vectors machine; Object detection"
"Das S., Das J., Umamahesh N.V.","Copula-based drought risk analysis on rainfed agriculture under stationary and non-stationary settings","10.1080/02626667.2022.2079416","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136965533&doi=10.1080%2f02626667.2022.2079416&partnerID=40&md5=5fde2e04d060782c321af641b532e546","Assessing the risk to the agricultural system is important for agricultural sustainability. The present study analyses agricultural drought risk with respect to different drought severities. Different drought indices–namely, Standardized Precipitation Evapotranspiration Index (SPEI), Standardized Soil moisture Index (SSI), Vegetation Condition Index (VCI), and Temperature Condition Index (TCI) – are used to evaluate the conditional probability. Non-stationary analysis is carried out for SPEI and SSI to incorporate the impact of large-scale oscillations and regional hydrological variability. Copula analysis is performed between drought conditions and various crop yield anomalies over Maharashtra, India, during 1998–2015. The outcomes suggest that SPEI is a significant drought indicator over the maximum number of districts in all the crops. Sea Surface Temperature (SST) and Indian Summer Monsoon Index (ISMI) are selected as suitable covariates to model the non-stationarity in the SPEI time series. The drought risk is estimated to increase with drought severity for all of the selected crops. It is observed that the exclusion of non-stationarity will underestimate the agricultural risk. © 2022 IAHS.","agricultural risk; copula; drought; India; rainfed crops","Crops; Oceanography; Risk analysis; Risk assessment; Risk perception; Soil moisture; Surface waters; Agricultural risk; Copula; Drought risks; Drought severity; India; Non-stationarities; Nonstationary; Rain fed agriculture; Rainfed crop; Soil moisture index; Drought; alternative agriculture; drought; evapotranspiration; farming system; monsoon; rainfed agriculture; risk assessment; sea surface temperature; soil moisture; India"
"de Anda-Trasviña A., Nieto-Garibay A., Gutiérrez J.","Natural language report of the composting process status using linguistic perception","10.1016/j.asoc.2022.109357","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135375270&doi=10.1016%2fj.asoc.2022.109357&partnerID=40&md5=a80d9c66384d8c4e28e814942a4dffac","The paper presents an automated system to report the evolution of a process in natural language expressions, analyzing wireless sensor data with process patterns by the linguistic description of complex phenomena approach. An implemented system generates reports of the composting process using the temperature measured in the core of a compost pile regarding the temperature pattern during the composting phases. The linguistic reports include sentences about the current status, trend, and behavior of the composting process. The automated system posts each linguistic report via a messaging app, such as Twitter, allowing instant and continuous communication with authorized users on mobile devices. The resulting expressions show that this real-time linguistic report system is a suitable and practical framework to inform users of the process evolution, in preference and complement to a database or graph tools, supporting the users to make decisions for processes that require proper data-interpretation-based supervision. © 2022 Elsevier B.V.","Compost; Fuzzy logic; Granular model; Wireless sensor","Automation; Composting; Fuzzy logic; Piles; Automated systems; Compost; Composting process; Fuzzy-Logic; Granular models; Natural languages; Natural-language expressions; Process status; Wireless sensor; Wireless sensor data; Linguistics"
"De la Cruz A., Bastos R., Silva E., Cabral J.A., Santos M.","What to expect from alternative management strategies to conserve seabirds? Hints from a dynamic modelling framework applied to an endangered population","10.1111/acv.12751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117813770&doi=10.1111%2facv.12751&partnerID=40&md5=58c7bf974a0a82e173a0806c0bda4efc","The worldwide decline of seabird populations due to the combined effects of global and regional changes is creating immense challenges for managers and conservationists. Predicting population responses to proposed management strategies could provide the most effective tools to prevent, halt and reverse ongoing declines. System dynamic modelling frameworks are considered particularly relevant to interrelate biological, ecological and environmental characteristics and to predict population trends. A system dynamics model was designed, compiling diverse information concerning a relict population of the European Shag located in western Iberia, to outline the most effective management options for its conservation. The simulations demonstrate that mortality caused by invasive animals and bycatch mortality were the main reasons for the current population decline. Without management interventions, a decrease of 8% was projected for the next decade, which could be mitigated by specific conservation actions. The results show the usefulness of dynamic modelling frameworks to understand local cause-effect relationships and species responses to ecosystem management under changing environmental conditions. We highlight that the framework proposed, after specific parameterization, could be easily adaptable to other species within similar socio-ecological systems. © 2021 The Authors. Animal Conservation published by John Wiley & Sons Ltd on behalf of Zoological Society of London.","dynamic modelling frameworks; ecological indicators; environmental management; Gulosus aristotelis; marine protected areas; population dynamics; seabirds; umbrella species","bioindicator; ecosystem management; endangered species; environmental management; marine park; modeling; population dynamics; seabird; species conservation; Iberian Peninsula"
"De Lotto R., Sessi M., Venco E.M.","Semi-Automatic Method to Evaluate Ecological Value of Urban Settlements with the Biotope Area Factor Index: Sources and Logical Framework","10.3390/su14041993","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124769146&doi=10.3390%2fsu14041993&partnerID=40&md5=49541db3483707956dbe01235a18cd35","As the number of people living in cities continues to increase and as their needs continue rapidly to evolve, planners and scholars have been encouraged to define what constitutes high levels of quality of life in urban settlements. The relationship of an area’s inhabitants with natural and green resources increases urban environmental value, which is one of the most relevant aspects in the determination of the quality of life in built-up contexts. Moreover, it is fundamental to find quantitative parameters that can monitor the development of planning processes, working together with natural systems. The authors present a comparative method that can be used to analyze and evaluate the ecological value of urban settlements, using a semi-automatic process that is based on calculating the biotope area factor (BAF) using different open-access databases (a cartographic dataset, aerial imagery, and Sentinel-2 images). Two different Italian case studies that are set in the Milan metropolitan area are presented. In this paper, the authors describe the two settlements using the city-planning parameters of physical structure and morphology; they show the ecological differences and similarities throughout the various remote sensing sources and data. Finally, the authors indicate how the research can be developed, highlighting the weaknesses, the potentiality, the replicability process, and the urban planning implications of the methodology. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Biotope area factor; Free-source dataset; Sentinel-2 and aerial imagery; Urban ecological value; Urban planning","cellular automaton; environmental values; human settlement; index method; quality of life; satellite imagery; Sentinel; urban area; urban development; urban planning; Italy"
"Dehghan-Shoar M.H., Orsi A.A., Pullanagari R.R., Yule I.J.","A hybrid model to predict nitrogen concentration in heterogeneous grassland using field spectroscopy","10.1016/j.rse.2022.113385","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143310295&doi=10.1016%2fj.rse.2022.113385&partnerID=40&md5=06866cf8b98c56a130c42176aab96a3b","Field spectroscopy is a rapid and non-destructive tool used for the estimation of nitrogen concentration (N%) of vegetation. Empirical and physically-based models are widely used for retrieving N%. However, model transferability to different times and locations, and feature redundancy remain the two key challenges of field spectroscopy analysis. Here we addressed these problems by developing a hybrid method (i.e., a combination of physically-based (PROSAIL) and empirical models) to retrieve N% in grasslands. We used a large spectral dataset with &gt;6000 samples collected over 8 years (2009–2016) for grassland farms across New Zealand. The hybrid model combines the features derived from PROSAIL inversion and an empirical model and develops a predictive model using a Gaussian Process Regression (GPR) algorithm. The model performance is tested on spatially and temporally independent data and compared with PROSAIL and empirical models. The hybrid model achieves a higher performance with an RMSE (%N), R2 and Mean Prediction Interval Width (MPIW) of 0.27, 0.78 and 0.26 as compared to empirical (RMSE = 0.28, R2 = 0.77 and MPIW = 0.32) and physically-based models (RMSE = 0.33, R2 = 0.65 and MPIW = 0.56). In addition, the hybrid model significantly outperforms the physically-based and empirical models during autumn (RMSE = 0.32, R2 = 0.78 and MPIW = 0.11) and summer (RMSE = 0.27, R2 = 0.80 and MPIW = 0.16) seasons. © 2022 Elsevier Inc.","Field spectroscopy; Foliar nitrogen; Grasslands; Modelling; PROSAIL; Radiative transfer","Large dataset; Empirical model; Field spectroscopy; Foliar nitrogen; Grassland; Hybrid model; Modeling; Nitrogen concentrations; Physically based models; Prediction interval; PROSAIL; Nitrogen; algorithm; ecological modeling; grassland; soil nitrogen; spectroscopy; New Zealand"
"Dehghan-Shoar M.H., Pullanagari R.R., Orsi A.A., Yule I.J.","Simulating spaceborne imaging to retrieve grassland nitrogen concentration","10.1016/j.rsase.2022.100912","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147127144&doi=10.1016%2fj.rsase.2022.100912&partnerID=40&md5=10c64c52b11c0d3a042b370bcbda3bbd","Spaceborne optical imaging enables continuous monitoring of nitrogen concentration (N%) in grasslands. However, the differences in instrumental setup, image pre-processing, wavelength coverage, and sampling rate pose a challenge when attempting to leverage data from multiple spaceborne instruments. We develop a method that makes use of field spectroscopy and the Soil–Plant–Atmosphere Radiative Transfer (SPART) model to simulate any Top Of Atmosphere (TOA) spaceborne sensor. The purpose of this method is to allow better integration of field spectroscopy data with spaceborne optical imagery. We develop a hybrid model using simulated data and a Random Forest Regressor, which is then independently validated using real Sentinel-2 TOA reflectance collected during 2016 and 2020. Our model achieves an independent validation accuracy of 0.44 (RMSE), MPIW of 0.11 and R2 of 0.55, demonstrating the potential of this methodology for monitoring grassland N% using field spectroscopy. © 2022","Field spectroscopy; Grasslands nitrogen concentration; Machine learning; Multispectral imagery; Radiative transfer modeling",
"Delaney E., Greene D., Shalloo L., Lynch M., Keane M.T.","Forecasting for Sustainable Dairy Produce: Enhanced Long-Term, Milk-Supply Forecasting Using k-NN for Data Augmentation, with Prefactual Explanations for XAI","10.1007/978-3-031-14923-8_24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136966915&doi=10.1007%2f978-3-031-14923-8_24&partnerID=40&md5=93b177406a509610bed90ce59bcbf928","Accurate milk supply forecasting for the dairy sector, covering 1000 s of farms with low resolution data, is a key challenge in achieving a sustainable, precision agriculture that can improve farm management, balancing costs, energy use and environmental protection. We show that case-based reasoning (CBR) can meet this sustainability challenge, by supplementing a time series prediction model on a full-year-forecasting task. Using a dataset of three years of milk supply from Irish dairy farms (N = 2,479), we produce accurate full-year forecasts for each individual farm, by augmenting that farm’s data with data from nearest-neighboring farms, based on the similarity of their time series profiles (using Dynamic Time Warping). A study comparing four methods (Seasonal Naïve, LSTM, Prophet, ProphetNN ) showed that the method using CBR data-augmentation (ProphetNN) outperformed the other evaluated methods. We also demonstrate the utility of CBR in providing farmers with novel prefactual explanations for forecasting that could help them to realize actions that could boost future milk yields and profitability. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","CBR; Dairy production; Data augmentation; Prefactual explanation; Smart agriculture; Time series","Case based reasoning; Dairies; Forecasting; Long short-term memory; Nearest neighbor search; Sustainable development; Casebased reasonings (CBR); Dairy production; Data augmentation; Farm management; Lower resolution; Milk supply; Precision Agriculture; Prefactual explanation; Smart agricultures; Times series; Time series"
"Demirdöğen G., Işık Z., Arayici Y.","Determination of Business Intelligence and Analytics-Based Healthcare Facility Management Key Performance Indicators","10.3390/app12020651","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122508551&doi=10.3390%2fapp12020651&partnerID=40&md5=50bfbc2632c2f33e93811fe60a8a6126","The use of digital technologies such as Internet of Things (IoT) and smart meters induces a huge data stack in facility management (FM). However, the use of data analysis techniques has remained limited to converting available data into information within activities performed in FM. In this context, business intelligence and analytics (BI&A) techniques can provide a promising opportunity to elaborate facility performance and discover measurable new FM key performance indicators (KPIs) since existing KPIs are too crude to discover actual performance of facilities. Beside this, there is no comprehensive study that covers BI&A activities and their importance level for healthcare FM. Therefore, this study aims to identify healthcare FM KPIs and their importance levels for the Turkish healthcare FM industry with the use of the AHP integrated PROMETHEE method. As a result of the study, ninety-eight healthcare FM KPIs, which are categorized under six categories, were found. The comparison of the findings with the literature review showed that there are some similarities and differences between countries’ FM healthcare ranks. Within this context, differences between countries can be related to the consideration of limited FM KPIs in the existing studies. Therefore, the proposed FM KPIs under this study are very comprehensive and detailed to measure and discover healthcare FM performance. This study can help professionals perform more detailed building performance analyses in FM. Additionally, findings from this study will pave the way for new developments in FM software and effective use of available data to enable lean FM processes in healthcare facilities. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Business intelligence and analytics; Facility management; Healthcare facilities; Key performance indicators",
"Deng J., Jia G.","Effect of hydrated shell layers on surface tension of electrolyte solutions: Insights from interpretable machine learning","10.1016/j.molliq.2022.120887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143515396&doi=10.1016%2fj.molliq.2022.120887&partnerID=40&md5=1c81a1727f086f415f5f4432c2673737","To explore the effects of hydration shell layer on the surface tension of electrolytes solution and to build an effective prediction model, a machine learning based model is proposed to accurately predict and explain the surface tension of electrolytes solution. The model combines machine learning (ML) algorithms, force filed parameters of molecular dynamics simulations and radial distribution function (RDF) to accurately capture the structure feature for electrolytes solution. The prediction performed an extremely low average relative deviation. SHapley Additive explanation (SHAP) method is used to indicate the features order of importance from strong to weak. It noted that the second hydration shell on the influence of surface tension may beyond the first hydration shell. This work provides a method for one-step acquisition of surface tension data that not only to accurately predict physical and chemical properties of materials, but also to extend the application of molecular dynamics simulations, providing enlightening insights for detecting underlying physical mechanisms. © 2022 Elsevier B.V.","Hydration shell layer; Interpretable machine learning; Molecular dynamic parameter; Surface tension; The electrolytes solution","Distribution functions; Electrolytes; Forecasting; Hydration; Machine learning; Shells (structures); Surface tension; Dynamic parameters; Dynamics simulation; Hydration shell; Hydration shell layer; Interpretable machine learning; Machine-learning; Molecular dynamic parameter; Shell layers; The electrolyte solution; Molecular dynamics"
"Deng J., Jia G.","Dielectric constant prediction of pure organic liquids and their mixtures with water based on interpretable machine learning","10.1016/j.fluid.2022.113545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134317841&doi=10.1016%2fj.fluid.2022.113545&partnerID=40&md5=7c9f48696be6936596c0bd5ec4deaafe","The thermodynamic properties of mixed-solvent electrolytes are functions of pressure, temperature, and composition (PTC), and are generally considered to be characterized by their dielectric constant. In this work, an interpretable dielectric constant model is proposed based on a machine learning algorithm. The model combines machine learning algorithms, Abraham Solvation Parameters (ASP) and SHapley Additive exPlanations (SHAP) methods to accurately predict the dielectric constants of pure organic liquids and their mixtures with water, the significance of each feature and its impact on the results are explained. The predictions demonstrate extremely low mean square errors, and the effect of each feature on the dielectric constant is clearly characterized. This model provides the ability to accurately predict the dielectric constant for any pure organic liquids and their mixtures with water, and can analyze the sensitivity and influence of each feature to the dielectric constant. Furthermore, this work extends the application of the Abraham solvation parameter to prediction of solution properties. The interpretability of the model will make this a great resource to direct the prediction of physical and chemical properties of materials. © 2022 Elsevier B.V.","Abraham solvation parameters; Dielectric constant; Machine learning; Pure organic liquids and their mixtures with water; SHAP values","Dielectric liquids; Forecasting; Learning algorithms; Machine learning; Solvation; Thermodynamic properties; Abraham solvation parameters; Machine learning algorithms; Machine-learning; Mixed solvent electrolytes; Organic liquid; Pure organic liquid and their mixture with water; Shapley; Shapley additive explanation value; Thermodynamics property; Water based; Mean square error"
"Deng X., Wang G., Yan H., Zheng J., Li X.","Spatial–Temporal Pattern and Influencing Factors of Drought Impacts on Agriculture in China","10.3389/fenvs.2022.820615","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128557016&doi=10.3389%2ffenvs.2022.820615&partnerID=40&md5=eb7579069e43d6cd05fa3ddfc842cf54","Agricultural drought disaster is a major natural disaster affecting economic and social development. It is of significance to investigate the spatial–temporal pattern and the dominant influence of natural and human factors on agricultural drought disasters for drought hazard relief. In this study, Mann–Kendall test was adopted to explore the evolution of agricultural drought disasters. Random forest algorithm, which integrates feature importance and accumulated local effects plot, was applied to quantify the effect of principal influencing factors on agricultural drought disasters. Results show that over the period from 1950 to 2019, agricultural drought disasters in China have undergone significant fluctuations. The spatial pattern of agricultural drought disaster tends to decrease in severity from north to south. The total sown area of crops, precipitation, effective irrigation area, domestic patent application authorization, and regional GDP are the top 5 dominant factors influencing agricultural drought disasters. It also found that agricultural drought disaster negatively correlates with precipitation, domestic patent application authorization, and regional GDP, and the nonlinear response of agricultural drought disaster to total sown area of crops and effective irrigation area can be basically divided into two stages. In the first stage, with the increase of feature value, agricultural drought disaster is also increasing. In the second stage, with the increase of feature value, agricultural drought disaster is growing slow or just decreasing. The results can deepen the understanding of agricultural drought disasters and provide scientific basis for drought event monitoring, evaluation, and early warning. Copyright © 2022 Deng, Wang, Yan, Zheng and Li.","agricultural drought disaster; ALE plots; drought impacts; feature importance; human activities; influencing factors; random forest; spatial–temporal pattern",
"Deshpande N.M., Gite S., Pradhan B., Kotecha K., Alamri A.","Improved Otsu and Kapur approach for white blood cells segmentation based on LebTLBO optimization for the detection of Leukemia","10.3934/mbe.2022093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121830310&doi=10.3934%2fmbe.2022093&partnerID=40&md5=8a14c556480ea76758b8353164a89c29","The diagnosis of leukemia involves the detection of the abnormal characteristics of blood cells by a trained pathologist. Currently, this is done manually by observing the morphological characteristics of white blood cells in the microscopic images. Though there are some equipment-based and chemical-based tests available, the use and adaptation of the automated computer vision-based system is still an issue. There are certain software frameworks available in the literature; however, they are still not being adopted commercially. So there is a need for an automated and software- based framework for the detection of leukemia. In software-based detection, segmentation is the first critical stage that outputs the region of interest for further accurate diagnosis. Therefore, this paper explores an efficient and hybrid segmentation that proposes a more efficient and effective system for leukemia diagnosis. A very popular publicly available database, the acute lymphoblastic leukemia image database (ALL-IDB), is used in this research. First, the images are pre-processed and segmentation is done using Multilevel thresholding with Otsu and Kapur methods. To further optimize the segmentation performance, the Learning enthusiasm-based teaching-learning-based optimization (LebTLBO) algorithm is employed. Different metrics are used for measuring the system performance. A comparative analysis of the proposed methodology is done with existing benchmarks methods. The proposed approach has proven to be better than earlier techniques with measuring parameters of PSNR and Similarity index. The result shows a significant improvement in the performance measures with optimizing threshold algorithms and the LebTLBO technique. © 2022 the Author(s), licensee AIMS Press. This is an open access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0)","LebTLBO; Leukemia; Multi-level thresholding; Otsu; White blood cells segmentation","Blood; Cells; Chemical equipment; Computer software; Cytology; Image segmentation; Abnormal characteristics; Blood cells; Cell segmentation; Learning enthusiasm-based teaching-learning-based optimization; Multilevel thresholding; Optimisations; Otsu; Teaching-learning-based optimizations; White blood cell segmentation; White blood cells; Diseases; algorithm; diagnostic imaging; factual database; human; image processing; leukemia; leukocyte; procedures; Algorithms; Databases, Factual; Humans; Image Processing, Computer-Assisted; Leukemia; Leukocytes"
"Dey B., Masum Ul Haque M., Khatun R., Ahmed R.","Comparative performance of four CNN-based deep learning variants in detecting Hispa pest, two fungal diseases, and NPK deficiency symptoms of rice (Oryza sativa)","10.1016/j.compag.2022.107340","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137356226&doi=10.1016%2fj.compag.2022.107340&partnerID=40&md5=050aaa2444c87b35bab5e3a79f0a9e1c","Crop production can be significantly increased if stresses are detected at the earliest possible time to facilitate the implementation of necessary mitigation measures. This present study aims to evaluate the comparative performance of the Convolutional Neural Network (CNN) and four pre-trained deep CNN models, for automatic and rapid detections of Hispa, brown spot, leaf blast, and NPK deficiency symptoms from public and real field images. Deep learning models were trained using different public and field datasets combinations. Best accuracy was achieved for mixed public and field datasets rather than solely field or solely public datasets, with VGG19 models achieving 91.8% accuracy. Relatively simple structured CNN was found to predict phosphate deficient leaves with better performance (96% accuracy) than the other four advanced models, while VGG16 performed better for leaf blast and N deficiency identification. Likewise, ResNet50 could be recommended among the five models for the Potassium deficient leaf identification, while for the Hispa pest, VGG19 outperforms the InceptionV3, ResNet50, and VGG16 models, and was slightly better than the basic CNN. The implication of the study is enormous considering practical application as it deals with the complex dataset of pest, disease and nutrient deficiency. This non-invasive way of detecting different stresses of rice could help farmers in practicing precision agriculture. The findings from this study could be used to develop a user-friendly interface for the rapid and inexpensive detection of diseases and nutrition status by farmers, in a non-destructive way. Similar to rice, various biotic and abiotic stress symptoms in other economic crops could also be captured and identified by deep learning algorithms. © 2022 Elsevier B.V.","CNN; Diseases; NPK deficiency; Rice; Transfer learning","Crops; Cultivation; Deep learning; Learning algorithms; Transfer learning; Comparative performance; Convolutional neural network; Crop production; Fungal disease; Mitigation measures; Network-based; NPK deficiency; Rice; Rice (oryza sativa); Transfer learning; Convolutional neural networks"
"Dharani D.L., Jagadeesan S., Madhavi N.B., Senthilkumar N.C., Kumar M.S., Prabhu K.","CLASSIFICATION OF NITRATE CHEMICAL CONCENTRATION IN GROUND WATER USING CLOUD BASED ARTIFICIAL INTELLIGENCE","10.31838/ecb/2022.11.11.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146510748&doi=10.31838%2fecb%2f2022.11.11.010&partnerID=40&md5=6faef1bc6928a878102e6b6d7c4ed55e","In order to ensure effective management and the prevention of groundwater contamination within the watershed, it is required to conduct an accurate susceptibility study. Because it is a resource that is necessary for human existence, the creation of goods from agriculture, and the operation of machinery in industrial settings, groundwater needs to be adequately monitored and preserved for future use. Therefore, it is of the utmost importance that an accurate evaluation of the groundwater contamination vulnerability index be performed using ResNet-18. The groundwater vulnerability index is a helpful tool for analyzing the state of the environment in various parts of the world, and the ResNet-18 model is able to lend a hand in the effort to accomplish this goal. The research indicated that ResNet-18 was a powerful tool for improving the evaluation of groundwater contamination vulnerability, and that it may help in ensuring the safety of the environment by reducing the likelihood of contamination. These findings were presented in the form of conclusions that were drawn from the research. This was demonstrated by the fact that it assisted in improving the assessment of the potential for contaminating groundwater supplies. © 2022 Deuton-X Ltd. All rights reserved.","Chemica; Deep Learning; Nitrate; ResNet",
"Dhinesh Kumar R., Chavhan S.","Shift to 6G: Exploration on trends, vision, requirements, technologies, research, and standardization efforts","10.1016/j.seta.2022.102666","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139281439&doi=10.1016%2fj.seta.2022.102666&partnerID=40&md5=0a10b939d4cd5a4366f417afd323eb48","Recent technological breakthroughs and significant expansion in the number of Internet-of-Things (IoT) devices, a new paradigm of unparalleled user experiences, dramatically improved a host of innovative applications, and the emergence of various use cases has begun. To achieve this, a much better adaptable communication network architecture is required, one that is exceptionally intelligent and capable of providing hyper-fast, ultra-reliable, and low-latency communications. These needs of the next-generation wireless communication systems are expected to be met by sixth-generation (6G) communication technologies. The standardization process for fifth-generation is now complete, and the worldwide installation has begun. To keep cellular networks competitive, a collaboration between industry and academics has already commenced in designing the next phase called “6G” in communication networks. It provides the groundwork for layering the communication demands arising in the 2030s. 6G perception, services, technology, and standardization are all hot topics in academics and industries. In pursuit of this ambition, this paper outlines the most prospective avenues of 6G research from current literature. In this investigation, the paper highly focuses on state-of-art driving factors and technological developments propelling the 6G revolution. In this study, emerging applications and requirements are also discussed in depth. Then, to provide a perspective on the global aspect of 6G development, the frameworks for existing and ongoing research projects and activities, including standardization efforts, are reviewed. Finally, specific issues have been incorporated to give new insight into future development approaches towards 6G based on developing demands in the coming years. © 2022 Elsevier Ltd","3D networking; 5G; 6G; Artificial Intelligence; Emerging applications; Federated Learning; Internet of Everything; Quantum computing; Swarm UAV's; THz communications; V2X","5G mobile communication systems; Engineering education; Internet of things; Network architecture; Quantum computers; Standardization; Unmanned aerial vehicles (UAV); 3d networking; 5g; 6g; Communications networks; Emerging applications; Federated learning; Quantum Computing; Swarm UAV; THz communications; V2X; Internet of Everything; artificial intelligence; communication; network analysis; research; technological development"
"Dias P., Lunga D.","Embedding Ethics and Trustworthiness for Sustainable AI in Earth Sciences: Where Do We Begin?","10.1109/IGARSS46834.2022.9883030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140408245&doi=10.1109%2fIGARSS46834.2022.9883030&partnerID=40&md5=b4e7f10c82c6e132a80c57a834dc5f90","As in many other research domains, Artificial Intelligence (AI) techniques have been increasing their footprint in Earth Sciences to extract meaningful information from the large amount of high-detailed data available from multiple sensor modalities. While on the one hand the existing success cases endorse the great potential of AI to help address open challenges in ES, on the other hand on-going discussions and established lessons from studies on the sustainability, ethics and trustworthiness of AI must be taken into consideration if the community is to ensure that its research efforts move into directions that effectively benefit the society and the environment. In this paper, we discuss insights gathered from a brief literature review on the subtopics of AI Ethics, Sustainable AI, AI Trustworthiness and AI for Earth Sciences in an attempt to identify some of the promising directions and key needs to successfully bring these concepts together. © 2022 IEEE.","AI ethics; AI trustworthiness; Artificial Intelligence; Earth Sciences; Sustainable AI","Ethical technology; Sustainable development; Artificial intelligence ethic; Artificial intelligence techniques; Artificial intelligence trustworthiness; Embeddings; Hand-on; Large amounts; Multiple sensors; Research domains; Sensor modality; Sustainable artificial intelligence; Artificial intelligence"
"Dikshit A., Pradhan B., Santosh M.","Artificial neural networks in drought prediction in the 21st century–A scientometric analysis","10.1016/j.asoc.2021.108080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120620727&doi=10.1016%2fj.asoc.2021.108080&partnerID=40&md5=6ca1f48fb2e98d833b2fafb3f2e74558","Droughts are the most spatially complex geohazard, which often lasts for years, thereby severely impacting socio-economic sectors. One of the critical aspects of drought studies is developing a reliable and robust forecasting model, which could immensely help drought management planners in adopting adequate measures. Further, the prediction of drought events are extremely challenging due to the involvement of several hydro-meteorological factors, which are further aggravated by the effect of climate change. Among the several techniques such as statistical, physical and data-driven that are used to forecast droughts, artificial neural networks provide one of the most robust approach. As droughts are inherently non-linear and multivariate in nature, the capability of neural networks to capture the dynamic relationship easily and efficiently has seen a rise in its use. Here we evaluate the most used architectures in the last two decades, using scientometric analysis. A general framework used in drought prediction studies is explained and examples from various continents are provided, thus exploring the topic in a global context. The findings show that using sophisticated input representation, the artificial intelligence-based solutions applied to drought prediction of hydro-meteorological variables have promising success, particularly in complex geographical scenarios. The future works need to focus on interpretable models, use of deep learning architectures for long lead time forecasting and use of neural networks to predict different drought characteristics like drought propagation and flash droughts. We also summarize the most widely used neural network approaches in spatial drought prediction, which would serve as a foundation for future research in drought prediction studies. © 2021 Elsevier B.V.","Deep learning; Drought prediction; Interpretable models; Neural networks; Scientometric analysis","Backpropagation; Climate change; Complex networks; Deep learning; Network architecture; Neural networks; Weather forecasting; Deep learning; Drought management; Drought prediction; Economic sectors; Forecasting models; Geohazards; Interpretable model; Neural-networks; Scientometric analysis; Socio-economics; Drought"
"Ding L., Noborio K., Shibuya K.","Modelling and learning cause-effect - application in frost forecast","10.1016/j.procs.2020.09.285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093361796&doi=10.1016%2fj.procs.2020.09.285&partnerID=40&md5=61ad4d640ebef760e6fc132efcc8b6d5","With the recent achievements in real world applications, being able to learn cause-effect has been expected as a new aim of artificial intelligence (AI) and machine learning (ML). As a preliminary attempt, causal modelling has been proposed for capturing relation between past observation of environment factors and future event of frost. This article continues explore methods of modelling and learning cause-effect relation in frost forecast. It first argues that the relation between environment factors and frost event is of cause-effect more than correlation, then discusses the involvement of time in modelling such cause-effect. Methods of modelling are discussed with their assumptions and rational behind. Performance comparison is provided. © 2020 The Authors. Published by Elsevier B.V.","Cause-effect; Frost forecast; Modelling of machine learning; Structured causal model; Time series","Artificial intelligence; Knowledge based systems; Causal modelling; Cause-effect; Environment factors; Performance comparison; Real-world; Learning systems"
"Dix M., Chouhan A., Ganguly S., Pradhan S., Saraswat D., Agrawal S., Prabhune A.","Anomaly Detection in the Time-Series Data of Industrial Plants using Neural Network Architectures","10.1109/BigDataService52369.2021.00035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120984476&doi=10.1109%2fBigDataService52369.2021.00035&partnerID=40&md5=3e257e2c689914aa6c0977cd36b08d9d","Industrial process control systems collect a vast amount of production data, especially time-series data from various sensors in a plant. This data provides a plethora of potential use cases for AI and machine learning that can help plant operators better understand and predict complex plant situations and thereby run their plants more effectively and safely. A relevant use case is anomaly detection, due to the time and cost-intensive process of detecting and rectifying issues, e.g., plant equipment failures. In this paper, the anomaly detection problem for multivariate industrial time-series data is addressed with the help of neural network architectures. In particular, three architectures are evaluated and compared: Dense Autoencoders, LSTM Autoencoders, and LSTMs. The evaluation is performed to detect 20 simulated plant equipment failures for a real-world industrial process found in oil production fields, called the three-phase separator process. The evaluation is done by 1) measuring to what extent the anomaly detection models succeed in detecting the anomalies, and 2) how well the models are able to explain the anomaly root cause. The main contribution of this paper is to find an anomaly detection model that is best suited for the detection and explanation of various failure cases in such an industrial process setting. The evaluation results show the quantitative comparison of the three models metrics and their performances. Here, it is observed that the Dense Autoencoders performed best for the given 20 failure cases. © 2021 IEEE.","anomaly detection; Explainable AI (XAI); Industrial process plants; Multivariate time-series data","Anomaly detection; Industrial plants; Long short-term memory; Petroleum reservoir evaluation; Time series; Anomaly detection; Auto encoders; Explainable AI (XAI); Industrial process plant; Industrial processs; Multivariate time series; Multivariate time-series data; Neural network architecture; Process plants; Time-series data; Network architecture"
"Djenouri Y., Belhadi A., Srivastava G., Lin J.C.-W.","When explainable AI meets IoT applications for supervised learning","10.1007/s10586-022-03659-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136211551&doi=10.1007%2fs10586-022-03659-3&partnerID=40&md5=231c83d1ff30cb9a5bc7a1b40d23694a","This paper introduces a novel and complete framework for solving different Internet of Things (IoT) applications, which explores eXplainable AI (XAI), deep learning, and evolutionary computation. The IoT data coming from different sensors is first converted into an image database using the Gamian angular field. The images are trained using VGG16, where XAI technology and hyper-parameter optimization are introduced. Thus, analyzing the impact of the different input values in the output and understanding the different weights of a deep learning model used in the learning process helps us to increase interpretation of the overall process of IoT systems. Extensive testing was conducted to demonstrate the performance of our developed model on two separate IoT datasets. Results show the efficiency of the proposed approach compared to the baseline approaches in terms of both runtime and accuracy. © 2022, The Author(s).","Deep learning; Genetic algorithm; IoT applications; XAI","Deep learning; Internet of things; Learning systems; Angular field; Deep learning; Hyper-parameter optimizations; Image database; Input values; Internet of thing application; Learning models; Learning process; Technology parameters optimization; XAI; Genetic algorithms"
"Djenouri Y., Belhadi A., Yazidi A., Srivastava G., Lin J.C.-W.","Artificial intelligence of medical things for disease detection using ensemble deep learning and attention mechanism","10.1111/exsy.13093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132920104&doi=10.1111%2fexsy.13093&partnerID=40&md5=4681a6b483a99e286b0998bd4250a748","In this paper, we present a novel paradigm for disease detection. We build an artificial intelligence based system where various biomedical data are retrieved from distributed and homogeneous sensors. We use different deep learning architectures (VGG16, RESNET, and DenseNet) with ensemble learning and attention mechanisms to study the interactions between different biomedical data to detect and diagnose diseases. We conduct extensive testing on biomedical data. The results show the benefits of using deep learning technologies in the field of artificial intelligence of medical things to diagnose diseases in the healthcare decision-making process. For example, the disease detection rate using the proposed methodology achieves 92%, which is greatly improved compared to the higher-level disease detection models. © 2022 The Authors. Expert Systems published by John Wiley & Sons Ltd.","agriculture; artificial intelligence; attention mechanism; deep learning; ensemble learning",
"Dong J., Zeng W., Lei G., Wu L., Chen H., Wu J., Huang J., Gaiser T., Srivastava A.K.","Simulation of dew point temperature in different time scales based on grasshopper algorithm optimized extreme gradient boosting","10.1016/j.jhydrol.2022.127452","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122792063&doi=10.1016%2fj.jhydrol.2022.127452&partnerID=40&md5=173e2802368f41ccab4df32918027cad","Dew point temperature (Tdew) plays an important role in hydrology, meteorology, and other related research. This study evaluated the ability of a new machine learning model (hybrid extreme gradient boosting with grasshopper optimization algorithm (GOA-XGBoost)) to estimate Tdew and compared it with two other tree-based models (XGBoost and random forest (RF)). We collected meteorological data namely actual vapor pressure (ea), maximum air temperature (Tmax), minimum air temperature (Tmin), maximum relative humidity (RHmax), minimum relative humidity (RHmin), atmospheric pressure (Pa), 2 m high wind speed (Ud), during 2016–2019 on daily and hourly time scales from the Sijiqinglin station in China to train, test, and validate each model. The results showed that the GOA-XGBoost model performed best, and the RF model had severe over-fitting problems during the validation phase at daily time scale. The models showed the best accuracy and stability when the input was ea (on average R2 = 1.000, RMSE = 0.296℃, MBE = 0.001℃, MAE = 0.167℃, and KGE = 0.991). The models had more significant errors when the inputs were Tmax, Tmin (on average R2 = 0.721, RMSE = 6.756℃, MBE = -0.101℃, MAE = 5.071℃, and KGE = 0.771). The estimation loss exhibited by the models were similar for the hourly and daily scale patterns. T and RH were the most basic meteorological factors and adding extraneous factors would affect the estimation accuracy of the model. The variability of meteorological data varied less on an hourly scale than on a daily scale. Therefore, the accuracy of the models was higher, but the data set and the volume of operations became larger. This led to a possible reduction in model stability, but the hourly scales are better suited for assessing the effects of simulations in extreme situations. Taking accuracy and stability into account, the GOA-XGBoost model was the best model and the most practical input for both time scales was ea. Therefore, in subsequent studies, the GOA-XGBoost model can be combined with the input ea to estimate Tdew accurately. © 2022 Elsevier B.V.","Cross-validation; Dew point temperature; Extreme gradient boosting; Grasshopper optimization algorithm; Time scale","Adaptive boosting; Atmospheric humidity; Atmospheric pressure; Atmospheric temperature; Decision trees; Machine learning; Optimization; Wind; Air temperature; Cross validation; Dewpoint temperature; Different time scale; Extreme gradient boosting; Gradient boosting; Grasshopper optimization algorithm; Meteorological data; Optimization algorithms; Time-scales; Time measurement; algorithm; dew point; hydrological modeling; optimization; simulation; timescale; China"
"Duan Y., Wang J.","Design of Semiautomatic Digital Creation System for Electronic Music Based on Recurrent Neural Network","10.1155/2022/5457376","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133577382&doi=10.1155%2f2022%2f5457376&partnerID=40&md5=dbdcf549f14729aae296aa9efbb98193","Semiautomated digital creation is increasingly important in the manipulation of electronic music. How to realize the learning of local effective features of audio data is a difficult point in the current research field. Based on recurrent neural network theory, this paper designs a semiautomatic digital creation system for electronic music for digital manipulation and genre classification. The recurrent neural network improves the transmission of electronic music information between the input and output of the network by adopting dense connections consistent with DenseNet and adopts an inception-like structure for the autonomous selection of effective recursive nuclear electronic music categories. In the simulation process, the prediction method based on semiautomatic digital audio clips is also adopted, which pays more attention to the learning of local effective features of audio data, which gives the model the ability to create audio samples of different lengths and improves the model's support for creative tasks in different scenarios. It includes the determination of the number of neurons, the selection of the function of neurons, the determination of the connection method, and the specific learning algorithm rules, and then the training samples are formed. The experimental results show that the recurrent neural network exhibits powerful feature extraction ability and classification ability of music information. The 10-fold cross-validation on GTZAN dataset and ISMIR2004 dataset has obtained 88.7% and 87.68%, surpassing similar ones. The model has reached a leading level. After further use of the MSD (Million Song Dataset) dataset for pre-semiautomatic training, the model effect has been further greatly improved. The accuracy rate on the dataset has been increased to 91.0% and 89.91%, respectively, which has improved the semiautomatic number and creative advancement. © 2022 Yonghui Duan and Jianping Wang.",,"Audio acoustics; Automation; Classification (of information); Computer music; E-learning; Learning algorithms; Learning systems; Music; 'current; Audio data; Creatives; Digital genres; Digital manipulation; Electronic music; Genre classification; Input and outputs; Music information; Research fields; Recurrent neural networks; algorithm; computer simulation; electronics; music; Algorithms; Computer Simulation; Electronics; Music; Neural Networks, Computer"
"Duong H.T., Phan H.C., Tran T.M., Dhar A.S.","Assessment of critical buckling load of functionally graded plates using artificial neural network modeling","10.1007/s00521-021-06238-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109253606&doi=10.1007%2fs00521-021-06238-6&partnerID=40&md5=d6257a043d17a39c11316acae3582546","Predicting the critical buckling loads of functionally graded material (FGM) plates using an analytical method requires solving complex equations with various modes of deformation to determine the minimum loads. The approach is too complex for application in engineering practice. In this paper, a data-driven model using the artificial neural network (ANN) is proposed for the critical buckling load of FGM plates, as an alternative tool for practicing engineers. A database is first developed for randomly selected inputs using an analytical solution based on first-order shear deformation theory for simply supported FGM plates. The database is then divided into a training dataset with 80% of the data and a testing dataset with 20% of the data for developing and validating, respectively, the ANN model. The ANN model developed using six hidden layers with 32 nodes in each layer is found to match the data with a coefficient of determination of 99.95%. Using the ANN model, the stochastic characteristic of the critical buckling load is examined with respect to randomness of the input parameters. The study reveals that along with the dimensional parameters, the critical buckling load is significantly affected by the randomness of the volume fraction ratio and ratio of the modulus of elasticity of the ceramic and the metal. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Artificial neural network; Buckling analysis; Functionally graded material; Machine learning; Monte Carlo simulation; Shear deformation plate theory","Beams and girders; Buckling; Complex networks; Functionally graded materials; Plates (structural components); Random processes; Shear deformation; Statistical tests; Stochastic models; Stochastic systems; Artificial neural network modeling; Critical buckling loads; Dimensional parameters; Engineering practices; First-order shear deformation theory; Functionally graded material (FGM); Functionally graded plates; Stochastic characteristic; Neural networks"
"Ebrahimi-Khusfi Z., Dargahian F., Nafarzadegan A.R.","Predicting the dust events frequency around a degraded ecosystem and determining the contribution of their controlling factors using gradient boosting-based approaches and game theory","10.1007/s11356-021-17265-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123272972&doi=10.1007%2fs11356-021-17265-0&partnerID=40&md5=85f58989f510f0c9fd510ff4a4a4e835","This study was aimed to evaluate the performance of gradient boosting machine (GBM) and extreme gradient boosting (XGB) models with linear, tree, and DART boosters to predict monthly dust events frequency (MDEF) around a degraded wetland in southwestern Iran. The monthly required data for a long-term period from 1988 to 2018 were obtained through ground stations and satellite imageries. The best predictors were selected among the eighteen climatic, terrestrial, and hydrological variables based on the multicollinearity (MC) test and the Boruta algorithm. The models’ performance was evaluated using the Taylor diagram. Game theory (i.e., SHAP values: SHV) was used to determine the contribution of factors controlling MDEF in different seasons. Mean wind speed, maximum wind speed, rainfall, standardized precipitation evapotranspiration index (SPEI), soil moisture, erosive winds frequency, vapor pressure, vegetation area, water body area, and dried bed area of the wetland were confirmed as the best variables for predicting the MDEF around the studied wetland. The XGB-linear and XGB-tree showed a higher capability in predicting the MDEF variations in the summer and spring seasons. However, the XGB-Dart yielded better than XGB-linear and XGB-tree models in predicting the MDEF during the autumn and winter seasons. Rainfall (SHV = 1.6), surface water discharge (SHV = 2.4), mean wind speed (SHV = 10.1), and erosive winds frequency (SHV = 1.6) had the highest contribution in predicting the target variable in winter, spring, summer, and autumn, respectively. These findings demonstrate the effectiveness of the gradient boosting-based approaches and game theory in determining the factors affecting MDEF around a destroyed international wetland in southwestern Iran and the findings may be used to diminish their impacts on residents of this region of Iran. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Dust events frequency; Environmental factors; Extreme gradient boosting; Iran; Machine learning; Shadegan International Wetland; SHAP values; Wetland degradation","discharge; dust; environmental degradation; environmental factor; evapotranspiration; frequency analysis; game theory; machine learning; performance assessment; satellite imagery; soil moisture; vapor pressure; wetland; Iran; water; dust; ecosystem; game; wetland; Dust; Ecosystem; Game Theory; Water; Wetlands"
"Ebrahimi-Khusfi Z., Taghizadeh-Mehrjardi R., Kazemi M., Nafarzadegan A.R.","Predicting the ground-level pollutants concentrations and identifying the influencing factors using machine learning, wavelet transformation, and remote sensing techniques","10.1016/j.apr.2021.101064","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105532646&doi=10.1016%2fj.apr.2021.101064&partnerID=40&md5=91cd89e260b66f1042fe5cdce1bbe7c8","This study was conducted to evaluate the performance of the support vector regression (SVR) model with and without applying wavelet transformation for predicting the PM10, PM2.5, SO2, NO2, CO, and O3 in Isfahan metropolis, central Iran. Ground-based data, TerraClimate, and MODIS products were used to predict air pollution parameters. These factors were first trained using the SVR and Wavelet-SVR models, and their performance was then compared using the error evaluation statistics. Uncertainties were evaluated using local errors and the clustering method. The influencing factors were lastly determined using the permutation features importance method. The results indicated that the Wavelet-SVR model resulted in improving the performance of prediction compared to the SVR model. The mean prediction interval values were also decreased after applying the wavelet transformation on the SVR model. It was found that the dominant agents affecting the temporal changes of study pollutants are soil moisture and meteorological drought. Urban development and increased energy consumption were observed in the areas with the highest air pollution. Researchers and stakeholders can use these findings to assess air pollution hazards and to improve air quality and human living conditions in metropolises. © 2021 Turkish National Committee for Air Pollution Research and Control","Air pollution; Metropolises; Remote sensing; Support vector machine; Wavelet transformation",
"Edalat M., Dastres E., Jahangiri E., Moayedi G., Zamani A., Pourghasemi H.R., Tiefenbacher J.P.","Spatial mapping Zataria multiflora using different machine-learning algorithms","10.1016/j.catena.2021.106007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123627051&doi=10.1016%2fj.catena.2021.106007&partnerID=40&md5=b051abf17c6c59ab6083994497925a01","Understanding the relationships between environmental factors that influence the distribution of medicinal plants is crucial to identifying suitable habitats for them. Studies have shown that the responses of such species to environmental influences is unclear. A region known as one of the most important areas for Zataria multiflora is Fars Province in southwestern Iran. This study determines the importance of 13 environmental factors (elevation, distance from rivers, distance from roads, pH, electrical conductivity, mean annual temperature, mean annual rainfall, slope angle, slope aspect, plan curvature, and soil properties) to the distribution of Zataria multiflora. The suitable habitats for Zataria multiflora are distinguished by the species-variable relationships and the application of five machine-learning techniques (MLTs): generalized linear model (GLM), generalized boosting model (GBM), boosted regression tree (BRT), functional discrimination analysis (FDA), and mixture discriminant analysis (MDA). The partial least-squares algorithm was used to determine the rank of importance of each variable. The results reveal that the most important factors influencing Zataria multiflora distribution are slope, elevation, EC, and mean annual temperature. The MLTs were applied, and the predictions were classified into four classes (very high, high, moderate, and low). Results indicate that the region of low habitat suitability is in the central portion of the study area and the percentages of the study area classified as having low potential are: 62.01% for GLM, 74.51% for MDA, 63.56% for FDA, 70.14% for GBM, and 23.19% for BRT. The models accuracies as indicated by AUC are MDA (93.6%), GBM (90.3%), GLM (89.1%), FDM (88.1%), and (83.4%). Modeling of habitat suitability can improve farmers’ and managers’ decisions regarding the protection of medicinal plants. © 2021","Ecology; Machine-learning; Medicinal plants; Spatial modeling; Zataria multiflora","algorithm; discriminant analysis; mapping; regression; spatial planning; Fars; Fars; Iran; Iran"
"Egidi E., Delgado-Baquerizo M., Berdugo M., Guirado E., Albanese D., Singh B.K., Coleine C.","UV index and climate seasonality explain fungal community turnover in global drylands","10.1111/geb.13607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142905067&doi=10.1111%2fgeb.13607&partnerID=40&md5=c2495a519ce3939e615ac8b05d62d3a5","Aim: Fungi are major drivers of ecosystem functioning. Increases in aridity are known to negatively impact fungal community composition in dryland ecosystems globally; yet, much less is known on the potential influence of other environmental drivers, and whether these relationships are linear or nonlinear. Time period: 2017–2021. Location: Global. Major taxa studied: Fungi. Methods: We re-analysed multiple datasets from different dryland biogeographical regions, for a total of 912 samples and 1,483 taxa. We examined geographical patterns in community diversity and composition, and spatial, edaphic and climatic factors driving them. Results: UV index, climate seasonality, and sand content were the most important environmental predictors of community shifts, showing the strongest association with the richness of putative plant pathogens and saprobes. Important nonlinear relationships existed with each of these fungal guilds, with increases in UV and temperature seasonality above 7.5 and 900 SD (standard deviation x 100 of the mean monthly temperature), respectively, being associated with an increased probability of plant pathogen and unspecified saprotroph occurrence. Conversely, these environmental parameters had a negative relationship with litter and soil saprotroph richness. Consequently, these ecological groups might be particularly sensitive to shifts in UV radiation and climate seasonality, which is likely to disturb current plant–soil dynamics in drylands. Main conclusions: Our synthesis integrates fungal community data from drylands across the globe, allowing the investigation of fungal distribution and providing the first evidence of shifts in fungal diversity and composition of key fungal ecological groups along diverse spatial, climatic and edaphic gradients in these widely distributed ecosystems. Our findings imply that shifts in soil structure and seasonal climatic patterns induced by global change will have disproportionate consequences for the distribution of fungal groups linked to vegetation and biogeochemical cycling in drylands, with implications for plant–soil interactions in drylands. © 2022 The Authors. Global Ecology and Biogeography published by John Wiley & Sons Ltd.","climate change; drylands; environmental predictors; fungal traits; fungi","aridity; biogeochemical cycle; biogeography; climate change; community composition; data set; fungus; index method; seasonality; taxonomy; ultraviolet radiation; vegetation dynamics"
"Eisenman J., Yang F.","Organizational Structure, Policy Learning, and Economic Performance: Evidence from the Chinese Commune","10.1177/2378023118757650","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135470877&doi=10.1177%2f2378023118757650&partnerID=40&md5=146d633ae50ccb39eddba2a71011e76d","Using original county-level panel data on Chinese communes over two decades, 1958 to 1979, this article builds upon existing theories about the influence of organizational size and structure on institutional performance. We found a consistent and robust interaction effect among the size of the commune (i.e., the coordination level) and its subunits, the brigade (i.e., the supervisory level) and production teams (i.e., the working level), on agricultural productivity. Future work on the relationship between organizational performance and size would likely benefit from including such interaction variables. We also provide evidence that to create a more productive institution, county-level officials learned from their most productive neighbors and adjusted the size of their communes accordingly. This work explains the role of organizational structure as a driver of economic performance and how policy diffusion occurred during China’s Maoist era—a period generally treated as a monolith rather than a period of institutional change. © The Author(s) 2018.","agriculture; China; learning; organization; productivity",
"Ekmekcioğlu Ö., Başakın E.E., Özger M.","Developing meta-heuristic optimization based ensemble machine learning algorithms for hydraulic efficiency assessment of storm water grate inlets","10.1080/1573062X.2022.2134806","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141026550&doi=10.1080%2f1573062X.2022.2134806&partnerID=40&md5=59b221ee1a2b50d2207fe8e38709700b","This research explored the performance comparison of machine learning algorithms, i.e. random forest (RF) and Adaboost, each coupled with the genetic algorithm (GA) and particle swarm optimization (PSO), in intercepted discharge calculations. Thus, six different storm water grate inlets were evaluated through laboratory experiments, and the acquired data was used to construct the integrated prediction framework. Consequently, the RF-based models outperformed the models constructed with Adaboost. Overall, the PSO-RF was found as the best strategy with Nash-Sutcliffe Efficiency index and determination coefficient values of 0.8896 and 0.8990, respectively. In addition, the game-theoretical SHAP analysis demonstrated that the approach flow depth is the most influential variable for hydraulic efficiency evaluations, followed by the grate inlet width and transversal slope of the road. This study further concluded that the lower the grate inlet width, the lower the intercepted discharge capacity, while the increase in transversal slope results in an increase in hydraulic efficiency. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Hydraulic efficiency; meta-heuristics; optimization; storm water grate inlet; tree-based machine learning; urban drainage","algorithm; efficiency measurement; hydraulics; machine learning; optimization; stormwater; urban drainage"
"El Bilali A., Abdeslam T., Ayoub N., Lamane H., Ezzaouini M.A., Elbeltagi A.","An interpretable machine learning approach based on DNN, SVR, Extra Tree, and XGBoost models for predicting daily pan evaporation","10.1016/j.jenvman.2022.116890","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145567758&doi=10.1016%2fj.jenvman.2022.116890&partnerID=40&md5=da087b151d3dfc8c8fd9923a35691f2f","Evaporation is an important hydrological process in the water cycle, especially for water bodies. Machine Learning (ML) models have become accurate and powerful tools in predicting pan evaporation. Meanwhile, the “black-box” character and the consistency with the physical process can decrease the practical implication of ML models. To overcome such limitations, we attempt to develop an interpretable based-ML framework to predict daily pan evaporation using Extra Tree, XGBoost, SVR, and Deep Neural Network (DNN) ML models using hourly climate datasets. To that end, we integrated and employed the Shapely Additive explanations (SHAP), Sobol-based sensitivity analysis, and Local Interpretable Model-agnostic Explanations (LIME) to evaluate the interpretability of the models in predicting daily pan evaporation, at Sidi Mohammed Ben Abdellah (SMBA) weather station, in Morocco. The validation results of the models showed that the developed models are accurate in reproducing the daily pan evaporation with NSE ranging from 0.76 to 0.83 during the validation phase. Furthermore, the interpretability results of the ML models showed that the air temperature (Ta), solar radiation (Rs), followed by relative humidity (H) are the most important climate variables with inflection points of the Ta_median, Ta_mean, Rs_sum, H_mean, and w_std are 17.42 °C, 17.65 °C, 3.8 kw.m−2, 69.59%, and 1.25 m s−1, sequentially. Overall, the interpretability of the models showed a good consistency of the ML models with the real hydro-climatic process of evaporation in a semi-arid environment. Hence, the proposed methodology is powerful in enhancing the reliability and transparency of the developed models for predicting daily pan evaporation. Finally, the proposed approach is new insights to reduce the ‘‘Black-Box’’ character of ML models in hydrological studies. © 2022 Elsevier Ltd","Climate variables; Interpretable machine learning; LIME; SHAP; Sobol index","air temperature; climate change; evaporation; machine learning; relative humidity; solar radiation; Agnostic; air temperature; article; climate; controlled study; deep neural network; desert; evaporation; human; machine learning; Morocco; relative humidity; reliability; sensitivity analysis; solar radiation; weather; physical phenomena; reproducibility; Morocco; Climate; Machine Learning; Neural Networks, Computer; Physical Phenomena; Reproducibility of Results"
"El Bilali A., Lamane H., Taleb A., Nafii A.","A framework based on multivariate distribution-based virtual sample generation and DNN for predicting water quality with small data","10.1016/j.jclepro.2022.133227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135294902&doi=10.1016%2fj.jclepro.2022.133227&partnerID=40&md5=4224db6979ae060723c99936ded9fb04","Deep Neural Network (DNN) is a powerful tool for predicting and monitoring water quality. However, its application is only limited to well-monitored zones where the availability of data for training and validation phases. In this study, we attempt to develop a novel framework based on Multivariate distributions (MVD) (elliptical copulas)-based Virtual Sample Generation (VSG) method to broaden the application of DNN to predict water quality even with a small dataset. This framework is evaluated to predict the Entropy Weighted Water Quality Index (EWQI) using DNN and Electrical Conductivity, Temperature, and pH as input variables, in Berrechid and Chaouia aquifer systems, Morocco. Validation results showed that the virtual samples generated from 400, 50, 30, and 20 original samples improved the NSE from 0.88 to 0.92, from 0.53 to 0.91, from 0.42 to 0.91, and from 0.24 to 0.87, respectively. Besides, sensitivity analysis of the methodology to the virtual data sizes and the original samples showed that the RMSE and NSE of the DNN models have limits in function to virtual data sizes according to the first order Exponential Decay and logistic trends, respectively. These limits highly depend on original sample sizes. Such empirical trends are crucial for reproducing the proposed methodology in other sites to determine optimal virtual datasets. Overall, the proposed methodology provided new insights to improve the DNN model performances in predicting water quality with small datasets. Hence, it is useful to manage water quality in order to supply clean water for the population in poorly monitored zones. © 2022 Elsevier Ltd","Deep neural network; Entropy water quality index; Multivariate normal variable; Virtual data","Aquifers; Entropy; Forecasting; Neural network models; Quality control; Sampling; Sensitivity analysis; Water quality; Entropy water quality index; Multivariate distributions; Multivariate normal; Multivariate normal variable; Original sample; Sample generations; Small data set; Virtual data; Virtual sample; Water quality indexes; Deep neural networks"
"Elbadawi M., McCoubrey L.E., Gavins F.K.H., Ong J.J., Goyanes A., Gaisford S., Basit A.W.","Harnessing artificial intelligence for the next generation of 3D printed medicines","10.1016/j.addr.2021.05.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106912971&doi=10.1016%2fj.addr.2021.05.015&partnerID=40&md5=c929cbed6114ad13e5baddc62e7a7192","Artificial intelligence (AI) is redefining how we exist in the world. In almost every sector of society, AI is performing tasks with super-human speed and intellect; from the prediction of stock market trends to driverless vehicles, diagnosis of disease, and robotic surgery. Despite this growing success, the pharmaceutical field is yet to truly harness AI. Development and manufacture of medicines remains largely in a ‘one size fits all’ paradigm, in which mass-produced, identical formulations are expected to meet individual patient needs. Recently, 3D printing (3DP) has illuminated a path for on-demand production of fully customisable medicines. Due to its flexibility, pharmaceutical 3DP presents innumerable options during formulation development that generally require expert navigation. Leveraging AI within pharmaceutical 3DP removes the need for human expertise, as optimal process parameters can be accurately predicted by machine learning. AI can also be incorporated into a pharmaceutical 3DP ‘Internet of Things’, moving the personalised production of medicines into an intelligent, streamlined, and autonomous pipeline. Supportive infrastructure, such as The Cloud and blockchain, will also play a vital role. Crucially, these technologies will expedite the use of pharmaceutical 3DP in clinical settings and drive the global movement towards personalised medicine and Industry 4.0. © 2021","4D printed personalized pharmaceuticals and medical devices; Additive manufacturing; Computational modeling and finite element analysis; Computer aided design of printlets; Digital therapeutics and healthcare; Drug product design and development; Fabricating gastrointestinal drug delivery systems and dosage forms; Falsified and counterfeit oral pharmaceutical products; Mass customization and machine learning; Translational pharmaceutics and pharmaceutical sciences","3D printers; Automobile manufacture; Diagnosis; Electronic trading; Robotic surgery; 3-D printing; Clinical settings; Formulation development; Human expertise; Market trends; Optimal process; Pharmaceutical fields; Supportive infrastructure; Artificial intelligence; algorithm; artificial intelligence; binder jetting; biocompatibility; bioprinting; computational fluid dynamics; deep learning; drug delivery system; drug formulation; drug industry; drug stability; electrohydrodynamic printing; finite element analysis; fused deposition modeling; glass transition temperature; human; hydrodynamics; inkjet printing; machine learning; measurement accuracy; medicine; melting temperature; nerve cell network; nonhuman; pharmacokinetics; powder base fusion; prediction; reinforcement learning (machine learning); Review; robot assisted surgery; stereolithography; stock market; supervised machine learning; support vector machine; thermostability; three dimensional printing; unmanned aerial vehicle; viscosity; animal; drug development; procedures; Animals; Artificial Intelligence; Drug Development; Humans; Machine Learning; Printing, Three-Dimensional"
"Elliott S.N., Shields A.J.B., Klaehn E.M., Tien I.","Identifying Critical Infrastructure in Imagery Data Using Explainable Convolutional Neural Networks","10.3390/rs14215331","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141842195&doi=10.3390%2frs14215331&partnerID=40&md5=4890fbe7b3f7a3632259a24216539c85","To date, no method utilizing satellite imagery exists for detailing the locations and functions of critical infrastructure across the United States, making response to natural disasters and other events challenging due to complex infrastructural interdependencies. This paper presents a repeatable, transferable, and explainable method for critical infrastructure analysis and implementation of a robust model for critical infrastructure detection in satellite imagery. This model consists of a DenseNet-161 convolutional neural network, pretrained with the ImageNet database. The model was provided additional training with a custom dataset, containing nine infrastructure classes. The resultant analysis achieved an overall accuracy of 90%, with the highest accuracy for airports (97%), hydroelectric dams (96%), solar farms (94%), substations (91%), potable water tanks (93%), and hospitals (93%). Critical infrastructure types with relatively low accuracy are likely influenced by data commonality between similar infrastructure components for petroleum terminals (86%), water treatment plants (78%), and natural gas generation (78%). Local interpretable model-agnostic explanations (LIME) was integrated into the overall modeling pipeline to establish trust for users in critical infrastructure applications. The results demonstrate the effectiveness of a convolutional neural network approach for critical infrastructure identification, with higher than 90% accuracy in identifying six of the critical infrastructure facility types. © 2022 by the authors.","convolutional neural networks; critical infrastructure detection; explainability; machine learning; remote sensing","Convolution; Convolutional neural networks; Critical infrastructures; Disasters; Gas plants; Machine learning; Public works; Remote sensing; Satellite imagery; Water supply; Water tanks; Water treatment; Convolutional neural network; Critical infrastructure detection; Explainability; Imagery data; Infrastructural interdependencies; Machine-learning; Natural disasters; Overall accuracies; Remote-sensing; Robust modeling; Potable water"
"Elyan E., Hussain A., Sheikh A., Elmanama A.A., Vuttipittayamongkol P., Hijazi K.","Antimicrobial Resistance and Machine Learning: Challenges and Opportunities","10.1109/ACCESS.2022.3160213","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126520655&doi=10.1109%2fACCESS.2022.3160213&partnerID=40&md5=954b52cf2cf4cb28c74efdce86a30e06","Antimicrobial Resistance (AMR) has been identified by the World Health Organisation (WHO) as one of the top ten global health threats. Inappropriate use of antibiotics around the world and in particular in Low-to-Middle-Income Countries (LMICs), where antibiotics use and prescription are poorly managed, is considered one of the main reasons for this problem. It is projected that the COVID-19 pandemic will accelerate the threat of AMR due to the increasing use of antibiotics across the world, and especially in countries with limited resources. In recent years, machine learning-based methods showed promising results and proved capable of providing the necessary tools to inform antimicrobial prescription and combat AMR. This timely paper provides a critical and technical review of existing machine learning-based methods for addressing AMR. First, an overview of the AMR problem as a global threat to public health, and its impact on countries with limited resources (LMICs) are presented. Then, a technical review and evaluation of existing literature that utilises machine learning to tackle AMR are provided with emphasis on methods that use readily available demographic and clinical data as well as microbial culture and sensitivity laboratory data of clinical isolates associated with multi-drug resistant infections. This is followed by a discussion of challenges and limitations that are considered barriers to scaling up the use of machine learning to address AMR. Finally, a framework for accelerating the use of AMR data-driven framework, and building a feasible solution that can be realistically implemented in LMICs is presented with a discussion of future directions and recommendations. © 2022 IEEE.","AMR; antimicrobial resistance; LMICs; machine learning","Artificial intelligence; Health; Health risks; Learning systems; Microorganisms; Antimicrobial resistances; Critical review; Global health; Low-to-middle-income country; Machine-learning; Middle-income countries; Resistance problems; Technical reviews; World Health Organization; Antibiotics"
"Espinoza J.L., Dupont C.L.","VEBA: a modular end-to-end suite for in silico recovery, clustering, and analysis of prokaryotic, microeukaryotic, and viral genomes from metagenomes","10.1186/s12859-022-04973-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139751178&doi=10.1186%2fs12859-022-04973-8&partnerID=40&md5=50a857d84b4f05c9611ca458d02ac49e","Background: With the advent of metagenomics, the importance of microorganisms and how their interactions are relevant to ecosystem resilience, sustainability, and human health has become evident. Cataloging and preserving biodiversity is paramount not only for the Earth’s natural systems but also for discovering solutions to challenges that we face as a growing civilization. Metagenomics pertains to the in silico study of all microorganisms within an ecological community in situ, however, many software suites recover only prokaryotes and have limited to no support for viruses and eukaryotes. Results: In this study, we introduce the Viral Eukaryotic Bacterial Archaeal (VEBA) open-source software suite developed to recover genomes from all domains. To our knowledge, VEBA is the first end-to-end metagenomics suite that can directly recover, quality assess, and classify prokaryotic, eukaryotic, and viral genomes from metagenomes. VEBA implements a novel iterative binning procedure and hybrid sample-specific/multi-sample framework that yields more genomes than any existing methodology alone. VEBA includes a consensus microeukaryotic database containing proteins from existing databases to optimize microeukaryotic gene modeling and taxonomic classification. VEBA also provides a unique clustering-based dereplication strategy allowing for sample-specific genomes and genes to be directly compared across non-overlapping biological samples. Finally, VEBA is the only pipeline that automates the detection of candidate phyla radiation bacteria and implements the appropriate genome quality assessments. VEBA’s capabilities are demonstrated by reanalyzing 3 existing public datasets which recovered a total of 948 MAGs (458 prokaryotic, 8 eukaryotic, and 482 viral) including several uncharacterized organisms and organisms with no public genome representatives. Conclusions: The VEBA software suite allows for the in silico recovery of microorganisms from all domains of life by integrating cutting edge algorithms in novel ways. VEBA fully integrates both end-to-end and task-specific metagenomic analysis in a modular architecture that minimizes dependencies and maximizes productivity. The contributions of VEBA to the metagenomics community includes seamless end-to-end metagenomics analysis but also provides users with the flexibility to perform specific analytical tasks. VEBA allows for the automation of several metagenomics steps and shows that new information can be recovered from existing datasets. © 2022, The Author(s).","Binning; Metagenome-assembled genome; Metagenomics; Pipeline","Bacteria; Biodiversity; Classification (of information); Ecosystems; Genes; Iterative methods; Open systems; Pipelines; Quality control; Recovery; Viruses; Archaeal; Binning; Clusterings; End to end; Eukaryotics; In-silico; Metagenome-assembled genome; Metagenomes; Metagenomics; Software suite; Open source software; archaeon; bacterium; cluster analysis; ecosystem; eukaryote; genetics; human; metagenome; metagenomics; procedures; virus genome; Archaea; Bacteria; Cluster Analysis; Ecosystem; Eukaryota; Genome, Viral; Humans; Metagenome; Metagenomics"
"Estévez J., Salinero-Delgado M., Berger K., Pipia L., Rivera-Caicedo J.P., Wocher M., Reyes-Muñoz P., Tagliabue G., Boschetti M., Verrelst J.","Gaussian processes retrieval of crop traits in Google Earth Engine based on Sentinel-2 top-of-atmosphere data","10.1016/j.rse.2022.112958","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126823126&doi=10.1016%2fj.rse.2022.112958&partnerID=40&md5=25344cfb3a98d8a3ff75defec3cc5ef9","The unprecedented availability of optical satellite data in cloud-based computing platforms, such as Google Earth Engine (GEE), opens new possibilities to develop crop trait retrieval models from the local to the planetary scale. Hybrid retrieval models are of interest to run in these platforms as they combine the advantages of physically-based radiative transfer models (RTM) with the flexibility of machine learning regression algorithms. Previous research with GEE primarily relied on processing bottom-of-atmosphere (BOA) reflectance data, which requires atmospheric correction. In the present study, we implemented hybrid models directly into GEE for processing Sentinel-2 (S2) Level-1C (L1C) top-of-atmosphere (TOA) reflectance data into crop traits. To achieve this, a training dataset was generated using the leaf-canopy RTM PROSAIL in combination with the atmospheric model 6SV. Gaussian process regression (GPR) retrieval models were then established for eight essential crop traits namely leaf chlorophyll content, leaf water content, leaf dry matter content, fractional vegetation cover, leaf area index (LAI), and upscaled leaf variables (i.e., canopy chlorophyll content, canopy water content and canopy dry matter content). An important pre-requisite for implementation into GEE is that the models are sufficiently light in order to facilitate efficient and fast processing. Successful reduction of the training dataset by 78% was achieved using the active learning technique Euclidean distance-based diversity (EBD). With the EBD-GPR models, highly accurate validation results of LAI and upscaled leaf variables were obtained against in situ field data from the validation study site Munich-North-Isar (MNI), with normalized root mean square errors (NRMSE) from 6% to 13%. Using an independent validation dataset of similar crop types (Italian Grosseto test site), the retrieval models showed moderate to good performances for canopy-level variables, with NRMSE ranging from 14% to 50%, but failed for the leaf-level estimates. Obtained maps over the MNI site were further compared against Sentinel-2 Level 2 Prototype Processor (SL2P) vegetation estimates generated from the ESA Sentinels' Application Platform (SNAP) Biophysical Processor, proving high consistency of both retrievals (R2 from 0.80 to 0.94). Finally, thanks to the seamless GEE processing capability, the TOA-based mapping was applied over the entirety of Germany at 20 m spatial resolution including information about prediction uncertainty. The obtained maps provided confidence of the developed EBD-GPR retrieval models for integration in the GEE framework and national scale mapping from S2-L1C imagery. In summary, the proposed retrieval workflow demonstrates the possibility of routine processing of S2 TOA data into crop traits maps at any place on Earth as required for operational agricultural applications. © 2022 The Authors","Active learning (AL); Atmosphere radiative transfer model; Biophysical and biochemical crop traits; Euclidean distance-based diversity (EBD); Gaussian processes (GP); Google Earth Engine; Hybrid retrieval methods; Sentinel-2; Top-of-atmosphere reflectance; Uncertainty estimates","Chlorophyll; Crops; Engines; Gaussian noise (electronic); Information retrieval; Machine learning; Mean square error; Radiative transfer; Reflection; Statistical tests; Uncertainty analysis; Vegetation; Active Learning; Atmosphere radiative transfer model; Biophysical and biochemical crop trait; Crop traits; Distance-based; Euclidean distance; Euclidean distance-based diversity; Gaussian process; Google earth engine; Google earths; Hybrid retrieval method; Radiative transfer modelling; Retrieval methods; Sentinel-2; Top of atmospheres; Top-of-atmosphere reflectance; Uncertainty estimates; Gaussian distribution; chlorophyll; error analysis; field method; Gaussian method; leaf area index; model validation; performance assessment; prediction; radiative transfer; satellite data; Sentinel; spatial resolution; surface reflectance; top of atmosphere; uncertainty analysis; Bavaria; Germany; Munich"
"Fahim M., El Mhouti A., Boudaa T., Jakimi A.","Modeling and implementation of a low-cost IoT-smart weather monitoring station and air quality assessment based on fuzzy inference model and MQTT protocol","10.1007/s40808-023-01701-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147502380&doi=10.1007%2fs40808-023-01701-w&partnerID=40&md5=d61109aa99195324e9ba2f29a40130e0","The automatic weather system serves to inform farmers, tourists, planners, and others with precise information to help them take the appropriate action. Today, with the advancement of smart technologies, the system has evolved into many sensing methods to gather real-time climate data. This article investigates the modeling and implementation of a low-cost weather station device that also functions to measure air quality. The proposed system based on the Internet of Things (IoT) allows access to real-time climate data for a given area. This system monitors environmental conditions such as ambient temperature, humidity, atmospheric pressure, altitude, and levels of harmful atmospheric gases like CO2 and NO2. This real-time telemetry device uses MQ-135, DHT-11 and BMP280 sensors to gather data. The ESP32 board processes the obtained data from all sensors. Additionally, we present a model for a fuzzy inference system (FIS) that performs parameter categorization using a reasoning procedure and incorporates the results into an air quality index (AQI) that describes the levels of pollution for Al Hoceima city. The FIS takes CO2 and NO2 values as input and returns the AQI. The AQI for Al Hoceima city is categorized into six levels: Excellent, Good, Regular, Bad, Dangerous, and Very Dangerous. Furthermore, the suggested system's block hardware employs the Message Queuing Telemetry Transport (MQTT) protocol to broadcast collected data to a mobile and web application via the Internet. The suggested IoT-embedded device was tested in real life, and the results were promising. © 2023, The Author(s), under exclusive licence to Springer Nature Switzerland AG.","Air pollution; Air quality; Fuzzy inference system; IoT; MQTT protocol; Smart weather station",
"Fan X., Zhou R., Tjahjadi T., Das Choudhury S., Ye Q.","A Segmentation-Guided Deep Learning Framework for Leaf Counting","10.3389/fpls.2022.844522","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131768171&doi=10.3389%2ffpls.2022.844522&partnerID=40&md5=41e7169fbb1d5e3202c98748b85ff3ef","Deep learning-based methods have recently provided a means to rapidly and effectively extract various plant traits due to their powerful ability to depict a plant image across a variety of species and growth conditions. In this study, we focus on dealing with two fundamental tasks in plant phenotyping, i.e., plant segmentation and leaf counting, and propose a two-steam deep learning framework for segmenting plants and counting leaves with various size and shape from two-dimensional plant images. In the first stream, a multi-scale segmentation model using spatial pyramid is developed to extract leaves with different size and shape, where the fine-grained details of leaves are captured using deep feature extractor. In the second stream, a regression counting model is proposed to estimate the number of leaves without any pre-detection, where an auxiliary binary mask from segmentation stream is introduced to enhance the counting performance by effectively alleviating the influence of complex background. Extensive pot experiments are conducted CVPPP 2017 Leaf Counting Challenge dataset, which contains images of Arabidopsis and tobacco plants. The experimental results demonstrate that the proposed framework achieves a promising performance both in plant segmentation and leaf counting, providing a reference for the automatic analysis of plant phenotypes. Copyright © 2022 Fan, Zhou, Tjahjadi, Das Choudhury and Ye.","deep CNN architecture; leaf counting; multiple traits; plant phenotyping; segmentation",
"Fan Z., Zhang N., Wang D., Wu G., Angulo-Cabanillas L., Kaur K.","Simulation of Pear Tree Growth Geometry Based on CAD 3D Modeling and Visualization Technology","10.14733/cadaps.2023.S3.56-71","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143489994&doi=10.14733%2fcadaps.2023.S3.56-71&partnerID=40&md5=d627507f336a99729e58f0d09d4b4de7","This study employs virtual plants as a bridge between them to achieve the goal of merging the ongoing development of computer technology with modern agriculture. Virtual plants are a new study subject that has emerged in recent years as information technology and computer technology have advanced rapidly. It is a multidisciplinary field that combines computer graphics, botany, mathematics, and virtual reality technologies. This work proposes a method for visualizing fruit tree branches and stems using morphological feature information and the parameter L system. The relevant morphological and structural characteristics, as well as ecological and physiological characteristics, were extracted from the pear tree's tree structure; the L-system modeling method was used to create a model of the pear tree, which included details such as branch thickness, bifurcation angle, and so on; The geometric information of pear tree growth is turned into intuitive three-dimensional visual graphic information using three-dimensional modeling technology, laying the groundwork for the construction of a pear tree shape and pruning computer simulation system. Furthermore, the yield per unit area of an open center tree is 73.93 percent, the weight of a single fruit is 84.22 percent, and the rate of high-quality fruit is 76.15 percent, all of which are less than 85 percent, according to the real test. Only the soluble sugar content, soluble solid content, and fruit hardness relative values are greater than 90%. © 2023 CAD Solutions, LLC.","3D modeling; CAD L system; Pear branches and stems; Visualization","3D modeling; Computer aided design; Information use; Orchards; Physiological models; Plants (botany); Three dimensional computer graphics; Virtual reality; Visualization; 3-D visualization technology; 3d modeling technologies; 3D models; 3d-modeling; CAD L system; Computer technology; L-systems; Pear branch and stem; Tree growth; Virtual plants; Fruits"
"Fang L., Zhan X., Kalluri S., Yu P., Hain C., Anderson M., Laszlo I.","Application of a Machine Learning Algorithm in Generating an Evapotranspiration Data Product From Coupled Thermal Infrared and Microwave Satellite Observations","10.3389/fdata.2022.768676","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131717589&doi=10.3389%2ffdata.2022.768676&partnerID=40&md5=d725ee2319f945749cd0ad5685b2bc27","Land surface evapotranspiration (ET) is one of the main energy sources for atmospheric dynamics and a critical component of the local, regional, and global water cycles. Consequently, accurate measurement or estimation of ET is one of the most active topics in hydro-climatology research. With massive and spatially distributed observational data sets of land surface properties and environmental conditions being collected from the ground, airborne or space-borne platforms daily over the past few decades, many research teams have started to use big data science to advance the ET estimation methods. The Geostationary satellite Evapotranspiration and Drought (GET-D) product system was developed at the National Oceanic and Atmospheric Administration (NOAA) in 2016 to generate daily ET and drought maps operationally. The primary inputs of the current GET-D system are the thermal infrared (TIR) observations from NOAA GOES satellite series. Because of the cloud contamination to the TIR observations, the spatial coverage of the daily GET-D ET product has been severely impacted. Based on the most recent advances, we have tested a machine learning algorithm to estimate all-weather land surface temperature (LST) from TIR and microwave (MW) combined satellite observations. With the regression tree machine learning approach, we can combine the high accuracy and high spatial resolution of GOES TIR data with the better spatial coverage of passive microwave observations and LST simulations from a land surface model (LSM). The regression tree model combines the three LST data sources for both clear and cloudy days, which enables the GET-D system to derive an all-weather ET product. This paper reports how the all-weather LST and ET are generated in the upgraded GET-D system and provides an evaluation of these LST and ET estimates with ground measurements. The results demonstrate that the regression tree machine learning method is feasible and effective for generating daily ET under all weather conditions with satisfactory accuracy from the big volume of satellite observations. Copyright © 2022 Fang, Zhan, Kalluri, Yu, Hain, Anderson and Laszlo.","evapotranspiration (ET); GOES-R; land surface temperature (LST); machine learning (ML); regression tree (RT)",
"Farhat H., Sakr G.E., Kilany R.","Deep learning applications in pulmonary medical imaging: recent updates and insights on COVID-19","10.1007/s00138-020-01101-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088820662&doi=10.1007%2fs00138-020-01101-5&partnerID=40&md5=409920a58b8ec29062c21e60b6ffe8c0","Shortly after deep learning algorithms were applied to Image Analysis, and more importantly to medical imaging, their applications increased significantly to become a trend. Likewise, deep learning applications (DL) on pulmonary medical images emerged to achieve remarkable advances leading to promising clinical trials. Yet, coronavirus can be the real trigger to open the route for fast integration of DL in hospitals and medical centers. This paper reviews the development of deep learning applications in medical image analysis targeting pulmonary imaging and giving insights of contributions to COVID-19. It covers more than 160 contributions and surveys in this field, all issued between February 2017 and May 2020 inclusively, highlighting various deep learning tasks such as classification, segmentation, and detection, as well as different pulmonary pathologies like airway diseases, lung cancer, COVID-19 and other infections. It summarizes and discusses the current state-of-the-art approaches in this research domain, highlighting the challenges, especially with COVID-19 pandemic current situation. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Convolutional Neural Networks; Coronavirus Deep Learning; Medical Image Analysis; Pulmonary Imaging","Hospitals; Image analysis; Learning algorithms; Medical imaging; Clinical trial; Coronaviruses; Current situation; Learning tasks; Medical center; Pulmonary imaging; Research domains; State-of-the-art approach; Deep learning"
"Fariss B., DeMello N., Powlen K.A., Latimer C.E., Masuda Y., Kennedy C.M.","Catalyzing success in community-based conservation","10.1111/cobi.13973","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136667056&doi=10.1111%2fcobi.13973&partnerID=40&md5=6ea4d2a37e8bd8d1e66d4c0f1b5ba9ab","Efforts to devolve rights and engage Indigenous Peoples and local communities in conservation have increased the demand for evidence of the efficacy of community-based conservation (CBC) and insights into what enables its success. We examined the human well-being and environmental outcomes of a diverse set of 128 CBC projects. Over 80% of CBC projects had some positive human well-being or environmental outcomes, although just 32% achieved positive outcomes for both (i.e., combined success). We coded 57 total national-, community-, and project-level variables and controls from this set, performed random forest classification to identify the variables most important to combined success, and calculated accumulated local effects to describe their individual influence on the probability of achieving it. The best predictors of combined success were 17 variables suggestive of various recommendations and opportunities for conservation practitioners related to national contexts, community characteristics, and the implementation of various strategies and interventions informed by existing CBC frameworks. Specifically, CBC projects had higher probabilities of combined success when they occurred in national contexts supportive of local governance, confronted challenges to collective action, promoted economic diversification, and invested in various capacity-building efforts. Our results provide important insights into how to encourage greater success in CBC. © 2022 The Authors. Conservation Biology published by Wiley Periodicals LLC on behalf of Society for Conservation Biology.","accumulated local effects; community-based conservation; conservation evaluation; conservation outcomes; evidence-based conservation; machine learning; random forest classification","community resource management; conservation planning; forest management; indigenous population; machine learning; community participation; environmental protection; human; procedures; Community Participation; Conservation of Natural Resources; Humans; Indigenous Peoples"
"Farooq M.S., Javid R., Riaz S., Atal Z.","IoT Based Smart Greenhouse Framework and Control Strategies for Sustainable Agriculture","10.1109/ACCESS.2022.3204066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137902526&doi=10.1109%2fACCESS.2022.3204066&partnerID=40&md5=cdcdc018929d8009d2926287905d5e25","In recent years, the Internet of Things (IoT) has become one of the most familiar names creating a benchmark and scaling new heights. IoT an indeed future of the communication that has transformed the objects (things) of the real world into smarter devices. With the advent of IoT technology, this decade is witnessing a transformation from traditional agriculture approaches to the most advanced ones. In perspective to the current standing of IoT in agriculture, identification of the most prominent application of IoT-based smart farming i.e. greenhouse has been highlighted and presented a systematic analysis and investigated the high quality research work for the implementation of greenhouse farming. The primary objective of this study is to propose an IoT-based network framework for a sustainable greenhouse environment and implement control strategies for efficient resources management. A rigorous discussion on IoT-based greenhouse applications, sensors/devices, and communication protocols have been presented. Furthermore, this research also presents an inclusive review of IoT-based greenhouse sensors/devices and communication protocols. Moreover, we have also presented a rigorous discussion on smart greenhouse farming challenges and security issues as well as identified future research directions to overcome these challenges. This research has explained many aspects of the technologies involved in IoT-based greenhouse and proposed network architecture, topology, and platforms. In the end, research results have been summarized by developing an IoT-based greenhouse farm management taxonomy and attacks taxonomy. © 2013 IEEE.","applications; big data analytics; cloud computing; communication protocols; greenhouse; Internet of Things (IoT); security attacks; sensors","Agriculture; Cloud analytics; Greenhouses; Internet of things; Internet protocols; Network security; Taxonomies; Big data analytic; Cloud-computing; Communications protocols; Data analytics; Farming; Green products; Internet of thing; Security; Security attacks; Wireless sensor networks"
"Farooq M.S., Riaz S., Helou M.A., Khan F.S., Abid A., Alvi A.","Internet of Things in Greenhouse Agriculture: A Survey on Enabling Technologies, Applications, and Protocols","10.1109/ACCESS.2022.3166634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128272006&doi=10.1109%2fACCESS.2022.3166634&partnerID=40&md5=7f7d06b7ce3a4cca6d5834ef58f85d2f","The greenhouse is one of the sustainable forms of smart agricultural farming. It is considered as an alternate method to overcome the food crisis which is generated due to high population growth, climate change, and environmental pollution. Although this method supports off-the-season crops within the enclosed area even in severe climatic zones. It has required to efficiently control and manage the crop parameters at a greenhouse in a more precise and secure way. The advancement of the Internet of Things (IoT) has introduced smart solutions to automate the greenhouse farming parameters such as plant monitoring, internal atmosphere control, and irrigation control. The survey presents a hierarchy on the major components of IoT-based greenhouse farming. A rigorous discussion on greenhouse farming techniques, IoT-based greenhouse categories, network technologies (cloud/edge computing, IoT protocols, data analytics, sensors) has been presented. Furthermore, a detailed discussion on mobile-based greenhouse applications and IoT applications has been presented to manage the greenhouse farm. Moreover, the success stories and statistical analysis of some agricultural countries have been presented to standardize IoT-based greenhouse farming. Lastly, the open issues and research challenges related to IoT-enabled greenhouse farming has been presented with state-of-the-art future research directions. © 2013 IEEE.","communication protocols; hydroponics; IoT; IoT sensors; mobile apps; network technologies; security issues; smart greenhouse; vertical farm","Climate change; Greenhouses; Internet of things; Internet protocols; Network security; Population statistics; Surveys; Alternate method; Communications protocols; Green products; Hydroponic; Internet of thing sensor; Mobile app; Network technologies; Security issues; Smart greenhouse; Vertical farm; Crops"
"Farouq M.W., Boulila W., Hussain Z., Rashid A., Shah M., Hussain S., Ng N., Ng D., Hanif H., Shaikh M.G., Sheikh A., Hussain A.","A novel coupled reaction-diffusion system for explainable gene expression profiling","10.3390/s21062190","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102683788&doi=10.3390%2fs21062190&partnerID=40&md5=3199d9dedd9207af6b2a883c45ce9aab","Machine learning (ML)-based algorithms are playing an important role in cancer diagnosis and are increasingly being used to aid clinical decision-making. However, these commonly op-erate as ‘black boxes’ and it is unclear how decisions are derived. Recently, techniques have been applied to help us understand how specific ML models work and explain the rational for outputs. This study aims to determine why a given type of cancer has a certain phenotypic characteristic. Cancer results in cellular dysregulation and a thorough consideration of cancer regulators is re-quired. This would increase our understanding of the nature of the disease and help discover more effective diagnostic, prognostic, and treatment methods for a variety of cancer types and stages. Our study proposes a novel explainable analysis of potential biomarkers denoting tumorigenesis in non-small cell lung cancer. A number of these biomarkers are known to appear following various treatment pathways. An enhanced analysis is enabled through a novel mathematical formulation for the regulators of mRNA, the regulators of ncRNA, and the coupled mRNA–ncRNA regulators. Tem-poral gene expression profiles are approximated in a two-dimensional spatial domain for the tran-sition states before converging to the stationary state, using a system comprised of coupled-reaction partial differential equations. Simulation experiments demonstrate that the proposed mathematical gene-expression profile represents a best fit for the population abundance of these oncogenes. In future, our proposed solution can lead to the development of alternative interpretable approaches, through the application of ML models to discover unknown dynamics in gene regulatory systems. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Coupled reaction PDE; Diffusion equation; Explainable machine learning; Gene expression; Non-small cell lung cancer","Biomarkers; Decision making; Diagnosis; Gene expression; Machine learning; Oncogenic viruses; Clinical decision making; Coupled reaction-diffusion systems; Gene expression profiles; Gene expression profiling; Mathematical formulation; Non small cell lung cancer; Regulatory systems; Treatment methods; Diseases; algorithm; diffusion; gene expression profiling; genetics; human; lung tumor; non small cell lung cancer; Algorithms; Carcinoma, Non-Small-Cell Lung; Diffusion; Gene Expression Profiling; Humans; Lung Neoplasms"
"Fatahi R., Nasiri H., Dadfar E., Chehreh Chelgani S.","Modeling of energy consumption factors for an industrial cement vertical roller mill by SHAP-XGBoost: a ""conscious lab"" approach","10.1038/s41598-022-11429-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129516931&doi=10.1038%2fs41598-022-11429-9&partnerID=40&md5=3591ca4b117788dc7cc488582a921aff","Cement production is one of the most energy-intensive manufacturing industries, and the milling circuit of cement plants consumes around 4% of a year's global electrical energy production. It is well understood that modeling and digitalizing industrial-scale processes would help control production circuits better, improve efficiency, enhance personal training systems, and decrease plants' energy consumption. This tactical approach could be integrated using conscious lab (CL) as an innovative concept in the internet age. Surprisingly, no CL has been reported for the milling circuit of a cement plant. A robust CL interconnect datasets originated from monitoring operational variables in the plants and translating them to human basis information using explainable artificial intelligence (EAI) models. By initiating a CL for an industrial cement vertical roller mill (VRM), this study conducted a novel strategy to explore relationships between VRM monitored operational variables and their representative energy consumption factors (output temperature and motor power). Using SHapley Additive exPlanations (SHAP) as one of the most recent EAI models accurately helped fill the lack of information about correlations within VRM variables. SHAP analyses highlighted that working pressure and input gas rate with positive relationships are the key factors influencing energy consumption. eXtreme Gradient Boosting (XGBoost) as a powerful predictive tool could accurately model energy representative factors by R-square ever 0.80 in the testing phase. Comparison assessments indicated that SHAP-XGBoost could provide higher accuracy for VRM-CL structure than conventional modeling tools (Pearson correlation, Random Forest, and Support vector regression. © 2022, The Author(s).",,"artificial intelligence; human; machine learning; physical phenomena; physiological process; Artificial Intelligence; Humans; Machine Learning; Physical Phenomena; Physiological Phenomena"
"Fatima J., Mohsan M., Jameel A., Akram M.U., Muzaffar Syed A.","Vertebrae localization and spine segmentation on radiographic images for feature-based curvature classification for scoliosis","10.1002/cpe.7300","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136901081&doi=10.1002%2fcpe.7300&partnerID=40&md5=8e9544581bd08e0ea1e8acddb147dd19","Spinal cord is the one of the most important organs in the central nervous system (CNS). It acts as the main processing hub which serves as the main passage line for information transfer from brain to the rest of the body. It supports the whole skeleton structure along with mobility, bending, turning, twisting and so forth. Several factors may result in the deformity of spine such as a major injury, fracture or a defect by birth. In this research, we have discussed two modules: one is for vertebrae localization and spine segmentation and the second one is for analysis of spine dis-proportionality. A recent approach of YOLOv5 is used for the localization of vertebrae in combination with Mask RCNN for segmentation of spinal column. The combined results from both these modules are used for feature extraction which supports our classification-based shape analysis module. The AASCE 2019 challenge dataset is used to evaluate the experimental results and the value of mAP achieved is 0.94 at 0.5 IOU threshold of YOLOv5 model. The proposed technique with novel feature set achieved an average classification accuracy of 94.69%. © 2022 John Wiley & Sons, Ltd.","convolutional neural networks; mask RCNN; spinal cord; vertebrae segmentation; YOLO","Classification (of information); Image classification; Image segmentation; Musculoskeletal system; Central nervous systems; Convolutional neural network; Feature-based; Information transfers; Localisation; Mask RCNN; Radiographic images; Spinal-cord; Vertebrae segmentation; YOLO; Convolutional neural networks"
"Faust O., De Michele S., Koh J.E.W., Jahmunah V., Lih O.S., Kamath A.P., Barua P.D., Ciaccio E.J., Lewis S.K., Green P.H., Bhagat G., Acharya U.R.","Automated analysis of small intestinal lamina propria to distinguish normal, Celiac Disease, and Non-Celiac Duodenitis biopsy images","10.1016/j.cmpb.2022.107320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145781814&doi=10.1016%2fj.cmpb.2022.107320&partnerID=40&md5=c9556c52e6d0365091a07f97da41b56b","Background and objective: Celiac Disease (CD) is characterized by gluten intolerance in genetically predisposed individuals. High disease prevalence, absence of a cure, and low diagnosis rates make this disease a public health problem. The diagnosis of CD predominantly relies on recognizing characteristic mucosal alterations of the small intestine, such as villous atrophy, crypt hyperplasia, and intraepithelial lymphocytosis. However, these changes are not entirely specific to CD and overlap with Non-Celiac Duodenitis (NCD) due to various etiologies. We investigated whether Artificial Intelligence (AI) models could assist in distinguishing normal, CD, and NCD (and unaffected individuals) based on the characteristics of small intestinal lamina propria (LP). Methods: Our method was developed using a dataset comprising high magnification biopsy images of the duodenal LP compartment of CD patients with different clinical stages of CD, those with NCD, and individuals lacking an intestinal inflammatory disorder (controls). A pre-processing step was used to standardize and enhance the acquired images. Results: For the normal controls versus CD use case, a Support Vector Machine (SVM) achieved an Accuracy (ACC) of 98.53%. For a second use case, we investigated the ability of the classification algorithm to differentiate between normal controls and NCD. In this use case, the SVM algorithm with linear kernel outperformed all the tested classifiers by achieving 98.55% ACC. Conclusions: To the best of our knowledge, this is the first study that documents automated differentiation between normal, NCD, and CD biopsy images. These findings are a stepping stone toward automated biopsy image analysis that can significantly benefit patients and healthcare providers. © 2022","Biopsy; Celiac Disease; Computer-aided diagnosis; Explainable artificial intelligence; Inflammation; Lamina propria","Automation; Computer aided analysis; Computer aided diagnosis; Image analysis; Image enhancement; Support vector machines; Automated analysis; Biopsy images; Celiac disease; Explainable artificial intelligence; Individual-based; Inflammation; Intelligence models; Lamina propria; Normal controls; Small intestine; Biopsy; Article; artificial intelligence; autoanalysis; celiac disease; classification algorithm; classifier; clinical article; controlled study; diagnostic accuracy; diagnostic test accuracy study; duodenitis; duodenum biopsy; human; human tissue; image processing; lamina propria; small intestine; support vector machine"
"Faust O., Hong W., Loh H.W., Xu S., Tan R.-S., Chakraborty S., Barua P.D., Molinari F., Acharya U.R.","Heart rate variability for medical decision support systems: A review","10.1016/j.compbiomed.2022.105407","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127060718&doi=10.1016%2fj.compbiomed.2022.105407&partnerID=40&md5=64a0690f3495a03abbe4e930d34a379d","Heart Rate Variability (HRV) is a good predictor of human health because the heart rhythm is modulated by a wide range of physiological processes. This statement embodies both challenges to and opportunities for HRV analysis. Opportunities arise from the wide-ranging applicability of HRV analysis for disease detection. The availability of modern high-quality sensors and the low data rate of heart rate signals make HRV easy to measure, communicate, store, and process. However, there are also significant obstacles that prevent a wider use of this technology. HRV signals are both nonstationary and nonlinear and, to the human eye, they appear noise-like. This makes them difficult to analyze and indeed the analysis findings are difficult to explain. Moreover, it is difficult to discriminate between the influences of different complex physiological processes on the HRV. These difficulties are compounded by the effects of aging and the presence of comorbidities. In this review, we have looked at scientific studies that have addressed these challenges with advanced signal processing and Artificial Intelligence (AI) methods. © 2022 Elsevier Ltd","Artificial intelligence; Computer-aided diagnosis; Heart rate variability; Patient remote monitoring","Computer aided diagnosis; Decision support systems; Heart; Medical computing; Signal processing; Disease detection; Heart rate signal; Heart rate variability; Heart rate variability analysis; Heart rate variability signals; High quality; Human health; Low data rates; Medical decision support system; Physiological process; Artificial intelligence; addiction; artificial intelligence; autonomic nervous system; blood pressure; blood pressure measurement; brain; cardiology; comorbidity; decision support system; deep learning; diabetes mellitus; electrocardiography; epilepsy; heart depolarization; heart rate variability; human; infant; lifestyle; medical decision making; patient monitoring; photoelectric plethysmography; remote sensing; respiratory tract disease; Review; signal processing; artificial intelligence; electrocardiography; heart rate; physiology; procedures; Artificial Intelligence; Electrocardiography; Heart Rate; Humans; Signal Processing, Computer-Assisted"
"Feldkamp N., Bergmann S., Conrad F., Strassburger S.","A Method Using Generative Adversarial Networks for Robustness Optimization","10.1145/3503511","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127409520&doi=10.1145%2f3503511&partnerID=40&md5=45556c8c9e7f6d4b8c47f0365af4e021","The evaluation of robustness is an important goal within simulation-based analysis, especially in production and logistics systems. Robustness refers to setting controllable factors of a system in such a way that variance in the uncontrollable factors (noise) has minimal effect on a given output. In this paper, we present an approach for optimizing robustness based on deep generative models, a special method of deep learning. We propose a method consisting of two Generative Adversarial Networks (GANs) to generate optimized experiment plans for the decision factors and the noise factors in a competitive, turn-based game. In a case study, the proposed method is tested and compared to traditional methods for robustness analysis including Taguchi method and Response Surface Method. © 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Deep learning; Generative Adversarial Networks; Machine learning; Robustness optimization","Deep learning; Taguchi methods; Case-studies; Decision factors; Deep learning; Generative model; Minimal effects; Noise factor; Production and logistic systems; Robustness optimizations; Simulation-based analysis; Uncontrollable factors; Generative adversarial networks"
"Feldkamp N., Genath J., Strassburger S.","Explainable AI For Data Farming Output Analysis: A Use Case for Knowledge Generation Through Black-Box Classifiers","10.1109/WSC57314.2022.10015304","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147451206&doi=10.1109%2fWSC57314.2022.10015304&partnerID=40&md5=112b9e1a46ae9b420291d3a06c94f906","Data farming combines large-scale simulation experiments with high performance computing and sophisticated big data analysis methods. The portfolio of analysis methods for those large amounts of simulation data still yields potential to further development, and new methods emerge frequently. Among the most interesting are methods of explainable artificial intelligence (XAI). Those methods enable the use of black-box-classifiers for data farming output analysis, which has been shown in a previous paper. In this paper, we apply the concept for XAI-based data farming analysis on a complex, real world case study to investigate the suitability of such concept in a real world application, and we also elaborate on which black-box classifiers are actually the most suitable for large-scale simulation data that accumulates in a data farming project. © 2022 IEEE.",,"Artificial intelligence; Big data; Analysis method; Black boxes; Data analysis-methods; Data farming; Knowledge generations; Large scale simulations; Output analysis; Performance computing; Real-world; Simulation data; Classification (of information)"
"Feldkamp N.","Data Farming Output Analysis Using Explainable AI","10.1109/WSC52266.2021.9715470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126105252&doi=10.1109%2fWSC52266.2021.9715470&partnerID=40&md5=7c8899e49abd0fba080624c6372471e4","Data Farming combines large-scale simulation experiments with high performance computing and sophisticated big data analysis methods. The portfolio of analysis methods for those large amounts of simulation data still yields potential to further development, and new methods emerge frequently. Especially the application of machine learning and artificial intelligence is difficult, since a lot of those methods are very good at approximating data for prediction, but less at actually revealing their underlying model of rules. To overcome the lack of comprehensibility of such black-box algorithms, a discipline called explainable artificial intelligence (XAI) has gained a lot of traction and has become very popular recently. This paper shows how to extend the portfolio of Data Farming output analysis methods using XAI. © 2021 IEEE.",,"Analysis method; Data analysis-methods; Data farming; Further development; Large amounts; Large scale simulations; Output analysis; Performance computing; Simulation data; Yield potential; Artificial intelligence"
"Feldkamp N., Bergmann S., Strassburger S.","Knowledge Discovery in Simulation Data","10.1145/3391299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097351436&doi=10.1145%2f3391299&partnerID=40&md5=348f817f023371c045db646494640317","This article provides a comprehensive and in-depth overview of our work on knowledge discovery in simulations. Application-wise, we focus on manufacturing simulations. Specifically, we propose and discuss a methodology for designing, executing, and analyzing large-scale simulation experiments with a broad coverage of possible system behavior targeted at generating knowledge about the system. Based on the concept of data farming, we suggest a two-phase process which starts with a data generation phase, in which a smart experiment design is used to set up and efficiently execute a large number of simulation experiments. In the second phase, the knowledge discovery phase, data mining and visually aided analysis methods are applied on the gathered simulation input and output data. This article gives insights into this knowledge discovery phase by discussing different machine learning approaches and their suitability for different manufacturing simulation problems. With this, we provide guidelines on how to conduct knowledge discovery studies within the manufacturing simulation context. We also introduce different case studies, both academic and applied, and use them to validate our methodology. © 2020 ACM.","data farming; data mining; knowledge discovery; Simulation; visual analytics","Data visualization; Manufacture; Data generation; Experiment design; Input and outputs; Large scale simulations; Machine learning approaches; Manufacturing simulation; System behaviors; Two-phase process; Data mining"
"Felix-Cuencas L., Jarro A., Delis-Hechavarria E., Parola-Contreras I., Torres-Pacheco I., Guevara-González R.G., Escamilla-García A., García-Trejo J.F., Soto-Zarazúa G.M.","Bioactivity characterization of herbal molecules","10.1016/B978-0-323-85852-6.00007-X","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132550285&doi=10.1016%2fB978-0-323-85852-6.00007-X&partnerID=40&md5=6cb94ca139db42697d1c1a5d6cc5865f","This chapter was written as an effort to show the readers an overview of possibilities for bioactivities for medical applications using herbal molecules. The different sections of this chapter display aspects related with characterization and specific applications of these type of molecules in diseases related to dental care, respiratory, and gastrointestinal diseases as well as bioactivities of herbal molecules as analgesic, antimicrobial, and antiinflammatory activities. Moreover, in the final section new strategies are shown using big-data approaches in order to discover new herbal molecules for healthcare. In this latter aspect, machine and deep learning (DL) strategies are mentioned and described in order to help in future identification and characterization of herbal molecules for therapeutic applications in healthcare. © 2022 Elsevier Inc. All rights reserved.","analgesic; antiinflammatory; antimicrobial; Dental care; healthcare; herbal molecules; machine learning",
"Felsche E., Ludwig R.","Applying machine learning for drought prediction in a perfect model framework using data from a large ensemble of climate simulations","10.5194/nhess-21-3679-2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119213825&doi=10.5194%2fnhess-21-3679-2021&partnerID=40&md5=dcff066a6f12efc0e602af8a422e9c4a","There is a strong scientific and social interest in understanding the factors leading to extreme events in order to improve the management of risks associated with hazards like droughts. In this study, artificial neural networks are applied to predict the occurrence of a drought in two contrasting European domains, Munich and Lisbon, with a lead time of 1 month. The approach takes into account a list of 28 atmospheric and soil variables as input parameters from a single-model initial-condition large ensemble (CRCM5-LE). The data were produced in the context of the ClimEx project by Ouranos, with the Canadian Regional Climate Model (CRCM5) driven by 50 members of the Canadian Earth System Model (CanESM2). Drought occurrence is defined using the standardized precipitation index. The best-performing machine learning algorithms manage to obtain a correct classification of drought or no drought for a lead time of 1 month for around 55%-57% of the events of each class for both domains. Explainable AI methods like SHapley Additive exPlanations (SHAP) are applied to understand the trained algorithms better. Variables like the North Atlantic Oscillation index and air pressure 1 month before the event prove essential for the prediction. The study shows that seasonality strongly influences the performance of drought prediction, especially for the Lisbon domain. © 2021 Elizaveta Felsche.",,"computer simulation; drought; ensemble forecasting; machine learning; North Atlantic Oscillation; numerical model; weather forecasting; Bavaria; Germany; Lisboa [Portugal]; Lisbon; Munich; Portugal"
"Feng X., Zhao C., Wang C., Wu H., Miao Y., Zhang J.","A Vegetable Leaf Disease Identification Model Based on Image-Text Cross-Modal Feature Fusion","10.3389/fpls.2022.918940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134052492&doi=10.3389%2ffpls.2022.918940&partnerID=40&md5=c75042c63a30349a5a028ba084fa85e7","In view of the differences in appearance and the complex backgrounds of crop diseases, automatic identification of field diseases is an extremely challenging topic in smart agriculture. To address this challenge, a popular approach is to design a Deep Convolutional Neural Network (DCNN) model that extracts visual disease features in the images and then identifies the diseases based on the extracted features. This approach performs well under simple background conditions, but has low accuracy and poor robustness under complex backgrounds. In this paper, an end-to-end disease identification model composed of a disease-spot region detector and a disease classifier (YOLOv5s + BiCMT) was proposed. Specifically, the YOLOv5s network was used to detect the disease-spot regions so as to provide a regional attention mechanism to facilitate the disease identification task of the classifier. For the classifier, a Bidirectional Cross-Modal Transformer (BiCMT) model combining the image and text modal information was constructed, which utilizes the correlation and complementarity between the features of the two modalities to achieve the fusion and recognition of disease features. Meanwhile, the problem of inconsistent lengths among different modal data sequences was solved. Eventually, the YOLOv5s + BiCMT model achieved the optimal results on a small dataset. Its Accuracy, Precision, Sensitivity, and Specificity reached 99.23, 97.37, 97.54, and 99.54%, respectively. This paper proves that the bidirectional cross-modal feature fusion by combining disease images and texts is an effective method to identify vegetable diseases in field environments. Copyright © 2022 Feng, Zhao, Wang, Wu, Miao and Zhang.","complex background; cross-modal fusion; disease identification; few-shot; transformer",
"Ferguson A.L., Ranganathan R.","100th Anniversary of Macromolecular Science Viewpoint: Data-Driven Protein Design","10.1021/acsmacrolett.0c00885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101723155&doi=10.1021%2facsmacrolett.0c00885&partnerID=40&md5=f7c5eda00d95bc8d40996b80a14d13fe","The design of synthetic proteins with the desired function is a long-standing goal in biomolecular science, with broad applications in biochemical engineering, agriculture, medicine, and public health. Rational de novo design and experimental directed evolution have achieved remarkable successes but are challenged by the requirement to find functional ""needles""in the vast ""haystack""of protein sequence space. Data-driven models for fitness landscapes provide a predictive map between protein sequence and function and can prospectively identify functional candidates for experimental testing to greatly improve the efficiency of this search. This Viewpoint reviews the applications of machine learning and, in particular, deep learning as part of data-driven protein engineering platforms. We highlight recent successes, review promising computational methodologies, and provide an outlook on future challenges and opportunities. The article is written for a broad audience comprising both polymer and protein scientists and computer and data scientists interested in an up-to-date review of recent innovations and opportunities in this rapidly evolving field. © 2021 American Chemical Society. All rights reserved.",,"Agricultural robots; Biochemical engineering; Deep learning; Biomolecular science; Computational methodology; Data-driven model; Directed evolution; Experimental testing; Future challenges; Protein engineering; Synthetic protein; Proteins; protein; amino acid sequence; chemistry; history; machine learning; macromolecule; protein engineering; Amino Acid Sequence; Anniversaries and Special Events; Machine Learning; Macromolecular Substances; Protein Engineering; Proteins"
"Fernández A.P., Leenders C., Aerts J.-M., Berckmans D.","Emotional States versus Mental Heart Rate Component Monitored via Wearables","10.3390/app13020807","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146636306&doi=10.3390%2fapp13020807&partnerID=40&md5=3b5af98ba1e3f93edb974b56a8ccffb3","Featured Application: This technology is an effort towards real-life and real-time emotion monitoring, using mental heart rate component as a derived physiological signal. In this way, an ecological momentary intervention system is developed that allows mental health experts to advise users based upon objective data. This application can allow early detection and prevention of mental disease. Psychiatric illnesses are estimated to account for over 15% of the burden of disease, which is more than all kinds of cancer together. Since mental disease is often preceded by issues in emotion processing, a method to objectively measure emotions in daily life would be needed. The goal of this research is to investigate the possibilities of mental heart rate component, assessed with a real-time individualized algorithm that decomposes total heart rate in a physical, basal, and mental component, to classify discrete emotions. For this aim, twenty participants committed to wearing a wristband 24/7 for three months and to label the occurrence of fourteen emotions on their smartphones. In total, 1255 labels were added. The dynamics of the mental heart rate component responses to emotions were identified via data-based mechanistic transfer function models. For the classification, the numerator and denominator model orders and parameters, the four features that define transfer function models, were used as features in a support vector machine classifier. This resulted in an average classification accuracy of the mental heart rate responses of 51.1% over all participants, compared to a random classifier with an average accuracy of 28.5%. We concluded that the dynamics of emotions are not only highly variable between individuals, but that they are also time varying on an individual basis. To increase accuracy, more and higher quality labels are indispensable. © 2023 by the authors.","dynamic model; emotion recognition; mental health; mental heart rate; mobile health",
"Ferreyra E., Hagras H., Kern M., Owusu G.","Depicting Decision-Making: A Type-2 Fuzzy Logic Based Explainable Artificial Intelligence System for Goal-Driven Simulation in the Workforce Allocation Domain","10.1109/FUZZ-IEEE.2019.8858933","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073795793&doi=10.1109%2fFUZZ-IEEE.2019.8858933&partnerID=40&md5=89174c46ecadcc1fbf557520cc94e495","The recent years have witnessed a growing anticipation for the positive transformation of industries which adopt Artificial Intelligence (AI) for the core areas of their business activities. However, the effectiveness and reliability of such AI systems must comprise the ability to explain their data acquisition, the underlying algorithms operations and the final decisions to stakeholders, including regulators, risk managers, supervisors and end-users among others. There are plenty of areas where Explainable AI (XAI) holds the promise to be a major disruptor. Particularly, in Telecommunication Service Providers (TSPs) which is a core business activity relating to the workforce allocation domain, which, involves costly and time-consuming scheduling processes. This paper focuses on the construction of an XAI framework to assist workforce allocation based on a big bang- big crunch interval type-2 fuzzy logic system (BB-BC IT2FLS) for modelling and scaling goal-driven simulation (GDS) problems, specifically within the telecommunications industry. The obtained results reported the proposed XAI system produces similar results to opaque box models like Neural Networks (NNs) and LSTM Recurrent NNs while being able to explain the decision and operation of the employed system. © 2019 IEEE.","big bang-big crunch; Explainable AI; goal-driven simulation; interval type-2 fuzzy logic systems","Behavioral research; Computer circuits; Data acquisition; Decision making; Fuzzy systems; Long short-term memory; Personnel; Telecommunication industry; Artificial intelligence systems; Big Crunch; Business activities; Goal driven; Interval type-2 fuzzy logic systems; Neural networks (NNS); Telecommunication service provider; Telecommunications industry; Fuzzy logic"
"Filippi P., Whelan B.M., Vervoort R.W., Bishop T.F.A.","Identifying crop yield gaps with site- and season-specific data-driven models of yield potential","10.1007/s11119-021-09850-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114820884&doi=10.1007%2fs11119-021-09850-7&partnerID=40&md5=614480b86fbcb051e6ffa8030ba20c11","There is considerable interest and value in identifying the gap between crop yields that have actually been achieved, and yields that could have potentially been achieved. A suite of methods currently exist to estimate the yield potential of a crop, but there are no approaches that predict the site- and season-specific yield potential using datasets that are readily available and easily accessible for farmers. The aim of this study was to fill this need and develop a novel approach to identify crop yield gaps through site- and season-specific models of crop yield potential. The study focused on cotton lint yield, with data from 14 different seasons and 68 different fields from a collection of large, irrigated cotton farms in eastern Australia. This abundance of yield data was then joined with other spatial and temporal datasets that describe yield, such as rainfall, temperature, soil, and management. A quantile random forest machine learning model was then used to model yield at 30 m resolution, where the 95th percentile predictions were treated as the yield potential. The yield gaps at a 30 m resolution were then estimated for all seasons and sites. The results were compared to a more traditional ‘historical maximum yield’ approach, where no data modelling and only empirical yield data was used to estimate the yield potential. This revealed that there was a general agreement between the two approaches, although the quantile machine learning approach is both site- and season-specific, not just site-specific. Overall, there is a great need for alternative approaches to estimate yield potential and yield gaps, as the approaches currently available possess many limitations. The approach developed in this study has the potential for wide-spread adoption in broadacre cropping systems, and if the causes of yield gaps are identified, could lead to the implementation of management strategies to close them. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Cotton; Data-driven models; Irrigation; Precision agriculture; Yield stability; Yield variability",
"Finnestad S., Neufeld E.","The Accidental Philosopher and One of the Hardest Problems in the World","10.3390/philosophies7040076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133687858&doi=10.3390%2fphilosophies7040076&partnerID=40&md5=575e6300de19581d366a14bc85c5f8ff","Given the difficulties of defining “machine” and “think”, Turing proposed to replace the question “Can machines think?” with a proxy: how well can an agent engage in sustained conversation with a human? Though Turing neither described himself as a philosopher nor published much on philosophical matters, his Imitation Game has stood the test of time. Most understood at that time that success would not come easy, but few would have guessed just how difficult engaging in ordinary conversation would turn out to be. Despite the proliferation of language processing tools, we have seen little progress towards doing well at the Imitation Game. Had Turing instead suggested ability at games or even translation as a proxy for intelligence, his paper might have been forgotten. We argue that these and related problems are amenable to mechanical, though sophisticated, formal techniques. Turing appears to have taken care to select sustained, productive conversation and that alone as his proxy. Even simple conversation challenges a machine to engage in the rich practice of human discourse in all its generality and variety. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","artificial intelligence; computational linguistics; Imitation Game; Turing Test",
"Fiorillo D., Kapelan Z., Xenochristou M., De Paola F., Giugni M.","Assessing the Impact of Climate Change on Future Water Demand using Weather Data","10.1007/s11269-021-02789-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103661022&doi=10.1007%2fs11269-021-02789-4&partnerID=40&md5=b1442d3b9f0b6e4035b268a34edbd529","Assessing the impact of climate change on water demand is a challenging task. This paper proposes a novel methodology that quantifies this impact by establishing a link between water demand and weather based on climate change scenarios, via Coupled General Circulation Models. These models simulate the response of the global climate system to increasing greenhouse gas concentrations by reproducing atmospheric and ocean processes. In order to establish the link between water demand and weather, Random Forest models based on weather variables were used. This methodology was applied to a district metered area in Naples (Italy). Results demonstrate that the total district water demand may increase by 9–10% during the weeks with the highest temperatures. Furthermore, results show that the increase in water demand changes depending on the social characteristics of the users. The water demand of employed users with high education may increase by 13–15% when the highest temperatures occur. These increases can seriously affect the capacity and operation of existing water systems. © 2021, The Author(s).","Climate change; Smart meters; Water demand; Water distribution network","Climate models; Decision trees; Greenhouse gases; Climate change scenarios; Coupled general circulation models; Gas concentration; Global climate system; High educations; Highest temperature; Novel methodology; Ocean process; Climate change; climate change; climate effect; distribution system; future prospect; general circulation model; hydrological response; temperature effect; water demand; water management; water planning; weather forecasting; Campania [Italy]; Italy; Naples; Napoli [Campania]"
"Fitzsimmons L., Dewan M., Dexheimer J.W.","Diversity in Machine Learning: A Systematic Review of Text-Based Diagnostic Applications","10.1055/s-0042-1749119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130867264&doi=10.1055%2fs-0042-1749119&partnerID=40&md5=ab8b990f618ad11af9532b320b6f4b70","Objective As the storage of clinical data has transitioned into electronic formats, medical informatics has become increasingly relevant in providing diagnostic aid. The purpose of this review is to evaluate machine learning models that use text data for diagnosis and to assess the diversity of the included study populations. Methods We conducted a systematic literature review on three public databases. Two authors reviewed every abstract for inclusion. Articles were included if they used or developed machine learning algorithms to aid in diagnosis. Articles focusing on imaging informatics were excluded. Results From 2,260 identified papers, we included 78. Of the machine learning models used, neural networks were relied upon most frequently (44.9%). Studies had a median population of 661.5 patients, and diseases and disorders of 10 different body systems were studied. Of the 35.9% (N = 28) of papers that included race data, 57.1% (N = 16) of study populations were majority White, 14.3% were majority Asian, and 7.1% were majority Black. In 75% (N = 21) of papers, White was the largest racial group represented. Of the papers included, 43.6% (N = 34) included the sex ratio of the patient population. Discussion With the power to build robust algorithms supported by massive quantities of clinical data, machine learning is shaping the future of diagnostics. Limitations of the underlying data create potential biases, especially if patient demographics are unknown or not included in the training. Conclusion As the movement toward clinical reliance on machine learning accelerates, both recording demographic information and using diverse training sets should be emphasized. Extrapolating algorithms to demographics beyond the original study population leaves large gaps for potential biases. © 2022 Georg Thieme Verlag. All rights reserved.","clinical decision-making; computer assisted; diagnosis; electronic health records; gender data; machine learning","algorithm; human; machine learning; Algorithms; Humans; Machine Learning"
"Flutura S., Seiderer A., Huber T., Weitz K., Aslan I., Schlagowski R., André E., Rathmann J.","Interactive Machine Learning and Explainability in Mobile Classification of Forest-Aesthetics","10.1145/3411170.3411225","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091269391&doi=10.1145%2f3411170.3411225&partnerID=40&md5=e62e4a5da03a18ba227305b1ef50937c","This paper presents an application that classifies forest's aesthetics using interactive machine learning on mobile devices. Transfer learning is used to be able to build upon deep ANNs (MobileNet) using the limited resources available on smart-phones. We trained and evaluated a model using our application based on a data-set that is plausible to be created by a single user. In order to increase the comprehensibility of our model we explore the potential of incorporating explainable Artificial Intelligence (XAI) into our mobile application. To this end we use deep Taylor decomposition to generate saliency maps that highlight areas of the input that were relevant for the decision of the ANN and conducted a user study to evaluate the usefulness of this approach for end-users. © 2020 ACM.","artificial neural networks; explainable AI; interactive machine learning; scenic beauty classification","Forestry; Smartphones; Transfer learning; Data set; End users; Forest aesthetics; Interactive machine learning; Mobile applications; Saliency map; Single users; User study; Learning systems"
"França R.P., Borges Monteiro A.C., Arthur R., Iano Y.","An overview of deep learning in big data, image, and signal processing in the modern digital age","10.1016/B978-0-12-822226-3.00003-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105234252&doi=10.1016%2fB978-0-12-822226-3.00003-9&partnerID=40&md5=feccb6c1d93508816ec2956354d3573f","Nowadays, data is generated all the time on the internet. Faced with this scenario, technologies have emerged to take advantage of this feature, so that in addition to just being able to measure and understand where they come from, it is possible for them to be collected, quantified, decoded, and analyzed, allowing the understanding of behaviors and trends, the definition of strategies, and the process of insight generation. Big data leverages resources that organize and catalog this information, increasing the availability of relevant data for informed decision making. Machine learning is an aspect of artificial intelligence that competently performs automation in the process of building analytical models that allow machines to adapt independently to new scenarios, enabling software to successfully predict and react to the deployment of scenarios based on past results. Deep learning has this nomenclature because it deals with neural networks having multiple (deep) layers that allow learning; therefore it is a subset of machine learning, which considers algorithms inspired by the human brain, the artificial neural networks, which learn from large amounts of data. Deep learning techniques are especially useful for analyzing complex, rich, and multidimensional data such as voice, images, and videos. In short, all deep learning is machine learning, but not all machine learning is deep learning. This chapter examines the technology of deep learning and machine learning in big data by addressing its evolution and fundamental concepts and its integration into new technologies, by approaching its success, and by categorizing and synthesizing the potential of both technologies. © 2021 Elsevier Inc. All rights reserved.","Artificial intelligence; Big data; CNN; Computer vision; Data; Deep learning; Machine learning; Natural language processing; Neural networks",
"Francesconi S., Harfouche A., Maesano M., Balestra G.M.","UAV-Based Thermal, RGB Imaging and Gene Expression Analysis Allowed Detection of Fusarium Head Blight and Gave New Insights Into the Physiological Responses to the Disease in Durum Wheat","10.3389/fpls.2021.628575","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104267861&doi=10.3389%2ffpls.2021.628575&partnerID=40&md5=9d284420e04b97b7593de6cba0a99591","Wheat is one of the world’s most economically important cereal crop, grown on 220 million hectares. Fusarium head blight (FHB) disease is considered a major threat to durum (Triticum turgidum subsp. durum (Desfontaines) Husnache) and bread wheat (T. aestivum L.) cultivars and is mainly managed by the application of fungicides at anthesis. However, fungicides are applied when FHB symptoms are clearly visible and the spikes are almost entirely bleached (% of diseased spikelets > 80%), by when it is too late to control FHB disease. For this reason, farmers often react by performing repeated fungicide treatments that, however, due to the advanced state of the infection, cause a waste of money and pose significant risks to the environment and non-target organisms. In the present study, we used unmanned aerial vehicle (UAV)-based thermal infrared (TIR) and red-green-blue (RGB) imaging for FHB detection in T. turgidum (cv. Marco Aurelio) under natural field conditions. TIR and RGB data coupled with ground-based measurements such as spike’s temperature, photosynthetic efficiency and molecular identification of FHB pathogens, detected FHB at anthesis half-way (Zadoks stage 65, ZS 65), when the percentage (%) of diseased spikelets ranged between 20% and 60%. Moreover, in greenhouse experiments the transcripts of the key genes involved in stomatal closure were mostly up-regulated in F. graminearum-inoculated plants, demonstrating that the physiological mechanism behind the spike’s temperature increase and photosynthetic efficiency decrease could be attributed to the closure of the guard cells in response to F. graminearum. In addition, preliminary analysis revealed that there is differential regulation of genes between drought-stressed and F. graminearum-inoculated plants, suggesting that there might be a possibility to discriminate between water stress and FHB infection. This study shows the potential of UAV-based TIR and RGB imaging for field phenotyping of wheat and other cereal crop species in response to environmental stresses. This is anticipated to have enormous promise for the detection of FHB disease and tremendous implications for optimizing the application of fungicides, since global food crop demand is to be met with minimal environmental impacts. © Copyright © 2021 Francesconi, Harfouche, Maesano and Balestra.","durum wheat; early disease detection; Fusarium head blight; gene expression; high-throughput plant phenotyping; RGB imaging; thermal imaging",
"Freeman D., Gupta S., Hudson Smith D., Maja J.M., Robbins J., Owen J.S., Jr., Peña J.M., de Castro A.I.","Watson on the farm: Using cloud-based artificial intelligence to identify early indicators of water stress","10.3390/rs11222645","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075382375&doi=10.3390%2frs11222645&partnerID=40&md5=fe55ec6faf34a28ad6b30689d14e5173","As demand for freshwater increases while supply remains stagnant, the critical need for sustainable water use in agriculture has led the EPA Strategic Plan to call for new technologies that can optimize water allocation in real-time. This work assesses the use of cloud-based artificial intelligence to detect early indicators of water stress across six container-grown ornamental shrub species. Near-infrared images were previously collected with modified Canon and MAPIR Survey II cameras deployed via a small unmanned aircraft system (sUAS) at an altitude of 30 meters. Cropped images of plants in no, low-, and high-water stress conditions were split into four-fold cross-validation sets and used to train models through IBM Watson's Visual Recognition service. Despite constraints such as small sample size (36 plants, 150 images) and low image resolution (150 pixels by 150 pixels per plant),Watson generated models were able to detect indicators of stress after 48 hours of water deprivation with a significant to marginally significant degree of separation in four out of five species tested (p < 0.10). Two models were also able to detect indicators of water stress after only 24 hours, with models trained on images of as few as eight water-stressed Buddleia plants achieving an average area under the curve (AUC) of 0.9884 across four folds. Ease of pre-processing, minimal amount of training data required, and outsourced computation make cloud-based artificial intelligence services such as IBM Watson Visual Recognition an attractive tool for agriculture analytics. Cloud-based artificial intelligence can be combined with technologies such as sUAS and spectral imaging to help crop producers identify deficient irrigation strategies and intervene before crop value is diminished. When brought to scale, frameworks such as these can drive responsive irrigation systems that monitor crop status in real-time and maximize sustainable water use. © 2019 by the authors.","Artificial intelligence; Container-grown; Deep learning; Machine learning; Neural network; Ornamental; Precision agriculture; sUAS; Visual recognition; Water stress","Containers; Crops; Deep learning; Deep neural networks; Digital storage; Image resolution; Infrared devices; Infrared imaging; Irrigation; Learning systems; Neural networks; Pixels; Precision agriculture; Real time systems; Spectroscopy; Training aircraft; Unmanned aerial vehicles (UAV); Water conservation; Area under the curves; Near- infrared images; Ornamental; Small unmanned aircrafts; sUAS; Sustainable water use; Visual recognition; Water stress; Artificial intelligence"
"Frias-De-Diego A., Posey R., Pecoraro B.M., Carnevale R.F., Beaty A., Crisci E.","A century of swine influenza: Is it really just about the pigs?","10.3390/vetsci7040189","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097304798&doi=10.3390%2fvetsci7040189&partnerID=40&md5=a1fd8b604400d6477378ed072a034f4e","Influenza viruses (IV) are one of the major threats to human and animal health worldwide due to the variety of species they affect. Pigs play an important role in IV ecology as the “mixing vessel,” since they can be infected by swine, avian and human IV, allowing the appearance of new subtypes. Human viruses originated in swine are known as IV of swine origin or swine influenza virus (SwIV) variants. In this study, we identified knowledge tendencies of SwIV and assessed potential bias in the literature caused by these variants. We identified the most mentioned SwIV variants and manually reviewed the literature to determine the number of publications applying the whole influenza nomenclature, a partial nomenclature, only the subtype or mixed terminology, along with the proportion of articles in which the GenBank ID number was available. We observed that the 2009 H1N1 human pandemic created an important bias in SwIV research driven by an increase in human publications on the IV of swine origin. H1N1 is the most studied subtype for swine and humans, followed by H3N2. We found differences between the nomenclatures applied, where partial classifications were slightly more common. Finally, from all the publications, only 25% stated the GenBank ID of the sequence studied. This review represents the most complete exploration of trends in SwIV knowledge to date and will serve as a guidance for future search strategies in SwIV research. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Bibliometrics; GenBank; Global health; Influenza variants; Swine influenza virus","2009 H1N1 influenza; animal experiment; Article; controlled study; global health; human; Influenza A virus (H1N1); Influenza A virus (H3N2); Influenza virus; nonhuman; pandemic; swine disease; swine influenza; swine influenza virus; virus strain"
"Friedrich S., Antes G., Behr S., Binder H., Brannath W., Dumpert F., Ickstadt K., Kestler H.A., Lederer J., Leitgöb H., Pauly M., Steland A., Wilhelm A., Friede T.","Is there a role for statistics in artificial intelligence?","10.1007/s11634-021-00455-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112616391&doi=10.1007%2fs11634-021-00455-6&partnerID=40&md5=845be5fa0a7878e2da489fe163507fce","The research on and application of artificial intelligence (AI) has triggered a comprehensive scientific, economic, social and political discussion. Here we argue that statistics, as an interdisciplinary scientific field, plays a substantial role both for the theoretical and practical understanding of AI and for its future development. Statistics might even be considered a core element of AI. With its specialist knowledge of data evaluation, starting with the precise formulation of the research question and passing through a study design stage on to analysis and interpretation of the results, statistics is a natural partner for other disciplines in teaching, research and practice. This paper aims at highlighting the relevance of statistical methodology in the context of AI development. In particular, we discuss contributions of statistics to the field of artificial intelligence concerning methodological development, planning and design of studies, assessment of data quality and data collection, differentiation of causality and associations and assessment of uncertainty in results. Moreover, the paper also discusses the equally necessary and meaningful extensions of curricula in schools and universities to integrate statistical aspects into AI teaching. © 2021, The Author(s).","Artificial intelligence; Data science; Machine learning; Statistics","Data Science; Machine learning; Core elements; Data evaluation; Design stage; Machine-learning; Research questions; Scientific fields; Statistical methodologies; Study design; Teaching practices; Teaching researches; Statistics"
"Fries M., Ludwig T.","‘Why are the Sales Forecasts so low?’ Socio-Technical Challenges of Using Machine Learning for Forecasting Sales in a Bakery","10.1007/s10606-022-09458-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143905662&doi=10.1007%2fs10606-022-09458-z&partnerID=40&md5=830c6a622c3df8a2654aface891c9f58","Artificial intelligence and the underlying machine learning (ML) methods are increasingly finding their way into our working world. One of these areas is sales planning, where machine learning is used to leverage a variety of different input parameters such as prices, promotions, or the weather, to forecast sales, and therefore directly affects the production of products and goods. To satisfy the goal of environmental sustainability as well as address short shelf life, the food industry represents an interesting application field for the use of ML for optimizing sales planning. Within this paper, we will examine the design, and especially the application, of ML methods in the food industry and show the current challenges that exist in the use of such concepts and technologies from the end-user’s point of view. Our study of a smaller bakery company shows that there are enormous challenges in setting up the appropriate infrastructure and processes for the implementation of ML, that the output quality of ML processes does not always match the perceived result quality, and that trust in the functioning of the algorithms is the most important criterion for using ML processes in practice. © 2022, The Author(s).","Artificial Intelligence; Human-AI Interaction; Human–Computer Interaction; Machine Learning; Sales Forecast","Human computer interaction; Machine learning; Sustainable development; Weather forecasting; Food industries; Human-AI interaction; Input parameter; Learning process; Machine learning methods; Machine-learning; Price promotions; Sales forecasts; Sociotechnical; Technical challenges; Sales"
"Fu R., Chen R., Wang C., Chen X., Gu H., Wang C., Xu B., Liu G., Yin G.","Generating High-Resolution and Long-Term SPEI Dataset over Southwest China through Downscaling EEAD Product by Machine Learning","10.3390/rs14071662","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128061277&doi=10.3390%2frs14071662&partnerID=40&md5=c504663ac340d25e49ba31a08be5b9d4","Drought is an event of shortages in the water supply, whether atmospheric, surface water or ground water. Prolonged droughts have negative impacts on ecosystems, agriculture, society, and the economy. Although existing drought index products are widely utilized in drought monitoring, the coarse spatial resolution greatly limits their applications on regional or local scales. Machine learning driven by remote sensing observations offers an opportunity to monitor regional scale droughts. However, the limited time range of remote sensing observations such as vegetation index (VI) resulted in a substantial gap in generating high resolution drought index products before 2000. This study generated spatiotemporally continuous Standardized Precipitation Evapotranspiration Index (SPEI) data spanning from 1901–2018 in southwestern China by machine learning. It indicated that four Classification and Regression Tree (CART) approaches, decision trees (DT), random forest (RF), gradient boosted regression trees (GBRT) and extra trees (ET), can provide valid local drought information by downscaling the Estación Experimental de Aula Dei (EEAD) data. The in-situ SPEI dataset produced by the Penman–Monteith method was used as a benchmark to evaluate the temporal and spatial performance of the downscaled SPEI. In addition, the necessity of VI in SPEI downscaling was also assessed. The results showed that: (1) the ET-based product has the best performance (R2 = 0.889, MAE = 0.232, RMSE = 0.432); (2) the VI provides no significant improvement for SPEI re-construction; (3) topography exerts an obvious influence on the downscaling process, and (4) the downscaled SPEI shows more consistency with the in-situ SPEI compared with EEAD SPEI. The proposed method can be easily extended to other areas without in-situ data and enhance the ability of long-term drought monitoring. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","downscaling; machine learning; SPEI; vegetation index","Benchmarking; Classification (of information); Decision trees; Forestry; Groundwater; Machine learning; Remote sensing; Surface waters; Topography; Vegetation; Water supply; Down-scaling; Drought monitoring; Extra-trees; High resolution; Machine-learning; Regional scale; Remote-sensing; Southwest China; Standardized precipitation evapotranspiration index; Vegetation index; Drought"
"Fu Z., Liu W., Huang C., Mei T.","A Review of Performance Prediction Based on Machine Learning in Materials Science","10.3390/nano12172957","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137805780&doi=10.3390%2fnano12172957&partnerID=40&md5=117bfaa560a01cc8dd3b48b8f6522e6a","With increasing demand in many areas, materials are constantly evolving. However, they still have numerous practical constraints. The rational design and discovery of new materials can create a huge technological and social impact. However, such rational design and discovery require a holistic, multi-stage design process, including the design of the material composition, material structure, material properties as well as process design and engineering. Such a complex exploration using traditional scientific methods is not only blind but also a huge waste of time and resources. Machine learning (ML), which is used across data to find correlations in material properties and understand the chemical properties of materials, is being considered a new way to explore the materials field. This paper reviews some of the major recent advances and applications of ML in the field of properties prediction of materials and discusses the key challenges and opportunities in this cross-cutting area. © 2022 by the authors.","deep learning; machine learning; materials science; performance prediction",
"Fuentes-Cortés L.F., Flores-Tlacuahuac A., Nigam K.D.P.","Machine Learning Algorithms Used in PSE Environments: A Didactic Approach and Critical Perspective","10.1021/acs.iecr.2c00335","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131835713&doi=10.1021%2facs.iecr.2c00335&partnerID=40&md5=f340665647d2433be4bdeeb9c063788b","This work addresses recent developments for solving problems in process systems engineering based on machine learning algorithms. A general description of most popular supervised and unsupervised learning algorithms is presented, as well as the applications addressed in the current literature. Because of their wide usage and potential applications, support vector machines and neural networks are addressed as special cases. The approach used is fundamentally didactic. Therefore, several of the references included are recommendations for novice readers interested in entering the area of machine learning and data science. The applications were selected considering simplicity, popularity of the application, and accessibility for inexperienced readers, but with knowledge of the process systems engineering area. Finally, a critical perspective for future development and applications is provided. Epistemological issues and modeling limitations are discussed in order to analyze the real significance of data-driven strategies as well as a questioning of academic marketing in recent years. © 2022 American Chemical Society. All rights reserved.",,"Learning algorithms; Marketing; Systems engineering; 'current; Critical perspectives; General description; In-process; Machine learning algorithms; Neural-networks; Process systems engineering; Supervised and unsupervised learning; Support vectors machine; Unsupervised learning algorithms; Support vector machines"
"Galli G., Sabadin F., Yassue R.M., Galves C., Carvalho H.F., Crossa J., Montesinos-López O.A., Fritsche-Neto R.","Automated Machine Learning: A Case Study of Genomic “Image-Based” Prediction in Maize Hybrids","10.3389/fpls.2022.845524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127243004&doi=10.3389%2ffpls.2022.845524&partnerID=40&md5=837c99c28901fe7b37856f609e9bcd7f","Machine learning methods such as multilayer perceptrons (MLP) and Convolutional Neural Networks (CNN) have emerged as promising methods for genomic prediction (GP). In this context, we assess the performance of MLP and CNN on regression and classification tasks in a case study with maize hybrids. The genomic information was provided to the MLP as a relationship matrix and to the CNN as “genomic images.” In the regression task, the machine learning models were compared along with GBLUP. Under the classification task, MLP and CNN were compared. In this case, the traits (plant height and grain yield) were discretized in such a way to create balanced (moderate selection intensity) and unbalanced (extreme selection intensity) datasets for further evaluations. An automatic hyperparameter search for MLP and CNN was performed, and the best models were reported. For both task types, several metrics were calculated under a validation scheme to assess the effect of the prediction method and other variables. Overall, MLP and CNN presented competitive results to GBLUP. Also, we bring new insights on automated machine learning for genomic prediction and its implications to plant breeding. Copyright © 2022 Galli, Sabadin, Yassue, Galves, Carvalho, Crossa, Montesinos-López and Fritsche-Neto.","accuracy; AutoML; convolutional neural networks; multilayer perceptrons; non-image to image",
"Galvis J.A., Corzo C.A., Prada J.M., Machado G.","Modeling between-farm transmission dynamics of porcine epidemic diarrhea virus: Characterizing the dominant transmission routes","10.1016/j.prevetmed.2022.105759","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138520768&doi=10.1016%2fj.prevetmed.2022.105759&partnerID=40&md5=1347c536913c7e90d3c9ac553c176fdd","The role of transportation vehicles, pig movement between farms, proximity to infected premises, and feed deliveries has not been fully considered in the dissemination dynamics of porcine epidemic diarrhea virus (PEDV). This has limited efforts for disease prevention, control and elimination restricting the development of risk-based resource allocation to the most relevant modes of PEDV dissemination. Here, we modeled nine pathways of between-farm transmission represented by a contact network of pig movements between sites, farm-to-farm proximity (local transmission), four distinct contact networks of transportation vehicles (trucks that transport pigs from farm-to-farm and farm-to-markets, as well as trucks transporting feed and staff), the volume of animal by-products in feed diets (e.g., fat and meat-and-bone-meal) to reproduce PEDV transmission dynamics. The model was calibrated in space and time with weekly PEDV outbreaks. We investigated the model performance to identify outbreak locations and the contribution of each route in the dissemination of PEDV. The model estimated that 42.7% of the infections in sow farms were related to vehicles transporting feed, 34.5% of infected nurseries were associated with vehicles transporting pigs between farms, and for both farm types, local transmission or pig movements were the next most relevant transmission routes. On the other hand, finishers were most often (31.4%) infected via local transmission, followed by the vehicles transporting feed and pigs between farms. Feed ingredients did not significantly improve model calibration metrics, sensitivity, and specificity; therefore, it was considered to have a negligible contribution in the dissemination of PEDV. The proposed modeling framework provides an evaluation of PEDV transmission dynamics, ranking the most important routes of PEDV dissemination and granting the swine industry valuable information to focus efforts and resources on the most important transmission routes. © 2022 Elsevier B.V.","Feed formulation; Spatiotemporal model; Stochastic model; Truck","animal experiment; animal food; animal model; Article; biosecurity; farm animal; female; geographic distribution; market; movement (physiology); nonhuman; pig; pig farming; porcine epidemic diarrhea; Porcine epidemic diarrhea virus; resource allocation; sensitivity and specificity; stochastic model; traffic and transport; virus transmission; agricultural land; animal; Coronavirus infection; epidemic; swine disease; veterinary medicine; Animals; Coronavirus Infections; Disease Outbreaks; Farms; Female; Porcine epidemic diarrhea virus; Swine; Swine Diseases"
"Gao R., Torres-Rua A.F., Aboutalebi M., White W.A., Anderson M., Kustas W.P., Agam N., Alsina M.M., Alfieri J., Hipps L., Dokoozlian N., Nieto H., Gao F., McKee L.G., Prueger J.H., Sanchez L., Mcelrone A.J., Bambach-Ortiz N., Coopmans C., Gowing I.","LAI estimation across California vineyards using sUAS multi-seasonal multi-spectral, thermal, and elevation information and machine learning","10.1007/s00271-022-00776-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126233750&doi=10.1007%2fs00271-022-00776-0&partnerID=40&md5=4ac8898dce7db21ce16957a2088433ab","In agriculture, leaf area index (LAI) is an important variable that describes occurring biomass and relates to the distribution of energy fluxes and evapotranspiration components. Current LAI estimation methods at subfield scale are limited not only by the characteristics of the spatial data (pixel size and spectral information) but also by the empiricity of developed models, mostly based on vegetation indices, which do not necessarily scale spatiality (among different varieties or planting characteristics) or temporally (need for different LAI models for different phenological stages). Widely used machine learning (ML) algorithms and high-resolution small unmanned aerial system (sUAS) information provide an opportunity for spatial and temporal LAI estimation addressing the spatial and temporal limitations. In this study, considering both accuracy and efficiency, a point-cloud-based feature-extraction approach (Full Approach) and a raster-based feature-extraction approach (Fast Approach) using sUAS information were developed based on multiple growing seasons (2014–2019) to extract and generate vine-scale information for LAI estimation in commercial vineyards across California. Three known ML algorithms, Random Forest (RF), eXtreme Gradient Boosting (XGB), and Relevance Vector Machine (RVM), were considered, along with hybrid ML schemes based on those three algorithms, coupled with different feature-extraction approaches. Results showed that the hybrid ML technique using RF and RVM and the Fast Approach with 9 input variables, called RVM-RFFast model, performs better than others in a visual and statistical assessments of the generated LAI being also computationally efficient. Furthermore, using the generated LAI products in the quantification of energy balance using the two-source energy balance Priestley-Taylor version (TSEB-PT) model and EC tower data, the results indicated excellent estimation of net radiation (Rn) and latent heat flux (LE), good estimation of surface heat flux (G), and poor estimation of sensible heat flux (H). Additionally, TSEB-PT sensitivity analysis performed by regenerating LAI maps based on the generated LAI map (from − 15% of the original LAI map to + 15% with a 5% gap) showed that LAI uncertainty had a major impact on G, followed by evapotranspiration partitioning (T/ET), H, LE, and Rn. When considering the annual growth cycle of grapevines, the impact of LAI uncertainty on the T/ET in the veraison stage was larger than in the fruit set stage. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.",,"Antennas; Decision trees; Energy balance; Evapotranspiration; Extraction; Machine learning; Reforestation; Sensitivity analysis; Uncertainty analysis; California; Features extraction; Hybrid machine learning; Index maps; Leaf Area Index; Machine learning algorithms; Random forests; Relevance Vector Machine; System information; Unmanned aerial systems; Feature extraction"
"Gao R., Torres-Rua A., Nassar A., Alfieri J., Aboutalebi M., Hipps L., Bambach Ortiz N., McElrone A.J., Coopmans C., Kustas W., White W., McKee L., Del Mar Alsina M., Dokoozlian N., Sanchez L., Prueger J.H., Nieto H., Agam N.","Evapotranspiration partitioning assessment using a machine-learning-based leaf area index and the two-source energy balance model with sUAV information","10.1117/12.2586259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109028926&doi=10.1117%2f12.2586259&partnerID=40&md5=99435bec228ac1fa4d2f91f5f133be2c","Accurate quantification of the partitioning of evapotranspiration (ET) into transpiration and evaporation fluxes is necessary to understanding ecosystem interactions among carbon, water, and energy flux components. ET partitioning can also support the description of atmosphere and land interactions and provide unique insights into vegetation water status. Previous studies have identified leaf area index (LAI) estimation as a key descriptor of biomass conditions needed for the estimation of transpiration and evaporation. LAI estimation in clumped vegetation systems, such as vineyards and orchards, has proven challenging and is strongly related to crop phenological status and canopy management. In this study, a feature extraction model based on previous research was built to generate a total of 202 preliminary variables at a 3.6-by-3.6- meter-grid scale based on submeter-resolution information from a small Unmanned Aerial Vehicle (sUAV) in four commercial vineyards across California. Using these variables, a machine learning model called eXtreme Gradient Boosting (XGBoost) was successfully built for LAI estimation. The XGBoost built-in function requires only six variables relating to vegetation indices and temperature to produce high-accuracy LAI estimation for the vineyard. Using the sixvariable XGBoost-based LAI map, two versions of the Two-Source Energy Balance (TSEB) model, TSEB-PT and TSEB- 2T were used for energy balance and ET partitioning. Comparing these results with the Eddy-Covariance (EC) tower data, showed that TSEB-PT outperforms TSEB-2T on the estimation of sensible heat flux (within 13% relative error) and surface heat flux (within 34% relative error), while TSEB-2T outperforms TSEB-PT on the estimation of net radiation (within 14% relative error) and latent heat flux (within 2% relative error). For the mature vineyard (north block), TSEB-2T performs better than TSEB-PT in partitioning the canopy latent heat flux with 6.8% relative error and soil latent heat flux with 21.7% relative error; however, for the younger vineyard (south block), TSEB-PT performs better than TSEB-2T in partitioning the canopy latent heat flux with 11.7% relative error and soil latent heat flux with 39.3% relative error. © COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only.","EC tower data; ET partitioning; LAI; TSEB models; XGBoost","Adaptive boosting; Antennas; Commercial vehicles; Energy balance; Errors; Evapotranspiration; Forestry; Latent heat; Machine learning; Transpiration; Turing machines; Vegetation; Accurate quantifications; Built-in functions; Machine learning models; Sensible heat flux; Small unmanned aerial vehicles; Surface heat fluxes; Two-source energy balance model; Vegetation systems; Heat flux"
"Garcia R., Aguilar J., Toro M., Jimenez M.","Weight-Identification Model of Cattle Using Machine-Learning Techniques for Anomaly Detection","10.1109/SSCI50451.2021.9659840","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125797977&doi=10.1109%2fSSCI50451.2021.9659840&partnerID=40&md5=c064dabac07efb6c06cb3076a0bfc1f1","Cattle raising is an important economic activity, where livestock entrepreneurs keep track of their production and investment costs, to measure production and business profitability, based on cattle weighing. However, it is complicated for the farmer to detect if the animals they are weighing have gained the right weight. This paper proposes a framework to identify the fattening process, which can be used to detect anomalies in cattle weight-gain over time. This framework used records of animals raised and fattened at 'El Rosario' farm, located at the municipality of Monteriá (Córdoba-Colombia), to identify the fattening process. The performance of four machine-learning techniques to identify the ideal weight from real data was compared. The algorithms used were Decision Tree (DT), Gradient Boosting (GB), regression based on K-Nearest Neighbors (KNN), and Random Forest (RF). In addition, an outlier-detection process was performed to identify anomalous weights. In general, the results showed that the DT model was the one with the best performance with an average Mean Absolute Error (MAE) of 5.4 kg. © 2021 IEEE.","Anomaly detection; Identification system; Machine learning; Precision Livestock Farming","Adaptive boosting; Agriculture; Animals; Decision trees; Economics; Machine learning; Nearest neighbor search; Weighing; Anomaly detection; Cattle-raising; Economic activities; Identification modeling; Investment costs; Keep track of; Machine learning techniques; Performance; Precision livestock farming; Production cost; Anomaly detection"
"García-Magariño I., Muttukrishnan R., Lloret J.","Human-centric AI for trustworthy IoT systems with explainable multilayer perceptrons","10.1109/ACCESS.2019.2937521","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072209784&doi=10.1109%2fACCESS.2019.2937521&partnerID=40&md5=0510fb7ffe8e1147056bba9097d34143","Internet of Things (IoT) widely use analysis of data with artificial intelligence (AI) techniques in order to learn from user actions, support decisions, track relevant aspects of the user, and notify certain events when appropriate. However, most AI techniques are based on mathematical models that are difficult to understand by the general public, so most people use AI-based technology as a black box that they eventually start to trust based on their personal experience. This article proposes to go a step forward in the use of AI in IoT, and proposes a novel approach within the Human-centric AI field for generating explanations about the knowledge learned by a neural network (in particular a multilayer perceptron) from IoT environments. More concretely, this work proposes two techniques based on the analysis of artificial neuron weights, and another technique aimed at explaining each estimation based on the analysis of training cases. This approach has been illustrated in the context of a smart IoT kitchen that detects the user depression based on the food used for each meal, using a simulator for this purpose. The results revealed that most auto-generated explanations made sense in this context (i.e. 97.0%), and the execution times were low (i.e. 1.5 ms or lower) even considering the common configurations varying independently the number of neurons per hidden layer (up to 20), the number of hidden layers (up to 20) and the number of training cases (up to 4,000). © 2019 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",,"Multilayer neural networks; Multilayers; AI techniques; Analysis of data; Artificial neurons; General publics; Hidden layers; Human-centric; Internet of Things (IOT); Personal experience; Internet of things"
"Garnaik S., Samant P.K., Mandal M., Mohanty T.R., Dwibedi S.K., Patra R.K., Mohapatra K.K., Wanjari R.H., Sethi D., Sena D.R., Sapkota T.B., Nayak J., Patra S., Parihar C.M., Nayak H.S.","Untangling the effect of soil quality on rice productivity under a 16-years long-term fertilizer experiment using conditional random forest","10.1016/j.compag.2022.106965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128509211&doi=10.1016%2fj.compag.2022.106965&partnerID=40&md5=06957f5cc1b8500ff5fbb6c76dee18ea","In a 16-years long-term fertilizer experiment, an in-depth study was carried out to evaluate the changes in soil physical, chemical, and biological properties under long-term fertilizer application and establish cause and effect relationship between soil properties and rice productivity using interpretable machine learning. There were 12 treatments involving control (without fertilizer application), 100% N (recommended dose of nitrogen), 100% NP (recommended dose of nitrogen and phosphorus), 100% PK (recommended dose of phosphorus and potassium), 100% NPK (recommended dose of nitrogen, phosphorus, and potassium), 150% NPK (50% higher nitrogen, phosphorus, and potassium than recommended), 100% NPK + Zn (recommended nitrogen, phosphorus, and potassium along with Zinc), 100% NPK + FYM (recommended nitrogen, phosphorus, and potassium along with farmyard manure (FYM)), 100% NPK + FYM + LIME (recommended nitrogen, phosphorus, and potassium along with FYM and lime), 100% NPK + Zn + S (recommended nitrogen, phosphorus, and potassium along with zinc and sulphur), 100% NPK + Zn + B (recommended nitrogen, phosphorus, and potassium along with Zinc and Boron) and 100% NPK + Lime (recommended nitrogen, phosphorus, and potassium along with lime). At first, a conditional random forest model was built, based on which important variables were selected using the permutation-based variable importance approach. Further, the accumulated local effect plot was used to establish a cause and effect relationship between important soil properties and rice yield. Although most of the soil properties varied across the treatments, total potassium, protease, urease, and permanganate oxidisable carbon are the most important soil properties, individually accounting for up to 400 kg ha−1 variation in the rice productivity. The study demonstrated how interpretable machine learning techniques could be used in long-term fertilizer experiments to unravel the most meaningful information, and these techniques can be used in other similar long-term experiments. © 2022 Elsevier B.V.","Accumulated local effect plots; Interpretable machine learning; Rice-rice system; Soil properties; Variable importance","Decision trees; Machine learning; Nitrogen fertilizers; Phosphorus; Productivity; Random forests; Soils; Zinc; Accumulated local effect plot; Farmyard manure; Fertilizer applications; Interpretable machine learning; Local effects; Long-term fertilizer experiments; Nitrogen phosphorus; Rice-rice system; Soil property; Variable importances; Lime; crop production; fertilizer application; machine learning; rice; soil quality"
"Garrett K.A., Bebber D.P., Etherton B.A., Gold K.M., Plex Sulá A.I., Selvaraj M.G.","Climate Change Effects on Pathogen Emergence: Artificial Intelligence to Translate Big Data for Mitigation","10.1146/annurev-phyto-021021-042636","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137134727&doi=10.1146%2fannurev-phyto-021021-042636&partnerID=40&md5=14b0d0fa4826bbd763afd803c87730eb","Plant pathology has developed a wide range of concepts and tools for improving plant disease management, including models for understanding and responding to new risks from climate change. Most of these tools can be improved using new advances in artificial intelligence (AI), such as machine learning to integrate massive data sets in predictive models. There is the potential to develop automated analyses of risk that alert decision-makers, from farm managers to national plant protection organizations, to the likely need for action and provide decision support for targeting responses. We review machine-learning applications in plant pathology and synthesize ideas for the next steps to make the most of these tools in digital agriculture. Global projects, such as the proposed global surveillance system for plant disease, will be strengthened by the integration of the wide range of new data, including data from tools like remote sensors, that are used to evaluate the risk ofplant disease. There is exciting potential for the use of AI to strengthen global capacity building as well, from image analysis for disease diagnostics and associated management recommendations on farmers rsquo phones to future training methodologies for plant pathologists that are customized in real-time for management needs in response to the current risks. International cooperation in integrating data and models will help develop the most effective responses to new challenges from climate change. Copyright © 2022 by Annual Reviews. All rights reserved.","artificial intelligence; climate change; decision support; geographic risk; plant disease; remote sensing","agriculture; artificial intelligence; climate change; machine learning; Agriculture; Artificial Intelligence; Big Data; Climate Change; Machine Learning"
"Garrido M.C., Cadenas J.M., Bueno-Crespo A., Martínez-España R., Giménez J.G., Cecilia J.M.","Evaporation Forecasting through Interpretable Data Analysis Techniques","10.3390/electronics11040536","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124269465&doi=10.3390%2felectronics11040536&partnerID=40&md5=46fae0a68efba34b71381b7baf66417d","Climate change is increasing temperatures and causing periods of water scarcity in arid and semi-arid climates. The agricultural sector is one of the most affected by these changes, having to optimise scarce water resources. An important phenomenon within the water cycle is the evaporation from water reservoirs, which implies a considerable amount of water lost during warmer periods of the year. Indeed, evaporation rate forecasting can help farmers grow crops more sustainably by managing water resources more efficiently in the context of precision agriculture. In this work, we expose an interpretable machine learning approach, based on a multivariate decision tree, to forecast the evaporation rate on a daily basis using data from an Internet of Things (IoT) infrastructure, which is deployed on a real irrigated plot located in Murcia (southeastern Spain). The climate data collected feed the models that provide a forecast of evaporation and a summary of the parameters involved in this process. Finally, the results of the interpretable presented model are validated with the best literature models for evaporation rate prediction, i.e., Artificial Neural Networks, obtaining results very similar to those obtained for them, reaching up to 0.85R2 and 0.6MAE. Therefore, in this work, a double objective is faced: to maintain the performance obtained by the models most frequently used in the problem while maintaining the interpretability of the knowledge captured in it, which allows better understanding the problem and carrying out appropriate actions. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Evaporation forecast; Interpretable machine learning; IoT; Smart agriculture",
"Gazis I.-Z., Greinert J.","Importance of spatial autocorrelation in machine learning modeling of polymetallic nodules, model uncertainty and transferability at local scale","10.3390/min11111172","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117621165&doi=10.3390%2fmin11111172&partnerID=40&md5=38baaa9e7260567ab4137323bebfac8d","Machine learning spatial modeling is used for mapping the distribution of deep-sea polymetallic nodules (PMN). However, the presence and influence of spatial autocorrelation (SAC) have not been extensively studied. SAC can provide information regarding the variable selection before modeling, and it results in erroneous validation performance when ignored. ML models are also problematic when applied in areas far away from the initial training locations, especially if the (new) area to be predicted covers another feature space. Here, we study the spatial distribution of PMN in a geomorphologically heterogeneous area of the Peru Basin, where SAC of PMN exists. The local Moran’s I analysis showed that there are areas with a significantly higher or lower number of PMN, associated with different backscatter values, aspect orientation, and seafloor geomorphological characteristics. A quantile regression forests (QRF) model is used using three cross-validation (CV) techniques (random-, spatial-, and cluster-blocking). We used the recently proposed “Area of Applicability” method to quantify the geographical areas where feature space extrapolation occurs. The results show that QRF predicts well in morphologically similar areas, with spatial block crossvalidation being the least unbiased method. Conversely, random-CV overestimates the prediction performance. Under new conditions, the model transferability is reduced even on local scales, highlighting the need for spatial model-based dissimilarity analysis and transferability assessment in new areas. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Cross-validation; Model transferability; Polymetallic nodules; Spatial autocorrelation",
"Gebrekidan B.H., Heckelei T., Rasch S.","Modeling intensification decisions in the Kilombero Valley floodplain: A Bayesian belief network approach","10.1111/agec.12740","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137770476&doi=10.1111%2fagec.12740&partnerID=40&md5=a9980ed63dffe5a8de7745f66e7e5340","The Kilombero Valley floodplain in Tanzania is a major agricultural area. Government initiatives and projects supported by international funding have long sought to boost productivity. Due to increasing population pressure, smallholder farmers are forced to increase their output. Nevertheless, the level of intensification is still lower than what is considered necessary to increase production and support smallholder livelihoods significantly. This article aims to better understand farmers’ intensification choices and their interdependent determinants. We propose a novel modeling approach for identifying determinants of intensification and their interrelationships by combining a Bayesian belief network (BBN), experimental design, and multivariate regression trees. Our approach complements existing lower-dimensional statistical models by considering uncertainty and providing an easily updatable model structure. The BBN is constructed and calibrated using data from a survey of 304 farm households. Our findings show how the data-driven BBN approach can be used to identify variables that influence farmers’ decision to choose one technique over another. Furthermore, the most important drivers vary widely, depending on the intensification options being considered. © 2022 The Authors. Agricultural Economics published by Wiley Periodicals LLC on behalf of International Association of Agricultural Economists.","agriculture; Bayesian belief network; intensification; Kilombero Valley; land use; regression trees; Tanzania","agricultural intensification; agricultural modeling; Bayesian analysis; decision making; floodplain; government; land use change; livelihood; regression analysis; smallholder; Kilombero Valley; Morogoro [Tanzania]; Tanzania"
"Georganos S., Kalogirou S.","A Forest of Forests: A Spatially Weighted and Computationally Efficient Formulation of Geographical Random Forests","10.3390/ijgi11090471","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138719562&doi=10.3390%2fijgi11090471&partnerID=40&md5=2c3149498c6106d662894346a75ff8ee","The aim of this paper is to present developments of an advanced geospatial analytics algorithm that improves the prediction power of a random forest regression model while addressing the issue of spatial dependence commonly found in geographical data. We applied the methodology to a simple model of mean household income in the European Union regions to allow easy understanding and reproducibility of the analysis. The results are encouraging and suggest an improvement in the prediction power compared to previous techniques. The algorithm has been implemented in R and is available in the updated version of the SpatialML package in the CRAN repository. © 2022 by the authors.","random forest; spatial heterogeneity; spatial machine learning; spatial modelling",
"Gevaert C.M.","Explainable AI for earth observation: A review including societal and regulatory perspectives","10.1016/j.jag.2022.102869","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133305595&doi=10.1016%2fj.jag.2022.102869&partnerID=40&md5=694eb37b8be910cc4fd29a25f7c02b5b","Artificial intelligence and machine learning are ubiquitous in the domain of Earth Observation (EO) and Remote Sensing. Congruent to their success in the domain of computer vision, they have proven to obtain high accuracies for EO applications. Yet experts of EO should also consider the weaknesses of complex, machine-learning models before adopting them for specific applications. One such weakness is the lack of explainability of complex deep learning models. This paper reviews published examples of explainable ML or explainable AI in the field of Earth Observation. Explainability methods are classified as: intrinsic versus post-hoc, model-specific versus model-agnostic, and global versus local explanations and examples of each type are provided. This paper also identifies key explainability requirements identified the social sciences and upcoming regulatory recommendations from UNESCO Ethics of Artificial Intelligence and requirements from the EU draft Artificial Intelligence Act and analyzes whether these limitations are sufficiently addressed in the field of EO. The findings indicate that there is a lack of clarity regarding which models can be considered interpretable or not. EO applications often utilize Random Forests as an “interpretable” benchmark algorithm to compare to complex deep-learning models even though social sciences clearly argue that large Random Forests cannot be considered as such. Secondly, most explanations target domain experts and not possible users of the algorithm, regulatory bodies, or those who might be affected by an algorithm's decisions. Finally, publications tend to simply provide explanations without testing the usefulness of the explanation by the intended audience. In light of these societal and regulatory considerations, a framework is provided to guide the selection of an appropriate machine learning algorithm based on the availability of simpler algorithms with a high predictive accuracy as well as the purpose and intended audience of the explanation. © 2022 The Author(s)","Earth observation; Ethics; Explainable artificial intelligence; Machine learning; Regulations; Remote sensing","algorithm; artificial intelligence; computer simulation; EOS; ethics; geodesy; machine learning; regulatory approach; remote sensing"
"Ghnemat R., Shaout A., Al-Sowi A.M.","Higher Education Transformation for Artificial Intelligence Revolution: Transformation Framework","10.3991/ijet.v17i19.33309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140648124&doi=10.3991%2fijet.v17i19.33309&partnerID=40&md5=87f6b3c5efa617b64b2f4ff733889383","The field of Artificial Intelligence in Education (AIED) will change the shape of education in the future completely, current classroom environment management, collaboration with teachers, and development of AI-based technology platforms. The intelligent adaptive transformation of learning and teaching in higher education required the emergence of all educational process structures. This paper presents a revolutionary educational process called AI-based learning, Which involves technologies within universities, cultures, practices, goals, and communities. This transformation reduces the gap between higher education’s outcome and industry’s needs, by producing lifelong learners. The proposed framework illustrates the full structure, the development steps, and the implementation benefits. The proposed framework also provides connections of scattered scientific research work in different related domains. Using AI competency-based learning will let students achieve the course outcomes easier and faster and increase student engagement by solving real-life industrial problems in different application domains. The paper also presents implementations phases, benefits and provides a comparison after applying the framework. © 2022,International Journal of Emerging Technologies in Learning. All Rights Reserved.","Active lifelong learning; Artificial intelligence; Educational data mining; Personalized learning; Smart education","Artificial intelligence; Metadata; Students; 'current; Active lifelong learning; Artificial intelligence in education; Classroom environment; Educational data mining; Educational process; High educations; Life long learning; Personalized learning; Smart education; Data mining"
"Ghosh P., Azam S., Jonkman M., Karim A., Shamrat F.M.J.M., Ignatious E., Shultana S., Beeravolu A.R., De Boer F.","Efficient prediction of cardiovascular disease using machine learning algorithms with relief and lasso feature selection techniques","10.1109/ACCESS.2021.3053759","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100517914&doi=10.1109%2fACCESS.2021.3053759&partnerID=40&md5=a1375a73257449ef0d9477f37e85c8bb","Cardiovascular diseases (CVD) are among the most common serious illnesses affecting human health. CVDs may be prevented or mitigated by early diagnosis, and this may reduce mortality rates. Identifying risk factors using machine learning models is a promising approach. We would like to propose a model that incorporates different methods to achieve effective prediction of heart disease. For our proposed model to be successful, we have used efficient Data Collection, Data Pre-processing and Data Transformation methods to create accurate information for the training model. We have used a combined dataset (Cleveland, Long Beach VA, Switzerland, Hungarian and Stat log). Suitable features are selected by using the Relief, and Least Absolute Shrinkage and Selection Operator (LASSO) techniques. New hybrid classifiers like Decision Tree Bagging Method (DTBM), Random Forest Bagging Method (RFBM), K-Nearest Neighbors Bagging Method (KNNBM), AdaBoost Boosting Method (ABBM), and Gradient Boosting Boosting Method (GBBM) are developed by integrating the traditional classifiers with bagging and boosting methods, which are used in the training process. We have also instrumented some machine learning algorithms to calculate the Accuracy (ACC), Sensitivity (SEN), Error Rate, Precision (PRE) and F1 Score (F1) of our model, along with the Negative Predictive Value (NPR), False Positive Rate (FPR), and False Negative Rate (FNR). The results are shown separately to provide comparisons. Based on the result analysis, we can conclude that our proposed model produced the highest accuracy while using RFBM and Relief feature selection methods (99.05%). © 2013 IEEE.","AdaBoost; and gradient boosting; CVD; decision tree; Heart disease; K-nearest neighbors; LASSO feature selection; machine learning; random forest; relief feature selection","Adaptive boosting; Cardiology; Data acquisition; Decision trees; Diagnosis; Diseases; Feature extraction; Metadata; Nearest neighbor search; Predictive analytics; Regression analysis; Cardio-vascular disease; Efficient predictions; Feature selection methods; Least absolute shrinkage and selection operators; Machine learning models; Negative predictive value; Prediction of heart disease; Selection techniques; Machine learning"
"Giannitsopoulos M.L., Burgess P.J., Bell M.J., Richter G.M., Topp C.F.E., Ingram J., Takahashi T.","Translating and applying a simulation model to enhance understanding of grassland management","10.1111/gfs.12584","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139002869&doi=10.1111%2fgfs.12584&partnerID=40&md5=c4d8c6bc28cfbf168717823ca02504eb","Each new generation of grassland managers could benefit from an improved understanding of how modification of nitrogen application and harvest dates in response to different weather and soil conditions will affect grass yields and quality. The purpose of this study was to develop a freely available grass yield simulation model, validated for England and Wales, and to examine its strengths and weaknesses as a teaching tool for improving grass management. The model, called LINGRA-N-Plus, was implemented in a Microsoft Excel spreadsheet and iteratively evaluated by students and practitioners (farmers, consultants, and researchers) in a series of workshops across the UK over 2 years. The iterative feedback led to the addition of new algorithms, an improved user interface, and the development of a teaching guide. The students and practitioners identified the ease of use and the capacity to understand, visualize and evaluate how decisions, such as variation of cutting intervals, affect grass yields as strengths of the model. We propose that an effective teaching tool must achieve an appropriate balance between being sufficiently detailed to demonstrate the major relationships (e.g., the effect of nitrogen on grass yields) whilst not becoming so complex that the relationships become incomprehensible. We observed that improving the user-interface allowed us to extend the scope of the model without reducing the level of comprehension. The students appeared to be interested in the explanatory nature of the model whilst the practitioners were more interested in the application of a validated model to enhance their decision making. © 2022 The Authors. Grass and Forage Science published by John Wiley & Sons Ltd.","agronomy; decision support; education; grassland management; LINGRA",
"Gichenje H., Pinto-Correia T., Godinho S.","An analysis of the drivers that affect greening and browning trends in the context of pursuing land degradation-neutrality","10.1016/j.rsase.2019.100251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070732600&doi=10.1016%2fj.rsase.2019.100251&partnerID=40&md5=b9947d98968cef8d338b18d926a1f36f","Understanding the drivers of land degradation and regeneration is crucial for planning appropriate responses within both degraded and non-degraded land. In this paper, using Kenya as the study area, we sought to identify the key drivers that affect greening and browning trends within the 4 main land cover types (agriculture, forest, grassland and shrubland) and within an area characterised by land cover change. The methodological approach used was the random forest classification algorithm, whereby the dependent variable was represented as 4 classes of NDVI greening and browning trends (strong browning, moderate browning, moderate greening, and strong greening). The explanatory variables (n = 28) were broadly grouped into 2 categories, natural and anthropogenic, and included a number of variables as proxies for broad socio-economic development. All models showed strong performance, and the mean values for accuracy and Kappa were 0.96 and 0.95, respectively. Variables that repeatedly featured as the 5 most important variables across the datasets were: travel time to an urban area, distance to towns, distance to roads, distance to rivers, slope and vulnerability to climate change impacts. When the variables were grouped by SDGs, the results obtained showed that the variables grouped under the SDGs 15 (life on land), 8 (economic growth) and 13 (climate action) cumulatively accounted for approximately 80% of the prediction of the greening and browning trends. Our results raise the following considerations to enrich on-going and future policy and planning discussions aimed at addressing LDN: the implementation of LDN should be anchored on tried and tested SLM interventions; further analysis of the drivers of greening and browning trends should be undertaken at the sub-national level; integrated approaches that lead to greater alignment across multiple development priorities, including climate change, should be promoted; and targeted enforcement of environmental legislation is needed to deter processes and activities that are likely to lead to the degradation of land. © 2019 Elsevier B.V.","Drivers; Kenya; Land degradation-neutrality; NDVI; Random forest",
"Giese E., Rohn S., Fritsche J.","Chemometric tools for the authentication of cod liver oil based on nuclear magnetic resonance and infrared spectroscopy data","10.1007/s00216-019-02063-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070287871&doi=10.1007%2fs00216-019-02063-y&partnerID=40&md5=ed1c8f8b8bc02aec2f0b329b522b3f56","Cod liver oil is a popular dietary supplement marketed as a rich source of omega-3 fatty acids as well as vitamins A and D. Due to its high market price, cod liver oil is vulnerable to adulteration with lower priced vegetable oils. In this study, 1H and 13C nuclear magnetic resonance spectroscopy, Fourier transform infrared spectroscopy, and gas chromatography (coupled to a flame ionization detector) were used in combination with multivariate statistics to determine cod liver oil adulteration with common vegetable oils (sunflower and canola oils). Artificial neural networks (ANN) were able to differentiate adulteration levels based on infrared spectra with a detection limit of 0.22% and a root mean square error of prediction (RMSEP) of 0.86%. ANN models using 1H NMR and 13C NMR data yielded detection limits of 3.0% and 1.8% and RMSEPs of 2.7% and 1.1%, respectively. In comparison, the ANN model based on fatty acid profiles determined by gas chromatography achieved a detection limit of 0.81% and an RMSEP of 1.1%. The approach of using spectroscopic techniques in combination with multivariate statistics can be regarded as a promising tool for the authentication of cod liver oil and may pave the way for a holistic quality assessment of fish oils. [Figure not available: see fulltext.] © 2019, The Author(s).","Adulteration; Artificial neural networks; Authenticity; Fish oil; Infrared spectroscopy; Nuclear magnetic resonance spectroscopy","Authentication; Commerce; Dietary supplements; Fatty acids; Fish; Fourier transform infrared spectroscopy; Gas chromatography; Gas oils; Infrared spectroscopy; Ionization of gases; Magnetic resonance spectrometers; Magnetism; Mean square error; Multivariant analysis; Neural networks; Nuclear magnetic resonance; Sunflower oil; Vitamins; Adulteration; Authenticity; Fish oil; Flame ionization detectors; Multivariate statistics; Omega-3-fatty acids; Root-mean-square error of predictions; Spectroscopic technique; Nuclear magnetic resonance spectroscopy; cod liver oil; artificial neural network; dietary supplement; food contamination; infrared spectroscopy; multivariate analysis; nuclear magnetic resonance imaging; procedures; Cod Liver Oil; Dietary Supplements; Food Contamination; Magnetic Resonance Imaging; Multivariate Analysis; Neural Networks (Computer); Spectroscopy, Fourier Transform Infrared"
"Gill M., Anderson R., Hu H., Bennamoun M., Petereit J., Valliyodan B., Nguyen H.T., Batley J., Bayer P.E., Edwards D.","Machine learning models outperform deep learning models, provide interpretation and facilitate feature selection for soybean trait prediction","10.1186/s12870-022-03559-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127930225&doi=10.1186%2fs12870-022-03559-z&partnerID=40&md5=c81393b013953de65b7f9782f2974e01","Recent growth in crop genomic and trait data have opened opportunities for the application of novel approaches to accelerate crop improvement. Machine learning and deep learning are at the forefront of prediction-based data analysis. However, few approaches for genotype to phenotype prediction compare machine learning with deep learning and further interpret the models that support the predictions. This study uses genome wide molecular markers and traits across 1110 soybean individuals to develop accurate prediction models. For 13/14 sets of predictions, XGBoost or random forest outperformed deep learning models in prediction performance. Top ranked SNPs by F-score were identified from XGBoost, and with further investigation found overlap with significantly associated loci identified from GWAS and previous literature. Feature importance rankings were used to reduce marker input by up to 90%, and subsequent models maintained or improved their prediction performance. These findings support interpretable machine learning as an approach for genomic based prediction of traits in soybean and other crops. © 2022, The Author(s).","Feature selection; Genomic selection; Interpretable models; Machine learning; Soybean; XGBoost","genetics; genotype; machine learning; phenotype; soybean; Deep Learning; Genotype; Machine Learning; Phenotype; Soybeans"
"Gokulnath B.V., Usha Devi G.","Boosted-DEPICT: an effective maize disease categorization framework using deep clustering","10.1007/s00521-020-05303-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091009777&doi=10.1007%2fs00521-020-05303-w&partnerID=40&md5=ae2322145ceba089e52f3e1543634d31","Clustering of plant disease from digital images is an arduous task due to its dynamic nature and change of appearance under different environmental conditions. In most cases, the image captured in the real-time scenario is subjected to added noise, distortion, poor lighting conditions, and other potential factors that results in poor model performance during the process of discriminating between normal and disease-affected samples. It eventually maximizes the margin of the error rate, thereby leading to misclassification of disease of different varieties of plants in the database with other categories. This paper presents an effective deep clustering-based plant disease categorization algorithm, Boosted-Deep Embedded Regularized Clustering (DEPICT). This model integrates the convolutional autoencoder model with locality-preserving constraints and group sparsity into the network, which improves the embedded learning representation of the images. The PlantVillage and PDD image databases are accessed to develop this model for maize crop. The images are segmented by eliminating the background, cropped, augmented before model training. The performance of the system is evaluated by clustering accuracy and normalized mutual information. The proposed Boosted-DEPICT exhibits better performance, attains promising results with an accuracy of 97.73% and 91.25% on PV and PDD datasets, and outperforms state-of-the-art deep clustering algorithms. This system could be further enhanced by automating the entire process and transforming it into a mobile application for real-time analysis to gain instant results from any region. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","Autoencoders; Boosted-DEPICT; Deep clustering; Image processing; Plant disease","Image enhancement; Learning systems; Clustering accuracy; Environmental conditions; Lighting conditions; Locality-preserving; Misclassifications; Mobile applications; Normalized mutual information; Real time analysis; Clustering algorithms"
"Golder P.N., Dekimpe M.G., An J.T., van Heerde H.J., Kim D.S.U., Alba J.W.","Learning from Data: An Empirics-First Approach to Relevant Knowledge Generation","10.1177/00222429221129200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139963589&doi=10.1177%2f00222429221129200&partnerID=40&md5=83059900b11b8da840acfcdaa1a6e6af","A theory-first paradigm tends to be the dominant approach in much academic marketing research. In this approach, a theory is borrowed, refined, or developed and then tested empirically. In this challenging-the-boundaries article, the authors make a case for an empirics-first approach. “Empirics-first” refers to research that (1) is grounded in (originates from) a real-world marketing phenomenon, problem, or observation, (2) involves obtaining and analyzing data, and (3) produces valid marketing-relevant insights without necessarily developing or testing theory. The empirics-first approach is not antagonistic to theory but rather can serve as a stepping-stone to theory. The approach lends itself well to today’s data-rich environment, which can reveal novel research questions untethered to theory. The present article describes the underlying principles of an empirics-first approach, which consists of exploring a domain purposefully without preconceptions. Using a rich set of published examples, the authors offer guidance on how to implement empirics-first research and how it can lead to valuable knowledge development. Advice is also offered to scholars on how to report empirics-first research and to reviewers and to editorial teams on how to evaluate it. The ultimate objective is to pave a way for the empirics-first approach to enter the mainstream of academic marketing research. © The Author(s) 2022.","empirical generalizations; empirical research; marketing theory; relevance; research methods",
"Gomes H.M., Mello R.F.D., Pfahringer B., Bifet A.","Feature Scoring using Tree-Based Ensembles for Evolving Data Streams","10.1109/BigData47090.2019.9006366","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081328988&doi=10.1109%2fBigData47090.2019.9006366&partnerID=40&md5=5da8e184ffb93ad3d116f7c2081dd431","Assigning scores to individual features is a popular method for estimating the relevance of features in supervised learning. An accurate feature score estimation provides essential insights in sensitive domains, which is decisive to explain how features influence a given decision, contributing to the interpretability of the model. Learning from streaming data adds several challenges to machine learning tasks, including limited resources and changes to the underlying data distribution (i.e., evolving data streams). In this work, we introduce and analyze methods to efficiently estimate the Mean Decrease in Impurity (MDI) and COVER measures using ensembles of incremental decision trees. To achieve current scores in evolving data streams, we employ tree-ensembles that incorporate active drift detection. Experimental results show how MDI and COVER can be used to track the feature scores when their importance to the ensemble model shift over time. On top of that, we present the impact on the feature scores when the learning problem includes a non-negligible verification latency for the arrival of the labels. We also present a counter-intuitive experiment using a standard benchmark dataset where the feature scores correctly illustrate the importance of two features to the ensemble model. However, these features are prioritized due to biased split decisions, and in their absence, the model increases in predictive performance. We conclude that the presented measures can be used to understand the impact of features in the ensemble model better, still, such measures should be used with caution as they are limited by the underlying tree building and ensemble model biases. © 2019 IEEE.","data streams; feature score; model interpretation; supervised learning","Big data; Decision trees; Learning systems; Supervised learning; Trees (mathematics); Benchmark datasets; Data distribution; feature score; Individual features; Model interpretations; Predictive performance; Tree-based ensembles; Verification latencies; Data streams"
"Gomes M.A.S., Kovaleski J.L., Pagani R.N., da Silva V.L.","Machine learning applied to healthcare: a conceptual review","10.1080/03091902.2022.2080885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131675994&doi=10.1080%2f03091902.2022.2080885&partnerID=40&md5=6f48411286fe49e7e477ed7bad4d545e","The technological inference in procedures applied to healthcare is frequently investigated in order to understand the real contribution to decision-making and clinical improvement. In this context, the theoretical field of machine learning has suitably presented itself. The objective of this research is to identify the main machine learning algorithms used in healthcare through the methodology of a systematic literature review. Considering the time frame of the last twenty years, 173 studies were mined based on established criteria, which allowed the grouping of algorithms into typologies. Supervised Learning, Unsupervised Learning, and Deep Learning were the groups derived from the studies mined, establishing 59 works employed. We expect that this research will stimulate investigations towards machine learning applications in healthcare. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","algorithms; health systems; healthcare; Machine learning","Decision making; Deep learning; Learning algorithms; Conceptual review; Decisions makings; Health systems; Machine learning algorithms; Machine learning applications; Systematic literature review; Time frame; Health care; algorithm; deep learning; human; learning; machine learning; review; systematic review; health care delivery; Algorithms; Delivery of Health Care; Machine Learning"
"Gomes V., Melo-Pinto P.","Towards robust Machine Learning models for grape ripeness assessment","10.1109/JCSSE53117.2021.9493822","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112353301&doi=10.1109%2fJCSSE53117.2021.9493822&partnerID=40&md5=b381cd13bb9b0eb9fcb80c6d2f361942","Artificial intelligence methods need to be more transparent for wider acceptance by the industry. In particular deep neural networks (DNN) are not explainable, due to the complex processes the input undergo. The present work addresses model explainability for wine grapes quality assessment through 1D-CNN, using regression activation maps (RAM) to show the contribution score of each wavelength for the prediction of sugar content. This way we identify the relevant regions related to this enological parameter. The results obtained indicate that the proposed approach can successfully highlight important spectral regions related to sugars absorption, improving the current state of the art, and opening way to dimensionality reduction methods and further model interpretation. © 2021 IEEE.","grape berries; hyperspectral imaging; model explainability; One-dimensional convolutional neural networks; regression activation maps; sugar content","Deep learning; Deep neural networks; Dimensionality reduction; Artificial intelligence methods; Complex Processes; Dimensionality reduction method; Machine learning models; Model interpretations; Quality assessment; Spectral region; State of the art; Software engineering"
"Gómez-Orellana A.M., Guijo-Rubio D., Pérez-Aracil J., Gutiérrez P.A., Salcedo-Sanz S., Hervás-Martínez C.","One month in advance prediction of air temperature from Reanalysis data with eXplainable Artificial Intelligence techniques","10.1016/j.atmosres.2023.106608","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147090922&doi=10.1016%2fj.atmosres.2023.106608&partnerID=40&md5=339c9323f2560f446682655101740e86","In this paper we have tackled the problem of long-term air temperature prediction with eXplainable Artificial Intelligence (XAI) models. Specifically, we have evaluated the performance of an Artificial Neural Network (ANN) architecture with sigmoidal neurons in the hidden layer, trained by means of an evolutionary algorithm (Evolutionary ANNs, EANNs). This XAI model architecture (XAI-EANN) has been applied to the long-term air temperature prediction at different sub-regions of the South of the Iberian Peninsula. In this case, the average August air temperature has been predicted from ERA5 Reanalysis data variables, obtaining good predictions skills and explainable models in terms of the input climatological variables considered. A cluster analysis has been first carried out in terms of the average air temperature in the zone, in such a way that a number of sub-regions with different air temperature behaviour have been defined. The proposed XAI-EANN model architecture has been applied to each of the defined sub-regions, in order to find significant differences among them, which can be explained with the XAI-EANN models obtained. Finally, a comprehensive comparison against some state-of-the-art techniques has also been carried out, concluding that there are statistically significant differences in terms of accuracy in favour of the proposed XAI-EANN model, which also benefits from being an XAI model. © 2023 The Authors","Air temperature; Climatology; Long-term air temperature prediction; Neural networks; XAI","Atmospheric temperature; Cluster analysis; Multilayer neural networks; Network architecture; Air temperature; Evolutionary ANN; Long-term air temperature prediction; Modeling architecture; Neural-networks; Reanalysis; Sub-regions; Temperature prediction; XAI; Forecasting"
"Gonzales-Inca C., Calle M., Croghan D., Torabi Haghighi A., Marttila H., Silander J., Alho P.","Geospatial Artificial Intelligence (GeoAI) in the Integrated Hydrological and Fluvial Systems Modeling: Review of Current Applications and Trends","10.3390/w14142211","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137347610&doi=10.3390%2fw14142211&partnerID=40&md5=b04a5fab09fdc701e6c9243878635d17","This paper reviews the current GeoAI and machine learning applications in hydrological and hydraulic modeling, hydrological optimization problems, water quality modeling, and fluvial geomorphic and morphodynamic mapping. GeoAI effectively harnesses the vast amount of spatial and non-spatial data collected with the new automatic technologies. The fast development of GeoAI provides multiple methods and techniques, although it also makes comparisons between different methods challenging. Overall, selecting a particular GeoAI method depends on the application’s objective, data availability, and user expertise. GeoAI has shown advantages in non-linear modeling, computational efficiency, integration of multiple data sources, high accurate prediction capability, and the unraveling of new hydrological patterns and processes. A major drawback in most GeoAI models is the adequate model setting and low physical interpretability, explainability, and model generalization. The most recent research on hydrological GeoAI has focused on integrating the physical-based models’ principles with the GeoAI methods and on the progress towards autonomous prediction and forecasting systems. © 2022 by the authors.","artificial intelligence; fluvial; GeoAI; geomorphic; hydraulic; hydrological; machine learning; modeling; water quality","Computational efficiency; Forecasting; Machine learning; 'current; Artificial intelligence methods; Fluvials; Geo-spatial; Geomorphic; Geospatial artificial intelligence; Hydrological; Hydrological system; Machine-learning; Modeling; Water quality"
"Gordon S., Jones D.K., Blazer V.S., Iwanowicz L., Williams B., Smalling K.","Modeling estrogenic activity in streams throughout the Potomac and Chesapeake Bay watersheds","10.1007/s10661-021-08899-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100257702&doi=10.1007%2fs10661-021-08899-1&partnerID=40&md5=44dd69a7e58646158b0a66472e6de198","Endocrine-disrupting compounds (EDCs), specifically estrogenic endocrine-disrupting compounds, vary in concentration and composition in surface waters under the influence of different landscape sources and landcover gradients. Estrogenic activity in surface waters may lead to adverse effects in aquatic species at both individual and population levels, often observed through the presence of intersex and vitellogenin induction in male fish. In the Chesapeake Bay Watershed, located on the mid-Atlantic coast of the USA, intersex has been observed in several sub-watersheds where previous studies have identified specific landscape sources of EDCs in tandem with observed fish health effects. Previous work in the Potomac River Watershed (PRW), the largest basin within the Chesapeake Bay Watershed, was leveraged to build random forest regression models to predict estrogenic activity at unsampled reaches in both the Potomac River and larger Chesapeake Bay Watersheds (CBW). Model outputs including important variables, partial dependence plots, and predicted values of estrogenic activity at unsampled reaches provide insight into drivers of estrogenic activity at different seasons and scales. Using the US Environmental Protection Agency effects-based threshold of 1.0 ng/L 17 β-estradiol equivalents, catchments predicted to exceed this value were categorized as at risk for adverse effects from exposure to estrogenic compounds and evaluated relative to healthy watersheds and recreation access locations throughout the PRW. Results show immediate catchment scale models are more reliable than upstream models, and the best predictive variables differ by season and scale. A small percentage of healthy watersheds (< 13%) and public access sites were classified as at risk using the “Total” (annual) model in the CBW. This study is the first Potomac River Watershed assessment of estrogenic activity, providing a new foundation for future risk assessment and management design efforts, with additional context provided for the entire Chesapeake Bay Watershed. © 2021, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.","Chesapeake Bay Watershed; Endocrine-disrupting compounds; Estrogenic activity; Random forest regression; Spatial modeling","Catchments; Decision trees; Endocrinology; Environmental Protection Agency; Fish; Organic pollutants; Regression analysis; Risk assessment; Rivers; Runoff; Watersheds; Chesapeake Bay watershed; Endocrine disrupting compound; Estrogenic activities; Estrogenic compounds; Population levels; Predictive variables; Risk assessment and managements; US Environmental Protection Agency; Endocrine disrupters; endocrine disruptor; surface water; vitellogenin; endocrine disruptor; estrogen; endocrine disruptor; estrogenic compound; numerical model; regression analysis; spatial analysis; streamwater; watershed; adverse event; Article; catchment area (hydrology); controlled study; estrogen activity; exposure; landscape; male; nonhuman; principal component analysis; random forest; risk assessment; seasonal variation; spatiotemporal analysis; stream (river); watershed; watershed management; analysis; animal; bay; environmental monitoring; river; toxicity; water pollutant; Chesapeake Bay; Potomac Basin; United States; Animals; Bays; Endocrine Disruptors; Environmental Monitoring; Estrogens; Male; Rivers; Water Pollutants, Chemical"
"Gorzalczany M.B., Rudzinski F.","Intrusion Detection in Internet of Things With MQTT Protocol - An Accurate and Interpretable Genetic-Fuzzy Rule-Based Solution","10.1109/JIOT.2022.3194837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135747865&doi=10.1109%2fJIOT.2022.3194837&partnerID=40&md5=e197df31dd960119eb7332abcaeb6806","This article addresses the problem of an accurate and interpretable intrusion detection in Internet of Things (IoT) systems using the knowledge-discovery data-mining/machine-learning approach proposed by us. This approach - implemented as a fuzzy rule-based classifier - employs our generalization of the well-known multiobjective evolutionary optimization algorithm to optimize the accuracy-interpretability tradeoff of the IoT intrusion detection systems (IoT IDSs). The main contribution of this work is the design of accurate and interpretable IoT IDSs from the most recently published data - referred to as MQTT-IOT-IDS2020 data sets - describing the behavior of an MQTT-protocol-based IoT system. A comparison with seven available alternative approaches was also performed demonstrating that the approach proposed by us significantly outperforms alternative methods in terms of interpretability of intrusion-detection decisions made while remaining competitive or superior in terms of the accuracy of those decisions. © 2014 IEEE.","Data mining (DM); fuzzy rule-based classifiers (FRBCs); Internet of Things (IoT); interpretable intrusion detection; intrusion detection systems; machine learning (ML); MQTT protocol; multiobjective evolutionary optimization","Computer crime; Economic and social effects; Fuzzy rules; Genetic algorithms; Internet of things; Intrusion detection; Job analysis; Learning systems; Multiobjective optimization; Cyber-attacks; Fuzzy rule-based classifier; Interpretable intrusion detection; Intrusion Detection Systems; Intrusion-Detection; Machine-learning; MQTT protocol; Multi-objective evolutionary optimizations; Optimisations; Task analysis; Data mining"
"Graben P., Huber M., Meyer W., Römer R., Wolff M.","Vector Symbolic Architectures for Context-Free Grammars","10.1007/s12559-021-09974-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121622617&doi=10.1007%2fs12559-021-09974-y&partnerID=40&md5=1d652b807d88ae8f2e7d9b5bf6eab148","Vector symbolic architectures (VSA) are a viable approach for the hyperdimensional representation of symbolic data, such as documents, syntactic structures, or semantic frames. We present a rigorous mathematical framework for the representation of phrase structure trees and parse trees of context-free grammars (CFG) in Fock space, i.e. infinite-dimensional Hilbert space as being used in quantum field theory. We define a novel normal form for CFG by means of term algebras. Using a recently developed software toolbox, called FockBox, we construct Fock space representations for the trees built up by a CFG left-corner (LC) parser. We prove a universal representation theorem for CFG term algebras in Fock space and illustrate our findings through a low-dimensional principal component projection of the LC parser state. Our approach could leverage the development of VSA for explainable artificial intelligence (XAI) by means of hyperdimensional deep neural computation. © 2021, The Author(s).","Explainable artificial intelligence (XAI); Fock space; Formal grammars; Geometric cognition; Language processing; Vector symbolic architectures","Artificial intelligence; Forestry; Hilbert spaces; Semantics; Syntactics; Trees (mathematics); Vector spaces; Context-free grammars; Explainable artificial intelligence (XAI); Fock spaces; Formal grammars; Geometric cognition; Language processing; Symbolic data; Syntactic structure; Term algebras; Vector symbolic architecture; Context free grammars"
"Greasley A., Panchal G., Samvedi A.","The Use of Simulation with Machine Learning and Optimization for a Digital Twin-A Case on Formula 1 DSS","10.1109/WSC57314.2022.10015299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147442119&doi=10.1109%2fWSC57314.2022.10015299&partnerID=40&md5=9490203e3f5e9c6c8543a9ec645fe2d4","The implementation of a digital twin presents a challenging environment for simulation. One challenge is the need for fast execution speed to maintain synchronization with the real system. When providing predictive outcomes, the complementary use of simulation with machine learning and optimization software may be employed to achieve this aim. The article investigates the use of simulation, machine learning and optimization in terms of providing a digital twin capability. The article presents a case on Formula 1 or F1 competition, where a decision support system (DSS) framework is presented to explore a digital twin capability. © 2022 IEEE.",,"Decision support systems; E-learning; Machine learning; Decision support system frameworks; Execution speed; Machine learning software; Machine-learning; Optimisations; Optimization software; Real systems; Simulation machine; Computer software"
"Gröschler K.-C., Oppelt N.","Using Drones to Monitor Broad-Leaved Orchids (Dactylorhiza majalis) in High-Nature-Value Grassland","10.3390/drones6070174","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136190759&doi=10.3390%2fdrones6070174&partnerID=40&md5=20b257306303ffc8570c6514c9027133","Dactylorhiza majalis is a threatened indicator species for the habitat quality of nutrient-poor grassland sites. Environmentalists utilize the species to validate the success of conservation efforts. Conventionally, plant surveys are field campaigns where the plant numbers are estimated and their spatial distribution is either approximated by GPS or labor-intensively measured by differential GPS. In this study, we propose a monitoring approach using multispectral drone-based data with a very high spatial resolution (~3 cm). We developed the magenta vegetation index to enhance the spectral response of Dactylorhiza majalis in the drone data. We integrated the magenta vegetation index in a random forest classification routine among other vegetation indices and analyzed feature impact on model decision making using SHAP. We applied an image object-level median filter to the classification result to account for image artefacts. Finally, we aggregated the filtered result to individuals per square meter using an overlaying vector grid. The SHAP analysis showed that magenta vegetation index had the highest impact on model decision making. The random forest model could reliably classify Dactylorhiza majalis in the drone data (F1 score: 0.99). We validated the drone-derived plant count using field mappings and achieved good results with an RMSE of 12 individuals per square meter, which is within the error margin stated by experts for a conventional plant survey. In addition to abundance, we revealed the comprehensive spatial distribution of the plants. The results indicate that drone surveys are a suitable alternative to conventional monitoring because they can aid in evaluating conservation efforts and optimizing site-specific management. © 2022 by the authors.","biodiversity conservation; high-resolution imagery; indicator species; random forest; remote sensing; vegetation index; western marsh orchid",
"Grossberg S.","Conscious MIND, Resonant BRAIN: How Each Brain Makes a Mind","10.1093/oso/9780190070557.001.0001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079620801&doi=10.1093%2foso%2f9780190070557.001.0001&partnerID=40&md5=16ed71568ee9e0baa35e6b92d7bd29c4","The book is the culmination of 50 years of intensive research by the author, who is broadly acknowledged to be the most important pioneer and current research leader who models how brains give rise to minds, notably how neural circuits in multiple brain regions interact together to generate psychological functions. The book provides a unified understanding of how, where, and why our brains can consciously see, hear, feel, and know about the world, and effectively plan and act within it. It hereby embodies a revolutionary Principia of Mind that clarifies how autonomous adaptive intelligence is achieved, thereby providing mechanistic explanations of multiple mental disorders, biological bases of morality, religion, and the human condition, as well as solutions to large-scale problems in machine learning, technology, and Artificial Intelligence. Because brains embody a universal developmental code, unifying insights also emerge about all living cellular tissues and about how mental laws reflect laws of the physical world. © Oxford University Press 2021.","AI; Audition; Autonomous intelligence; Brain; Cognition; Consciousness; Creativity; Emotion; Human condition; Learning; Machine learning; Mental disorders; Mind; Morality; Neural networks; Religion; Robotics; Vision",
"Gue I.H.V., Sy A.M.T., Nuñez A.B., Loresco P.J.M., Onia J.G.Y., Belino M.C., Onia J.G.Y.","A Rule Induction Framework on the Effect of ‘Negative' Attributes to Academic Performance","10.3991/ijet.v16i15.24269","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112824462&doi=10.3991%2fijet.v16i15.24269&partnerID=40&md5=af7bedfae15f9bb79f21282e76af0081","Attaining high retention rates among engineering institutions is a predominant issue. A significant portion of engineering students face challenges of retention. Academic advising was implemented to resolve the issue. Decision support systems were developed to support the endeavor. Machine learning have been integrated among such systems in predicting student performance accurately. Most works, however, rely on a black box model approach. Rule induction generates simpler if-then rules, exhibiting clearer understanding. As most research works considered attributes for positive academic performance, there is the need to consider ‘negative' attributes. ‘Negative' attributes are critical indicators to possibility of failure. This work applied rule induction techniques for course grade prediction using ‘negative' attributes. The dataset is the academic performance of 48 mechanical engineering students taking a machine design course. Students' attributes on workload, course repetition, and incurred absences are the predictors. This work implemented two rule induction techniques, rough set theory (RST) and adaptive neuro fuzzy inference system (FIS). Both models attained a classification accuracy of 70.83% with better performance for course grades of ‘Pass' and ‘High'. RST generated 16 crisp rules while ANFIS generated 27 fuzzy rules, yielding significant insights. Results of this study can be used for comparative analysis of student traits between institutions. The illustrated framework can be used in formulating linguistic rules of other institutions. © 2021. All Rights Reserved.","academic advising; machine learning; mechanical engineering","Classification (of information); Curricula; Decision support systems; Fuzzy neural networks; Fuzzy systems; Machine design; Rough set theory; Students; Turing machines; Academic performance; Adaptive neuro-fuzzy inference system; Classification accuracy; Comparative analysis; Engineering institutions; Machine design course; Mechanical engineering students; Rough set theory (RST); Fuzzy inference"
"Guindo M.L., Kabir M.H., Chen R., Huang J., Liu F., Li X., Fang H.","Chemometric Approach Based on Explainable AI for Rapid Assessment of Macronutrients in Different Organic Fertilizers Using Fusion Spectra","10.3390/molecules28020799","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146712350&doi=10.3390%2fmolecules28020799&partnerID=40&md5=228402ba384aa7efe61c1a79061ba455","Wet chemical methods are usually employed in the analysis of macronutrients such as Potassium (K) and Phosphorus (P) and followed by traditional sensor techniques, including inductively coupled plasma optical emission spectrometry (ICP OES), flame atomic absorption spectrometry (FAAS), graphite furnace atomic absorption spectrometry (GF AAS), and inductively coupled plasma mass spectrometry (ICP-MS). Although these procedures have been established for many years, they are costly, time-consuming, and challenging to follow. This study studied the combination of laser-induced breakdown spectroscopy (LIBS) and visible and near-infrared spectroscopy (Vis-NIR) for the quick detection of PK in different varieties of organic fertilizers. Explainable AI (XAI) through Shapley additive explanation values computation (Shap values) was used to extract the valuable features of both sensors. The characteristic variables from different spectroscopic devices were combined to form the spectra fusion. Then, PK was determined using Support Vector Regression (SVR), Partial Least Squares Regression (PLSR), and Extremely Randomized Trees (Extratrees) models. The computation of the coefficient of determination (R2), root mean squared error (RMSE), and residual prediction deviation (RPD) showed that FUSION was more efficient in detecting P (R2p = 0.9946, RMSEp = 0.0649% and RPD = 13.26) and K (R2p = 0.9976, RMSEp = 0.0508% and RPD = 20.28) than single-sensor detection. The outcomes indicated that the features extracted by XAI and the data fusion of LIBS and Vis-NIR could improve the prediction of PK in different varieties of organic fertilizers. © 2023 by the authors.","chemometrics; data fusion; explainable AI; phosphorous; potassium; spectroscopy",
"Guo Y., Li S., Zhang Z., Li Y., Hu Z., Xin D., Chen Q., Wang J., Zhu R.","Automatic and Accurate Calculation of Rice Seed Setting Rate Based on Image Segmentation and Deep Learning","10.3389/fpls.2021.770916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121976212&doi=10.3389%2ffpls.2021.770916&partnerID=40&md5=c709ad06ef5e8c474a824296ea45edda","The rice seed setting rate (RSSR) is an important component in calculating rice yields and a key phenotype for its genetic analysis. Automatic calculations of RSSR through computer vision technology have great significance for rice yield predictions. The basic premise for calculating RSSR is having an accurate and high throughput identification of rice grains. In this study, we propose a method based on image segmentation and deep learning to automatically identify rice grains and calculate RSSR. By collecting information on the rice panicle, our proposed image automatic segmentation method can detect the full grain and empty grain, after which the RSSR can be calculated by our proposed rice seed setting rate optimization algorithm (RSSROA). Finally, the proposed method was used to predict the RSSR during which process, the average identification accuracy reached 99.43%. This method has therefore been proven as an effective, non-invasive method for high throughput identification and calculation of RSSR. It is also applicable to soybean yields, as well as wheat and other crops with similar characteristics. Copyright © 2021 Guo, Li, Zhang, Li, Hu, Xin, Chen, Wang and Zhu.","computer vision; deep learning; image segmentation; rice grain identification; rice seed setting rate",
"Gupta N., Singh J., Chakraborty C., Alazab M., Do D.-T.","Smart and secure internet of healthcare things","10.1201/9781003239895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144813359&doi=10.1201%2f9781003239895&partnerID=40&md5=7e2afc613f2c5128e00f4c48329f8fed","Internet of Healthcare Things (IoHT) is an Internet of Things (IoT)-based solution that includes a network architecture which allows the connection between a patient and healthcare facilities. This book covers various research issues of smart and secure IoHT, aimed at providing solutions for remote healthcare monitoring using pertinent techniques. Applications of machine learning techniques and data analytics in IoHT, along with the latest communication and networking technologies and cloud computing, are also discussed. Features: Provides a detailed introduction to IoHT and its applications; Reviews underlying sensor and hardware technologies; Includes recent advances in the IoHT, such as remote healthcare montoring and wearable devices; Explores applications of data analytics/data mining in IoHT, including data management and data governance; Focuses on regulatory and compliance issues in IoHT. This book is intended for graduate students and researchers in Bioinformatics, Biomedical Engineering, Big Data and Analytics, Data Mining, and Information Management, IoT and Computer and Electrical Engineering. © 2023 selection and editorial matter, Nitin Gupta, Jagdeep Singh, Chinmay Chakraborty, Mamoun Alazab and Dinh-Thuan Do; individual chapters, the contributors. All rights reserved.",,
"Gupta P.K., Andreu-Perez J.","Enhanced type-2 Wang-Mendel Approach","10.1080/0952813X.2022.2135614","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142123536&doi=10.1080%2f0952813X.2022.2135614&partnerID=40&md5=f0d3003c436375773d3831d9afe8ecc2","The Wang-Mendel Approach (WMA) focuses on combining the numerical as well as linguistic information for achieving greater explainability for inference models. The standard WMA models the linguistic information using type-1 (T1) fuzzy sets (FSs), which have a reduced capability to model the semantics of linguistic information. Therefore, we propose a novel Enhanced WMA, which models the linguistic information using the type-2 (T2) FSs. Further, our Enhanced T2 FS-based WMA can be modified to reflect the use of interval type-2 (IT2) FSs, for modelling linguistic uncertainty. IT2 FSs are suitable when better uncertainty handling capabilities are required compared to T1 FSs, however, at a computational cost lesser than the T2 FSs. Performance of Enhanced WMA is demonstrated through a real-world crop-yield prediction problem in smart agriculture and an additional exemplar application on users’ satisfaction ratings. Further, we have compared our approach with the performance obtained from the T1 FS-based WMA and the original estimations given in the original data. We found that our Enhanced WMA provides more precise estimates than the other two with 95% confidence level. To the best of our knowledge, this is the first proposal of a T2 FSs method for enhancing the modeling of linguistic uncertainty in the WMA. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Explainable artificial intelligence; Interval type-2 fuzzy sets; Wang-Mendel Approach","Fuzzy sets; Information use; Uncertainty analysis; Explainable artificial intelligence; Inference models; Interval type-2 fuzzy sets; Linguistic information; Linguistic uncertainty; Numerical information; Performance; Type-1 fuzzy sets; Type-2 fuzzy set; Wang-mendel approach; Semantics"
"Gupta R., Zhang L., Hou J., Zhang Z., Liu H., You S., Sik Ok Y., Li W.","Review of explainable machine learning for anaerobic digestion","10.1016/j.biortech.2022.128468","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144573814&doi=10.1016%2fj.biortech.2022.128468&partnerID=40&md5=35e5bc11c659db5c089108a4c5fdaacc","Anaerobic digestion (AD) is a promising technology for recovering value-added resources from organic waste, thus achieving sustainable waste management. The performance of AD is dictated by a variety of factors including system design and operating conditions. This necessitates developing suitable modelling and optimization tools to quantify its off-design performance, where the application of machine learning (ML) and soft computing approaches have received increasing attention. Here, we succinctly reviewed the latest progress in black-box ML approaches for AD modelling with a thrust on global and local model interpretability metrics (e.g., Shapley values, partial dependence analysis, permutation feature importance). Categorical applications of the ML and soft computing approaches such as what-if scenario analysis, fault detection in AD systems, long-term operation prediction, and integration of ML with life cycle assessment are discussed. Finally, the research gaps and scopes for future work are summarized. © 2022 Elsevier Ltd","Artificial intelligence; Bioenergy; Data-driven modelling; Renewable energy; Sustainable waste management","Failure analysis; Fault detection; Life cycle; Machine learning; Soft computing; Bio-energy; Data-driven model; Design condition; Machine-learning; Operating condition; Organic wastes; Performance; Renewable energies; Soft computing approaches; Sustainable waste management; Anaerobic digestion; alternative energy; anaerobic digestion; artificial intelligence; bioenergy; design method; literature review; machine learning; numerical model; waste management; anaerobic digestion; artificial intelligence; bioenergy; learning; life cycle assessment; machine learning; prediction; renewable energy; review; waste management; anaerobic growth; machine learning; technology; Anaerobiosis; Machine Learning; Technology; Waste Management"
"Gutiérrez R., Rampérez V., Paggi H., Lara J.A., Soriano J.","On the use of information fusion techniques to improve information quality: Taxonomy, opportunities and challenges","10.1016/j.inffus.2021.09.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118750648&doi=10.1016%2fj.inffus.2021.09.017&partnerID=40&md5=3693e0df77ea47cb595906a4bc02888f","The information fusion field has recently been attracting a lot of interest within the scientific community, as it provides, through the combination of different sources of heterogeneous information, a fuller and/or more precise understanding of the real world than can be gained considering the above sources separately. One of the fundamental aims of computer systems, and especially decision support systems, is to assure that the quality of the information they process is high. There are many different approaches for this purpose, including information fusion. Information fusion is currently one of the most promising methods. It is particularly useful under circumstances where quality might be compromised, for example, either intrinsically due to imperfect information (vagueness, uncertainty, …) or because of limited resources (energy, time, …). In response to this goal, a wide range of research has been undertaken over recent years. To date, the literature reviews in this field have focused on problem-specific issues and have been circumscribed to certain system types. Therefore, there is no holistic and systematic knowledge of the state of the art to help establish the steps to be taken in the future. In particular, aspects like what impact different information fusion methods have on information quality, how information quality is characterised, measured and evaluated in different application domains depending on the problem data type or whether fusion is designed as a flexible process capable of adapting to changing system circumstances and their intrinsically limited resources have not been addressed. This paper aims precisely to review the literature on research into the use of information fusion techniques specifically to improve information quality, analysing the above issues in order to identify a series of challenges and research directions, which are presented in this paper. © 2021 Elsevier B.V.","Information fusion; Information imperfections; Information quality; Sustainability","Artificial intelligence; Decision support systems; Information analysis; Information use; Energy-time; Heterogeneous information; Imperfect information; Information fusion techniques; Information imperfection; Information quality; Literature reviews; Real-world; Scientific community; Uncertainty; Information fusion"
"Gutman D., Olatunji S.A., Markfeld N., Givati S., Sarne-Fleischmann V., Oron-Gilad T., Edan Y.","Evaluating levels of automation with different feedback modes in an assistive robotic table clearing task for eldercare","10.1016/j.apergo.2022.103859","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137625848&doi=10.1016%2fj.apergo.2022.103859&partnerID=40&md5=06bd13c75c474f8197c1d741766b65a9","This paper focuses on how the autonomy level of an assistive robot that offers support for older adults in a daily task and its feedback affect the interaction. Identifying the level of automation (LOA) that prioritizes older adults’ preferences while avoiding passiveness and sedentariness is challenging. The feedback mode should match the cognitive and perceptual capabilities of older adults and the LOA. We characterized three LOAs and paired them with two modes of feedback in a human-robot collaborative task. Twenty-seven older adults participated in evaluating the LOA-feedback variations in a mixed experimental design, utilizing an experimental setup of an assistive robot in a table clearing task. The quality of the interaction was evaluated with objective and subjective measures. The combination of high LOA with voice feedback improved the overall interaction when compared to other LOA and feedback combinations. This study emphasizes the importance of appropriate coupling of LOA and feedback for successful interaction of the older adults with an assistive robot. © 2022 The Authors","Assistive robots; Human-robot interaction; Interaction design; Older adults","Machine design; Man machine systems; Assistive robotics; Assistive robots; Autonomy levels; Daily tasks; Eldercare; Feedback mode; Humans-robot interactions; Interaction design; Levels of automation; Older adults; Human robot interaction; age; aged; Article; automation; clinical evaluation; cognition; comparative study; controlled study; educational status; feedback system; female; food handling; geriatric care; human; human experiment; male; measurement accuracy; normal human; online system; perception; safety; social norm; task performance; feedback system; psychology; robot assisted surgery; robotics; self help device; Aged; Feedback; Humans; Robotic Surgical Procedures; Robotics; Self-Help Devices"
"Haase E.","Driving the environmental extra mile – Car sharing and voluntary carbon dioxide offsetting","10.1016/j.trd.2022.103361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132738563&doi=10.1016%2fj.trd.2022.103361&partnerID=40&md5=761a2df30b2400d60263ad7e9df6afc2","Sharing seems a key feature of transforming linear consumption to a more environmentally friendly system. This is especially applicable to car sharing. The aim of this study is to find out which factors influence environmentally friendly behaviour and how strongly. 13,629 journeys of a German car sharing provider specialised in the transport of goods and larger groups of people are evaluated. The focus is on the possibility for customers to offset their carbon footprint by voluntarily making their journeys climate neutral. Considering socio-economic characteristics, a Light Gradient Boosting Machine (LightGBM) model is applied to analyse variables which influence environmentally friendly behaviour. Age, place of residence, mileage driven, and education level have a statistically significant influence in predicting whether a customer will voluntarily offset CO2 or not, in contrast to gender. These findings have societal and political implications which could be used for future policy making. © 2022 Elsevier Ltd","Car sharing; Carbon offsetting; Environmental behaviour; Light gradient boosting machine; Machine learning","Adaptive boosting; Carbon dioxide; Carbon footprint; Car sharing; Carbon offsetting; Environmental behavior; Environmentally friendly systems; Gradient boosting; Key feature; Large groups; Light gradient boosting machine; Light gradients; Machine-learning; Machine learning; car use; carbon dioxide; consumption behavior; future prospect; machine learning; policy making; transportation mode; Germany"
"Hajnal E., Kovács L., Vakulya G.","Dairy Cattle Rumen Bolus Developments with Special Regard to the Applicable Artificial Intelligence (AI) Methods","10.3390/s22186812","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138430335&doi=10.3390%2fs22186812&partnerID=40&md5=be5233b73494e7f3d98fedfa31daf8c9","It is a well-known worldwide trend to increase the number of animals on dairy farms and to reduce human labor costs. At the same time, there is a growing need to ensure economical animal husbandry and animal welfare. One way to resolve the two conflicting demands is to continuously monitor the animals. In this article, rumen bolus sensor techniques are reviewed, as they can provide lifelong monitoring due to their implementation. The applied sensory modalities are reviewed also using data transmission and data-processing techniques. During the processing of the literature, we have given priority to artificial intelligence methods, the application of which can represent a significant development in this field. Recommendations are also given regarding the applicable hardware and data analysis technologies. Data processing is executed on at least four levels from measurement to integrated analysis. We concluded that significant results can be achieved in this field only if the modern tools of computer science and intelligent data analysis are used at all levels. © 2022 by the authors.","artificial intelligence; dairy cattle; data processing; machine learning; rumen bolus","Data handling; Information analysis; Machine learning; Wages; Animal husbandry; Animal welfare; Artificial intelligence methods; Dairy cattles; Dairy farms; Human labor; Labor costs; Machine-learning; Rumen bolus; Sensors technique; Animals; animal; animal husbandry; animal welfare; artificial intelligence; bovine; cattle disease; human; rumen; Animal Husbandry; Animal Welfare; Animals; Artificial Intelligence; Cattle; Cattle Diseases; Humans; Rumen"
"Hakak S., Gadekallu T.R., Maddikunta P.K.R., Ramu S.P., M P., De Alwis C., Liyanage M.","Autonomous vehicles in 5G and beyond: A survey","10.1016/j.vehcom.2022.100551","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143491492&doi=10.1016%2fj.vehcom.2022.100551&partnerID=40&md5=bee814e193e9609717c52fdb67679f04","Fifth Generation (5G) mobile technology is the latest generation of mobile networks that is being deployed to facilitate emerging applications and services. 5G offers enhanced mobile broadband, massive machine type communication, and ultra reliable low latency communication. Hence, the capabilities of 5G can be harnessed to satisfy the requirements of autonomous vehicles (AV). AVs are developed to offer comfort, safety and efficient driving. However, the capabilities of 5G are yet to be harness by AVs and related technologies. In response, this survey provides a comprehensive review on AVs in the 5G and beyond era. The paper provides a discussion on the current advancements in AVs, automation levels, enabling technologies and the requirement of 5G networks. Furthermore, the paper focuses on emerging technologies enabling the integration of 5G with AVs, the impact of 5G and B5G for AVs and the envisaged security concerns in AVs. The paper also provides a comprehensive understanding of recent developments in terms of standardisation activities and projects on 5G AV technologies. The article also provides lessons learnt, existing challenges, and future research directions to facilitate the development of AV technologies in the 5G and beyond era. © 2022 Elsevier Inc.","5G technology; Autonomous vehicles; B5G technology; Road safety; Security in AV; Vehicular communications",
"Hakim G.P.N., Septiyana D., Suwarno I.","Survey Paper Artificial and Computational Intelligence in the Internet of Things and Wireless Sensor Network","10.18196/jrc.v3i4.15539","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142936445&doi=10.18196%2fjrc.v3i4.15539&partnerID=40&md5=5e3fbf36d9da4d24312c06586c1b0b7c","In this modern age, Internet of Things (IoT) and Wireless Sensor Network (WSN) as its derivatives have become one of the most popular and important technological advancements. In IoT, all things and services in the real world are digitalized and it continues to grow exponentially every year. This growth in number of IoT device in the end has created a tremendous amount of data and new data services such as big data systems. These new technologies can be managed to produce additional value to the existing business model. It also can provide a forecasting service and is capable to produce decision-making support using computational intelligence methods. In this survey paper, we provide detailed research activities concerning Computational Intelligence methods application in IoT WSN. To build a good understanding, in this paper we also present various challenges and issues for Computational Intelligence in IoT WSN. In the last presentation, we discuss the future direction of Computational Intelligence applications in IoT WSN such as Self-Organizing Network (dynamic network) concept. © 2022 Department of Agribusiness, Universitas Muhammadiyah Yogyakarta. All Rights Reserved.","Artificial Intelligence; Computational Intelligence; Dynamic Network; IoT; WSN",
"Hakkoum H., Abnane I., Idri A.","Interpretability in the medical field: A systematic mapping and review study","10.1016/j.asoc.2021.108391","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122624142&doi=10.1016%2fj.asoc.2021.108391&partnerID=40&md5=38db4d1f5c417a07d0a3204639e157a2","Context: Recently, the machine learning (ML) field has been rapidly growing, mainly owing to the availability of historical datasets and advanced computational power. This growth is still facing a set of challenges, such as the interpretability of ML models. In particular, in the medical field, interpretability is a real bottleneck to the use of ML by physicians. Therefore, numerous interpretability techniques have been proposed and evaluated to help ML gain the trust of its users. Methods: This review was carried out according to the well-known systematic map and review process to analyze the literature on interpretability techniques when applied in the medical field with regard to different aspects: publication venues and publication year, contribution and empirical types, medical and ML disciplines and objectives, ML black-box techniques interpreted, interpretability techniques investigated, their performance and the best performing techniques, and lastly, the datasets used when evaluating interpretability techniques. Results: A total of 179 articles (1994–2020) were selected from six digital libraries: ScienceDirect, IEEE Xplore, ACM Digital Library, SpringerLink, Wiley, and Google Scholar. The results showed that the number of studies dealing with interpretability increased over the years with a dominance of solution proposals and experiment-based empirical type. Diagnosis, oncology, and classification were the most frequent medical task, discipline, and ML objective studied, respectively. Artificial neural networks were the most widely used ML black-box techniques investigated for interpretability. Additionally, global interpretability techniques focusing on a specific black-box model, such as rules, were the dominant explanation types, and most of the metrics used to evaluate interpretability were accuracy, fidelity, and number of rules. Moreover, the variety of the techniques used by the selected papers did not allow categorization at the technique level, and the high number of the sum of evaluations (671) of the articles raised a suspicion of subjectivity. Datasets that contained numerical and categorical attributes were the most frequently used in the selected studies. Conclusions: Further effort is needed in disciplines other than diagnosis and classification. Global techniques such as rules are the most used because of their comprehensibility to doctors, but new local techniques should be explored more in the medical field to gain more insights into the model's behavior. More experiments and comparisons against existing techniques are encouraged to determine the best performing techniques. Lastly, quantitative evaluation of interpretability and physicians’ implications in interpretability techniques evaluation is highly recommended to evaluate how the techniques will perform in real-world scenarios. It can ensure the soundness of the techniques and help gain trust in black-box models in medical environments. © 2022 Elsevier B.V.","Artificial intelligence; Explainability; Interpretability; Machine learning; Medicine; Systematic review; XAI","Computer aided diagnosis; Digital libraries; Neural networks; Black box modelling; Black boxes; Computational power; Explainability; Historical dataset; Interpretability; Medical fields; Systematic mapping; Systematic Review; XAI; Machine learning"
"Haldar D., Shabbirahmed A.M., Mahanty B.","Multivariate regression and artificial neural network modelling of sugar yields from acid pretreatment and enzymatic hydrolysis of lignocellulosic biomass","10.1016/j.biortech.2022.128519","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144899181&doi=10.1016%2fj.biortech.2022.128519&partnerID=40&md5=66e453802512182bc234b18f0192a836","Reducing sugar generation from lignocellulosic biomass (LCB) is closely linked with biomass characteristics, pretreatment and enzymatic hydrolysis conditions. In this study curated experimental data from literature was used to develop multivariate regression and artificial neural network (ANN) model considering nine predictors (i.e., cellulose, hemicellulose, lignin content, cellulose-lignin ratio, acid concentration, temperature, time, pretreatment severity, and enzyme concentration). Selected reduced polynomial model (R2: 0.891, Adj. R2: 0.849) suggests positive influence of acid and enzyme, while negative influence of treatment severity, temperature and time on reducing sugar generation. Genetic algorithm-optimized ANN model offered excellent fitness for LCB hydrolysis on training (R2: 0.997), validation (R2: 0.984), and test sets (R2: 0.967). Sensitivity analysis of the ANN predictors suggests lignin and to some extent hemicellulose contents can be inhibitory. Though polynomial models can have simple interpretation, use of optimized ANN offers better predictability in dataset with diverse biomass compositions. © 2022 Elsevier Ltd","Cellulase; Genetic algorithm; Lignin; Polynomial model","Biomass; Cellulose; Enzymatic hydrolysis; Lignin; Neural networks; Polynomials; Regression analysis; Sensitivity analysis; Sugars; Acid pretreatment; Artificial neural network modeling; Cellulase; Enzymatic hydrolysis conditions; Lignocellulosic biomass; Multivariate regression; Polynomial models; Pre-treatments; Reducing sugars; Sugar yield; Genetic algorithms; acid; carbohydrate; cellulose; enzyme; hemicellulose; lignin; lignocellulose; carbohydrate; cellulase; lignin; lignocellulose; artificial neural network; biomass; enzyme; enzyme activity; hydrolysis; lignin; sugar; Article; artificial neural network; biomass; concentration (parameter); cross validation; enzymatic hydrolysis; genetic algorithm; prediction; sensitivity analysis; temperature; time factor; weight; biomass; hydrolysis; Biomass; Cellulose; Enzymolysis; Neural Networks; Regression Analysis; Biomass; Carbohydrates; Cellulase; Cellulose; Hydrolysis; Lignin; Neural Networks, Computer; Sugars"
"Hall O., Ohlsson M., Rögnvaldsson T.","A review of explainable AI in the satellite data, deep machine learning, and human poverty domain","10.1016/j.patter.2022.100600","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140913941&doi=10.1016%2fj.patter.2022.100600&partnerID=40&md5=3cd05cd3f00c377dccd5ddb276bac5b1","Recent advances in artificial intelligence and deep machine learning have created a step change in how to measure human development indicators, in particular asset-based poverty. The combination of satellite imagery and deep machine learning now has the capability to estimate some types of poverty at a level close to what is achieved with traditional household surveys. An increasingly important issue beyond static estimations is whether this technology can contribute to scientific discovery and, consequently, new knowledge in the poverty and welfare domain. A foundation for achieving scientific insights is domain knowledge, which in turn translates into explainability and scientific consistency. We perform an integrative literature review focusing on three core elements relevant in this context—transparency, interpretability, and explainability—and investigate how they relate to the poverty, machine learning, and satellite imagery nexus. Our inclusion criteria for papers are that they cover poverty/wealth prediction, using survey data as the basis for the ground truth poverty/wealth estimates, be applicable to both urban and rural settings, use satellite images as the basis for at least some of the inputs (features), and the method should include deep neural networks. Our review of 32 papers shows that the status of the three core elements of explainable machine learning (transparency, interpretability, and domain knowledge) is varied and does not completely fulfill the requirements set up for scientific insights and discoveries. We argue that explainability is essential to support wider dissemination and acceptance of this research in the development community and that explainability means more than just interpretability. © 2022 The Author(s)","machine learning; poverty and satellite imagery; XAI","Deep neural networks; Satellite imagery; Surveys; Transparency; Core elements; Domain knowledge; Household surveys; Human development; Interpretability; Machine-learning; Poverty and satellite imagery; Satellite data; Step changes; XAI; Domain Knowledge"
"Hameed A., Atiq M., Ahmed Z., Rajput N.A., Younas M., Rehman A., Alam M.W., Sarfaraz S., Liaqat N., Fatima K., Tariq K., Jameel S., Ghazali H.M.Z.U., Vachova P., Salmen S.H., Ansari M.J.","Predicting the impact of environmental factors on citrus canker through multiple regression","10.1371/journal.pone.0260746","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127651319&doi=10.1371%2fjournal.pone.0260746&partnerID=40&md5=35ed92052bcb006d9fa8fe729869dfee","Climatic conditions play a significant role in the development of citrus canker caused by Xanthomonas citri pv. citri (Xcc). Citrus canker is regarded as one of the major threats being faced by citrus industry in citrus growing countries of the world. Climatic factors exert significant impacts on growth stage, host susceptibility, succulence, vigor, survival, multiplication rate, pathogen dispersion, spore penetration rate, and spore germination. Predicting the impacts of climatic factors on these traits could aid in the development of effective management strategies against the disease. This study predicted the impacts of environmental variables, i.e., temperature, relative humidity, rainfall, and wind speed the development of citrus canker through multiple regression. These environmental variables were correlated with the development of canker on thirty (30) citrus varieties during 2017 to 2020. Significant positive correlations were noted among environment variables and disease development modeled through multiple regression model (Y = +24.02 + 0.5585 X1 + 0.2997 X2 + 0.3534 X3 + 3.590 X4 + 1.639 X5). Goodness of fit of the model was signified by coefficient determination value (97.5%). Results revealed the optimum values of environmental variables, i.e., maximum temperature (37C), minimum temperature (27C), relative humidity (55%), rainfall (4.7–7.1 mm) and wind speed (8 Km/h), which were conducive for the development of citrus canker. Current study would help researchers in designing better management strategies against citrus canker disease under changing climatic conditions in the future. Copyright: © 2022 Hameed et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Article; bacterial plant disease; citron; Citrus; Citrus aurantifolia swingle; citrus canker; Citrus jambhiri; Citrus japonica; Citrus latifolia; Citrus limettioides; Citrus paradise; Citrus poncirus; Citrus pseudolimon; climate change; disease association; environmental factor; environmental impact; environmental temperature; high temperature; low temperature; mandarin; nonhuman; Pakistan; plant response; prediction; pummelo; relative humidity; sour orange; sweet orange; wind speed; Citrus; plant disease; Xanthomonas; Citrus; Plant Diseases; Xanthomonas"
"Hamlet A., Ramos D.G., Gaythorpe K.A.M., Romano A.P.M., Garske T., Ferguson N.M.","Seasonality of agricultural exposure as an important predictor of seasonal yellow fever spillover in Brazil","10.1038/s41467-021-23926-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108158607&doi=10.1038%2fs41467-021-23926-y&partnerID=40&md5=f2ace42fb5b5c38c24d28d662a8f8066","Yellow fever virus (YFV) is a zoonotic arbovirus affecting both humans and non-human primates (NHP’s) in Africa and South America. Previous descriptions of YF’s seasonality have relied purely on climatic explanations, despite the high proportion of cases occurring in people involved in agriculture. We use a series of random forest classification models to predict the monthly occurrence of YF in humans and NHP’s across Brazil, by fitting four classes of covariates related to the seasonality of climate and agriculture (planting and harvesting), crop output and host demography. We find that models captured seasonal YF reporting in humans and NHPs when they considered seasonality of agriculture rather than climate, particularly for monthly aggregated reports. These findings illustrate the seasonality of exposure, through agriculture, as a component of zoonotic spillover. Additionally, by highlighting crop types and anthropogenic seasonality, these results could directly identify areas at highest risk of zoonotic spillover. © 2021, The Author(s).",,"climate change; covariance analysis; numerical model; random walk method; risk assessment; seasonality; spillover effect; yellow fever; agriculture; animal reservoir; Article; Brazil; climate change; comparative study; computer language; controlled study; demography; disease surveillance; disease transmission; environmental exposure; geographic distribution; governmental organization; human; infection risk; nonhuman; random forest; seasonal variation; virus transmission; yellow fever; animal; climate; epidemic; forest; primate; season; yellow fever; Yellow fever virus; zoonosis; Africa; Brazil; Arbovirus; Yellow fever virus; Agriculture; Animals; Brazil; Climate; Disease Outbreaks; Forests; Humans; Primates; Seasons; Yellow Fever; Yellow fever virus; Zoonoses"
"Hammes F., Hagg A., Asteroth A., Link D.","Artificial Intelligence in Elite Sports—A Narrative Review of Success Stories and Challenges","10.3389/fspor.2022.861466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134699558&doi=10.3389%2ffspor.2022.861466&partnerID=40&md5=3a05cbea9b483f4c494703ebcc4133f4","This paper explores the role of artificial intelligence (AI) in elite sports. We approach the topic from two perspectives. Firstly, we provide a literature based overview of AI success stories in areas other than sports. We identified multiple approaches in the area of Machine Perception, Machine Learning and Modeling, Planning and Optimization as well as Interaction and Intervention, holding a potential for improving training and competition. Secondly, we discover the present status of AI use in elite sports. Therefore, in addition to another literature review, we interviewed leading sports scientist, which are closely connected to the main national service institute for elite sports in their countries. The analysis of this literature review and the interviews show that the most activity is carried out in the methodical categories of signal and image processing. However, projects in the field of modeling & planning have become increasingly popular within the last years. Based on these two perspectives, we extract deficits, issues and opportunities and summarize them in six key challenges faced by the sports analytics community. These challenges include data collection, controllability of an AI by the practitioners and explainability of AI results. Copyright © 2022 Hammes, Hagg, Asteroth and Link.","AI usage in sports; artificial intelligence; elite sports; explainable AI; SMPA loop",
"Han J., Zhang Z., Cao J., Luo Y., Zhang L., Li Z., Zhang J.","Prediction of winter wheat yield based on multi-source data and machine learning in China","10.3390/rs12020236","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081078655&doi=10.3390%2frs12020236&partnerID=40&md5=d821dce8f15b400fe5942d850e2b4263","Wheat is one of the main crops in China, and crop yield prediction is important for regional trade and national food security. There are increasing concerns with respect to how to integrate multi-source data and employ machine learning techniques to establish a simple, timely, and accurate crop yield prediction model at an administrative unit. Many previous studies were mainly focused on the whole crop growth period through expensive manual surveys, remote sensing, or climate data. However, the effect of selecting different time window on yield prediction was still unknown. Thus, we separated the whole growth period into four time windows and assessed their corresponding predictive ability by taking the major winter wheat production regions of China as an example in the study. Firstly we developed a modeling framework to integrate climate data, remote sensing data and soil data to predict winter wheat yield based on the Google Earth Engine (GEE) platform. The results show that the models can accurately predict yield 1~2 months before the harvesting dates at the county level in China with an R2 &gt; 0.75 and yield error less than 10%. Support vector machine (SVM), Gaussian process regression (GPR), and random forest (RF) represent the top three best methods for predicting yields among the eight typical machine learning models tested in this study. In addition, we also found that different agricultural zones and temporal training settings affect prediction accuracy. The three models perform better as more winter wheat growing season information becomes available. Our findings highlight a potentially powerful tool to predict yield using multiple-source data and machine learning in other regions and for crops. © 2020 by the authors.","Google Earth Engine (GEE); Machine learning; Multi-source data; Triticum aestivum L.; Wheat yield prediction","Crops; Decision trees; Earth (planet); Engines; Food supply; Forecasting; Random forests; Remote sensing; Support vector machines; Support vector regression; Different time windows; Gaussian process regression; Google earths; Machine learning models; Machine learning techniques; Multisource data; Triticum aestivum L; Wheat yield; Learning systems"
"Han L., Yang G., Yang X., Song X., Xu B., Li Z., Wu J., Yang H., Wu J.","An explainable XGBoost model improved by SMOTE-ENN technique for maize lodging detection based on multi-source unmanned aerial vehicle images","10.1016/j.compag.2022.106804","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125148347&doi=10.1016%2fj.compag.2022.106804&partnerID=40&md5=e312a7b04f746ff7846d7a9d285f80a1","Remote sensing image is becoming an increasingly popular tool for crop lodging detection because it conveniently provides features for building machine learning models and predicting lodging. However, difficulties in interpreting machine learning models and their predictions limit the confidence of using remote sensing images to detect lodging. In addition, the lodging datasets used for modeling are difficult to balance under natural conditions. Designing a robust and interpretable classification model for the detection of lodging in an imbalanced distribution dataset poses a particularly difficult challenge. In this study, visible and multi-spectral images were collected with a UAV to extract relevant features from remote sensing images. In a preliminary step, Synthetic Minority Oversampling Technique (SMOTE) and Edited Nearest Neighbors (ENN) method were used to treat imbalanced datasets. The SMOTE-ENN-XGBoost model is proposed for the efficient identification of maize lodging at the plot scale. The SMOTE-ENN-XGBoost model achieved an F1-score of 0.930 and a recall of 0.899 on a testing set, suggesting that it can be used for modeling lodging detection. Additionally, the SHapley Additive exPlanations (SHAP) approach was employed to interpret the identification and prioritization of features that determine lodging classification and activity prediction. The results showed that canopy structure and textural features are relatively stable compared with spectral features, which are susceptible to the external environment when modeling is employed to detect lodging. This work also showed that canopy structural, spectral, and textural information should be considered simultaneously rather than separately when detecting crop lodging in a crop breeding program in order to prevent differences in expression controlled by the interaction between genotype and environment obscuring the change in a single feature before and after lodging. For practical applications of machine learning models in crop lodging detection, such insights are of critical relevance. Taken together, the results of this study encourage further applications of remote sensing techniques to build interpretable machine learning models. © 2022","Lodging; Remote sensing; SHAP; SMOTE; XGBoost","Antennas; Classification (of information); Feature extraction; Forecasting; Image enhancement; Machine learning; Remote sensing; Spectroscopy; Unmanned aerial vehicles (UAV); Lodging; Machine learning models; Nearest neighbors techniques; Nearest-neighbour; Remote sensing images; Remote-sensing; Shapley; Shapley additive explanation; Synthetic minority over-sampling techniques; Xgboost; Crops; data set; detection method; image analysis; image classification; maize; numerical model; spectral analysis; unmanned vehicle"
"Han L., Zhao J., Gao Y., Gu Z.","Prediction and evaluation of spatial distributions of ozone and urban heat island using a machine learning modified land use regression method","10.1016/j.scs.2021.103643","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122396341&doi=10.1016%2fj.scs.2021.103643&partnerID=40&md5=0f9f085de006698cdc1732ddee77bd02","In summer, Ozone (O3) pollution and urban heat island (UHI) pose serious health risks to humans. To obtain the spatial distributions of ozone and urban heat island in Xi'an in summer and develop a simultaneous control strategy of ozone and urban heat island, the land use regression model is modified and improved using the machine learning random forest algorithm. The LUR-Kriging-RF integrated prediction model is then established. The land use regression and kriging are used to extract the feature variables, while random forest is used to establish a regression model. The spatial distribution maps of ozone and urban heat island in Xi'an are obtained by regression mapping of the prediction model, and the spatial relationships between them are analyzed. The SHapley Additive explanation (SHAP) and partial dependence plot (PDP) are adopted to explain the way feature variables act on ozone and urban heat island. Based on the spatial distribution and interaction mode, a simultaneous control strategy of ozone and urban heat island in Xi'an is put forward. For ozone, the R2 of the integrated prediction model (0.65) is higher than that of land use regression (0.4), while the RMSE (28.18) of the integrated model is lower than that of land use regression (35.66). For temperature, the R2 of the integrated model (0.93) is higher than that of land use regression (0.8), while its RMSE (0.92) is lower than that of land use regression (1.52). The performance of the LUR-Kriging-RF integrated prediction model is better than that of land use regression. This study reveals the spatial interactions between ozone and land use regression in the central urban areas. The suitable strategies for mapping ozone pollution and urban heat island control include reducing VOCs emissions from industrial sources and agricultural sources, increasing plants with low VOCs emissions, and spray humidification. This study can be used to evaluate ozone exposure and thermal exposure, provide scientific support for environmental protection and urban heat island control policies, contribute to reducing public health threats, promote the sustainability of urban environments, and promote the practical application of machine learning in this field. © 2021 Elsevier Ltd","Land use regression; Ozone; Random forest; Spatial distribution; Urban heat island","Air pollution; Atmospheric temperature; Decision trees; Forecasting; Health risks; Industrial emissions; Interpolation; Land use; Landforms; Machine learning; Regression analysis; Spatial distribution; Sustainable development; Thermal pollution; Control strategies; Feature variable; Integrated modeling; Integrated prediction models; Island control; Land use regression; Random forests; Simultaneous control; Urban heat island; VOC emissions; Ozone; heat island; land use change; ozone; prediction; regression analysis; seasonal variation; spatiotemporal analysis; urban area; China; Shaanxi; Xian"
"Han Z., Huang H., Lu D., Fan Q., Ma C., Chen X., Gu Q., Chen Q.","One-stage and lightweight CNN detection approach with attention: Application to WBC detection of microscopic images","10.1016/j.compbiomed.2023.106606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146681962&doi=10.1016%2fj.compbiomed.2023.106606&partnerID=40&md5=16b6dd8082a9f733efd29d6a3afcd4d7","White blood cell (WBC) detection in microscopic images is indispensable in medical diagnostics; however, this work, based on manual checking, is time-consuming, labor-intensive, and easily results in errors. Using object detectors for WBCs with deep convolutional neural networks can be regarded as a feasible solution. In this paper, to improve the examination precision and efficiency, a one-stage and lightweight CNN detector with an attention mechanism for detecting microscopic WBC images, and a white blood cell detection vision system are proposed. The method integrates different optimizing strategies to strengthen the feature extraction capability through the combination of an improved residual convolution module, hybrid spatial pyramid pooling module, improved coordinate attention mechanism, efficient intersection over union (EIOU) loss and Mish activation function. Extensive ablation and contrast experiments on the latest public Raabin-WBC dataset verify the effectiveness and robustness of the proposed detector for achieving a better overall detection performance. It is also more efficient than other existing studies for blood cell detection on two additional classic public BCCD and LISC datasets. The novel detection approach is significant and flexible for medical technicians to use for blood cell microscopic examination in clinical practice. © 2023 Elsevier Ltd","Computer vision; Detection vision system; Object detection; White blood cell detection; YOLO","Blood; Cells; Computer vision; Convolution; Convolutional neural networks; Cytology; Deep neural networks; Diagnosis; Feature extraction; Image enhancement; Medical imaging; Attention mechanisms; Cell detection; Detection approach; Detection vision system; Microscopic image; Objects detection; Vision systems; White blood cell detection; White blood cells; YOLO; Object detection; article; attention; blood cell; clinical practice; computer vision; convolutional neural network; feature extraction; human cell; leukocyte; loss of function mutation; microscopy; vision"
"Hanadé Houmma I., El Mansouri L., Gadal S., Garba M., Hadria R.","Modelling agricultural drought: a review of latest advances in big data technologies","10.1080/19475705.2022.2131471","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139792176&doi=10.1080%2f19475705.2022.2131471&partnerID=40&md5=7954425677bbe4ef0a1c5d13c3ad3240","This article reviews the main recent applications of multi-sensor remote sensing and Artificial Intelligence techniques in multivariate modelling of agricultural drought. The study focused mainly on three fundamental aspects, namely descriptive modelling, predictive modelling, and spatial modelling of expected risks and vulnerability to drought. Thus, out of 417 articles across all studies on drought, 226 articles published from 2010 to 2022 were analyzed to provide a global overview of the current state of knowledge on multivariate drought modelling using the inclusion criteria. The main objective is to review the recent available scientific evidence regarding multivariate drought modelling based on the joint use of geospatial technologies and artificial intelligence. The analysis focused on the different methods used, the choice of algorithms and the most relevant variables depending on whether they are descriptive or predictive models. Criteria such as the skill score, the given game complexity used, and the nature of validation data were considered to draw the main conclusions. The results highlight the very heterogeneous nature of studies on multivariate modelling of agricultural drought, and the very original nature of studies on multivariate modelling of agricultural drought in the recent literature. For future studies, in addition to scientific advances in prospects, case studies and comparative studies appear necessary for an in-depth analysis of the reproducibility and operational applicability of the different approaches proposed for spatial and temporal modelling of agricultural drought. HIGHLIGHTS The components and fundamentals of multivariate modelling of agricultural drought were discussed. The importance of hybrid artificial intelligence models is widely discussed in improving the performance of traditional machine learning models. Quantum machine learning algorithms are weakly explored in multivariate drought modelling. Therefore, future studies should explore this approach. The major challenge of multivariate modelling of drought frequency is mainly related to the difference in the return periods of the different variables (time-shifted and spatially effects). © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","agricultural drought indices; artificial intelligence; drought frequency; machine learning; Multi-sensor modelling; multivariate drought modelling","Agriculture; Big data; Learning algorithms; Machine learning; Remote sensing; Risk assessment; Agricultural drought; Agricultural drought index; Drought frequency; Drought modeling; Machine-learning; Multi sensor; Multi-sensor modeling; Multivariate drought modeling; Multivariate modeling; Sensors models; Drought"
"Hanoon S.K., Abdullah A.F., Shafri H.Z.M., Wayayok A.","A Novel Approach Based on Machine Learning and Public Engagement to Predict Water-Scarcity Risk in Urban Areas","10.3390/ijgi11120606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144905177&doi=10.3390%2fijgi11120606&partnerID=40&md5=c7c5fe2084d8550e0f8febfc09d493cd","Climate change, population growth and urban sprawl have put a strain on water supplies across the world, making it difficult to meet water demand, especially in city regions where more than half of the world’s population now reside. Due to the complex urban fabric, conventional techniques should be developed to diagnose water shortage risk (WSR) by engaging crowdsourcing. This study aims to develop a novel approach based on public participation (PP) with a geographic information system coupled with machine learning (ML) in the urban water domain. The approach was used to detect (WSR) in two ways, namely, prediction using ML models directly and using the weighted linear combination (WLC) function in GIS. Five types of ML algorithm, namely, support vector machine (SVM), multilayer perceptron, K-nearest neighbour, random forest and naïve Bayes, were incorporated for this purpose. The Shapley additive explanation model was added to analyse the results. The Water Evolution and Planning system was also used to predict unmet water demand as a relevant criterion, which was aggregated with other criteria. The five algorithms that were used in this work indicated that diagnosing WSR using PP achieved good-to-perfect accuracy. In addition, the findings of the prediction process achieved high accuracy in the two proposed techniques. However, the weights of relevant criteria that were extracted by SVM achieved higher accuracy than the weights of the other four models. Furthermore, the average weights of the five models that were applied in the WLC technique increased the prediction accuracy of WSR. Although the uncertainty ratio was associated with the results, the novel approach interpreted the results clearly, supporting decision makers in the proactive exploration processes of urban WSR, to choose the appropriate alternatives at the right time. © 2022 by the authors.","crowdsourcing; GIS; machine learning; public engagement; urban water; water-shortage risk",
"Hansen B.D., Tamouk J., Tidmarsh C.A., Johansen R., Moeslund T.B., Jensen D.G.","Prediction of the Methane Production in Biogas Plants Using a Combined Gompertz and Machine Learning Model","10.1007/978-3-030-58799-4_53","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092728168&doi=10.1007%2f978-3-030-58799-4_53&partnerID=40&md5=d102593e838843e7e1268f4456c241f2","Biogas production is a complicated process and mathematical modeling of the process is essential in order to plan the management of the plants. Gompertz models can predict the biogas production, but in co-digestion, where many feedstocks are used it can be hard to obtain a sufficient calibration, and often more research is required in order to find the exact calibration parameters. The scope of this article is to investigate if machine learning approaches can be used to optimize the predictions of Gompertz models. Increasing the precision of the models is important in order to get an optimal usage of the resources and thereby ensure a more sustainable energy production. Three models were tested: A Gompertz model (Mean Absolute Percentage Error (MAPE) = 9.61%), a machine learning model (MAPE = 4.84%), and a hybrid model (MAPE = 4.52%). The results showed that the hybrid model could decrease the error in the predictions with 53% when predicting the methane production one day ahead. When encountering an offset in the predictions the reduction of the error was increased to 66%. © 2020, Springer Nature Switzerland AG.","Biogas; Gompertz model; Machine learning; Prediction","Biogas; Calibration; Errors; Forecasting; Machine learning; Methane; Turing machines; Biogas production; Calibration parameters; Gompertz model; Machine learning approaches; Machine learning models; Mean absolute percentage error; Methane production; Sustainable energy; Predictive analytics"
"Haque M.A., Marwaha S., Deb C.K., Nigam S., Arora A., Hooda K.S., Soujanya P.L., Aggarwal S.K., Lall B., Kumar M., Islam S., Panwar M., Kumar P., Agrawal R.C.","Deep learning-based approach for identification of diseases of maize crop","10.1038/s41598-022-10140-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128286178&doi=10.1038%2fs41598-022-10140-z&partnerID=40&md5=44b2315016fbefab5126fe8a1ef88613","In recent years, deep learning techniques have shown impressive performance in the field of identification of diseases of crops using digital images. In this work, a deep learning approach for identification of in-field diseased images of maize crop has been proposed. The images were captured from experimental fields of ICAR-IIMR, Ludhiana, India, targeted to three important diseases viz. Maydis Leaf Blight, Turcicum Leaf Blight and Banded Leaf and Sheath Blight in a non-destructive manner with varied backgrounds using digital cameras and smartphones. In order to solve the problem of class imbalance, artificial images were generated by rotation enhancement and brightness enhancement methods. In this study, three different architectures based on the framework of ‘Inception-v3’ network were trained with the collected diseased images of maize using baseline training approach. The best-performed model achieved an overall classification accuracy of 95.99% with average recall of 95.96% on the separate test dataset. Furthermore, we compared the performance of the best-performing model with some pre-trained state-of-the-art models and presented the comparative results in this manuscript. The results reported that best-performing model performed quite better than the pre-trained models. This demonstrates the applicability of baseline training approach of the proposed model for better feature extraction and learning. Overall performance analysis suggested that the best-performed model is efficient in recognizing diseases of maize from in-field images even with varied backgrounds. © 2022, The Author(s).",,"crop; India; maize; Crops, Agricultural; Deep Learning; India; Zea mays"
"Harfouche A.L., Nakhle F., Harfouche A.H., Sardella O.G., Dart E., Jacobson D.","A primer on artificial intelligence in plant digital phenomics: embarking on the data to insights journey","10.1016/j.tplants.2022.08.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138810775&doi=10.1016%2fj.tplants.2022.08.021&partnerID=40&md5=665c87f0a161fcd15220e88057076218","Artificial intelligence (AI) has emerged as a fundamental component of global agricultural research that is poised to impact on many aspects of plant science. In digital phenomics, AI is capable of learning intricate structure and patterns in large datasets. We provide a perspective and primer on AI applications to phenome research. We propose a novel human-centric explainable AI (X-AI) system architecture consisting of data architecture, technology infrastructure, and AI architecture design. We clarify the difference between post hoc models and 'interpretable by design' models. We include guidance for effectively using an interpretable by design model in phenomic analysis. We also provide directions to sources of tools and resources for making data analytics increasingly accessible. This primer is accompanied by an interactive online tutorial. © 2022 Elsevier Ltd","AI system architecture; black box models; data analytics; digital phenomics; explainable artificial intelligence; interpretable by design models","artificial intelligence; human; technology; Artificial Intelligence; Humans; Phenomics; Technology"
"Harfouche A.L., Petousi V., Meilan R., Sweet J., Twardowski T., Altman A.","Promoting Ethically Responsible Use of Agricultural Biotechnology","10.1016/j.tplants.2020.12.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099616848&doi=10.1016%2fj.tplants.2020.12.015&partnerID=40&md5=750c3a9fe13b0d7c1891c7cbb3c27e94","Growing global demands for food, bioenergy, and specialty products, along with the threat posed by various environmental changes, present substantial challenges for agricultural production. Agricultural biotechnology offers a promising avenue for meeting these challenges; however, ethical and sociocultural concerns must first be addressed, to ensure widespread public trust and uptake. To be effective, we need to develop solutions that are ethically responsible, socially responsive, relevant to people of different cultural and social backgrounds, and conveyed to the public in a convincing and straightforward manner. Here, we highlight how ethical approaches, principled decision-making strategies, citizen-stakeholder participation, effective science communication, and bioethics education should be used to guide responsible use of agricultural biotechnology. © 2020 Elsevier Ltd","bioethics education; ethical reasoning; plant biotechnology; public and political engagement; responsible research and innovation; science communication","agriculture; bioethics; biotechnology; Agriculture; Bioethics; Biotechnology"
"Harfouche A.L., Jacobson D.A., Kainer D., Romero J.C., Harfouche A.H., Scarascia Mugnozza G., Moshelion M., Tuskan G.A., Keurentjes J.J.B., Altman A.","Accelerating Climate Resilient Plant Breeding by Applying Next-Generation Artificial Intelligence","10.1016/j.tibtech.2019.05.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067510759&doi=10.1016%2fj.tibtech.2019.05.007&partnerID=40&md5=d98ac02d1cd5db06ba7c99f97937137d","Breeding crops for high yield and superior adaptability to new and variable climates is imperative to ensure continued food security, biomass production, and ecosystem services. Advances in genomics and phenomics are delivering insights into the complex biological mechanisms that underlie plant functions in response to environmental perturbations. However, linking genotype to phenotype remains a huge challenge and is hampering the optimal application of high-throughput genomics and phenomics to advanced breeding. Critical to success is the need to assimilate large amounts of data into biologically meaningful interpretations. Here, we present the current state of genomics and field phenomics, explore emerging approaches and challenges for multiomics big data integration by means of next-generation (Next-Gen) artificial intelligence (AI), and propose a workable path to improvement. © 2019 Elsevier Ltd","augmented breeding; explainable AI; field phenomics; genomics; next-generation artificial intelligence; smart farming","Artificial intelligence; Ecosystems; Food supply; augmented breeding; Biological mechanisms; Environmental perturbations; field phenomics; Genomics; High-throughput genomics; Large amounts of data; smart farming; Data integration; agricultural worker; artificial intelligence; big data; climate; genomics; human; plant breeding; review; artificial intelligence; biomass; climate; climate change; crop; ecosystem; genetics; genomics; genotype; phenotype; plant breeding; procedures; Artificial Intelligence; Biomass; Climate; Climate Change; Crops, Agricultural; Ecosystem; Genomics; Genotype; Humans; Phenomics; Phenotype; Plant Breeding"
"Hassani H., Huang X., Silva E.","The human digitalisation journey: Technology first at the expense of humans?","10.3390/info12070267","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109373302&doi=10.3390%2finfo12070267&partnerID=40&md5=b6b7548492ce320ce1ac06e39fc5507b","The ongoing COVID-19 pandemic has enhanced the impact of digitalisation as a driver of transformation and advancements across almost every aspect of human life. With the majority actively embracing smart technologies and their benefits, the journey of human digitalisation has begun. Will human beings continue to remain solitary unaffected beings in the middle of the whirlpool—a gateway to the completely digitalised future? This journey of human digitalisation probably started much earlier, before we even realised. This paper, in the format of an objective review and discussion, aims to investigate the journey of human digitalisation, explore the reality of domination between technology and humans, provide a better understanding of the human value and human vulnerability in this fast transforming digital era, so as to achieve valuable and insightful suggestion on the future direction of the human digitalisation journey. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; Human digitalisation; Human value; Human vulnerability; Intelligence augmentation; Technology dependence","Digital era; Human being; Human lives; Human values; Smart technology"
"Haug J., Braun A., Zürn S., Kasneci G.","Change Detection for Local Explainability in Evolving Data Streams","10.1145/3511808.3557257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140844394&doi=10.1145%2f3511808.3557257&partnerID=40&md5=7a3a335f5d5258b71fdcf833b76638b9","As complex machine learning models are increasingly used in sensitive applications like banking, trading or credit scoring, there is a growing demand for reliable explanation mechanisms. Local feature attribution methods have become a popular technique for post-hoc and model-agnostic explanations. However, attribution methods typically assume a stationary environment in which the predictive model has been trained and remains stable. As a result, it is often unclear how local attributions behave in realistic, constantly evolving settings such as streaming and online applications. In this paper, we discuss the impact of temporal change on local feature attributions. In particular, we show that local attributions can become obsolete each time the predictive model is updated or concept drift alters the data generating distribution. Consequently, local feature attributions in data streams provide high explanatory power only when combined with a mechanism that allows us to detect and respond to local changes over time. To this end, we present CDLEEDS, a flexible and model-agnostic framework for detecting local change and concept drift. CDLEEDS serves as an intuitive extension of attribution-based explanation techniques to identify outdated local attributions and enable more targeted recalculations. In experiments, we also show that the proposed framework can reliably detect both local and global concept drift. Accordingly, our work contributes to a more meaningful and robust explainability in online machine learning. © 2022 ACM.","concept drift detection; explainable machine learning; local feature attributions; online machine learning","E-learning; Feature extraction; Learning systems; Concept drift detection; Concept drifts; Data stream; Explainable machine learning; Local feature; Local feature attribution; Machine-learning; Online machine learning; Online machines; Change detection"
"He Y., Gao Q., Ma Z.","A Crop Leaf Disease Image Recognition Method Based on Bilinear Residual Networks","10.1155/2022/2948506","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129971200&doi=10.1155%2f2022%2f2948506&partnerID=40&md5=91e639825ba45d3ee3b53f9788cfbfaa","Deep learning models are widely used in crop leaf disease image recognition. These models can be divided into two categories: global model and local model. The global model directly takes the whole leaf disease images as input to training and recognition. It can achieve end-to-end training and recognition, which is very convenient to use. But this kind of model cannot very accurately and completely extract the features from the very small diseased spots in the image. Before training and recognizing, the local model needs to extract the diseased spots part from the image by image segmentation technology. Then the local model takes the disease spots part images as input to training and recognition. Features extracted by local model are more accurate and complete. But this kind of model cannot achieve end-to-end training and recognition, and the image segmentation will bring additional overhead. Considering the disadvantage of global model and local model, we proposed a crop leaf disease image recognition method based on bilinear residual networks (named DIR-BiRN). DIR-BiRN extracts features by two residual networks feature extractors and then integrates the features by a bilinear pooling function. By this way, it can extract features more accurately and completely while achieving end-to-end training and recognition. Experiments on the PlantVillage dataset show that, when compared with the standard ResNet-18 model, the DIR-BiRN improves on accuracy performance, recall performance, precision performance, and F1-measure performance by averages of 0.2918, 0.81641, 0.59185, and 0.52151 percentage points, respectively. © 2022 Yun He et al.",,"Crops; Deep learning; Image segmentation; Crop leaves; End to end; Global models; Global-local; Images segmentations; Leaf disease; Learning models; Local model; Performance; Recognition methods; Image recognition"
"Heitlinger S., Houston L.","Algorithmic food justice: Co-designing more-than-human blockchain futures for the food commons","10.1145/3411764.3445655","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106704427&doi=10.1145%2f3411764.3445655&partnerID=40&md5=ebc389424fbf5ef66d25520858c0d7d1","The relationships that constitute the global industrial food system tend towards two dominant values that are creating unsustainable social and environmental inequalities. The frst is a human-centered perspective on food that privileges humans over all other species. The second is a view of food as a commodity to be traded for maximum economic value, rewarding a small number of shareholders. We present work that explores the unique algorithmic afordances of blockchain to create new types of value exchange and governance in the food system. We describe a project that used roleplay with urban agricultural communities to co-design blockchain-based food futures and explore the conditions for creating a thriving multispecies food commons.We discuss how the project helped rethink algorithmic food justice by reconfguring more-than-human values and reconfguring food as more-than-human commons. We also discuss some of the challenges and tensions arising from these explorations. © 2021 ACM.","Algorithmic governance; Blockchain; Commons; Food justice; More-than-human design; Posthuman; Sustainability","Agricultural robots; Blockchain; Financial markets; Human engineering; Co-designing; Co-designs; Economic values; Food system; Human values; Multi-species; Role play; Social and environmental; Fintech"
"Helmy M., Smith D., Selvarajoo K.","Systems biology approaches integrated with artificial intelligence for optimized metabolic engineering","10.1016/j.mec.2020.e00149","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096856817&doi=10.1016%2fj.mec.2020.e00149&partnerID=40&md5=557dc20408aab8bf24feaa76a3178cb7","Metabolic engineering aims to maximize the production of bio-economically important substances (compounds, enzymes, or other proteins) through the optimization of the genetics, cellular processes and growth conditions of microorganisms. This requires detailed understanding of underlying metabolic pathways involved in the production of the targeted substances, and how the cellular processes or growth conditions are regulated by the engineering. To achieve this goal, a large system of experimental techniques, compound libraries, computational methods and data resources, including multi-omics data, are used. The recent advent of multi-omics systems biology approaches significantly impacted the field by opening new avenues to perform dynamic and large-scale analyses that deepen our knowledge on the manipulations. However, with the enormous transcriptomics, proteomics and metabolomics available, it is a daunting task to integrate the data for a more holistic understanding. Novel data mining and analytics approaches, including Artificial Intelligence (AI), can provide breakthroughs where traditional low-throughput experiment-alone methods cannot easily achieve. Here, we review the latest attempts of combining systems biology and AI in metabolic engineering research, and highlight how this alliance can help overcome the current challenges facing industrial biotechnology, especially for food-related substances and compounds using microorganisms. © 2020 The Authors","Artificial intelligence; Food industry; Machine learning; Metabolic engineering; Systems biology","artificial intelligence; biotechnology; data mining; food industry; library; metabolic engineering; metabolomics; microorganism; multiomics; nonhuman; proteomics; review; systems biology; transcriptomics"
"Hermann E., Hermann G., Tremblay J.-C.","Ethical Artificial Intelligence in Chemical Research and Development: A Dual Advantage for Sustainability","10.1007/s11948-021-00325-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110142021&doi=10.1007%2fs11948-021-00325-6&partnerID=40&md5=1edb254f85cba781b488da55f9cf0447","Artificial intelligence can be a game changer to address the global challenge of humanity-threatening climate change by fostering sustainable development. Since chemical research and development lay the foundation for innovative products and solutions, this study presents a novel chemical research and development process backed with artificial intelligence and guiding ethical principles to account for both process- and outcome-related sustainability. Particularly in ethically salient contexts, ethical principles have to accompany research and development powered by artificial intelligence to promote social and environmental good and sustainability (beneficence) while preventing any harm (non-maleficence) for all stakeholders (i.e., companies, individuals, society at large) affected. © 2021, The Author(s).","Artificial intelligence; Ethics; Research and development; Sustainability","artificial intelligence; beneficence; human; Artificial Intelligence; Beneficence; Humans"
"Hernández V.A.S., Monroy R., Medina-Pérez M.A., Loyola-González O., Herrera F.","A Practical Tutorial for Decision Tree Induction",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105367299&partnerID=40&md5=4db206e6280c5a7e2abdfc285202163a","Experts from different domains have resorted to machine learning techniques to produce explainable models that support decision-making. Among existing techniques, decision trees have been useful in many application domains for classification. Decision trees can make decisions in a language that is closer to that of the experts. Many researchers have attempted to create better decision tree models by improving the components of the induction algorithm. One of the main components that have been studied and improved is the evaluation measure for candidate splits. In this article, we introduce a tutorial that explains decision tree induction. Then, we present an experimental framework to assess the performance of 21 evaluation measures that produce different C4.5 variants considering 110 databases, two performance measures, and 10× 10-fold cross-validation. Furthermore, we compare and rank the evaluation measures by using a Bayesian statistical analysis. From our experimental results, we present the first two performance rankings in the literature of C4.5 variants. Moreover, we organize the evaluation measures into two groups according to their performance. Finally, we introduce meta-models that automatically determine the group of evaluation measures to produce a C4.5 variant for a new database and some further opportunities for decision tree models. © 2021 ACM.","decision trees; Evaluation measures for candidate splits; induction algorithm; machine learning techniques","Decision trees; Learning systems; Trees (mathematics); 10-fold cross-validation; Decision tree induction; Decision tree models; Evaluation measures; Induction algorithms; Machine learning techniques; Performance measure; Performance rankings; Decision making"
"Hess P., Drüke M., Petri S., Strnad F.M., Boers N.","Physically constrained generative adversarial networks for improving precipitation fields from Earth system models","10.1038/s42256-022-00540-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139259154&doi=10.1038%2fs42256-022-00540-1&partnerID=40&md5=b6686c1a8eabd14a731a4be4fe2aaf12","Precipitation results from complex processes across many scales, making its accurate simulation in Earth system models (ESMs) challenging. Existing post-processing methods can improve ESM simulations locally but cannot correct errors in modelled spatial patterns. Here we propose a framework based on physically constrained generative adversarial networks to improve local distributions and spatial structure simultaneously. We apply our approach to the computationally efficient CM2Mc–LPJmL ESM. Our method outperforms existing ones in correcting local distributions and leads to strongly improved spatial patterns, especially regarding the intermittency of daily precipitation. Notably, a double-peaked Intertropical Convergence Zone, a common problem in ESMs, is removed. Enforcing a physical constraint to preserve global precipitation sums, the generative adversarial network can generalize to future climate scenarios unseen during training. Feature attribution shows that the generative adversarial network identifies regions where the ESM exhibits strong biases. Our method constitutes a general framework for correcting ESM variables and enables realistic simulations at a fraction of the computational cost. © 2022, The Author(s), under exclusive licence to Springer Nature Limited.",,"Climate models; Earth (planet); Earth system models; Geographical distribution; Complex Processes; Computationally efficient; Correct error; Earth system modeling; Intermittency; Local distributions; Modeling simulation; Postprocessing methods; Spatial patterns; Spatial structure; Generative adversarial networks"
"Himeur Y., Rimal B., Tiwary A., Amira A.","Using artificial intelligence and data fusion for environmental monitoring: A review and future perspectives","10.1016/j.inffus.2022.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133352034&doi=10.1016%2fj.inffus.2022.06.003&partnerID=40&md5=6d01935fe28cf2edf2fb201ee512e8ea","Analyzing satellite images and remote sensing (RS) data using artificial intelligence (AI) tools and data fusion strategies has recently opened new perspectives for environmental monitoring and assessment. This is mainly due to the advancement of machine learning (ML) and data mining approaches, which facilitate extracting meaningful information at a large scale from geo-referenced and heterogeneous sources. This paper presents the first review of AI-based methodologies and data fusion strategies used for environmental monitoring, to the best of the authors’ knowledge. The first part of the article discusses the main challenges of geographical image analysis. Thereafter, a well-designed taxonomy is introduced to overview the existing frameworks, which have been focused on: (i) detecting different environmental impacts, e.g. land cover land use (LULC) change, gully erosion susceptibility (GES), waterlogging susceptibility (WLS), and land salinity and infertility (LSI); (ii) analyzing AI models deployed for extracting the pertinent features from RS images in addition to data fusion techniques used for combining images and/or features from heterogeneous sources; (iii) describing existing publicly-shared and open-access datasets; (iv) highlighting most frequent evaluation metrics; and (v) describing the most significant applications of ML and data fusion for RS image analysis. This is followed by an overview of existing works and discussions highlighting some of the challenges, limitations and shortcomings. To provide the reader with insight into real-world applications, two case studies illustrate the use of AI for classifying LULC changes and monitoring the environmental impacts due to dams’ construction, where classification accuracies of 98.57% and 97.05% have been reached, respectively. Lastly, recommendations and future directions are drawn. © 2022 Elsevier B.V.","Artificial intelligence; Data fusion; Environmental monitoring; Evaluation metrics; Land cover and land use; Remote sensing images","Artificial intelligence; Classification (of information); Data fusion; Data mining; Environmental impact; Image analysis; Monitoring; Remote sensing; Data fusion strategy; Environmental Monitoring; Evaluation metrics; Heterogeneous sources; Image-analysis; Land cover; Land cover and land use; Machine data; Machine-learning; Remote sensing images; Land use"
"Hittner J.B., Fasina F.O., Hoogesteijn A.L., Piccinini R., Maciorowski D., Kempaiah P., Smith S.D., Rivas A.L.","Testing-Related and Geo-Demographic Indicators Strongly Predict COVID-19 Deaths in the United States during March of 2020","10.3967/bes2021.102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116026116&doi=10.3967%2fbes2021.102&partnerID=40&md5=a0597cc8b55d8bee5ec8f663a91eb2f2",[No abstract available],,
"Hitzler P., Janowicz K., Sharda A., Shimizu C.","Advancing agriculture through semantic data management","10.3233/SW-210433","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108581328&doi=10.3233%2fSW-210433&partnerID=40&md5=8b8740be57e421278ddd108127e06329",[No abstract available],,
"Ho N.X., Le T.-T.","Effects of variability in experimental database on machine-learning-based prediction of ultimate load of circular concrete-filled steel tubes","10.1016/j.measurement.2021.109198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102037214&doi=10.1016%2fj.measurement.2021.109198&partnerID=40&md5=df1febc9ba4d1e45c676376360f44ccf","This study investigates the performance and robustness of regression machine-learning models in the presence of variability in the experimental database. The main objective of this work is to predict the ultimate load of circular concrete-filled steel tubes. The simulations were designed by combining size of the learning dataset, random realizations and prediction models. The variability (i.e. probability density function of each variable) is propagated to the output response through the regression machine-learning models. Results show that such variability must be considered when training and testing regression machine-learning models. The performance and robustness of the prediction models are presented and discussed. Based on the most robust and efficient model, a prediction equation is proposed for practical use. After conducting a comparison investigation, the performance of the proposed equation is found superior to one of current models. Finally, the proposed equation is implemented in Excel and appended to this paper. © 2021 Elsevier Ltd","Circular concrete-filled steel tubes; Regression machine-learning models; Support vector machine; Ultimate load; Variability propagation","Concretes; Forecasting; Probability density function; Regression analysis; Support vector machines; Circular concrete-filled steel tube; Concrete-filled steel tubes; Experimental database; Machine learning models; Performance; Prediction model; Regression machine-learning model; Support vectors machine; Ultimate loads; Variability propagation; Tubular steel structures"
"Hoenigsberger F., Saranti A., Angerschmid A., Retzlaff C.O., Gollob C., Witzmann S., Nothdurft A., Kieseberg P., Holzinger A., Stampfer K.","Machine Learning and Knowledge Extraction to Support Work Safety for Smart Forest Operations","10.1007/978-3-031-14463-9_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136983207&doi=10.1007%2f978-3-031-14463-9_23&partnerID=40&md5=f99b462b2809f95a3185abc1842e9253","Forestry work is one of the most difficult and dangerous professions in all production areas worldwide - therefore, any kind of occupational safety and any contribution to increasing occupational safety plays a major role, in line with addressing sustainability goal SDG 3 (good health and well-being). Detailed records of occupational accidents and the analysis of these data play an important role in understanding the interacting factors that lead to occupational accidents and, if possible, adjusting them for the future. However, the application of machine learning and knowledge extraction in this domain is still in its infancy, so this contribution is also intended to serve as a starting point and test bed for the future application of artificial intelligence in occupational safety and health, particularly in forestry. In this context, this study evaluates the accident data of Österreichische Bundesforste AG (ÖBf), Austria’s largest forestry company, for the years 2005–2021. Overall, there are 2481 registered accidents, 9 of which were fatal. For the task of forecasting the absence hours due to an accident as well as the classification of fatal or non-fatal cases, decision trees, random forests and fully-connected neuronal networks were used. © 2022, IFIP International Federation for Information Processing.","Artificial Intelligence; Explainability; Explainable AI; Forestry; Human-in-the-Loop; Machine learning; Occupational accident","Accident prevention; Accidents; Decision trees; Extraction; Forestry; Neurons; Occupational risks; Explainability; Explainable AI; Forest operation; Human-in-the-loop; Knowledge extraction; Machine knowledge; Machine-learning; Occupational accident; Occupational safety; Work safety; Machine learning"
"Hogan M., Aouf N., Spencer P., Almond J.","Explainable Object Detection for Uncrewed Aerial Vehicles using KernelSHAP","10.1109/ICARSC55462.2022.9784772","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133019893&doi=10.1109%2fICARSC55462.2022.9784772&partnerID=40&md5=32144c7986956971ccb860c28c872ed7","While the field of object detection has seen remarkable performance gains since the incorporation of Deep Neural Networks (DNNs), a significant drawback in DNN detection algorithms is that they lack transparency, making their behaviour somewhat unpredictable. Without transparency, employing DNNs for on-board object detection on Uncrewed Aerial Vehicles (UAVs) could have massive societal and safety consequences. In this paper, we propose adopting a proven explainer, KernelSHAP, to provide visual explanations for bounding boxes produced by detection algorithms intended for on-board UAVs. Our explainer can identify the important parts of an image that assisted a given detection or contributed to a specific failure mode. We evaluate our explainer's discriminative ability on aerial imagery through a pointing metric and an automatic deletion/insertion metric. We further assess our explainer by intentionally introducing a bias to the dataset for it to detect and using that bias to simulate failure modes that can then be discovered using our explainer. © 2022 IEEE.",,"Aerial photography; Aircraft detection; Antennas; Deep neural networks; Object recognition; Signal detection; Transparency; Aerial imagery; Automatic deletions; Bounding-box; Detection algorithm; Discriminative ability; Network detections; Objects detection; Performance Gain; Uncrewed aerial vehicles; Object detection"
"Hogan M., Aouf P.N.","Towards Real Time Interpretable Object Detection for UAV Platform by Saliency Maps","10.1109/ROBIO54168.2021.9739366","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128202263&doi=10.1109%2fROBIO54168.2021.9739366&partnerID=40&md5=a3da5ca27561a4a23711a0a6be78b424","On-board object detection is an important requirement for Unmanned Aerial Vehicles (UAVs) when carrying out a variety of tasks such as obstacle avoidance, search and rescue, and automatic target recognition. One of the main difficulties of conducting object detection for a UAV is that, because the objects of interest are observed from altitude, this causes them to appear very small in images acquired from an onboard camera. In this work, we attempt to provide a solution to this difficulty, while also seeking to meet two other criteria that are important to the deployment of Artificial Intelligence with UAVs: firstly, the capability to operate in real-time; and secondly, the ability of the user to be able to trust the predictions it makes. To meet the challenge of small object detection we present the use of an image Tile Loader to enhance the capability of Deep Neural Network (DNN) style detectors, while minimising the processing time costs. Furthermore, we also introduce the practice of using Grad-CAM to provide better insights into a detection style architecture as a means to enhance trustworthiness. © 2021 IEEE.","Deep learning; Explainable AI; UAV Object Detection","Aircraft detection; Antennas; Automatic target recognition; Deep neural networks; Image enhancement; Object detection; Object recognition; Deep learning; Explainable AI; Objects detection; Obstacles avoidance; Onboard camera; Real- time; Saliency map; Search and rescue; Unmanned aerial vehicle object detection; Vehicle platforms; Unmanned aerial vehicles (UAV)"
"Holzinger A., Keiblinger K., Holub P., Zatloukal K., Müller H.","AI for life: Trends in artificial intelligence for biotechnology","10.1016/j.nbt.2023.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147548778&doi=10.1016%2fj.nbt.2023.02.001&partnerID=40&md5=e92588cefa544399b512279720b0cc26","Due to popular successes (e.g., ChatGPT) Artificial Intelligence (AI) is on everyone's lips today. When advances in biotechnology are combined with advances in AI unprecedented new potential solutions become available. This can help with many global problems and contribute to important Sustainability Development Goals. Current examples include Food Security, Health and Well-being, Clean Water, Clean Energy, Responsible Consumption and Production, Climate Action, Life below Water, or protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss. AI is ubiquitous in the life sciences today. Topics include a wide range from machine learning and Big Data analytics, knowledge discovery and data mining, biomedical ontologies, knowledge-based reasoning, natural language processing, decision support and reasoning under uncertainty, temporal and spatial representation and inference, and methodological aspects of explainable AI (XAI) with applications of biotechnology. In this pre-Editorial paper, we provide an overview of open research issues and challenges for each of the topics addressed in this special issue. Potential authors can directly use this as a guideline for developing their paper. © 2023 The Authors","Artificial Intelligence; Biotechnology; Deep Learning; Digital Transformation; Machine Learning","Biotechnology; Data Analytics; Data mining; Decision support systems; Deep learning; E-learning; Food supply; Knowledge based systems; Learning algorithms; Learning systems; Natural language processing systems; 'current; Clean energy; Clean waters; Deep learning; Digital transformation; Food security; Global problems; Machine-learning; Sustainable use; Well being; Biodiversity; Article; artificial intelligence; big data; bioinformatics; biotechnology; data mining; decision support system; human; knowledge discovery; machine learning; medical ontology; natural language processing; trust"
"Holzinger A., Saranti A., Angerschmid A., Retzlaff C.O., Gronauer A., Pejakovic V., Medel-Jimenez F., Krexner T., Gollob C., Stampfer K.","Digital Transformation in Smart Farm and Forest Operations Needs Human-Centered AI: Challenges and Future Directions","10.3390/s22083043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128181274&doi=10.3390%2fs22083043&partnerID=40&md5=f082f34f2e8fd6fc475c4ab30b64ac26","The main impetus for the global efforts toward the current digital transformation in almost all areas of our daily lives is due to the great successes of artificial intelligence (AI), and in particular, the workhorse of AI, statistical machine learning (ML). The intelligent analysis, modeling, and management of agricultural and forest ecosystems, and of the use and protection of soils, already play important roles in securing our planet for future generations and will become irreplaceable in the future. Technical solutions must encompass the entire agricultural and forestry value chain. The process of digital transformation is supported by cyber-physical systems enabled by advances in ML, the availability of big data and increasing computing power. For certain tasks, algorithms today achieve performances that exceed human levels. The challenge is to use multimodal information fusion, i.e., to integrate data from different sources (sensor data, images, *omics), and explain to an expert why a certain result was achieved. However, ML models often react to even small changes, and disturbances can have dramatic effects on their results. Therefore, the use of AI in areas that matter to human life (agriculture, forestry, climate, health, etc.) has led to an increased need for trustworthy AI with two main components: explainability and robustness. One step toward making AI more robust is to leverage expert knowledge. For example, a farmer/forester in the loop can often bring in experience and conceptual understanding to the AI pipeline—no AI can do this. Consequently, human-centered AI (HCAI) is a combination of “artificial intelligence” and “natural intelligence” to empower, amplify, and augment human performance, rather than replace people. To achieve practical success of HCAI in agriculture and forestry, this article identifies three important frontier research areas: (1) intelligent information fusion; (2) robotics and embodied intelligence; and (3) augmentation, explanation, and verification for trusted decision support. This goal will also require an agile, human-centered design approach for three generations (G). G1: Enabling easily realizable applications through immediate deployment of existing technology. G2: Medium-term modification of existing technology. G3: Advanced adaptation and evolution beyond state-of-the-art. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","AI for good; artificial intelligence; cyber-physical systems; human-centered AI; machine learning; precision farming; precision forestry; sensors; smart farming; smart forestry","Cyber Physical System; Decision support systems; Ecosystems; Embedded systems; Information fusion; Knowledge management; Machine learning; Metadata; 'current; Artificial intelligence for good; Digital transformation; Forest operation; Human-centered artificial intelligence; Precision forestry; Precision-farming; Sensor; Smart farming; Smart forestry; Forestry; agricultural land; artificial intelligence; ecosystem; forest; human; robotics; Artificial Intelligence; Ecosystem; Farms; Forests; Humans; Robotics"
"Holzinger A., Goebel R., Fong R., Moon T., Müller K.-R., Samek W.","xxAI - Beyond Explainable Artificial Intelligence","10.1007/978-3-031-04083-2_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128906717&doi=10.1007%2f978-3-031-04083-2_1&partnerID=40&md5=8cf203855f78513aff15d563922a3324","The success of statistical machine learning from big data, especially of deep learning, has made artificial intelligence (AI) very popular. Unfortunately, especially with the most successful methods, the results are very difficult to comprehend by human experts. The application of AI in areas that impact human life (e.g., agriculture, climate, forestry, health, etc.) has therefore led to an demand for trust, which can be fostered if the methods can be interpreted and thus explained to humans. The research field of explainable artificial intelligence (XAI) provides the necessary foundations and methods. Historically, XAI has focused on the development of methods to explain the decisions and internal mechanisms of complex AI systems, with much initial research concentrating on explaining how convolutional neural networks produce image classification predictions by producing visualizations which highlight what input patterns are most influential in activating hidden units, or are most responsible for a model’s decision. In this volume, we summarize research that outlines and takes next steps towards a broader vision for explainable AI in moving beyond explaining classifiers via such methods, to include explaining other kinds of models (e.g., unsupervised and reinforcement learning models) via a diverse array of XAI techniques (e.g., question-and-answering systems, structured explanations). In addition, we also intend to move beyond simply providing model explanations to directly improving the transparency, efficiency and generalization ability of models. We hope this volume presents not only exciting research developments in explainable AI but also a guide for what next areas to focus on within this fascinating and highly relevant research field as we enter the second decade of the deep learning revolution. This volume is an outcome of the ICML 2020 workshop on “XXAI: Extending Explainable AI Beyond Deep Models and Classifiers.” © 2022, The Author(s).","Artificial intelligence; Explainability; Explainable AI; Machine learning","Convolutional neural networks; Deep learning; Reinforcement learning; Artificial intelligence systems; Classification prediction; Convolutional neural network; Explainability; Explainable artificial intelligence; Human expert; Human lives; Images classification; Research fields; Statistical machine learning; Forestry"
"Holzinger A., Kargl M., Kipperer B., Regitnig P., Plass M., Muller H.","Personas for Artificial Intelligence (AI) an Open Source Toolbox","10.1109/ACCESS.2022.3154776","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125724582&doi=10.1109%2fACCESS.2022.3154776&partnerID=40&md5=04b703ff43dfeb4bf376e1fc567d1059","Personas have successfully supported the development of classical user interfaces for more than two decades by mapping users' mental models to specific cons. The rapid proliferation of Artificial Intelligence (AI) applications makes it necessary to create new approaches for future human-AI interfaces. Human-AI interfaces differ from classical human-computer interfaces in many ways, such as gaining some degree of human-like cognitive, self-executing, and self-adaptive capabilities and autonomy, and generating unexpected outputs that require non-deterministic interactions. Moreover, the most successful AI approaches are so-called 'black box' systems, where the technology and the machine learning process are opaque to the user and the AI output is far not intuitive. This work shows how the personas method can be adapted to support the development of human-centered AI applications, and we demonstrate this on the example of a medical con. This work is - to our knowledge - the first to provide personas for AI using an openly available Personas for AI toolbox. The toolbox contains guidelines and material supporting persona development for AI as well as templates and pictures for persona visualisation. It is ready to use and freely available to the international research and development community. Additionally, an example from medical AI is provided as a best practice use case. This work is intended to help foster the development of novel human-AI interfaces that will be urgently needed in the near future. © 2013 IEEE.","Artificial intelligence; human-AI interface; personas","Artificial intelligence; Learning systems; Adaptive autonomy; Artificial intelligence interface; Human computer interfaces; Human like; Human&#x2013;; Mental model; New approaches; Open source toolboxes; Persona; Self adaptive capabilities; User interfaces"
"Holzinger A.","The Next Frontier: AI We Can Really Trust","10.1007/978-3-030-93736-2_33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126192307&doi=10.1007%2f978-3-030-93736-2_33&partnerID=40&md5=0b72544816d6578ae936a20ea652b8b0","Enormous advances in the domain of statistical machine learning, the availability of large amounts of training data, and increasing computing power have made Artificial Intelligence (AI) very successful. For certain tasks, algorithms can even achieve performance beyond the human level. Unfortunately, the most powerful methods suffer from the fact that it is difficult to explain why a certain result was achieved on the one hand, and that they lack robustness on the other. Our most powerful machine learning models are very sensitive to even small changes. Perturbations in the input data can have a dramatic impact on the output and lead to entirely different results. This is of great importance in virtually all critical domains where we suffer from low data quality, i.e. we do not have the expected i.i.d. data. Therefore, the use of AI in domains that impact human life (agriculture, climate, health,..) has led to an increased demand for trustworthy AI. Explainability is now even mandatory due to regulatory requirements in sensitive domains such as medicine, which requires traceability, transparency and interpretability capabilities. One possible step to make AI more robust is to combine statistical learning with knowledge representations. For certain tasks, it can be advantageous to use a human in the loop. A human expert can - sometimes, of course not always - bring experience, domain knowledge and conceptual understanding to the AI pipeline. Such approaches are not only a solution from a legal point of view, but in many application areas the “why” is often more important than a pure classification result. Consequently, both explainability and robustness can promote reliability and trust and ensure that humans remain in control, thus complementing human intelligence with artificial intelligence. © 2021, Springer Nature Switzerland AG.","Artificial intelligence; Explainable AI; Human-in-the-loop; Robustness; Trust","Domain Knowledge; Machine learning; Robustness (control systems); Computing power; Explainable artificial intelligence; Human levels; Human-in-the-loop; Large amounts; Performance; Robustness; Statistical machine learning; Training data; Trust; Knowledge representation"
"Holzinger A., Weippl E., Tjoa A.M., Kieseberg P.","Digital Transformation for Sustainable Development Goals (SDGs) - A Security, Safety and Privacy Perspective on AI","10.1007/978-3-030-84060-0_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115124541&doi=10.1007%2f978-3-030-84060-0_1&partnerID=40&md5=052104a30c7d79f502c48dcacfb1aebf","The main driver of the digital transformation currently underway is undoubtedly artificial intelligence (AI). The potential of AI to benefit humanity and its environment is undeniably enormous. AI can definitely help find new solutions to the most pressing challenges facing our human society in virtually all areas of life: from agriculture and forest ecosystems that affect our entire planet, to the health of every single human being. However, this article highlights a very different aspect. For all its benefits, the large-scale adoption of AI technologies also holds enormous and unimagined potential for new kinds of unforeseen threats. Therefore, all stakeholders, governments, policy makers, and industry, together with academia, must ensure that AI is developed with these potential threats in mind and that the safety, traceability, transparency, explainability, validity, and verifiability of AI applications in our everyday lives are ensured. It is the responsibility of all stakeholders to ensure the use of trustworthy and ethically reliable AI and to avoid the misuse of AI technologies. Achieving this will require a concerted effort to ensure that AI is always consistent with human values and includes a future that is safe in every way for all people on this planet. In this paper, we describe some of these threats and show that safety, security and explainability are indispensable cross-cutting issues and highlight this with two exemplary selected application areas: smart agriculture and smart health. © 2021, IFIP International Federation for Information Processing.","AI risks; AI threats; Artificial intelligence; Digital transformation; Explainability; Explainable AI; Resilience; Robustness; Safety; Security; Smart agriculture; Smart health","Agricultural robots; Agriculture; Data mining; Ecosystems; Extraction; Health risks; Machine learning; Sustainable development; AI applications; AI Technologies; Application area; Cross-cutting; Digital transformation; Forest ecosystem; Potential threats; Smart agricultures; Accident prevention"
"Hossain S.K.S., Ali S.S., Rushd S., Ayodele B.V., Cheng C.K.","Interaction effect of process parameters and Pd-electrocatalyst in formic acid electro-oxidation for fuel cell applications: Implementing supervised machine learning algorithms","10.1002/er.7602","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122132352&doi=10.1002%2fer.7602&partnerID=40&md5=c7ec810672fc706806ddbade676270e8","The increasing interest in renewable and sustainable energy production as a means of attaining net-zero carbon emissions in the near future has spurred research attention in the development of fuel cells that convert chemical energy to electrical energy. In this study machine learning algorithms namely Support Vector Machine (SVM) regression, Regression Trees, and Gaussian Process Regression (GPR) were configured for modeling the effect of palladium supported on carbon nanotube used for formic acid electro-oxidation. The effect of process parameters such as the amount of palladium, the amount of sodium tetrahydridoborate (NaBH4), amount of water, and the electro-oxidation reaction time on the formic acid electro-oxidation to generate current density was evaluated by the various models. The trained SVM regressions models incorporated with linear, quadratic, cubic, and fine Gaussian kernel functions, as well as the Boosted and the Bagged regression Trees, did not show impressive performance as indicated by a low coefficient of determination (R2) &lt; 0.5 and high prediction errors. However, the SVM regression modeled with Median Gaussian kernel function, the GPR incorporated with rotational quadratic and squared exponential kernel functions displayed higher performance with R2 &gt; 0.6 but less than 0.7. The optimization of the SVM, Ensemble Tree, and GPR models resulted in significant performance with R2 of 0.82, 0.83, and 0.85, respectively. The sensitivity analysis using modified Garson algorithm to determine how each of these parameters influences the predicted current density from the direct formic acid fuel cells showed that the level of importance of the input parameters on the predicted current density can be ranked as Pd composition &gt; electro-oxidation time &gt; amount of water &gt; NaBH4 proportion. © 2022 John Wiley & Sons Ltd.","direct fuel cells; electro-oxidation; formic acid; Gaussian process regression; regression tree; support vector machine","Carbon nanotubes; Electrocatalysts; Electrooxidation; Forestry; Formic acid; Gaussian distribution; Learning algorithms; Palladium; Parameter estimation; Regression analysis; Support vector machines; Formic acid electrooxidation; Fuel cell application; Gaussian kernel functions; Gaussian process regression; Interaction effect; Machine learning algorithms; Performance; Process parameters; Regression trees; Support vector machine regressions; Sensitivity analysis"
"Hossain S.M.M., Tanjil M.M.M., Ali M.A.B., Islam M.Z., Islam M.S., Mobassirin S., Sarker I.H., Islam S.M.R.","Rice Leaf Diseases Recognition Using Convolutional Neural Networks","10.1007/978-3-030-65390-3_23","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101873517&doi=10.1007%2f978-3-030-65390-3_23&partnerID=40&md5=2e86f16f4a4fd54200538b2a3363ae5d","The rice leaf suffers from several bacterial, viral, or fungal diseases and these diseases reduce rice production significantly. To sustain rice demand for a vast population globally, the recognition of rice leaf diseases is crucially important. However, recognition of rice leaf disease is limited to the image backgrounds and image capture conditions. The convolutional neural network (CNN) based model is a hot research topic in the field of rice leaf disease recognition. But the existing CNN-based models drop in recognition rates severely on independent dataset and are limited to the learning of large scale network parameters. In this paper, we propose a novel CNN-based model to recognize rice leaf diseases by reducing the network parameters. Using a novel dataset of 4199 rice leaf disease images, a number of CNN-based models are trained to identify five common rice leaf diseases. The proposed model achieves the highest training accuracy of 99.78% and validation accuracy of 97.35%. The effectiveness of the proposed model is evaluated on a set of independent rice leaf disease images with the best accuracy of 97.82% with an area under curve (AUC) of 0.99. Besides that, binary classification experiments have been carried out and our proposed model achieves recognition rates of 97%, 96%, 96%, 93%, and 95% for Blast, Brownspot, Bacterial Leaf Blight, Sheath Blight and Tungro, respectively. These results demonstrate the effectiveness and superiority of our approach in comparison to the state-of-the-art CNN-based rice leaf disease recognition models. © 2020, Springer Nature Switzerland AG.","Convolutional neural networks; Image recognition; Rice leaf diseases","Convolution; Data mining; Large dataset; Binary classification; Hot research topics; Large-scale network; Network parameters; Recognition models; Rice production; State of the art; Training accuracy; Convolutional neural networks"
"Hosseiny B., Abdi A.M., Jamali S.","Urban land use and land cover classification with interpretable machine learning – A case study using Sentinel-2 and auxiliary data","10.1016/j.rsase.2022.100843","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139016934&doi=10.1016%2fj.rsase.2022.100843&partnerID=40&md5=5821d14439b927f34bfceada849a07b9","The European Commission launch of the twin Sentinel-2 satellites provides new opportunities for land use and land cover (LULC) classification because of the ready availability of their data and their enhanced spatial, temporal and spectral resolutions. The rapid development of machine learning over the past decade led to data-driven models being at the forefront of high accuracy predictions of the physical world. However, the contribution of the driving variables behind these predictions cannot be explained beyond generalized metrics of overall performance. Here, we compared the performance of three shallow learners (support vector machines, random forest, and extreme gradient boosting) as well as two deep learners (a convolutional neural network and a residual network with 50 layers) in and around the city of Malmö in southern Sweden. Our complete analysis suite involved 141 input features, 85 scenarios, and 8 LULC classes. We explored the interpretability of the five learners using Shapley additive explanations to better understand feature importance at the level of individual LULC classes. The purpose of class-level feature importance was to identify the most parsimonious combination of features that could reasonably map a particular class and enhance overall map accuracy. We showed that not only do overall accuracies increase from shallow (mean = 84.64%) to deep learners (mean = 92.63%) but that the number of explanatory variables required to obtain maximum accuracy decreases along the same gradient. Furthermore, we demonstrated that class-level importance metrics can be successfully identified using Shapley additive explanations in both shallow and deep learners, which allows for a more detailed understanding of variable importance. We show that for certain LULC classes there is a convergence of variable importance across all the algorithms, which helps explain model predictions and aid the selection of more parsimonious models. The use of class-level feature importance metrics is still new in LULC classification, and this study provides important insight into the potential of more nuanced importance metrics. © 2022 The Author(s)","Artificial intelligence; Convolutional neural networks; Deep learning; Explainable AI; Shapley; Variable importance",
"Houda Z.A.E., Brik B., Khoukhi L.","'Why Should I Trust Your IDS?': An Explainable Deep Learning Framework for Intrusion Detection Systems in Internet of Things Networks","10.1109/OJCOMS.2022.3188750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134241547&doi=10.1109%2fOJCOMS.2022.3188750&partnerID=40&md5=f6122575f8a2437e45aeb7826c3b99d0","Internet of Things (IoT) is an emerging paradigm that is turning and revolutionizing worldwide cities into smart cities. However, this emergence is accompanied with several cybersecurity concerns due mainly to the data sharing and constant connectivity of IoT networks. To address this problem, multiple Intrusion Detection Systems (IDSs) have been designed as security mechanisms, which showed their efficiency in mitigating several IoT-related attacks, especially when using deep learning (DL) algorithms. Indeed, Deep Neural Networks (DNNs) significantly improve the detection rate of IoT-related intrusions. However, DL-based models are becoming more and more complex, and their decisions are hardly interpreted by users, especially companies' executive staff and cybersecurity experts. Hence, the corresponding users cannot neither understand and trust DL models decisions, nor optimize their decisions (users) based on DL models outputs. To overcome these limits, Explainable Artificial Intelligence (XAI) is an emerging paradigm of Artificial Intelligence (AI), that provides a set of techniques to help interpreting and understanding predictions made by DL models. Thus, XAI enables to explain the decisions of DL-based IDSs to make them interpretable by cybersecurity experts. In this paper, we design a new XAI-based framework to give explanations to any critical DL-based decisions for IoT-related IDSs. Our framework relies on a novel IDS for IoT networks, that we also develop by leveraging deep neural network, to detect IoT-related intrusions. In addition, our framework uses three main XAI techniques (i.e., RuleFit, Local Interpretable Model-Agnostic Explanations (LIME), and SHapley Additive exPlanations (SHAP)), on top of our DNN-based model. Our framework can provide both local and global explanations to optimize the interpretation of DL-based decisions. The local explanations target a single/particular DL output, while global explanations focus on deducing the most important features that have conducted to each made decision (e.g., intrusion detection). Thus, our proposed framework introduces more transparency and trust between the decisions made by our DL-based IDS model and cybersecurity experts. Both NSL-KDD and UNSW-NB15 datasets are used to validate the feasibility of our XAI framework. The experimental results show the efficiency of our framework to improve the interpretability of the IoT IDS against well-known IoT attacks, and help the cybersecurity experts get a better understanding of IDS decisions. © 2020 IEEE.","deep learning; explainable artificial intelligence; Internet of Things; intrusion detection system; local and global explanations","Computer architecture; Computer crime; Cybersecurity; Deep neural networks; Internet of things; Lime; Network security; Cyber security; Deep learning; Explainable artificial intelligence; Intrusion Detection Systems; Intrusion-Detection; Learning frameworks; Learning models; Local and global explanation; Predictive models; Intrusion detection"
"Housny H., Chater E.A., Fadil H.E.","Observer-based enhanced anfis control for a quadrotor UAV","10.15866/iremos.v14i1.18991","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103047334&doi=10.15866%2firemos.v14i1.18991&partnerID=40&md5=5a7944748762c207e53b9cbbf6904ec8","This paper introduces a new approach for optimizing the Adaptive Network Fuzzy Inference System (ANFIS) with the (metaheuristic) particle swarm optimization (PSO) algorithm to solve a trajectory tracking problem for a UAV quadrotor system. In this work, the input-output dataset is collected from the quadrotor's time response from a Proportional Integral Derivative (PID) controller. Then, before its use in the ANFIS algorithm, the collected dataset is optimized using the PSO algorithm. Moreover, an integral control action is integrated into the proposed ANFIS controller to ensure disturbance rejection. A suitable high gain observer is utilized in estimating unmeasured states for translational and rotational motions of the quadrotor system. Compared to a conventional ANFIS and traditional PID controllers, the results of two simulation tests demonstrate the efficiency and robustness of the proposed new output-feedback PSO-ANFIS controller. © 2021 Praise Worthy Prize S.r.l.-All rights reserved.","ANFIS; High Gain State Observer; PSO; Quadrotor Tracking Control",
"How M.-L., Chan Y.J., Cheah S.-M.","Predictive insights for improving the resilience of global food security using artificial intelligence","10.3390/SU12156272","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089903094&doi=10.3390%2fSU12156272&partnerID=40&md5=fc5ec9f1bd01003b55debf6c5ad24eb6","Unabated pressures on food systems affect food security on a global scale. A human-centric artificial intelligence-based probabilistic approach is used in this paper to perform a unified analysis of data from the Global Food Security Index (GFSI). The significance of this intuitive probabilistic reasoning approach for predictive forecasting lies in its simplicity and user-friendliness to people who may not be trained in classical computer science or in software programming. In this approach, predictive modeling using a counterfactual probabilistic reasoning analysis of the GFSI dataset can be utilized to reveal the interplay and tensions between the variables that underlie food affordability, food availability, food quality and safety, and the resilience of natural resources. Exemplars are provided in this paper to illustrate how computational simulations can be used to produce forecasts of good and bad conditions in food security using multi-variant optimizations. The forecast of these future scenarios is useful for informing policy makers and stakeholders across domain verticals, so they can make decisions that are favorable to global food security. © 2020 by the authors.","AI for social good; Artificial intelligence; Bayesian; Cognitive scaffolding; Counterfactual; Global food security index; Machine learning; Predictive modeling; Resilience; Sustainability","artificial intelligence; computer simulation; data set; food availability; food quality; food security; optimization; probability; software; stakeholder"
"Hu H., Kantardzic M., Sethi T.S.","No Free Lunch Theorem for concept drift detection in streaming data classification: A review","10.1002/widm.1327","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068528915&doi=10.1002%2fwidm.1327&partnerID=40&md5=4784307b8e374a939c6fd5d1891f9f1c","Many real-world data mining applications have to deal with unlabeled streaming data. They are unlabeled because the sheer volume of the stream makes it impractical to label a significant portion of the data. The data streams can evolve over time and these changes are called concept drifts. Concept drifts have different characteristics, which can be used to categorize them into different types. A trade-off between performance and cost exists among many concept drift detection approaches. On the one hand, high accuracy detection approach usually requires labeled data, possibly involving high cost for labeling. On the other hand, a variety of methods have been devoted to the topic of concept drift detection with unlabeled data, but these approaches often are most suited for only a subset of the concept drift types. The objective of this survey is to present these methods, categorize them and give recommendations of usage based on their behaviors under different types of concept drift. This article is categorized under: Fundamental Concepts of Data and Knowledge > Data Concepts Fundamental Concepts of Data and Knowledge > Key Design Issues in Data Mining Explainable AI > Classification. © 2019 Wiley Periodicals, Inc.","classification; concept drift; data stream; unlabeled samples","Data mining; Economic and social effects; Palmprint recognition; Concept drifts; Data mining applications; Data stream; Detection approach; Fundamental concepts; No free lunch theorem; Unlabeled data; Unlabeled samples; Classification (of information)"
"Hu M., Zhao B., Suhendri S., Cao J., Wang Q., Riffat S., Yang R., Su Y., Pei G.","Experimental study on a hybrid solar photothermic and radiative cooling collector equipped with a rotatable absorber/emitter plate","10.1016/j.apenergy.2021.118096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118510874&doi=10.1016%2fj.apenergy.2021.118096&partnerID=40&md5=56d56e022515d632b90247e7a4fbda32","Taking the frigid outer space as the heat sink, a terrestrial body can cool itself to a sub-ambient temperature via radiative sky cooling (RC) scheme. However, poor seasonal and regional adaptabilities and low cooling power density of the RC technology confine its effective applications only in hot seasons and regions with RC-friendly ambient conditions. Similarly, a solar thermal collector cannot work at night and is of little value when heat is needless. To tackle these challenges, a hybrid solar photothermic and radiative cooling (PT-RC) collector equipped with a rotatable absorber/emitter panel is proposed and experimentally investigated. This dual-mode collector can flexibly switch between PT and RC to match specific energy demands in different scenarios. The daily solar thermal efficiency of the PT-RC system at zero-reduced temperature reached 50.4%, a typical level of flat-plate solar water heating systems. The PT-RC system could not provide cooling energy during most daytime hours. However, the system could easily achieve nighttime cooling, with the cooling power of the collector decreasing from about 60 to 50 W/m2 as the circulated water being continuously cooled down from around 20 to 12 °C. The average nocturnal cooling power of the PT-RC collector ranged from 30.5 to 57.5 W/m2 in a multi-night RC test. This rotatable PT-RC collector offers a new strategy to flexibly deliver heat and coldness in a renewable and environmental-friendly manner and shows the potential of smart thermal management in buildings, vehicles, agriculture, etc. © 2021 Elsevier Ltd","Passive cooling; Radiative cooling; Rotatable; Solar collector; Solar energy","Meteorology; Solar collectors; Solar heating; Cooling power; Cooling power density; Cooling scheme; Cooling technology; Outer space; Passive cooling; Photothermics; Radiative cooling; Radiative cooling system; Rotatable; Solar energy; ambient air; cooling; energy flux; heating; solar power; temperature effect"
"Hu X., Shi L., Lin G., Lin L.","Comparison of physical-based, data-driven and hybrid modeling approaches for evapotranspiration estimation","10.1016/j.jhydrol.2021.126592","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109173566&doi=10.1016%2fj.jhydrol.2021.126592&partnerID=40&md5=446e32bb4e567fafaf8a2d3437be78ba","Obtaining accurate estimates of evapotranspiration is a key issue in many fields like hydrology, ecology, and agriculture. There exist different ways, including physical-based and data-driven approaches, to estimate evapotranspiration. Here, the physical-based model (the surface energy balance system, SEBS), data-driven models (using three machine learning techniques, deep neural network (DNN), random forest (RF), and symbolic regression (SR)), and hybrid model were compared using the FLUXNET2015 dataset. More importantly, different search strategies were investigated to optimize the network architecture and to explore the maximum accuracy of data-driven models. The Shapley additive explanations (SHAP) was introduced to quantify the contributions of input features to evapotranspiration estimation. The results show that there is a large error in the SEBS model with RMSE of 121 W m−2, while the data-driven models acquire the best evapotranspiration estimation with RMSE of 32–53 W m−2. The hybrid approach, whose RMSE is 60 W m−2, improves the SEBS model but still underperforms data-driven models. The complexity of data-driven models influences the accuracy of evapotranspiration estimations. By optimizing the network architecture, DNN and RF obtain results with similar precision. But the performance of SR, which generates a simple algebraic formula for evapotranspiration estimation, is significantly degraded. SHAP reveals that all models regard net radiation as the most crucial feature. The SEBS and hybrid models attach much importance to temperature and humidity. Three data-driven models learn the different relationships between input features and evapotranspiration. The DNN-based model is likely to learn a relatively correct relationship among the data-driven models because it has a similar feature importances pattern with physical-based and hybrid models. © 2021","Data-driven; Evapotranspiration; Hybrid modeling; Physical-based","Decision trees; Evapotranspiration; Network architecture; Data driven; Data driven modelling; Hybrid modelling; Neural-networks; Physical based modeling; Physical-based; Random forests; Surface energy balance systems; Symbolic regression; Systems modelling; Deep neural networks; accuracy assessment; comparative study; energy balance; estimation method; evapotranspiration; machine learning; numerical model; physical analysis"
"Hu Y., Long G., Liu J.","Real-time data transmission of cross-border e-commerce based on big data considering data complexity","10.1109/ICSSIT53264.2022.9716409","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127341957&doi=10.1109%2fICSSIT53264.2022.9716409&partnerID=40&md5=813804cec956d803e4a52c237c787676","Real-time data transmission of the cross-border e-commerce based on big data considering data complexity is studied in the paper. Wireless communication technology has been applied to many measurement and control sites and plays a great role. Because wireless data communication does not need wiring, it has fast layout and good expansibility, and has incomparable convenience compared with the wired data communication. Considering this basis feature, this paper will then consider the integration of the mentioned technique to revise the traditional data complexity estimation model. The function of the terminal device layer is to provide a consistent access interface for the kernel to call, so that the kernel does not have to consider the type of specific terminal when operating the serial port. With this theoretical basis, the novel safety guarantee model is considered to finalize the big data system. The experiment and application scenarios are selected as the cross-border e-commerce systems. © 2022 IEEE","cross-border e-commerce; Data complexity; data structure; data transmission; real-time data","Convolutional codes; Data communication systems; Data transfer; Electronic commerce; Cross-border; Cross-border e-commerce; Data complexity; Data-transmission; E- commerces; Measurement and control; Measurement sites; Real time data transmission; Real-time data; Wireless communication technology; Big data"
"Huang L., Cronan D., Kliskey A.","Modeling of Landscape Change and Tele-Coupling in Local Socio-Ecological Systems: A Simulation of Land Use Change and Recreational Activities in Southern Idaho, United States","10.23919/ANNSIM52504.2021.9552108","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117391335&doi=10.23919%2fANNSIM52504.2021.9552108&partnerID=40&md5=38df097aef0ec61869269f7a0c61cf24","The modeling of landscape change and socio-ecological systems (SES) tends to ignore the interactions across distance and boundaries. To fill the gap, this research analyzes landscape change by considering the tele-coupling effects at the local scale between Owyhee county and Treasure Valley in Idaho, United States. The spatial distribution of recreational activities in Owyhee county are modeled by Integrated Valuation of Ecosystem Services and Tradeoffs (InVEST). Land use and cover change (LUCC) are simulated using Multi-Layer Perceptron Neural Network (MLPNN). Results show that the tele-coupling effects have significant impacts on the nature-based recreation in Owyhee county. With the tele-coupling effects, MLPNN has achieved a high overall accuracy and kappa coefficient in LUCC. The findings suggest that the tele-coupling effects should be incorporated into the modeling of landscape change and SES. This study also provides policy implications for land management and stakeholder involvement in accommodating landscape change. © 2021 SCS.","land use change; landscape change; machine learning; recreation; tele-coupling","Agricultural robots; Ecosystems; Machine learning; Multilayer neural networks; Network layers; Public policy; Across distance; Coupling effect; Land use and cover change; Landscape changes; Landuse change; Multilayer perceptrons neural networks (MLPs); Recreation; Recreational activities; Socio-ecological systems; Tele-coupling; Land use"
"Huang L., Cronan D., Kliskey A.","Modeling of landscape change and tele-coupling in local socioecological systems: A simulation of land use change and recreational activities in Southern Idaho, United States",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118563136&partnerID=40&md5=cee4ade2c64612c3ed48bb4f1ac44831","The modeling of landscape change and socio-ecological systems (SES) tends to ignore the interactions across distance and boundaries. To fill the gap, this research analyzes landscape change by considering the tele-coupling effects at the local scale between Owyhee county and Treasure Valley in Idaho, United States. The spatial distribution of recreational activities in Owyhee county are modeled by Integrated Valuation of Ecosystem Services and Tradeoffs (InVEST). Land use and cover change (LUCC) are simulated using Multi-Layer Perceptron Neural Network (MLPNN). Results show that the tele-coupling effects have significant impacts on the nature-based recreation in Owyhee county. With the tele-coupling effects, MLPNN has achieved a high overall accuracy and kappa coefficient in LUCC. The findings suggest that the tele-coupling effects should be incorporated into the modeling of landscape change and SES. This study also provides policy implications for land management and stakeholder involvement in accommodating landscape change. © 2021 Society for Modeling & Simulation International (SCS).","Land use change; Landscape change; Machine learning; Recreation; Tele-coupling","Ecosystems; Land use; Multilayer neural networks; Network layers; Public policy; Across distance; Coupling effect; Land use and cover change; Landscape changes; Landuse change; Multilayer perceptrons neural networks (MLPs); Recreation; Recreational activities; Socio-ecological systems; Tele-coupling; Machine learning"
"Huang S.-Y., Mukundan A., Tsao Y.-M., Kim Y., Lin F.-C., Wang H.-C.","Recent Advances in Counterfeit Art, Document, Photo, Hologram, and Currency Detection Using Hyperspectral Imaging","10.3390/s22197308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139948062&doi=10.3390%2fs22197308&partnerID=40&md5=d0cf485d7ea37a88464c2123b1e44dfa","Forgery and tampering continue to provide unnecessary economic burdens. Although new anti-forgery and counterfeiting technologies arise, they inadvertently lead to the sophistication of forgery techniques over time, to a point where detection is no longer viable without technological aid. Among the various optical techniques, one of the recently used techniques to detect counterfeit products is HSI, which captures a range of electromagnetic data. To aid in the further exploration and eventual application of the technique, this study categorizes and summarizes existing related studies on hyperspectral imaging and creates a mini meta-analysis of this stream of literature. The literature review has been classified based on the product HSI has used in counterfeit documents, photos, holograms, artwork, and currency detection. © 2022 by the authors.","artwork authentication; counterfeit currency detection; document authentication; forgery detection; hologram authentication; hyperspectral imaging; photo authentication","Chemical detection; Crime; Holograms; Hyperspectral imaging; Spectroscopy; Artwork authentication; Counterfeit currency detection; Counterfeit products; Document authentication; Economic burden; Electromagnetic data; Forgery detections; Hologram authentication; Optical technique; Photo authentication; Authentication; meta analysis; Hyperspectral Imaging"
"Huang W., Li W., Xu J., Ma X., Li C., Liu C.","Hyperspectral Monitoring Driven by Machine Learning Methods for Grassland Above-Ground Biomass","10.3390/rs14092086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129601569&doi=10.3390%2frs14092086&partnerID=40&md5=9626eb771646565bd90020ec216f4ad3","Above-ground biomass (AGB) is a key indicator for studying grassland productivity and evaluating carbon sequestration capacity; it is also a key area of interest in hyperspectral ecological remote sensing. In this study, we use data from a typical alpine meadow in the Qinghai–Tibet Plateau during the main growing season (July–September), compare the results of various feature selection algorithms to extract an optimal subset of spectral variables, and use machine learning methods and data mining techniques to build an AGB prediction model and realize the optimal inversion of above-ground grassland biomass. The results show that the Lasso and RFE_SVM band filtering machine learning models can effectively select the global optimal feature and improve the prediction effect of the model. The analysis also compares the support vector machine (SVM), least squares regression boosting (LSB), and Gaussian process regression (GPR) AGB inversion models; our findings show that the results of the three models are similar, with the GPR machine learning model achieving the best outcomes. In addition, through the analysis of different data combinations, it is found that the accuracy of AGB inversion can be significantly improved by combining the spectral characteristics with the growing season. Finally, by constructing a machine learning interpretable model to analyze the specific role of features, it was found that the same band plays different roles in different records, and the related results can provide a scientific basis for the research of grassland resource monitoring and estimation. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","above-ground biomass; alpine grassland; feature selection; hyperspectral; interpretability; machine learning","Adaptive boosting; Biomass; Data mining; Feature extraction; Remote sensing; Aboveground biomass; Alpine grasslands; Features selection; Gaussian process regression; Growing season; HyperSpectral; Interpretability; Machine learning methods; Machine learning models; Support vectors machine; Support vector machines"
"Huang Z., Sklar E., Parsons S.","Design of automatic strawberry harvest robot suitable in complex environments","10.1145/3371382.3377443","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083195632&doi=10.1145%2f3371382.3377443&partnerID=40&md5=e6914d4e80434b6a2bcb36b999eb0179","Strawberries are an important cash crop that are grown worldwide. They are also a labour-intensive crop, with harvesting a particularly labour-intensive task because the fruit needs careful handling. This project investigates collaborative human-robot strawberry harvesting, where interacting with a human potentially increases the adaptability of a robot to work in more complex environments. The project mainly concentrates on two aspects of the problem: the identification of the fruit and the picking of the fruit. © 2020 ACM.","Agricultural robot; Human robot interaction; Learning from human","Agricultural robots; Crops; Fruits; Harvesting; Machine design; Man machine systems; Cash crops; Complex environments; Human robots; Labour-intensive; Human robot interaction"
"Huber F., Yushchenko A., Stratmann B., Steinhage V.","Extreme Gradient Boosting for yield estimation compared with Deep Learning approaches","10.1016/j.compag.2022.107346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138484819&doi=10.1016%2fj.compag.2022.107346&partnerID=40&md5=d1d2411ada0d65622424eb67e42c36e3","Accurate prediction of crop yield before harvest is of great importance for crop logistics, market planning, and food distribution around the world. Yield prediction requires monitoring of phenological and climatic characteristics over extended time periods to model the complex relations involved in crop development. Remote sensing satellite images provided by various satellites circumnavigating the world are a cheap and reliable way to obtain data for yield prediction. The field of yield prediction is currently dominated by Deep Learning approaches. While the accuracies reached with those approaches are promising, the needed amounts of data and the “black-box” nature can restrict the application of Deep Learning methods. The limitations can be overcome by proposing a pipeline to process remote sensing images into feature-based representations that allow the employment of Extreme Gradient Boosting (XGBoost) for yield prediction. A comparative evaluation of soybean yield prediction within the United States shows promising prediction accuracies compared to state-of-the-art yield prediction systems based on Deep Learning. Feature importances expose the near-infrared spectrum of light as an important feature within our models. The reported results hint at the capabilities of XGBoost for yield prediction and encourage future experiments with XGBoost for yield prediction on other crops in regions all around the world. © 2022 Elsevier B.V.","Explainability; Extreme Gradient Boosting; Remote sensing; Shapley value; Yield prediction","Crops; Deep learning; Forecasting; Infrared devices; Learning systems; Accurate prediction; Crop yield; Explainability; Extreme gradient boosting; Gradient boosting; Learning approach; Remote-sensing; Shapley value; Yield estimation; Yield prediction; Remote sensing; crop yield; estimation method; learning; remote sensing; yield response; United States"
"Hussain A.A., Al-Turjman F.","Artificial intelligence and blockchain: A review","10.1002/ett.4268","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103411800&doi=10.1002%2fett.4268&partnerID=40&md5=a2482a5c3a3af3d020acb5a573b8dabe","It is irrefutable that blockchain and artificial intelligence (AI) paradigms are spreading at an incredible rate. The two paradigms have distinctive level of innovative nature and multidimensional business propositions. Blockchain innovation can robotize instalments to grant a way for exchanging personal records, information, and logs in a secure, and decentralized manner and can be revealed digitally in the digital currency era. As of late, blockchain and AI are two of the most trending technologies. Blockchain can administer connections among members with no mediator via smart contracts. AI, then, offers insight and dynamic capacities for machines just like people. In this survey, we provide a comprehensive overview about the applications of AI in blockchain. We audit, and sum up the rise of blockchain applications, and stages explicitly focusing on the AI research area. We likewise recognize and summarize open challenges in using blockchain and AI techniques. We also classify the effect of the cloud with these two innovations with respect to the computerized economy, which includes Blockchain as a Cloud and Blockchain as a Service. We moreover survey difficulties and issues identified while provisioning these technologies. It has been found that the integration of AI and blockchain is trusted to make various prospects. Such techniques provide scientists and authorities with an accuracy of up to 90% when taken properly into consideration. © 2021 John Wiley & Sons, Ltd.",,"Blockchain; Economics; Electronic document exchange; Surveys; AI techniques; Applications of AI; Business proposition; Dynamic capacity; Artificial intelligence"
"Huynh T.-M.-T., Ni C.-F., Su Y.-S., Nguyen V.-C.-N., Lee I.-H., Lin C.-P., Nguyen H.-H.","Predicting Heavy Metal Concentrations in Shallow Aquifer Systems Based on Low-Cost Physiochemical Parameters Using Machine Learning Techniques","10.3390/ijerph191912180","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139974732&doi=10.3390%2fijerph191912180&partnerID=40&md5=332c26a5fed00112cbb2ecce4e9a47fd","Monitoring ex-situ water parameters, namely heavy metals, needs time and laboratory work for water sampling and analytical processes, which can retard the response to ongoing pollution events. Previous studies have successfully applied fast modeling techniques such as artificial intelligence algorithms to predict heavy metals. However, neither low-cost feature predictability nor explainability assessments have been considered in the modeling process. This study proposes a reliable and explainable framework to find an effective model and feature set to predict heavy metals in groundwater. The integrated assessment framework has four steps: model selection uncertainty, feature selection uncertainty, predictive uncertainty, and model interpretability. The results show that Random Forest is the most suitable model, and quick-measure parameters can be used as predictors for arsenic (As), iron (Fe), and manganese (Mn). Although the model performance is auspicious, it likely produces significant uncertainties. The findings also demonstrate that arsenic is related to nutrients and spatial distribution, while Fe and Mn are affected by spatial distribution and salinity. Some limitations and suggestions are also discussed to improve the prediction accuracy and interpretability. © 2022 by the authors.","explainable artificial intelligence (XAI); groundwater quality; heavy metals; prediction intervals; Random Forest","5 (4 methylpiperazin 1 yl) 2 [2 (3,4 dimethoxyphenyl)5 benzimidazoyl]benzimidazole; amifostine; aquaporin 5; B Raf kinase; caspase; collagenase; cytoprotective agent; Hermes antigen; K ras protein; Ki 67 antigen; mitogen activated protein kinase 1; mitogen activated protein kinase 3; mitogen activated protein kinase kinase 1; sotorasib; technetium 99m; unclassified drug; vitronectin receptor; aquifer; arsenic; artificial intelligence; groundwater; heavy metal; iron; laboratory method; machine learning; manganese; prediction; salinity; spatial distribution; uncertainty analysis; aged; animal experiment; animal model; animal tissue; Article; atomic force microscopy; cancer radiotherapy; cell migration; cell proliferation; cell stemness; controlled study; cytotoxicity assay; disease severity; DNA fingerprinting; female; gene sequence; high throughput sequencing; human; human cell; human tissue; immunohistochemistry; male; MAPK signaling; mouse; mouth squamous cell carcinoma; MTT assay; nonhuman; polymerase chain reaction; protein expression; protein phosphorylation; radiation dose; radiation field; radiation injury; saliva analysis; salivation; short tandem repeat; single photon emission computed tomography; survival rate; synergistic effect; tumor growth; tumor volume; wound healing assay; xenograft; xerostomia"
"Iatrou M., Karydas C., Tseni X., Mourelatos S.","Representation Learning with a Variational Autoencoder for Predicting Nitrogen Requirement in Rice","10.3390/rs14235978","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143772980&doi=10.3390%2frs14235978&partnerID=40&md5=cd304e0558806d33413301c297c38df5","The scope of this research was to provide rice growers with optimal N-rate recommendations through precision agriculture applications. To achieve this goal, a prediction rice yield model was constructed, based on soil data, remote sensing data (optical and radar), climatic data, and farming practices. The dataset was collected from a rice crop surface of 89.2 ha cultivated continuously for a 5-year period and was analyzed with machine learning (ML) systems. A variational autoencoder (VAE) for reconstructing the input data of the prediction model was applied, resulting in MAE of 0.6 tn/ha, with an average yield for the study fields and period measured at 9.6 tn/ha. VAE learns the original input data representation and transforms them in a latent feature space, so that the anomalies and the discrepancies of the data are reduced. The reconstructed data by VAE provided a more sophisticated and detailed ML model, improving our knowledge about the various correlations between soil, N management parameters, and yield. Both optical and radar imagery and the climatic data were found to be of high importance for the model, as indicated by the application of XAI (explainable artificial intelligence) techniques. The new model was applied in the 2022 rice cultivation in the study fields, resulting in an average yield increase of 4.32% compared to the 5 previous years of experimentation. © 2022 by the authors.","Sentinel-1; Sentinel-2; topdressing nitrogen fertilization; VAE (variational autoencoder); XAI (explainable artificial intelligence)","Artificial intelligence; Cultivation; Farms; Input output programs; Learning systems; Optical remote sensing; Radar imaging; Space-based radar; Auto encoders; Average yield; Climatic data; Input datas; Nitrogen fertilization; Sentinel-1; Sentinel-2; Topdressing nitrogen fertilization; Variational autoencoder; XAI (explainable artificial intelligence); Forecasting"
"Iban M.C., Sekertekin A.","Machine learning based wildfire susceptibility mapping using remotely sensed fire data and GIS: A case study of Adana and Mersin provinces, Turkey","10.1016/j.ecoinf.2022.101647","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128581839&doi=10.1016%2fj.ecoinf.2022.101647&partnerID=40&md5=4beced8ea216bdbfe88c0dcf138eda0e","In recent years, the number of wildfires has increased all over the world. Therefore, mapping wildfire susceptibility is crucial for prevention, early detection, and supporting wildfire management decisions. This study aims to generate Machine Learning (ML) based wildfire susceptibility maps for Adana and Mersin provinces, which are located in the Mediterranean Region of Turkey. To generate a wildfire inventory, this study uses active fire pixels derived from MODIS monthly MCD14ML composites. Furthermore, as a sub aim, the performance of seven ML approaches, namely, stand-alone Logistic Regression (LR), Support Vector Machine (SVM), Linear Discriminant Analysis (LDA), and ensemble algorithms, namely Random Forest (RF), Gradient Boosting (GB), eXtreme Gradient Boosting (XGB), and AdaBoost (AB), was evaluated based on wildfire susceptibility mapping. The capabilities of the corresponding ML methods were assessed using thirteen wildfire conditioning factors, which can be grouped into four main categories: topographical, meteorological, vegetation, and anthropogenic factors. The Information Gain (IG) approach was used to assess their importance scores. A multicollinearity analysis was also performed to assess the relationship between conditioning factors. To compare the predictive performances of ML algorithms, five performance metrics, namely average accuracy, precision, recall, F1 score, and area under the curve, were used. To test the significance of the generated wildfire susceptibility maps and to detect similarities and differences among the output of these ML algorithms, McNemar's test was implemented. In the end, the ML-based models were locally interpreted using the Shapley Additive exPlanations (SHAP) technique. The AUC values of seven methods varied from 0.817 to 0.879, and the accuracy scores ranged between 0.734 and 0.812. The results showed that the RF model provided the best results considering all performance metrics. The accuracy score and AUC values of the RF model were equal to 0.812 and 0.879, respectively. On the other hand, stand-alone algorithms (LDA, SVM, and LR) represented lower performance than tree-based ensemble methods. Both the IG and SHAP analyses showed that elevation, temperature, and slope factors were the most contributing factors. The RF model classifier found that 7.20% of the study area has very high wildfire susceptibility, and the majority of the wildfire samples (68.84%) correspond to the very high susceptible areas in the RF model. The outcomes of this study are likely to provide decision-makers with a better understanding of wildfires in the Eastern Mediterranean Region of Turkey. © 2022 Elsevier B.V.","GIS; Machine learning; MODIS data; Susceptibility mapping; Wildfires","conditioning; GIS; machine learning; mapping method; MODIS; remote sensing; wildfire; Adana; Mediterranean Region; Mersin; Turkey"
"Ifkirne M., Beri Q., Schaefer A., Pham Q.B., Acharki S., Farah A.","Study of the impact of ash fallout from the Icelandic volcano Eyjafjöll (2010) on vegetation using MODIS data","10.1007/s11069-022-05544-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136047172&doi=10.1007%2fs11069-022-05544-z&partnerID=40&md5=f55fa25dc25a367ba86a0fdff16ecc21","Volcanic ash fallout is a recurrent environmental disturbance of flora ash deposits from the Icelandic volcano Eyjafjöll (2010) over large areas are responsible for several impacts on ecological processes, agricultural production, and human health in Western Europe. This study assessed the ash fall effects from the subject volcano on the surrounding flora as well as vegetative recovery at two different sites (Scotland and southern Sweden). For this purpose, we analyzed Normalized Difference Vegetation Index (NDVI), Leaf Area Index (LAI), and Fraction of Photosynthetically Active Radiation absorbed by Plants (FPAR) data provided by the Moderate Resolution Imaging Spectroradiometer (MODIS). The cited biophysical variables were most strongly influenced by ash cloud fallout, with the lowest maxima recorded for both sites during the 2010 eruption year. To confirm this impact, a statistical study with climate indicators was performed. The results showed a significant correlation between LAI and precipitation (R2 = 0.63, p-value = 0.0022) at site 1 (Scotland), while a weak non-significant correlation (R2 = 0.2248, p-value &gt; 0.5) was observed at site 2. However, climatic data from both sites showed low correlations (R2 &lt; 50%) with NDVI vegetation indicator. Despite the heavy rainfall and heat recorded during this period, our statistical results show us that ash cloud fallout affects vegetative development. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.","Biophysical variables; Climate factors; Flora; Spatial distribution; Volcanos","fallout; flora; leaf area index; MODIS; NDVI; photosynthetically active radiation; vegetation dynamics; volcanic ash; volcano; Eyjafjallajokull; Iceland"
"Ilyas M., Rahman A., Khan N.H., Haroon M., Hussain H., Rehman L., Alam M., Rauf A., Waggas D.S., Bawazeer S.","Analysis of Germin-like protein genes family in Vitis vinifera (VvGLPs) using various in silico approaches [Análise da família de genes de proteínas semelhantes a germin em Vitis vinifera (VvGLPs) usando várias abordagens in silico]","10.1590/1519-6984.256732","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126727484&doi=10.1590%2f1519-6984.256732&partnerID=40&md5=19024052a9db22cef8a80081d96b8851","Germin-like proteins (GLPs) play an important role against various stresses. Vitis vinifera L. genome contains 7 GLPs; many of them are functionally unexplored. However, the computational analysis may provide important new insight into their function. Currently, physicochemical properties, subcellular localization, domain architectures, 3D structures, N-glycosylation &amp; phosphorylation sites, and phylogeney of the VvGLPs were investigated using the latest computational tools. Their functions were predicted using the Search tool for the retrieval of interacting genes/proteins (STRING) and Blast2Go servers. Most of the VvGLPs were extracellular (43%) in nature but also showed periplasmic (29%), plasma membrane (14%), and mitochondrial-or chloroplast-specific (14%) expression. The functional analysis predicted unique enzymatic activities for these proteins including terpene synthase, isoprenoid synthase, lipoxygenase, phosphate permease, receptor kinase, and hydrolases generally mediated by Mn+ cation. VvGLPs showed similarity in the overall structure, shape, and position of the cupin domain. Functionally, VvGLPs control and regulate the production of secondary metabolites to cope with various stresses. Phylogenetically VvGLP1,-3,-4,-5, and VvGLP7 showed greater similarity due to duplication while VvGLP2 and VvGLP6 revealed a distant relationship. Promoter analysis revealed the presence of diverse cis-regulatory elements among which CAAT box, MYB, MYC, unnamed-4 were common to all of them. The analysis will help to utilize VvGLPs and their promoters in future food programs by developing resistant cultivars against various biotic (Erysiphe necator and in Powdery Mildew etc.) and abiotic (Salt, drought, heat, dehydration, etc.) stresses. © 2024, Instituto Internacional de Ecologia. All rights reserved.","function; genes; In silico; protein; VvGLPs","germin; glycoprotein; plant protein; genetics; metabolism; Vitis; Glycoproteins; Plant Proteins; Vitis"
"Ilyas T., Jin H., Siddique M.I., Lee S.J., Kim H., Chua L.","DIANA: A deep learning-based paprika plant disease and pest phenotyping system with disease severity analysis","10.3389/fpls.2022.983625","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140452916&doi=10.3389%2ffpls.2022.983625&partnerID=40&md5=f19e2a74a6c6a8ff0a2e653dfcbc7cfe","The emergence of deep neural networks has allowed the development of fully automated and efficient diagnostic systems for plant disease and pest phenotyping. Although previous approaches have proven to be promising, they are limited, especially in real-life scenarios, to properly diagnose and characterize the problem. In this work, we propose a framework which besides recognizing and localizing various plant abnormalities also informs the user about the severity of the diseases infecting the plant. By taking a single image as input, our algorithm is able to generate detailed descriptive phrases (user-defined) that display the location, severity stage, and visual attributes of all the abnormalities that are present in the image. Our framework is composed of three main components. One of them is a detector that accurately and efficiently recognizes and localizes the abnormalities in plants by extracting region-based anomaly features using a deep neural network-based feature extractor. The second one is an encoder–decoder network that performs pixel-level analysis to generate abnormality-specific severity levels. Lastly is an integration unit which aggregates the information of these units and assigns unique IDs to all the detected anomaly instances, thus generating descriptive sentences describing the location, severity, and class of anomalies infecting plants. We discuss two possible ways of utilizing the abovementioned units in a single framework. We evaluate and analyze the efficacy of both approaches on newly constructed diverse paprika disease and pest recognition datasets, comprising six anomaly categories along with 11 different severity levels. Our algorithm achieves mean average precision of 91.7% for the abnormality detection task and a mean panoptic quality score of 70.78% for severity level prediction. Our algorithm provides a practical and cost-efficient solution to farmers that facilitates proper handling of crops. Copyright © 2022 Ilyas, Jin, Siddique, Lee, Kim and Chua.","deep learning; detection; disease severity analysis; diseases and pests recognition; plant phenotyping",
"Im J., Lee D., Park O.-J., Natarajan S., Park J., Yun C.-H., Han S.H.","RNA-Seq-based transcriptome analysis of methicillin-resistant Staphylococcus aureus growth inhibition by propionate","10.3389/fmicb.2022.1063650","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145742004&doi=10.3389%2ffmicb.2022.1063650&partnerID=40&md5=ba4e23286564eab35a9c71226f86d170","Staphylococcus aureus is a pathogen that causes a variety of infectious diseases such as pneumonia, endocarditis, and septic shock. Methicillin-resistant S. aureus (MRSA) evades virtually all available treatments, creating the need for an alternative control strategy. Although we previously demonstrated the inhibitory effect of sodium propionate (NaP) on MRSA, the regulatory mechanism of this effect remains unclear. In this study, we investigated the regulatory mechanism responsible for the inhibitory effect of NaP on MRSA using RNA-Seq analysis. Total RNAs were isolated from non-treated and 50 mM NaP-treated S. aureus USA300 for 3 h and transcriptional profiling was conducted by RNA-Seq analysis. A total of 171 differentially expressed genes (DEGs) with log2 fold change ≥2 and p &lt; 0.05 was identified in the NaP treatment group compared with the control group. Among the 171 genes, 131 were up-regulated and 40 were down-regulated. Upon gene ontology (GO) annotation analysis, total 26 specific GO terms in “Biological process,” “Molecular function,” and “Cellular component” were identified in MRSA treated with NaP for 3 h. “Purine metabolism”; “riboflavin metabolism”; and “glycine, serine, and threonine metabolism” were identified as major altered metabolic pathways among the eight significantly enriched KEGG pathways in MRSA treated with NaP. Furthermore, the MRSA strains deficient in purF, ilvA, ribE, or ribA, which were the up-regulated DEGs in the metabolic pathways, were more susceptible to NaP than wild-type MRSA. Collectively, these results demonstrate that NaP attenuates MRSA growth by altering its metabolic pathways, suggesting that NaP can be used as a potential bacteriostatic agent for prevention of MRSA infection. Copyright © 2022 Im, Lee, Park, Natarajan, Park, Yun and Han.","bacteriostatic; metabolic pathway; propionate; RNA-Seq; short-chain fatty acids","glycine; propionate sodium; propionic acid; riboflavin; RNA 16S; serine; short chain fatty acid; threonine; transcriptome; Article; bacterial growth; bacteriostatic activity; differential gene expression; DNA library; down regulation; gene ontology; glycine metabolism; growth inhibition; metabolism; methicillin resistant Staphylococcus aureus; methicillin resistant Staphylococcus aureus infection; minimum bactericidal concentration; minimum inhibitory concentration; nonhuman; purine metabolism; real time polymerase chain reaction; riboflavin metabolism; RNA extraction; RNA purification; RNA sequencing; serine metabolism; Staphylococcus aureus USA300; threonine metabolism; upregulation"
"Imran, Iqbal N., Kim D.H.","IoT Task Management Mechanism Based on Predictive Optimization for Efficient Energy Consumption in Smart Residential Buildings","10.1016/j.enbuild.2021.111762","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121963422&doi=10.1016%2fj.enbuild.2021.111762&partnerID=40&md5=445941515f1bd38c3f3b1edea98258a8","Energy-saving is a global challenge and one of the hot research topics of this decade. The need for sustainable technologies and solutions for energy-saving dramatically increased in residential buildings due to population growth, quality of indoor environment, and climate change. Recently, IoT based applications have been developed in smart homes, smart cities, smart hospitals, and other smart environments. The goals of sustainable technologies in residential buildings incorporate maximization of thermal comfort and minimizing energy consumption. The challenges and problems of residential buildings can be solved using consumer behavior models and integrating their inference into residential problem solutions. This paper proposes an IoT task management mechanism based on predictive optimization for energy consumption minimization in smart residential buildings. The proposed task management mechanism has a predictive optimization module based on prediction and an optimization module for solving energy consumption minimization problems. The energy data is obtained from different appliances to evaluate the proposed predictive optimization approach. The proposed approach results are compared with prediction and optimization modules. The performance is evaluated in terms of regression performance metrics. The case study results show that the predictive optimization mechanism based on task management performs better than standalone prediction and optimization-based energy consumption mechanisms in residential buildings. © 2021 Elsevier B.V.","Energy consumption; Energy saving; Optimization; Prediction; Predictive optimization; Task management","Automation; Climate change; Consumer behavior; Energy conservation; Forecasting; Housing; Intelligent buildings; Internet of things; Population statistics; Energy savings; Energy-consumption; Energy-savings; Management mechanisms; Mechanism-based; Optimisations; Predictive optimization; Residential building; Task management; Energy utilization"
"Ishengoma F.R., Shao D., Alexopoulos C., Saxena S., Nikiforova A.","Integration of artificial intelligence of things (AIoT) in the public sector: drivers, barriers and future research agenda","10.1108/DPRG-06-2022-0067","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139047542&doi=10.1108%2fDPRG-06-2022-0067&partnerID=40&md5=6cc206f6ed5134bd2ce358b5cc914794","Purpose: With the development of information technology (IT), governments around the globe are using state-of-the-art IT interfaces to implement the so-called 3E’s in public service delivery, that is, economy, efficiency and effectiveness. Two of these IT interfaces relate to Artificial Intelligence (AI) and Internet of Things (IoT). While AI focuses on providing a “human” garb for computing devices, thereby making them “intelligent” devices, IoT relies on interfaces between sensors and the environment to make “intelligent” decisions. Recently, the convergence of AI and IoT – also referred to as Artificial Intelligence of Things (AIoT) – is seen as a real opportunity to refurbish the public service delivery formats. However, there is limited understanding as to how AIoT could contribute to the improvisation of public service delivery. This study aims to create a modular framework for AIoT in addition to highlighting the drivers and barriers for its integration in the public sector. Design/methodology/approach: This descriptive-explanatory study takes a qualitative approach. It entails a thorough examination of the drivers and barriers of integrating AI and IoT in the public sector. A review of literature has led to the development of a conceptual framework outlining the various factors that contribute to creating public value. Findings: Value creation occurs when AI and IoT coalesce in the public service delivery mechanisms. Originality/value: AIoT is a cutting-edge technology revolutionizing health care, agriculture, infrastructure and all other industrial domains. This study adds to the growing body of knowledge on the public sector's use of AI and IoT. Understanding these disruptive technologies is critical to formulating policies and regulations that can maximize the potential benefits for the public-sector organizations. © 2022, Emerald Publishing Limited.","AI; AIoT; Artificial Intelligence; Artificial Internet of Things; Barriers; Drivers; Internet of Things; IoT; Public sector; Public service delivery",
"Islam M.S., Awal M.A., Laboni J.N., Pinki F.T., Karmokar S., Mumenin K.M., Al-Ahmadi S., Rahman M.A., Hossain M.S., Mirjalili S.","HGSORF: Henry Gas Solubility Optimization-based Random Forest for C-Section prediction and XAI-based cause analysis","10.1016/j.compbiomed.2022.105671","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131221843&doi=10.1016%2fj.compbiomed.2022.105671&partnerID=40&md5=af8131862b67b70fb463729d7e83e283","A stable predictive model is essential for forecasting the chances of cesarean or C-section (CS) delivery, as unnecessary CS delivery can adversely affect neonatal, maternal, and pediatric morbidity and mortality, and can incur significant financial burdens. Limited state-of-the-art machine learning models have been applied in this area in recent years, and the current models are insufficient to correctly predict the probability of CS delivery. To alleviate this drawback, we have proposed a Henry gas solubility optimization (HGSO)-based random forest (RF), with an improved objective function, called HGSORF, for the classification of CS and non-CS classes. Real-world CS datasets can be noisy, such as the Pakistan Demographic and Health Survey (PDHS) dataset used in this study. The HGSO can provide fine-tuned hyperparameters of RF by avoiding local minima points. To compare performance, Gaussian Naive Bayes (GNB), linear discriminant analysis (LDA), K-nearest neighbors (KNN), gradient boosting classifier (GBC), and logistic regression (LR) have been considered in this research. The ADAptive SYNthetic (ADASYN) algorithm has been used to balance the model, and the proposed HGSORF has been compared with other classifiers as well as with other studies. The superior performance was achieved by HGSORF with an accuracy of 98.33% for the PDHS dataset. The hyperparameters of RF have also been optimized by using commonly used hyperparameter-optimization algorithms, and the proposed HGSORF provided comparatively better performance. Additionally, to analyze the causes of CS and their significance, the HGSORF is explained locally and globally using eXplainable artificial intelligence (XAI)-based tools such as SHapely Additive exPlanation (SHAP) and Local Interpretable Model-Agnostic Explanations (LIME). A decision support system has been developed as a potential application to support clinical staffs. All pre-trained models and relevant codes are available on: https://github.com/MIrazul29/HGSORF_CSection. © 2022 Elsevier Ltd","ADASYN; Cesarean section; HGSORF; Hyperparameter optimization; LIME; Machine learning; SHAP; XAI","Adaptive boosting; Decision support systems; Decision trees; Discriminant analysis; Lime; Logistic regression; Machine learning; Nearest neighbor search; Solubility; Surveys; Adaptive synthetic; C-sections; Cesarean section; Gas solubility; HGSORF; Hyper-parameter optimizations; Local interpretable model-agnostic explanation; Random forests; Shapely additive explanation; XAI; Forecasting; Agnostic; article; artificial intelligence; Bayesian learning; cesarean section; classifier; decision support system; demography; discriminant analysis; drug solubility; health survey; human; k nearest neighbor; machine learning; Pakistan; prediction; random forest; staff; algorithm; artificial intelligence; Bayes theorem; child; newborn; solubility; Algorithms; Artificial Intelligence; Bayes Theorem; Child; Humans; Infant, Newborn; Machine Learning; Solubility"
"Issa G.F., Shaalan K., Shaalan Y., Saeed H.A., Fatima N., Rehman A.U.","Brain Stroke Prediction Using ANN","10.1109/ICCR56254.2022.9995885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146495641&doi=10.1109%2fICCR56254.2022.9995885&partnerID=40&md5=a8c4e664fd0502e07e15fc47dace7592","Brain stroke is an intense health condition that happens when a blood clot restricts the normal flow of blood and different nutrients withinside the brain. It can cause neurologic damage, headaches and often death if not cured at a certain stage. According to the WHO, brain stroke has turned out to be the maximum rising disorder that is inflicting death because of late prognosis in both adults and elder one's. Like a 'coronary heart attack' it damages or paralyzes the brain. There have been numerous predictions about cerebrovascular, however this disorder is the one that receives less consideration. Some foremost elements that contribute to the hazard of stroke are age, gender, race, and genetic history of the patient. Artificial intelligence based cognitive modeling simulates properties of biological neural networks. Artificial Neural Network offers the basis for the effectiveness of the studies. Different machine learning algorithms offer a sturdy base to discover the accuracy of the disorder. This study implements this model for higher instruction to combat pandemics in future. © 2022 IEEE.","neurologic; physiological; stroke","Learning algorithms; Machine learning; Neural networks; Blood clots; Brain strokes; Genetic history; Health condition; Heart attack; Neurologic; Neurologic damage; Normal flow; Physiological; Stroke; Blood"
"Issar S., Aneesh A.","What is algorithmic governance?","10.1111/soc4.12955","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121449044&doi=10.1111%2fsoc4.12955&partnerID=40&md5=c99a1fae3ee28c2a6c9cd8ad02059cb4","This article contributes a coherent framework to the rich literature emerging in the field of algorithmic governance while also resolving conflicting understandings. Tracing the history of algorithmic governance to the broad architecture of the universal Turing Machine, the article identifies a common thread of critical concern in the literature on algorithmic governance: the growing institutional capabilities to move contestable issues to a space of reduced negotiability, raising questions of social asymmetry, inequity, and inequality. Within the social context of algorithmic governance, the article highlights three general areas of concern where the social negotiability of processes is threatened: the problem of power (surveillance), discrimination (social bias), and identification (system identity). © 2021 John Wiley & Sons Ltd.",,
"Jabbar R., Jabbar R., Kamoun S.","Recent progress in generative adversarial networks applied to inversely designing inorganic materials: A brief review","10.1016/j.commatsci.2022.111612","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133356303&doi=10.1016%2fj.commatsci.2022.111612&partnerID=40&md5=0cad3943ffe8cde3af4f9b63aa76466e","Generative adversarial networks (GANs) are deep generative models (GMs) that have recently attracted attention owing to their impressive performance in generating completely novel images, text, music, and speech. Recently, GANs have made interesting progress in designing materials exhibiting desired functionalities, termed ‘inverse materials design’ (IMD). Because, discovering materials can lead to enormous technological progress, it is critical to provide a systematic review of new GAN applications to inversely designing inorganic materials. In this study, various aspects of GAN-based IMD were examined wherein IMD is a primary design process for discovering materials exhibiting desired features (physical properties, chemical formulae, etc.) by implementing constraints or conditions on input data or algorithms. We discussed fundamental materials databases and relevant machine-learning criteria. Furthermore, the comprehensive software tools currently available to materials scientists were presented. Descriptors including the criteria required for training GAN models were also discussed. Finally, we summarized both challenges and future direction for applying GANs to IMD research. © 2022 Elsevier B.V.","Deep learning; Generative adversarial networks; Inorganic material; Inverse material design","Deep learning; Design; Deep learning; Generative model; Image texts; Inorganic materials; Inverse material design; Materials design; Performance; Recent progress; Systematic Review; Technological progress; Generative adversarial networks"
"Jacobs M., Remus A., Gaillard C., Menendez H.M., Tedeschi L.O., Neethirajan S., Ellis J.L.","ASAS-NANP symposium: Mathematical modeling in animal nutrition: Limitations and potential next steps for modeling and modelers in the animal sciences","10.1093/jas/skac132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131701028&doi=10.1093%2fjas%2fskac132&partnerID=40&md5=51e505766adf91c307d4c92f20fd62b2","The field of animal science, and especially animal nutrition, relies heavily on modeling to accomplish its day-To-day objectives. New data streams (""big data"") and the exponential increase in computing power have allowed the appearance of ""new""modeling methodologies, under the umbrella of artificial intelligence (AI). However, many of these modeling methodologies have been around for decades. According to Gartner, technological innovation follows five distinct phases: Technology trigger, peak of inflated expectations, trough of disillusionment, slope of enlightenment, and plateau of productivity. The appearance of AI certainly elicited much hype within agriculture leading to overpromised plug-And-play solutions in a field heavily dependent on custom solutions. The threat of failure can become real when advertising a disruptive innovation as sustainable. This does not mean that we need to abandon AI models. What is most necessary is to demystify the field and place a lesser emphasis on the technology and more on business application. As AI becomes increasingly more powerful and applications start to diverge, new research fields are introduced, and opportunities arise to combine ""old""and ""new""modeling technologies into hybrids. However, sustainable application is still many years away, and companies and universities alike do well to remain at the forefront. This requires investment in hardware, software, and analytical talent. It also requires a strong connection to the outside world to test, that which does, and does not work in practice and a close view of when the field of agriculture is ready to take its next big steps. Other research fields, such as engineering and automotive, have shown that the application power of AI can be far reaching but only if a realistic view of models as whole is maintained. In this review, we share our view on the current and future limitations of modeling and potential next steps for modelers in the animal sciences. First, we discuss the inherent dependencies and limitations of modeling as a human process. Then, we highlight how models, fueled by AI, can play an enhanced sustainable role in the animal sciences ecosystem. Lastly, we provide recommendations for future animal scientists on how to support themselves, the farmers, and their field, considering the opportunities and challenges the technological innovation brings. © 2022 The Author(s) 2022. Published by Oxford University Press on behalf of the American Society of Animal Science. All rights reserved.","Data science; Education; Modeling; Precision livestock farming; Simulation; Smart livestock farming","agriculture; animal; artificial intelligence; ecosystem; theoretical model; Agriculture; Animals; Artificial Intelligence; Ecosystem; Models, Theoretical"
"Jagatheesaperumal S.K., Pham Q.-V., Ruby R., Yang Z., Xu C., Zhang Z.","Explainable AI Over the Internet of Things (IoT): Overview, State-of-the-Art and Future Directions","10.1109/OJCOMS.2022.3215676","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141539421&doi=10.1109%2fOJCOMS.2022.3215676&partnerID=40&md5=5dbb0907c006a2fccd89b9036b34e849","Explainable Artificial Intelligence (XAI) is transforming the field of Artificial Intelligence (AI) by enhancing the trust of end-users in machines. As the number of connected devices keeps on growing, the Internet of Things (IoT) market needs to be trustworthy for the end-users. However, existing literature still lacks a systematic and comprehensive survey work on the use of XAI for IoT. To bridge this lacking, in this paper, we address the XAI frameworks with a focus on their characteristics and support for IoT. We illustrate the widely-used XAI services for IoT applications, such as security enhancement, Internet of Medical Things (IoMT), Industrial IoT (IIoT), and Internet of City Things (IoCT). We also suggest the implementation choice of XAI models over IoT systems in these applications with appropriate examples and summarize the key inferences for future works. Moreover, we present the cutting-edge development in edge XAI structures and the support of sixth-generation (6G) communication services for IoT applications, along with key inferences. In a nutshell, this paper constitutes the first holistic compilation on the development of XAI-based frameworks tailored for the demands of future IoT use cases. © 2020 IEEE.","Artificial intelligence; deep learning; explainability; Internet of Things; machine learnin","Deep learning; Trusted computing; Communication service; Cutting edges; Deep learning; End-users; Explainability; Machine-learning; Market needs; Security enhancements; State of the art; Survey works; Internet of things"
"Jain K., Kumar A., Singh A.","Data transmission reduction techniques for improving network lifetime in wireless sensor networks: An up-to-date survey from 2017 to 2022","10.1002/ett.4674","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142266092&doi=10.1002%2fett.4674&partnerID=40&md5=677b6093efcc68f8f3e191f54dfc6f9c","Wireless sensor networks (WSNs) have now become a substantial part of our life as it provides an incredible setup for monitoring environmental conditions such as glaciers melting, earthquakes, climate change, volcanic eruption, agriculture, and other natural calamities. One of the most important challenges in data gathering and examining accurate data is “energy consumption.” However, continuously changing environmental conditions, mobility in devices and extreme resource usage, such as battery capacity in WSNs collectively contribute to a high possibility of redundant data transmission thus making it tremendously hard to achieve a satisfactory network lifetime. Additionally, these environmental monitoring applications periodically senses and aggregate data which usually exhibits high temporal and spatial redundancies. As a result, exploiting these redundancies is essential for both resource utilization, as well as accurate data transmission. Since a huge amount of energy is exhausted in transmitting the redundant data, which has become a bottleneck in scaling such applications. In this context, this article provides a thorough examination of existing energy-efficient redundant data transmission reduction techniques, as well as their strengths and drawbacks. The idea of redundant data transmission reduction concept is divided into three stages: the sensor nodes (SN) at the first stage, the cluster heads (CHs) at the second stage, and the base station (BS) at the third stage. Furthermore, this survey focuses on the current issues and challenges, as well as the future directions in reducing redundant data transmission for future investigation. © 2022 John Wiley & Sons Ltd.",,"Climate change; Data communication systems; Data reduction; Data transfer; Energy efficiency; Redundancy; Sensor nodes; Surveys; Volcanoes; Data gathering; Data-transmission; Energy-consumption; Environmental conditions; Glacier melting; Network lifetime; Reduction techniques; Redundant data; Transmission reduction; Volcanic eruptions; Energy utilization"
"Jain P., Gupta A., Kumar N.","A vision towards integrated 6G communication networks: Promising technologies, architecture, and use-cases","10.1016/j.phycom.2022.101917","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140879645&doi=10.1016%2fj.phycom.2022.101917&partnerID=40&md5=dd6d456b3b36d80381cb41e5804a83b7","The evolution of the previous mobile communication generations has led to innovative goals of the Internet of Everything (IoE) in the 5G. However, addressing all IoE-associated problems in 5G is difficult and a long-term process. As the key performance indicators (KPIs) of the 5G services are highly diverse, it is an intimidating task to develop a single platform enabling all KPIs. The vision of next-generation 6G wireless communications lies not only in enhancing these targets but also in providing new services. Numerous extensively envisaged future services, including life-critical services and wireless brain–computer interactions, will be critically dependent on an instant, virtually unlimited wireless connectivity. In this direction, the 6G is envisioned to have primely five service objectives; further-enhanced mobile broadband (FeMBB), ultra-massive machine type communication (umMTC), extremely reliable low latency communication (ERLLC), long-distance and high-mobility communications (LDHMC), and extremely low-power communications (ELPC). The 3D global integration of the wireless communication networks is lacking in the 5G, which is targeted by the future 6G. In this paper, we present an exhaustive review of the 6G wireless communication network. We explore the various existing mobile communication generations concerning data rate, frequency band, bandwidth allotted, latency, and applications. We also highlight various current trends and issues in the 5G communication network, which drives research for the 6G communication network. Our focus is to provide a comprehensive survey on the future 6G. So, we explored the objectives and design principles for 6G. This paper highlights the key 6G technology drivers. This paper also proposes an architectural design for 6G. Moreover, we carry out a case-study of 6G architecture operational design and compare the result with previous generation architecture designs. Further, 6G envisioned open research challenges, research directions, and recent advancements are also highlighted in this paper. Furthermore, we discuss possible use-cases in terms of real-time interactions of the biological, physical, and digital world, and also how these use-cases are going to serve in 6G. © 2022 Elsevier B.V.","6G; Architecture; Holographic verticals; Intelligent; Terahertz communications; Vision","5G mobile communication systems; Benchmarking; Biology; Digital storage; Network architecture; 6g; Communications networks; Holographic vertical; Intelligent; Key performance indicators; Mobile communications; Technology architectures; Tera Hertz; Terahertz communication; Wireless communications networks; Internet of Everything"
"Jamei M., Ahmadianfar I., Karbasi M., Malik A., Kisi O., Yaseen Z.M.","Development of wavelet-based Kalman Online Sequential Extreme Learning Machine optimized with Boruta-Random Forest for drought index forecasting","10.1016/j.engappai.2022.105545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143804589&doi=10.1016%2fj.engappai.2022.105545&partnerID=40&md5=95d25250806667795e2dce8c645b1ff9","Drought is a stochastic and recurring hydrological natural hazard that occurs due to a shortage of precipitation over a period of time. Drought forecasting in water resources systems has an important role in reducing devastating ecological and social impacts. However, due to the fluctuating nature of drought indicator time series, their forecasting on a short time scale without advanced pre-processing is extremely challenging, and little research has been presented in this field. In this study, a new complementary machine learning (ML) approach, Kalman filter regression-based Online Sequential Extreme Learning Machine and (KOSELM) coupled with the Boundary Corrected Maximal Overlap Discrete Wavelet Transform (BC-MODWT-KOSELM), was implemented for forecasting one-month/three-month ahead Standardized Precipitation Evapotranspiration Index (i.e., SPEI 12 and SPEI 24). Here, the Kalman filter regression was employed to optimize the hyper-parameters of the Online Sequential Extreme Learning Machine (OSELM). Precipitation and potential evapotranspiration data from Bandar Abbas (warm semi-humid climate) and Rasmar (humid climate) synoptic stations, Iran were used in the analysis for a period of (1987–2019). In order to validate the BC-MODWT-KOSELM model, it was compared with two other well-known ML approaches, classical Extreme Learning Machine (ELM) and Generalized Regression Neural Network (GRNN) in both standalone and BC-MODWT-based complementary frameworks (i.e., BC-MODWT-ELM and BC-MODWT-GRNN). First, the original time series of the benchmark drought index was decomposed into the wavelet and scaling coefficients based on three mother wavelets and different decomposition levels. Afterward, the most significant lags were extracted using the Boruta-random forest (B-RF) feature selection. The BC-MODWT-KOSELM was identified as the superior forecasting model for SPEI 12 (t ＋ 1) with R = 0.9511 and RMSE = 0.3318; for SPEI 12 (t ＋ 3) with R = 0.8171 and RMSE = 0.6168; for SPEI 24 (t ＋ 1) with R = 0.9710 and RMSE = 0.2156; for SPEI 24 (t ＋ 3) with R = 0.9014 and RMSE = 0.3937 in the Bandar Abbas station. Besides, the BC-MODWT-KOSELM outperformed the comparative counterpart model for SPEI 12 (t ＋ 1 with R = 0.9401 and RMSE = 0.3371; SPEI 12 (t ＋ 3) with R = 0.8266 and RMSE = 0.5723; for SPEI 24 (t ＋ 1) with R = 0.9640 and RMSE = 0.2974; for SPEI 24 (t ＋ 3) with R = 0.9063 and RMSE = 0.4874 in the Ramsar station. © 2022 Elsevier Ltd","Boruta-random forest; Drought; Online Sequential Extreme Learning Machine; SPEI","Discrete wavelet transforms; Drought; E-learning; Evapotranspiration; Forestry; Knowledge acquisition; Learning systems; Machine learning; Neural networks; Stochastic systems; Time series; Wavelet decomposition; Weather forecasting; Borutum-random forest; Generalized regression; Humid climates; Learning machines; Machine learning approaches; Online sequential extreme learning machine; Random forests; Regression neural networks; SPEI; Times series; Kalman filters"
"Jamil S., Rahman M.","A dual‐stage vocabulary of features (Vof)‐based technique for covid‐19 variants’ classification","10.3390/app112411902","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121272933&doi=10.3390%2fapp112411902&partnerID=40&md5=ec38f0771e46e1da871150ff662a4888","Novel coronavirus, known as COVID‐19, is a very dangerous virus. Initially detected in China, it has since spread all over the world causing many deaths. There are several variants of COVID‐19, which have been categorized into two major groups. These groups are variants of concern and variants of interest. Variants of concern are more dangerous, and there is a need to develop a system that can detect and classify COVID‐19 and its variants without touching an infected person. In this paper, we propose a dual‐stage‐based deep learning framework to detect and classify COVID‐19 and its variants. CT scans and chest X‐ray images are used. Initially, the detection is done through a convolutional neural network, and then spatial features are extracted with deep convo-lutional models, while handcrafted features are extracted from several handcrafted descriptors. Both spatial and handcrafted features are combined to make a feature vector. This feature vector is called the vocabulary of features (VoF), as it contains spatial and handcrafted features. This feature vector is fed as an input to the classifier to classify different variants. The proposed model is evalu-ated based on accuracy, F1‐score, specificity, sensitivity, specificity, Cohen’s kappa, and classification error. The experimental results show that the proposed method outperforms all the existing state‐of‐the‐art methods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Classification; COVID‐19; Delta variant; Detection; Feature extraction; Variant of concern",
"Janev V., Graux D., Jabeen H., Sallinger E.","Knowledge graphs and big data processing",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089497457&partnerID=40&md5=0a2efb5f922b39f0504eb3a30adda97b",[No abstract available],,
"Janik A., Sankaran K., Ortiz A.","Interpreting Black-Box Semantic Segmentation Models in Remote Sensing Applications","10.2312/mlvis.20191158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090325346&doi=10.2312%2fmlvis.20191158&partnerID=40&md5=ba77716566b1f7b7dff473809374e7c0","In the interpretability literature, attention is focused on understanding black-box classifiers, but many problems ranging from medicine through agriculture and crisis response in humanitarian aid are tackled by semantic segmentation models. The absence of interpretability for these canonical problems in computer vision motivates this study. In this study we present a usercentric approach that blends techniques from interpretability, representation learning, and interactive visualization. It allows to visualize and link latent representation to real data instances as well as qualitatively assess strength of predictions. We have applied our method to a deep learning model for semantic segmentation, U-Net, in a remote sensing application of building detection. This application is of high interest for humanitarian crisis response teams that rely on satellite images analysis. Preliminary results shows utility in understanding semantic segmentation models, demo presenting the idea is available online. Copyright © 2019 by the Eurographics Association.",,"Remote sensing; Semantic Segmentation; Semantics; Visualization; Black boxes; Canonical problems; Crisis response; Humanitarian aids; Interactive visualizations; Interpretability; Remote sensing applications; Segmentation models; Semantic segmentation; User-centric; Deep learning"
"Javaid M., Haleem A., Pratap Singh R., Suman R., Rab S.","Significance of machine learning in healthcare: Features, pillars and applications","10.1016/j.ijin.2022.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137997897&doi=10.1016%2fj.ijin.2022.05.002&partnerID=40&md5=9a52a1e15d4f62b99b9a2349a4cb2fcf","Machine Learning (ML) applications are making a considerable impact on healthcare. ML is a subtype of Artificial Intelligence (AI) technology that aims to improve the speed and accuracy of physicians' work. Countries are currently dealing with an overburdened healthcare system with a shortage of skilled physicians, where AI provides a big hope. The healthcare data can be used gainfully to identify the optimal trial sample, collect more data points, assess ongoing data from trial participants, and eliminate data-based errors. ML-based techniques assist in detecting early indicators of an epidemic or pandemic. This algorithm examines satellite data, news and social media reports, and even video sources to determine whether the sickness will become out of control. Using ML for healthcare can open up a world of possibilities in this field. It frees up healthcare providers' time to focus on patient care rather than searching or entering information. This paper studies ML and its need in healthcare, and then it discusses the associated features and appropriate pillars of ML for healthcare structure. Finally, it identified and discussed the significant applications of ML for healthcare. The applications of this technology in healthcare operations can be tremendously advantageous to the organisation. ML-based tools are used to provide various treatment alternatives and individualised treatments and improve the overall efficiency of hospitals and healthcare systems while lowering the cost of care. Shortly, ML will impact both physicians and hospitals. It will be crucial in developing clinical decision support, illness detection, and personalised treatment approaches to provide the best potential outcomes. © 2022 The Authors","Data; Efficiency; Healthcare; Machine learning; Patient outcome; Treatment",
"Jia W., Liu M., Luo R., Wang C., Pan N., Yang X., Ge X.","YOLOF-Snake: An Efficient Segmentation Model for Green Object Fruit","10.3389/fpls.2022.765523","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133424644&doi=10.3389%2ffpls.2022.765523&partnerID=40&md5=f560994f19598bff4d0ed4d30d249b49","Accurate detection and segmentation of the object fruit is the key part of orchard production measurement and automated picking. Affected by light, weather, and operating angle, it brings new challenges to the efficient and accurate detection and segmentation of the green object fruit under complex orchard backgrounds. For the green fruit segmentation, an efficient YOLOF-snake segmentation model is proposed. First, the ResNet101 structure is adopted as the backbone network to achieve feature extraction of the green object fruit. Then, the C5 feature maps are expanded with receptive fields and the decoder is used for classification and regression. Besides, the center point in the regression box is employed to get a diamond-shaped structure and fed into an additional Deep-snake network, which is adjusted to the contours of the target fruit to achieve fast and accurate segmentation of green fruit. The experimental results show that YOLOF-snake is sensitive to the green fruit, and the segmentation accuracy and efficiency are significantly improved. The proposed model can effectively extend the application of agricultural equipment and provide theoretical references for other fruits and vegetable segmentation. Copyright © 2022 Jia, Liu, Luo, Wang, Pan, Yang and Ge.","automatic harvesting; deep-snake; fruits segmentation; green fruits; YOLOF-snake",
"Jiang J., Ma X., Ouyang D., Williams R.O., III","Emerging Artificial Intelligence (AI) Technologies Used in the Development of Solid Dosage Forms","10.3390/pharmaceutics14112257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141884937&doi=10.3390%2fpharmaceutics14112257&partnerID=40&md5=29a579c196784e682af01febe062ea14","Artificial Intelligence (AI)-based formulation development is a promising approach for facilitating the drug product development process. AI is a versatile tool that contains multiple algorithms that can be applied in various circumstances. Solid dosage forms, represented by tablets, capsules, powder, granules, etc., are among the most widely used administration methods. During the product development process, multiple factors including critical material attributes (CMAs) and processing parameters can affect product properties, such as dissolution rates, physical and chemical stabilities, particle size distribution, and the aerosol performance of the dry powder. However, the conventional trial-and-error approach for product development is inefficient, laborious, and time-consuming. AI has been recently recognized as an emerging and cutting-edge tool for pharmaceutical formulation development which has gained much attention. This review provides the following insights: (1) a general introduction of AI in the pharmaceutical sciences and principal guidance from the regulatory agencies, (2) approaches to generating a database for solid dosage formulations, (3) insight on data preparation and processing, (4) a brief introduction to and comparisons of AI algorithms, and (5) information on applications and case studies of AI as applied to solid dosage forms. In addition, the powerful technique known as deep learning-based image analytics will be discussed along with its pharmaceutical applications. By applying emerging AI technology, scientists and researchers can better understand and predict the properties of drug formulations to facilitate more efficient drug product development processes. © 2022 by the authors.","artificial intelligence; deep learning; machine learning; solid dosage formulation","algorithm; artificial intelligence; biomedical engineering; data processing; deep learning; dispersion; drug capsule; drug database; drug dosage form; drug granule; drug release; drug solubility; dry powder; Food and Drug Administration; human; medical research; molecular dynamics; nonhuman; pharmaceutical care; Review; tablet; three dimensional printing"
"Jiang Y., Luo J., Huang D., Liu Y., Li D.-D.","Machine Learning Advances in Microbiology: A Review of Methods and Applications","10.3389/fmicb.2022.925454","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132773535&doi=10.3389%2ffmicb.2022.925454&partnerID=40&md5=526b4dbb5e0686725c6365e035291e18","Microorganisms play an important role in natural material and elemental cycles. Many common and general biology research techniques rely on microorganisms. Machine learning has been gradually integrated with multiple fields of study. Machine learning, including deep learning, aims to use mathematical insights to optimize variational functions to aid microbiology using various types of available data to help humans organize and apply collective knowledge of various research objects in a systematic and scaled manner. Classification and prediction have become the main achievements in the development of microbial community research in the direction of computational biology. This review summarizes the application and development of machine learning and deep learning in the field of microbiology and shows and compares the advantages and disadvantages of different algorithm tools in four fields: microbiome and taxonomy, microbial ecology, pathogen and epidemiology, and drug discovery. Copyright © 2022 Jiang, Luo, Huang, Liu and Li.","classification; deep learning; machine learning; microorganisms; prediction","classification algorithm; deep learning; ecology; learning algorithm; machine learning; microbial community; microbiology; microbiome; nonhuman; reinforcement learning (machine learning); Review; supervised machine learning; taxonomy; unsupervised machine learning"
"Jiang Y., Li C.","Convolutional neural networks for image-based high-throughput plant phenotyping: A review","10.34133/2020/4152816","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084494681&doi=10.34133%2f2020%2f4152816&partnerID=40&md5=4ed7aad0f14b1e110ead0cb064204da0","Plant phenotyping has been recognized as a bottleneck for improving the efficiency of breeding programs, understanding plant-environment interactions, and managing agricultural systems. In the past five years, imaging approaches have shown great potential for high-throughput plant phenotyping, resulting in more attention paid to imaging-based plant phenotyping. With this increased amount of image data, it has become urgent to develop robust analytical tools that can extract phenotypic traits accurately and rapidly. The goal of this review is to provide a comprehensive overview of the latest studies using deep convolutional neural networks (CNNs) in plant phenotyping applications. We specifically review the use of various CNN architecture for plant stress evaluation, plant development, and postharvest quality assessment. We systematically organize the studies based on technical developments resulting from imaging classification, object detection, and image segmentation, thereby identifying state-of-the-art solutions for certain phenotyping applications. Finally, we provide several directions for future research in the use of CNN architecture for plant phenotyping purposes. Copyright © 2020 Yu Jiang and Changying Li. Exclusive Licensee Nanjing Agricultural University. Distributed under a Creative Commons Attribution License (CC BY 4.0).",,"Agricultural robots; Convolution; Deep neural networks; Forestry; Image segmentation; Network architecture; Object detection; Agricultural system; Breeding program; Phenotypic traits; Plant development; Plant phenotyping; Postharvest quality; State of the art; Technical development; Convolutional neural networks"
"Jin F., Cai Y., Pedrycz W., Liu J.","Efficiency evaluation with regret-rejoice cross-efficiency DEA models under the distributed linguistic environment","10.1016/j.cie.2022.108281","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131447646&doi=10.1016%2fj.cie.2022.108281&partnerID=40&md5=751ab923c13faa03239a275a6f63b98e","Data envelopment analysis (DEA) is an effective mathematical method for evaluating the efficiencies of decision-making units (DMUs). However, in the process of cross-efficiency evaluation, DEA models commonly neglect the regret aversion psychological characteristics of decision makers (DMs). Therefore, this paper focuses on the construction of regret-rejoice cross-efficiency linguistic distribution DEA (RCE-LDDEA) method with regret theory, in which the input and output data by means of linguistic distributions and the regret aversion psychological characteristics of DMs are considered. First, a linguistic distribution DEA model is proposed to derive the self-evaluation efficiencies of DMUs with linguistic distribution evaluation information. Then, based on regret theory, a regret-rejoice cross-efficiency evaluation (RCEE) model is developed to evaluate the cross-efficiencies of DMUs. Subsequently, based on the regret-rejoice super-efficiency evaluation (RSEE) model, a RCE-LDDEA method is designed to generate the complete ranking of DMUs. Finally, an example for evaluating performance of 10 public hospitals in China is provided to illustrate the implementation of the proposed RCE-LDDEA method. The stability and advantages of the proposed RCE-LDDEA method is performed by sensitivity analysis and comparative analysis. © 2022 Elsevier Ltd","Cross-efficiency evaluation; Data envelopment analysis; Linguistic distribution; Regret theory","Decision making; Efficiency; Hospitals; Linguistics; Sensitivity analysis; Cross-efficiency; Cross-efficiency evaluation; Data envelopment analysis models; Decision makers; Decision making unit; Efficiency evaluation; Linguistic distribution; Psychological characteristics; Regret aversions; Regret theory; Data envelopment analysis"
"Jin X., Zhang J., Guo T., Wang X., Su T., Lai Y., Kong J., Bai Y.","Deep Network Based Prediction Model for Heavy Metal Cadmium Content in Wheat Processing Chain [小麦加工链中重金属镉含量的深度网络预测模型]","10.7506/spkx1002-6630-20210717-194","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140333056&doi=10.7506%2fspkx1002-6630-20210717-194&partnerID=40&md5=dddd1a7f7baafcb8037796925b051496","Cadmium is considered one of the most harmful heavy metals because of its wide range of dangerous contamination, high toxicity, and easy invasion. Long-term intake of excessive cadmium can cause many diseases including cancers. Cadmium content prediction in the wheat processing chain is of great practical importance for developing countermeasures to reduce its hazards. In this paper, we proposed a deep learning prediction model using the regularization method to address the problem that the data of cadmium content in the wheat processing chain contain strong nonlinear and random noises, which leads to poor fitness of the traditional model. Firstly, a gated recurrent unit (GRU) was used to build the deep learning prediction model. Secondly, the loss function of the model was modified using the regularization method to reduce the impact of noise on the prediction performance of the model by adding a noise penalty term to fade out the noise fit of the model during training. Finally, a Bayesian optimization method was used to select the hyperparameters to ensure that the model could accurately predict the cadmium content at each stage of the wheat processing chain. The prediction results show that flour made from wheat grains with a cadmium content less than 0.1 mg/kg can basically meet the requirements of the national standard (GB 2762-2017). © 2022, China Food Publishing Company. All right reserved.","Bayesian optimization; Cadmium; Gated recurrent unit; Predictive models; Wheat processing chain","Cadmium; Deep learning; Learning systems; Bayesian optimization; Cadmium content; Gated recurrent unit; Network-based; Practical importance; Prediction modelling; Predictive models; Processing chain; Regularization methods; Wheat processing chain; Forecasting"
"Joshi K., Pandey R., Bharany S., Rehman A.U., Taleb N., Kalra D.","Customization of Bookkeeping system for Blockchain System Analysis: A Review","10.1109/ICCR56254.2022.9995992","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146489207&doi=10.1109%2fICCR56254.2022.9995992&partnerID=40&md5=2afc58cba4562f75429ff73b21ca4b86","This paper proposes a blockchain system based on tokens, which streamlines the abstractions into a token structure, universally relevant. Every token's identity facilitates the implementation of governance and typical rollbacks, making more than half of the attacks non-defensible. As this method is based on tokens, with each transaction, the ownership is updated, and the system can be expanded parallel and transactions across chains are limitless. The mechanism for managing authority is flexible for the system proposed and this makes it suitable for regulations when the governance and supervision is adapted for accommodation of various scenarios of application. © 2022 IEEE.","Blockchain; Blockchain Technology (BT); Token Based","Block-chain; Blockchain technology; Customisation; Token based; Blockchain"
"Joshi S., Sharma M.","Sustainable Performance through Digital Supply Chains in Industry 4.0 Era: Amidst the Pandemic Experience","10.3390/su142416726","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144882560&doi=10.3390%2fsu142416726&partnerID=40&md5=70b7ff701dccb25157c7cdd3c95843dc","Amidst the COVID-19 pandemic disruption, industry 4.0 technologies (I4TEs) and digital supply chains (DSCs) are reinforcing businesses to gain economic stability and agility to enrich their sustainable performance (S.P.). Survey methods have been deployed based on the constructs obtained from the literature. Data collection through a survey resulted in 202 valid responses. Confirmatory factor analysis (CFA) confirms the constructs and the mediating effect of the DSCs through partial least squares structural equation modeling (PLS-SEM). The study is among the few studies that examine the I4TE impact on DSCs and S.P. The results show that industry 4.0 technologies enhance the sustainable performance of firms. Results also show a complete mediation of DSCs on the inter-relationship between I4TEs and S.P. Those DSCs with I4TE inclusion can transform an organization’s strategic decision-making. For the authors, this study is the first of its kind. Although some of the literature explored different aspects of the concept of industry 4.0 and digitalizing supply chains, studies have yet to specifically evaluate the potential impacts of digital supply chains on sustainable performance. The novelty of DSCs is their support of firms in improving their preparedness, agility, and transparency to strengthen their sustainable performance. These DSCs will provide agile, collaboration, responsiveness, end-to-end visibility, and resilient supply chains to diminish supply risk and enrich preparedness and responsiveness to recuperate quickly from uncertainty amidst the pandemic. The study will help managers re-designing their strategic planning, resulting in new cost reduction and resilience models for supply chains. The study calls for firms to employ multiple DSCs once they have set clear strategic priorities. The overall findings of the work fill the literature gaps of studies in the digitalization of supply chains. © 2022 by the authors.","digital supply chain (DSC); industry 4.0 technologies (I4TEs); pandemic; resilience; supply chain 4.0; sustainable performance (S.P.)","COVID-19; digitization; factor analysis; risk assessment; supply chain management; sustainability"
"Juan Y., Dai Y., Yang Y., Zhang J.","Accelerating materials discovery using machine learning","10.1016/j.jmst.2020.12.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098647217&doi=10.1016%2fj.jmst.2020.12.010&partnerID=40&md5=70790b474e9c51b1e22c7d6dd49b726a","The discovery of new materials is one of the driving forces to promote the development of modern society and technology innovation, the traditional materials research mainly depended on the trial-and-error method, which is time-consuming and laborious. Recently, machine learning (ML) methods have made great progress in the researches of materials science with the arrival of the big-data era, which gives a deep revolution in human society and advance science greatly. However, there exist few systematic generalization and summaries about the applications of ML methods in materials science. In this review, we first provide a brief account of the progress of researches on materials science with ML employed, the main ideas and basic procedures of this method are emphatically introduced. Then the algorithms of ML which were frequently used in the researches of materials science are classified and compared. Finally, the recent meaningful applications of ML in metal materials, battery materials, photovoltaic materials and metallic glass are reviewed. © 2021","Data-driven; Machine learning; Materials design; Materials discovery; Materials properties prediction","Metallic glass; Basic procedure; Battery materials; Driving forces; Metal materials; Photovoltaic materials; Society and technologies; Traditional materials; Trial-and-error method; Machine learning"
"Kalimeri K., Tjostheim I.","Artificial Intelligence and Concerns About the Future: A Case Study in Norway","10.1007/978-3-030-50344-4_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088742075&doi=10.1007%2f978-3-030-50344-4_20&partnerID=40&md5=4c9b43e8d8c1fa9365cf7af3aac047b9","Artificial Intelligence (AI) is an integral part of our lives with AI systems to revolutionise our daily practices. At the same time, the rapid pace of AI innovations entails inherent risks that can range from cyber-crime to social discrimination. Here, we administered a large scale survey assessing peoples’ concerns and expectations regarding AI’s influence on society in the future decade. The AI concerns employed in this study, originate from the “One hundred year study on Artificial Intelligence” project. Taking Norway as a case study, we discuss the participants’ prioritisation of concerns for their socio-demographic characteristics. Our findings show a divide in the society; with younger generations to expect a positive impact of AI on our lives in the future decade. More sceptical groups are afraid of structural changes in the economy and job losses, while supporters see opportunities that will improve our life quality. These findings can inform both academics and policymakers that should work closely to ensure fairness, explainability and maintain a trusting relationship between AI and society. © 2020, Springer Nature Switzerland AG.","AI for social good; Artificial Intelligence; Ethics; Explainable AI; Fairness; Morals","Employment; Human computer interaction; Cyber-crimes; Inherent risk; Integral part; Large scale surveys; Life qualities; Policy makers; Socio-demographic characteristics; Younger generations; Artificial intelligence"
"Kalopesa E., Karyotis K., Tziolas N., Tsakiridis N., Samarinas N., Zalidis G.","Estimation of Sugar Content in Wine Grapes via In Situ VNIR–SWIR Point Spectroscopy Using Explainable Artificial Intelligence Techniques","10.3390/s23031065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147895134&doi=10.3390%2fs23031065&partnerID=40&md5=79d440d60133c74baaa55aac88fd2368","Spectroscopy is a widely used technique that can contribute to food quality assessment in a simple and inexpensive way. Especially in grape production, the visible and near infrared (VNIR) and the short-wave infrared (SWIR) regions are of great interest, and they may be utilized for both fruit monitoring and quality control at all stages of maturity. The aim of this work was the quantitative estimation of the wine grape ripeness, for four different grape varieties, by using a highly accurate contact probe spectrometer that covers the entire VNIR–SWIR spectrum (350–2500 nm). The four varieties under examination were Chardonnay, Malagouzia, Sauvignon-Blanc, and Syrah and all the samples were collected over the 2020 and 2021 harvest and pre-harvest phenological stages (corresponding to stages 81 through 89 of the BBCH scale) from the vineyard of Ktima Gerovassiliou located in Northern Greece. All measurements were performed in situ and a refractometer was used to measure the total soluble solids content (°Brix) of the grapes, providing the ground truth data. After the development of the grape spectra library, four different machine learning algorithms, namely Partial Least Squares regression (PLS), Random Forest regression, Support Vector Regression (SVR), and Convolutional Neural Networks (CNN), coupled with several pre-treatment methods were applied for the prediction of the °Brix content from the VNIR–SWIR hyperspectral data. The performance of the different models was evaluated using a cross-validation strategy with three metrics, namely the coefficient of the determination ((Formula presented.)), the root mean square error (RMSE), and the ratio of performance to interquartile distance (RPIQ). High accuracy was achieved for Malagouzia, Sauvignon-Blanc, and Syrah from the best models developed using the CNN learning algorithm ((Formula presented.), (Formula presented.)), while a good fit was attained for the Chardonnay variety from SVR ((Formula presented.), (Formula presented.), (Formula presented.)), proving that by using a portable spectrometer the in situ estimation of the wine grape maturity could be provided. The proposed methodology could be a valuable tool for wine producers making real-time decisions on harvest time and with a non-destructive way. © 2023 by the authors.","cultivar; deep learning; NIR spectroscopy; oenological parameters; TSS; vineyard; vis–NIR","Convolutional neural networks; Deep learning; Forestry; Fruits; Infrared devices; Infrared radiation; Learning algorithms; Least squares approximations; Mean square error; Near infrared spectroscopy; Quality control; Spectrometers; Support vector regression; Cultivar; Deep learning; NIR spectroscopy; Oenological parameters; Short wave infrared; TSS; Vineyard; Visible and near infrared; Vis–NIR; Wine grapes; Wine; carbohydrate; artificial intelligence; chemistry; fruit; near infrared spectroscopy; procedures; Vitis; wine; Artificial Intelligence; Carbohydrates; Fruit; Spectroscopy, Near-Infrared; Sugars; Vitis; Wine"
"Kaluarachchi T., Reis A., Nanayakkara S.","A review of recent deep learning approaches in human-centered machine learning","10.3390/s21072514","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103490675&doi=10.3390%2fs21072514&partnerID=40&md5=0eebb859a92a0832c07dad741e9c5020","After Deep Learning (DL) regained popularity recently, the Artificial Intelligence (AI) or Machine Learning (ML) field is undergoing rapid growth concerning research and real-world application development. Deep Learning has generated complexities in algorithms, and researchers and users have raised concerns regarding the usability and adoptability of Deep Learning systems. These concerns, coupled with the increasing human-AI interactions, have created the emerging field that is Human-Centered Machine Learning (HCML). We present this review paper as an overview and analysis of existing work in HCML related to DL. Firstly, we collaborated with field domain experts to develop a working definition for HCML. Secondly, through a systematic literature review, we analyze and classify 162 publications that fall within HCML. Our classification is based on aspects including contribution type, application area, and focused human categories. Finally, we analyze the topology of the HCML landscape by identifying research gaps, highlighting conflicting interpretations, addressing current challenges, and presenting future HCML research opportunities. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep Learning; HCAI; HCML; Human-centered artificial intelligence; Human-centered machine learning","Learning systems; Application area; Application development; Domain experts; Learning approach; Research gaps; Research opportunities; Review papers; Systematic literature review; Deep learning; algorithm; artificial intelligence; human; machine learning; Algorithms; Artificial Intelligence; Deep Learning; Humans; Machine Learning"
"Kammerer M., Goslee S.C., Douglas M.R., Tooker J.F., Grozinger C.M.","Wild bees as winners and losers: Relative impacts of landscape composition, quality, and climate","10.1111/gcb.15485","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099244324&doi=10.1111%2fgcb.15485&partnerID=40&md5=32339ce8b7f0c93dc93c99548e37cbec","Wild bees, like many other taxa, are threatened by land-use and climate change, which, in turn, jeopardizes pollination of crops and wild plants. Understanding how land-use and climate factors interact is critical to predicting and managing pollinator populations and ensuring adequate pollination services, but most studies have evaluated either land-use or climate effects, not both. Furthermore, bee species are incredibly variable, spanning an array of behavioral, physiological, and life-history traits that can increase or decrease resilience to land-use or climate change. Thus, there are likely bee species that benefit, while others suffer, from changing climate and land use, but few studies have documented taxon-specific trends. To address these critical knowledge gaps, we analyzed a long-term dataset of wild bee occurrences from Maryland, Delaware, and Washington DC, USA, examining how different bee genera and functional groups respond to landscape composition, quality, and climate factors. Despite a large body of literature documenting land-use effects on wild bees, in this study, climate factors emerged as the main drivers of wild-bee abundance and richness. For wild-bee communities in spring and summer/fall, temperature and precipitation were more important predictors than landscape composition, landscape quality, or topography. However, relationships varied substantially between wild-bee genera and functional groups. In the Northeast USA, past trends and future predictions show a changing climate with warmer winters, more intense precipitation in winter and spring, and longer growing seasons with higher maximum temperatures. In almost all of our analyses, these conditions were associated with lower abundance of wild bees. Wild-bee richness results were more mixed, including neutral and positive relationships with predicted temperature and precipitation patterns. Thus, in this region and undoubtedly more broadly, changing climate poses a significant threat to wild-bee communities. © 2021 The Authors. Global Change Biology published by John Wiley & Sons Ltd","Apoidea; climate change; exotic species; land use; precipitation; temperature; urbanization; wild bees","anthropogenic effect; bee; climate change; climate effect; community response; functional group; growing season; land use; landscape structure; pollination; precipitation (climatology); species richness; temperature gradient; urbanization; Delaware; District of Columbia; Maryland; United States; Washington [District of Columbia]; Apoidea; animal; bee; crop; Maryland; pollination; season; temperature; Animals; Bees; Crops, Agricultural; Maryland; Pollination; Seasons; Temperature"
"Kang Q., Song X., Xin X., Chen B., Chen Y., Ye X., Zhang B.","Machine Learning-Aided Causal Inference Framework for Environmental Data Analysis: A COVID-19 Case Study","10.1021/acs.est.1c02204","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116537274&doi=10.1021%2facs.est.1c02204&partnerID=40&md5=bc040a940f322240816d36a3ad1f809f","Links between environmental conditions (e.g., meteorological factors and air quality) and COVID-19 severity have been reported worldwide. However, the existing frameworks of data analysis are insufficient or inefficient to investigate the potential causality behind the associations involving multidimensional factors and complicated interrelationships. Thus, a causal inference framework equipped with the structural causal model aided by machine learning methods was proposed and applied to examine the potential causal relationships between COVID-19 severity and 10 environmental factors (NO2, O3, PM2.5, PM10, SO2, CO, average air temperature, atmospheric pressure, relative humidity, and wind speed) in 166 Chinese cities. The cities were grouped into three clusters based on the socio-economic features. Time-series data from these cities in each cluster were analyzed in different pandemic phases. The robustness check refuted most potential causal relationships’ estimations (89 out of 90). Only one potential relationship about air temperature passed the final test with a causal effect of 0.041 under a specific cluster-phase condition. The results indicate that the environmental factors are unlikely to cause noticeable aggravation of the COVID-19 pandemic. This study also demonstrated the high value and potential of the proposed method in investigating causal problems with observational data in environmental or other fields. © 2021 The Authors. Published by American Chemical Society","air pollutant; causal inference; COVID-19; machine learning; meteorological factor; structural causal model","Atmospheric humidity; Atmospheric pressure; Atmospheric temperature; Data handling; Factor analysis; Information analysis; Machine learning; Wind; Air pollutants; Causal inferences; Causal modeling; Causal relationships; COVID-19; Environmental data; Environmental factors; Machine-learning; Meteorological factors; Structural causal model; Air quality; air temperature; COVID-19; data assimilation; environmental conditions; environmental factor; epidemic; machine learning; socioeconomic conditions; time series analysis; air pollutant; air temperature; Article; causal model; city; controlled study; coronavirus disease 2019; data analysis; disease exacerbation; environmental factor; human; machine learning; pandemic; time series analysis; air pollution; machine learning; China; Air Pollution; COVID-19; Humans; Machine Learning; Pandemics; SARS-CoV-2"
"Kang Y., Nam J., Kim Y., Lee S., Seong D., Jang S., Ryu C.","Assessment of regression models for predicting rice yield and protein content using unmanned aerial vehicle-based multispectral imagery","10.3390/rs13081508","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105764296&doi=10.3390%2frs13081508&partnerID=40&md5=71f838fa9a50238288077f3382807bcd","Unmanned aerial vehicle-based multispectral imagery including five spectral bands (blue, green, red, red-edge, and near-infrared) for a rice field in the ripening stage was used to develop regression models for predicting the rice yield and protein content and to select the most suitable regression analysis method for the year-invariant model: partial least squares regression, ridge regression, and artificial neural network (ANN). The regression models developed with six vegetation indices (green normalization difference vegetation index (GNDVI), normalization difference red-edge index (NDRE), chlorophyll index red edge (CIrededge), difference NIR/Green green difference vegetation index (GDVI), green-red NDVI (GRNDVI), and medium resolution imaging spectrometer terrestrial chlorophyll index (MTCI)), calculated from the spectral bands, were applied to single years (2018, 2019, and 2020) and multiple years (2018 + 2019, 2018 + 2020, 2019 + 2020, and all years). The regression models were cross-validated through mutual prediction against the vegetation indices in nonoverlapping years, and the prediction errors were evaluated via root mean squared error of prediction (RMSEP). The ANN model was reproducible, with low and sustained prediction errors of 24.2 kg/1000 m2 ≤ RMSEP ≤ 59.1 kg/1000 m2 in rice yield and 0.14% ≤ RMSEP ≤ 0.28% in rice-protein content in all single-year and multiple-year analyses. When the importance of each vegetation index of the regression models was evaluated, only the ANN model showed the same ranking in the vegetation index of the first (MTCI in both rice yield and protein content) and second importance (CIrededge in rice yield and GRNDVI in rice-protein content). Overall, this means that the ANN model has the highest potential for developing a year-invariant model with stable RMSEP and consistent variable ranking. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Multispectral imagery; Mutual prediction; Regression model; Rice yield; Rice-protein content","Antennas; Chlorophyll; Errors; Forecasting; Infrared devices; Least squares approximations; Mean square error; Neural networks; Proteins; Remote sensing; Unmanned aerial vehicles (UAV); Vegetation; Consistent variables; Green difference vegetation indices; Medium resolution imaging spectrometers; Multi-spectral imagery; Mutual predictions; Partial least squares regression; Regression analysis methods; Root mean squared errors; Regression analysis"
"Kang Z., Catal C., Tekinerdogan B.","Machine learning applications in production lines: A systematic literature review","10.1016/j.cie.2020.106773","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090044469&doi=10.1016%2fj.cie.2020.106773&partnerID=40&md5=79d3fc94086dd7290def7a9c6ebeba27","A production line is a set of sequential operations established in a factory where materials are put through a refining process to produce an end-product that is suitable for further usage. Monitoring production lines is essential to ensure that the targeted quality of the production process and the products are achieved. With the increased digitalization, lots of data can now be generated in the overall production line process. In parallel, the generated data sets are used by machine learning techniques for analytics of the production line to improve quality control, evaluate risks, and save cost. This paper aims to identify, assess, and synthesize the reported studies related to the application of machine learning in production lines, to provide a systematic overview of the current state-of-the-art and, as such, paving the way for further research. To this end, we have performed a Systematic Literature Review (SLR) in which we retrieved 271 papers, of which 39 primary studies were selected for a detailed analysis. This SLR presents and categorizes the production line problems addressed by machine learning, identifies the targeted industrial domains, discusses which machine learning algorithms have been used, and explains the adopted independent and dependent variables of the models. The study highlights the open problems that need to be solved and provides the identified research directions. © 2020 Elsevier Ltd","Data analytics; Data mining; Machine learning; Production lines; Systematic literature review","Machine learning; Quality control; Dependent variables; Machine learning applications; Machine learning techniques; Production process; Refining process; Sequential operations; Systematic literature review; Systematic literature review (SLR); Learning algorithms"
"Karger E.","Combining blockchain and artificial intelligence - Literature review and state of the art",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103471168&partnerID=40&md5=92b2d03b9e553332b2119e1d22fa245f","Artificial intelligence and blockchain are among the most popular technologies. Combine the two technologies also harbors manifold potentials. For instance, blockchain can help address specific AI-related difficulties such as the black box problem. Vice versa, AI offers opportunities to improve the blockchain's mining process, or smart contracts. Despite their relevance for companies, these combination solutions have so far received little attention. We undertake a systematic literature review to close this research gap and to provide a first comprehensive overview of this emerging field. We do so by providing a threefold categorization of the different options for connecting the blockchain and AI. © ICIS 2020. All rights reserved.","Artificial intelligence; Blockchain; Deep learning; Machine learning; Smart contracts","Blending; Blockchain; Information systems; Information use; Black boxes; Literature reviews; Mining process; State of the art; Systematic literature review; Artificial intelligence"
"Kariotis T., Mir D.J.","Fighting Back Algocracy: The need for new participatory approaches to technology assessment","10.1145/3384772.3385151","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087422994&doi=10.1145%2f3384772.3385151&partnerID=40&md5=29540c8a3d509c4aa21d92788267c73e","City, municipal, and state governments around the globe are increasingly looking towards algorithmic solutions to long-standing and difficult problems in governance. We use the term algorithmic governance to capture this increasing use of predictive and other algorithms to provide efficiencies in the targeting of services and government processes. However, in the course of pursuing these efficiencies, openness, transparency, public accountability, and community-based deliberation, key pillars of democracy, come under threat when decision making is black-boxed in an algorithm. Furthermore, algorithmic governance (for example, in domains like welfare management) typically exacerbates the marginalization of the most disadvantaged in society, while simultaneously making such marginalization invisible to the larger citizenry. A hybrid technology assessment (TA) comprising of elements of both participatory TA (that involves public debate about technology) and constructive TA (that involves co-construction of technology between society and designers) employed through the framework of engineering technology for social justice, may help address these challenges. © 2020 ACM.","Democracy; Participatory algorithmic governance; Social Justice; Technology Assessment","Efficiency; Algorithmic solutions; Community-based; Hybrid technology; Participatory approach; Public accountability; State governments; Technology assessments; Welfare management; Decision making"
"Karnouskos S.","Blockchain for Development in the Era of the COVID-19 Pandemic","10.1109/OJIES.2021.3121549","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121061353&doi=10.1109%2fOJIES.2021.3121549&partnerID=40&md5=f1e5b3aed7fcf5133e9fd481e0ff0db6","In the context of Informationand Communication Technologies (ICT) for Development (ICT4D), several efforts have been carried out over the last decades to help developing countries address their challenges. In times of a pandemic, such as the COVID-19, several of these challenges gain higher priority in development as they may become unmanageable with the developing world's resources. Blockchain is a disruptive technology that could potentially enable the sustainable addressing of some of them, and COVID-19 offers a unique and timely opportunity to operationalize it. Driven by the research question 'In what areas can Blockchain help address development challenges during a pandemic?' we aim to understand its applicability in addressing crucial social problems in developing countries. While the literature analysis points towards several promising areas, there are also significant concerns that need to be understood and carefully addressed when considering Blockchain in the context of developing countries. The critical discourse in this work is expected to benefit a wide variety of technology, policy, and research stakeholders. © 2020 IEEE.","Blockchain; COVID-19; ICT4D; information and communication technologies; pandemic; social implications; technology impact","Blockchain; Economic and social effects; Block-chain; COVID-19; ICT4D; INDEX TERMS blockchain; Information and Communication Technologies; Pandemic; Social implication; Stakeholder; Technology impact; Developing countries"
"Kaul R., Ossai C., Forkan A.R.M., Jayaraman P.P., Zelcer J., Vaughan S., Wickramasinghe N.","The role of AI for developing digital twins in healthcare: The case of cancer care","10.1002/widm.1480","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142395208&doi=10.1002%2fwidm.1480&partnerID=40&md5=91431a412f3a96c86fe9520ddbaaed60","Digital twins, succinctly described as the digital representation of a physical object, is a concept that has emerged relatively recently with increasing application in the manufacturing industry. This article proposes the application of this concept to the healthcare domain to provide enhanced clinical decision support and enable more patient-centric, and simultaneously more precise and individualized care to ensue. Digital twins combined with advances in Artificial Intelligence (AI) have the potential to facilitate the integration and processing of vast amounts of heterogeneous data stemming from diversified sources. Hence, in healthcare this can provide enhanced diagnosis and treatment decision support. In applying digital twins in combination with AI to complex healthcare contexts to assist clinical decision making, it is also likely that a key current challenge in healthcare; namely, providing better quality care which is of high value and can lead to better clinical outcomes and a higher level of patient satisfaction, can ensue. In this focus article, we address this proposition by focusing on the case study of cancer care and present our conceptualization of a digital twin model combined with AI to address key, current limitations in endometrial cancer treatment. We highlight the role of AI techniques in developing digital twins for cancer care and simultaneously identify key barriers and facilitators of this process from both a healthcare and technology perspective. This article is categorized under: Application Areas > Health Care. © 2022 The Authors. WIREs Data Mining and Knowledge Discovery published by Wiley Periodicals LLC.","artificial intelligence; cancer care; digital twin; health care","Artificial intelligence; Data mining; Decision making; Decision support systems; Diseases; 'current; Cancer care; Clinical decision making; Clinical decision support; Decision supports; Digital representations; Healthcare domains; Heterogeneous data; Manufacturing industries; Physical objects; Health care"
"Kaur P., Harnal S., Tiwari R., Upadhyay S., Bhatia S., Mashat A., Alabdali A.M.","Recognition of Leaf Disease Using Hybrid Convolutional Neural Network by Applying Feature Reduction","10.3390/s22020575","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122497134&doi=10.3390%2fs22020575&partnerID=40&md5=95ea014e08f7a2c89c88eda98599311d","Agriculture is crucial to the economic prosperity and development of India. Plant diseases can have a devastating influence towards food safety and a considerable loss in the production of agricultural products. Disease identification on the plant is essential for long‐term agriculture sus-tainability. Manually monitoring plant diseases is difficult due to time limitations and the diversity of diseases. In the realm of agricultural inputs, automatic characterization of plant diseases is widely required. Based on performance out of all image‐processing methods, is better suited for solving this task. This work investigates plant diseases in grapevines. Leaf blight, Black rot, stable, and Black measles are the four types of diseases found in grape plants. Several earlier research proposals using machine learning algorithms were created to detect one or two diseases in grape plant leaves; no one offers a complete detection of all four diseases. The photos are taken from the plant village dataset in order to use transfer learning to retrain the EfficientNet B7 deep architecture. Following the transfer learning, the collected features are down‐sampled using a Logistic Regression tech-nique. Finally, the most discriminant traits are identified with the highest constant accuracy of 98.7% using state‐of‐the‐art classifiers after 92 epochs. Based on the simulation findings, an appropriate classifier for this application is also suggested. The proposed technique’s effectiveness is confirmed by a fair comparison to existing procedures. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Convolutional neural network; EfficientNet B7; Feature reduction and extraction; Image classification; Leaf disease detection; Plant disease; Transfer learning","Agricultural products; Convolution; Convolutional neural networks; Feature extraction; Learning algorithms; Plants (botany); Convolutional neural network; Economic prosperity; Efficientnet b7; Features extraction; Features reductions; Images classification; Leaf disease; Leaf disease detections; Plant disease; Transfer learning; Image classification; algorithm; image processing; machine learning; plant disease; Algorithms; Image Processing, Computer-Assisted; Machine Learning; Neural Networks, Computer; Plant Diseases"
"Kawamura T., Egami S., Tamura K., Hokazono Y., Ugai T., Koyanagi Y., Nishino F., Okajima S., Murakami K., Takamatsu K., Sugiura A., Shiramatsu S., Zhang X., Kozaki K.","Report on the first knowledge graph reasoning challenge 2018: Toward the eXplainable AI system","10.1007/978-3-030-41407-8_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080871686&doi=10.1007%2f978-3-030-41407-8_2&partnerID=40&md5=8a4050ba698b4587c6a70630d5968f95","A new challenge for knowledge graph reasoning started in 2018. Deep learning has promoted the application of artificial intelligence (AI) techniques to a wide variety of social problems. Accordingly, being able to explain the reason for an AI decision is becoming important to ensure the secure and safe use of AI techniques. Thus, we, the Special Interest Group on Semantic Web and Ontology of the Japanese Society for AI, organized a challenge calling for techniques that reason and/or estimate which characters are criminals while providing a reasonable explanation based on an open knowledge graph of a well-known Sherlock Holmes mystery story. This paper presents a summary report of the first challenge held in 2018, including the knowledge graph construction, the techniques proposed for reasoning and/or estimation, the evaluation metrics, and the results. The first prize went to an approach that formalized the problem as a constraint satisfaction problem and solved it using a lightweight formal method; the second prize went to an approach that used SPARQL and rules; the best resource prize went to a submission that constructed word embedding of characters from all sentences of Sherlock Holmes novels; and the best idea prize went to a discussion multi-agents model. We conclude this paper with the plans and issues for the next challenge in 2019. © Springer Nature Switzerland AG 2020.","Knowledge graph; Machine learning; Open data; Reasoning","Deep learning; Formal methods; Learning systems; Multi agent systems; Open Data; Semantic Web; AI techniques; Evaluation metrics; Knowledge graphs; Lightweight formal methods; Multi-agents models; Reasoning; Social problems; Special interest groups; Constraint satisfaction problems"
"Kebonye N.M., Agyeman P.C., Seletlo Z., Eze P.N.","On exploring bivariate and trivariate maps as visualization tools for spatial associations in digital soil mapping: A focus on soil properties","10.1007/s11119-022-09955-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137740229&doi=10.1007%2fs11119-022-09955-7&partnerID=40&md5=bd9338c441405b8f6237cbfbdc972351","The benefits of digital soil maps cannot be overemphasised. For many years, researchers have mapped different soil classes, properties and processes while identifying the spatial associations between soil properties using side-by-side visualization maps. Although this is acceptable, it may be difficult to identify complex spatial associations between the mapped soil properties. For some, the task may be challenging owing to multiple times of side-by-side placing of the maps and the possible application of none user-friendly colour palettes and or schemes. Innovative tools are proposed for visualizing and identifying spatial associations between digital soil maps (raster layers) using bivariate and trivariate maps. These tools are applied in a case study to identify the spatial interactions between pH and selected macro-nutrients [nitrogen (N) and potassium (K)] of similar locality (Czech Republic), resolution and scale. This study further gives a brief overview of the applicability of bivariate and trivariate maps following the digital soil mapping process. Results show that bivariate and trivariate maps are effective for visualizing complex associations between pH and macro-nutrients. However, precautionary measures should be taken while applying bivariate and trivariate maps to ensure they are self-explanatory and that the legend colour schemes applied are user-friendly. Also, the variables mapped should be related. In this case, pH is a key soil quality indicator that affects macro-nutrient availability in soils. Graphical abstract: [Figure not available: see fulltext.]. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Czech Republic; Environmental covariates; Predictive soil mapping; Soil macro-nutrients; Visual analytics",
"Kennedy-Metz L.R., Mascagni P., Torralba A., Dias R.D., Perona P., Shah J.A., Padoy N., Zenati M.A.","Computer Vision in the Operating Room: Opportunities and Caveats","10.1109/TMRB.2020.3040002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115828804&doi=10.1109%2fTMRB.2020.3040002&partnerID=40&md5=46b18b1316fb5ac4cf95b4ea6f2c6e6e","Effectiveness of computer vision techniques has been demonstrated through a number of applications, both within and outside healthcare. The operating room environment specifically is a setting with rich data sources compatible with computational approaches and high potential for direct patient benefit. The aim of this review is to summarize major topics in computer vision for surgical domains. The major capabilities of computer vision are described as an aid to surgical teams to improve performance and contribute to enhanced patient safety. Literature was identified through leading experts in the fields of surgery, computational analysis and modeling in medicine, and computer vision in healthcare. The literature supports the application of computer vision principles to surgery. Potential applications within surgery include operating room vigilance, endoscopic vigilance, and individual and team-wide behavioral analysis. To advance the field, we recommend collecting and publishing carefully annotated datasets. Doing so will enable the surgery community to collectively define well-specified common objectives for automated systems, spur academic research, mobilize industry, and provide benchmarks with which we can track progress. Leveraging computer vision approaches through interdisciplinary collaboration and advanced approaches to data acquisition, modeling, interpretation, and integration promises a powerful impact on patient safety, public health, and financial costs. © 2018 IEEE.","Artificial intelligence; computer vision; patient safety; robotics; surgery; vigilance","Agricultural robots; Automation; Computational methods; Data acquisition; Medical computing; Operating rooms; Surgery; Annotated datasets; Behavioral analysis; Computational analysis; Computational approach; Computer vision techniques; Improve performance; Interdisciplinary collaborations; Operating room environment; Computer vision"
"Kenny E.M., Keane M.T.","Explaining Deep Learning using examples: Optimal feature weighting methods for twin systems using post-hoc, explanation-by-example in XAI","10.1016/j.knosys.2021.107530","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116525863&doi=10.1016%2fj.knosys.2021.107530&partnerID=40&md5=fd7284051085086175b03efcb1ad4983","In this paper, the twin-systems approach is reviewed, implemented, and competitively tested as a post-hoc explanation-by-example solution to the eXplainable Artificial Intelligence (XAI) problem. In twin-systems, an opaque artificial neural network (ANN) is explained by “twinning” it with a more interpretable case-based reasoning (CBR) system, by mapping the feature weights from the former to the latter. Extensive comparative tests are performed, over four experiments, to determine the optimal feature-weighting method for such twin-systems. Twin-systems for traditional multilayer perceptron (MLP) networks (MLP–CBR twins), convolutional neural networks (CNNs; CNN–CBR twins), and transformers for NLP (BERT–CBR twins) are examined. In addition, Feature Activation Maps (FAMs) are explored to enhance explainability by providing an additional layer of explanatory insight. The wider implications of this research on XAI is discussed, and a code library is provided to ease replicability. © 2021 The Author(s)","Artificial neural networks; Case-based reasoning; Computer vision; Deep Learning; Explainable AI; Explanation-by-example; Natural Language Processing","Case based reasoning; Computer vision; Convolutional neural networks; Deep learning; Multilayer neural networks; Case-based reasoning systems; Casebased reasonings (CBR); Comparative tests; Deep learning; Explainable AI; Explanation-by-example; Feature weight; Feature weighting; Systems approach; Weighting methods; Natural language processing systems"
"Kenny E.M., Ford C., Quinn M., Keane M.T.","Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies","10.1016/j.artint.2021.103459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100051479&doi=10.1016%2fj.artint.2021.103459&partnerID=40&md5=ccd4bea7bb8ddcfcd62ba469b508756a","In this paper, we describe a post-hoc explanation-by-example approach to eXplainable AI (XAI), where a black-box, deep learning system is explained by reference to a more transparent, proxy model (in this situation a case-based reasoner), based on a feature-weighting analysis of the former that is used to find explanatory cases from the latter (as one instance of the so-called Twin Systems approach). A novel method (COLE-HP) for extracting the feature-weights from black-box models is demonstrated for a convolutional neural network (CNN) applied to the MNIST dataset; in which extracted feature-weights are used to find explanatory, nearest-neighbours for test instances. Three user studies are reported examining people's judgements of right and wrong classifications made by this XAI twin-system, in the presence/absence of explanations-by-example and different error-rates (from 3-60%). The judgements gathered include item-level evaluations of both correctness and reasonableness, and system-level evaluations of trust, satisfaction, correctness, and reasonableness. Several proposals are made about the user's mental model in these tasks and how it is impacted by explanations at an item- and system-level. The wider lessons from this work for XAI and its user studies are reviewed. © 2021 The Authors","Case-based reasoning; Convolutional neural network; Deep learning; Explainable AI; Factual explanation; k-nearest neighbours; Trust; User testing","Convolutional neural networks; Deep learning; Statistical tests; Black-box model; Case-based reasoner; Feature weight; Feature weighting; Nearest neighbour; Presence/absence; System level evaluation; Systems approach; Learning systems"
"Kenny E.M., Keane M.T.","On Generating Plausible Counterfactual and Semi-Factual Explanations for Deep Learning",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128905660&partnerID=40&md5=3aa2aa8a15548df0907f337f6313cd8a","There is a growing concern that the recent progress made in AI, especially regarding the predictive competence of deep learning models, will be undermined by a failure to properly explain their operation and outputs. In response to this disquiet, counterfactual explanations have become very popular in eXplainable AI (XAI) due to their asserted computational, psychological, and legal benefits. In contrast however, semi-factuals (which appear to be equally useful) have surprisingly received no attention. Most counterfactual methods address tabular rather than image data, partly because the non-discrete nature of images makes good counterfactuals difficult to define; indeed, generating plausible counterfactual images which lie on the data manifold is also problematic. This paper advances a novel method for generating plausible counterfactuals and semi-factuals for black-box CNN classifiers doing computer vision. The present method, called PlausIble Exceptionality-based Contrastive Explanations (PIECE), modifies all “exceptional” features in a test image to be “normal” from the perspective of the counterfactual class, to generate plausible counterfactual images. Two controlled experiments compare this method to others in the literature, showing that PIECE generates highly plausible counterfactuals (and the best semi-factuals) on several benchmark measures. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,"Black boxes; Controlled experiment; Counterfactuals; Data manifolds; Image data; Learning models; Novel methods; Recent progress; Test images; Deep learning"
"Kenny E.M., Delaney E.D., Greene D., Keane M.T.","Post-hoc Explanation Options for XAI in Deep Learning: The Insight Centre for Data Analytics Perspective","10.1007/978-3-030-68796-0_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104334723&doi=10.1007%2f978-3-030-68796-0_2&partnerID=40&md5=dd8faa07e1e7557ab344201adb19e55f","This paper profiles the recent research work on eXplainable AI (XAI), at the Insight Centre for Data Analytics. This work concentrates on post-hoc explanation-by-example solutions to XAI as one approach to explaining black box deep-learning systems. Three different methods of post-hoc explanation are outlined for image and time-series datasets: that is, factual, counterfactual, and semi-factual methods). The future landscape for XAI solutions is discussed. © 2021, Springer Nature Switzerland AG.","Artificial Neural Networks; Case-based reasoning; Convolutional neural networks; Explainable AI; Interpretable AI; k-nearest neighbors; Trust","Data Analytics; Learning systems; Pattern recognition; Black boxes; Recent researches; Deep learning"
"Képeš E., Vrábel J., Adamovsky O., Střítežská S., Modlitbová P., Pořízka P., Kaiser J.","Interpreting support vector machines applied in laser-induced breakdown spectroscopy","10.1016/j.aca.2021.339352","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121215317&doi=10.1016%2fj.aca.2021.339352&partnerID=40&md5=2f0aecbe74aa011b4344ae3aef485cf4","Laser-induced breakdown spectroscopy is often combined with a multivariate black box model—such as support vector machines (SVMs)—to obtain desirable quantitative or qualitative results. This approach carries obvious risks when practiced in high-stakes applications. Moreover, the lack of understanding of a black-box model limits the user's ability to fine-tune the model. Thus, here we present four approaches to interpret SVMs through investigating which features the models consider important in the classification task of 19 algal and cyanobacterial species. The four feature importance metrics are compared with popular approaches to feature selection for optimal SVM performance. We report that the distinct feature importance metrics yield complementary and often comparable information. In addition, we identify our SVM model's bias towards features with a large variance, even though these features exhibit a significant overlap between classes. We also show that the linear and radial basis kernel SVMs weight the same features to the same degree. © 2021 Elsevier B.V.","Classification; Feature importance; Interpretable machine learning; LIBS; SVM","Atomic emission spectroscopy; Classification (of information); Laser induced breakdown spectroscopy; Algal species; Black box modelling; Classification tasks; Cyanobacterial species; Feature importance; Features selection; Interpretable machine learning; LIBS; Machine performance; Support vectors machine; Support vector machines; article; feature selection; laser induced breakdown spectroscopy; support vector machine; laser; spectroscopy; Lasers; Spectrum Analysis; Support Vector Machine"
"Kern C., Klausch T., Kreuter F.","Tree-based machine learning methods for survey research","10.18148/srm/2019.v13i1.7395","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066761781&doi=10.18148%2fsrm%2f2019.v13i1.7395&partnerID=40&md5=7cb81c72e23dc213e5ea420377547f85","Predictive modeling methods from the field of machine learning have become a popular tool across various disciplines for exploring and analyzing diverse data. These methods often do not require specific prior knowledge about the functional form of the relationship under study and are able to adapt to complex non-linear and non-additive interrelations between the outcome and its predictors while focusing specifically on prediction performance. This modeling perspective is beginning to be adopted by survey researchers in order to adjust or improve various aspects of data collection and/or survey management. To facilitate this strand of research, this paper (1) provides an introduction to prominent tree-based machine learning methods, (2) reviews and discusses previous and (potential) prospective applications of tree-based supervised learning in survey research, and (3) exemplifies the usage of these techniques in the context of modeling and predicting nonresponse in panel surveys. © European Survey Research Association.","Adaptive design; Machine learning; Nonresponse; Panel attrition; Predictive models",
"Kganyago M., Ovakoglou G., Mhangara P., Adjorlolo C., Alexandridis T., Laneve G., Beltran J.S.","Evaluating the contribution of Sentinel-2 view and illumination geometry to the accuracy of retrieving essential crop parameters","10.1080/15481603.2022.2163046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145504720&doi=10.1080%2f15481603.2022.2163046&partnerID=40&md5=90917966ff9d9d5d2714c637220772a5","Wide field-of-view (FOV) sensors such as Sentinel-2 exhibit per-pixel view and illumination geometry variation that may influence the retrieval accuracy of essential crop biophysical and biochemical variables (BVs) for precision agriculture. However, this aspect is rarely studied in the existing literature. Hence, the current study aimed to evaluate the contribution of view and illumination geometries to the accuracy of retrieving Leaf Chlorophyll a and b (LCab), Canopy Chlorophyll Content (CCC), and Leaf Area Index (LAI) using the Random Forest (RF). The experiments were performed on various input variable scenarios where per-pixel geometric covariates, i.e. View and Sun Zenith Angles (VZA and SZA, respectively), and Relative Azimuth Angle (RAA), are excluded and included in spectral bands (SB) and spectral vegetation indices (SVIs), respectively, in two semi-arid areas. The results showed that spectral bands or vegetation indices combined with geometric covariates improved the R 2 by 10–15% for LAI and 3–5% for CCC. In contrast, negligible improvements of 1–2% were achieved for LCab with cross-validation test data and independent held-out dataset, respectively. In agreement with previous studies, VZA and SZA were among the topmost influential variables in the RF models for estimating LAI, LCab, and CCC. Collectively, per-pixel geometric variables explained more than 30% of the variability in surface reflectance for all Sentinel-2 spectral bands (p &lt; 2.2e-16). Overall, the results showed that incorporating geometric covariates improved the accuracy of retrieving BVs; thus, it provided additional information that improves the predictive power of SB and SVIs. The significant benefits of the geometric variables were mainly realized for canopy-level BVs (i.e. LAI and CCC) than for LCab. Therefore, it is recommended to incorporate per-pixel view and illumination geometry in estimating LAI and CCC, especially when using wide-view sensors such as Sentinel-2. However, further testing in different phenology, site and acquisition conditions is needed to confirm the contribution of the geometric covariates to facilitate reliable retrieval of BVs from remotely sensed data and aid better agronomic decisions. © 2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Chlorophyll Content; Leaf Area Index; Random Forest; red-edge vegetation indices; Sentinel-2; sun-sensor geometry","accuracy assessment; algorithm; chlorophyll; geometry; leaf area index; Sentinel; vegetation index"
"Kganyago M., Mhangara P., Adjorlolo C.","Estimating crop biophysical parameters using machine learning algorithms and sentinel-2 imagery","10.3390/rs13214314","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118479866&doi=10.3390%2frs13214314&partnerID=40&md5=01006e733636d7e98dc306e7c02047c7","Global food security is critical to eliminating hunger and malnutrition. In the changing climate, farmers in developing countries must adopt technologies and farming practices such as precision agriculture (PA). PA-based approaches enable farmers to cope with frequent and intensified droughts and heatwaves, optimising yields, increasing efficiencies, and reducing operational costs. Biophysical parameters such as Leaf Area Index (LAI), Leaf Chlorophyll Content (LCab), and Canopy Chlorophyll Content (CCC) are essential for characterising field-level spatial variability and thus are necessary for enabling variable rate application technologies, precision irrigation, and crop monitoring. Moreover, robust machine learning algorithms offer prospects for improving the estimation of biophysical parameters due to their capability to deal with non-linear data, small samples, and noisy variables. This study compared the predictive performance of sparse Partial Least Squares (sPLS), Random Forest (RF), and Gradient Boosting Machines (GBM) for estimating LAI, LCab, and CCC with Sentinel-2 imagery in Bothaville, South Africa and identified, using variable importance measures, the most influential bands for estimating crop biophysical parameters. The results showed that RF was superior in estimating all three biophysical parameters, followed by GBM which was better in estimating LAI and CCC, but not LCab, where sPLS was relatively better. Since all biophysical parameters could be achieved with RF, it can be considered a good contender for operationalisation. Overall, the findings in this study are significant for future biophysical product development using RF to reduce reliance on many algorithms for specific parameters, thus facilitating the rapid extraction of actionable information to support PA and crop monitoring activities. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Canopy chlorophyll content; Gradient Boosting Machine; Leaf area index; Leaf chlorophyll content; Random forest; Sentinel-2; Sparse partial least squares","Adaptive boosting; Biophysics; Chlorophyll; Decision trees; Developing countries; Food supply; Least squares approximations; Parameter estimation; Time series; Canopy chlorophyll; Canopy chlorophyll content; Chlorophyll contents; Gradient boosting; Gradient boosting machine; Leaf Area Index; Leaf chlorophyll content; Random forests; Sentinel-2; Sparse partial least squares; Crops"
"Khai T.H., Abdullah S.N.H.S., Hasan M.K., Tarmizi A.","Underwater Fish Detection and Counting Using Mask Regional Convolutional Neural Network","10.3390/w14020222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122884021&doi=10.3390%2fw14020222&partnerID=40&md5=453fa3de62db1c0123999915f7b75fcf","Fish production has become a roadblock to the development of fish farming, and one of the issues encountered throughout the hatching process is the counting procedure. Previous research has mainly depended on the use of non‐machine learning‐based and machine learning-based counting methods and so was unable to provide precise results. In this work, we used a robotic eye camera to capture shrimp photos on a shrimp farm to train the model. The image data were classified into three categories based on the density of shrimps: low density, medium density, and high density. We used the parameter calibration strategy to discover the appropriate parameters and provided an improved Mask Regional Convolutional Neural Network (Mask R‐ CNN) model. As a result, the enhanced Mask R‐CNN model can reach an accuracy rate of up to 97.48%. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Counting; Deep learning; Machine learning; Shrimp detection; Underwater fish","Convolution; Convolutional neural networks; Deep learning; Classifieds; Convolutional neural network; Counting; Deep learning; Eye camera; Fish farming; Fish production; Image data; Shrimp detection; Underwater fish; Fish; accuracy assessment; artificial neural network; calibration; crustacean; detection method; fish culture; hatchery; hatching"
"Khairuddin M.Z.F., Lu Hui P., Hasikin K., Abd Razak N.A., Lai K.W., Mohd Saudi A.S., Ibrahim S.S.","Occupational Injury Risk Mitigation: Machine Learning Approach and Feature Optimization for Smart Workplace Surveillance","10.3390/ijerph192113962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141586326&doi=10.3390%2fijerph192113962&partnerID=40&md5=8102aa7a53910c862cef9daac3d9c452","Forecasting the severity of occupational injuries shall be all industries’ top priority. The use of machine learning is theoretically valuable to assist the predictive analysis, thus, this study attempts to propose a feature-optimized predictive model for anticipating occupational injury severity. A public database of 66,405 occupational injury records from OSHA is analyzed using five sets of machine learning models: Support Vector Machine, K-Nearest Neighbors, Naïve Bayes, Decision Tree, and Random Forest. For model comparison, Random Forest outperformed other models with higher accuracy and F1-score. Therefore, it highlighted the potential of ensemble learning as a more accurate prediction model in the field of occupational injury. In constructing the model, this study also proposed the feature optimization technique that revealed the three most important features; ‘nature of injury’, ‘type of event’, and ‘affected body part’ in developing model. The accuracy of the Random Forest model was improved by 0.5% or 0.895 and 0.954 for the prediction of hospitalization and amputation, respectively by redeveloping and optimizing the model with hyperparameter tuning. The feature optimization is essential in providing insight knowledge to the Safety and Health Practitioners for future injury corrective and preventive strategies. This study has shown promising potential for smart workplace surveillance. © 2022 by the authors.","artificial intelligence; features optimization; machine learning; occupational injury; occupational safety and health","artificial intelligence; machine learning; occupation; optimization; public health; risk assessment; workplace; amputation; Article; artificial intelligence; Bayesian learning; decision tree; feature optimization; hospitalization; human; injury severity; k nearest neighbor; machine learning; occupational accident; occupational safety; predictive model; random forest; support vector machine; algorithm; Bayes theorem; machine learning; occupational accident; workplace; Algorithms; Bayes Theorem; Humans; Machine Learning; Occupational Injuries; Support Vector Machine; Workplace"
"Khajwal A.B., Cheng C.-S., Noshadravan A.","Post-disaster damage classification based on deep multi-view image fusion","10.1111/mice.12890","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134669691&doi=10.1111%2fmice.12890&partnerID=40&md5=4432f1d561490491bea5dd2e32c752cb","This study aims to facilitate a more reliable automated postdisaster assessment of damaged buildings based on the use of multiple view imagery. Toward this, a Multi-View Convolutional Neural Network (MV-CNN) architecture is proposed, which combines the information from different views of a damaged building, resulting in 3-D aggregation of the 2-D damage features from each view. This spatial 3-D context damage information will result in more accurate and reliable damage quantification in the affected buildings. For validation, the presented model is trained and tested on a real-world visual data set of expert-labeled buildings following Hurricane Harvey. The developed model demonstrates an accuracy of 65% in predicting the exact damage states of buildings, and around 81% considering ±1 class deviation from ground-truth, based on a five-level damage scale. Value of information (VOI) analysis reveals that the hybrid models, which consider at least one aerial and ground view, perform better. © 2022 Computer-Aided Civil and Infrastructure Engineering.",,"Antennas; Convolutional neural networks; Image classification; Image fusion; 3-D aggregations; Convolutional neural network; Damage classification; Damage features; Damage information; Multi-view image; Multi-views; Multiple views; Neural network architecture; Post disasters; Buildings; building; damage; hurricane event; image classification; image processing; imagery; natural disaster"
"Khan A., ten Thij M., Wilbik A.","Communication-Efficient Vertical Federated Learning","10.3390/a15080273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137274668&doi=10.3390%2fa15080273&partnerID=40&md5=111d02f989538a9246f8299802ae2352","Federated learning (FL) is a privacy-preserving distributed learning approach that allows multiple parties to jointly build machine learning models without disclosing sensitive data. Although FL has solved the problem of collaboration without compromising privacy, it has a significant communication overhead due to the repetitive updating of models during training. Several studies have proposed communication-efficient FL approaches to address this issue, but adequate solutions are still lacking in cases where parties must deal with different data features, also referred to as vertical federated learning (VFL). In this paper, we propose a communication-efficient approach for VFL that compresses the local data of clients, and then aggregates the compressed data from all clients to build an ML model. Since local data are shared in compressed form, the privacy of these data is preserved. Experiments on publicly available benchmark datasets using our proposed method show that the final model obtained by aggregation of compressed data from clients outperforms the performance of the local models of the clients. © 2022 by the authors.","communication efficient; data privacy; federated machine learning; heterogeneous federated learning","Benchmarking; Privacy-preserving techniques; Sensitive data; Communication efficient; Compressed datum; Distributed learning; Federated machine learning; Heterogeneous federated learning; Learning approach; Local data; Machine learning models; Machine-learning; Privacy preserving; Machine learning"
"Khan A.A., Nauman M.A., Bashir R.N., Jahangir R., Alroobaea R., Binmahfoudh A., Alsafyani M., Wechtaisong C.","Context Aware Evapotranspiration (ETs) for Saline Soils Reclamation","10.1109/ACCESS.2022.3206009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139436830&doi=10.1109%2fACCESS.2022.3206009&partnerID=40&md5=7354274a5d04b71bdc97d6cd3f8fe8d2","Accurate Evapotranspiration for saline soils (ETs) is important as well as challenging for the reclamation of saline soils through an effective leaching process. Evapotranspiration (ET) by FAO-56 Penman-Monteith standard method is complex, especially for saline soils. Moreover, existing studies focus on the use of the Internet of Things (IoT) and machine learning-enabled smart and precision irrigation water recommendation systems along with the ET estimation by limited parameters. The ETs for saline soils are also equally important for the reclamation of saline soils, which is ignored by the existing literature. The study proposed IoT and machine leaching-based architecture of context-aware monthly ETs estimations for saline soil reclamation with the effective leaching process. The IoT-enabled crop field contexts in terms of crop field temperature, soil salinity, and irrigation water salinity are used as input features to the Long Short-Term Memory (LSTM) and ensembled LSTM models for monthly ETs predictions. The performance of the proposed solution is observed in terms of the accuracy of the machine learning models along with the comparison against the FAO-56 PM-based standard method. The implementation of the proposed solution reveals that the ensembled LSTM-based approach for ETs is more accurate as compared to the LSTM model with accuracies of 92 and 90% for the training and validation datasets, respectively. The predictions made by the ensembled LSTM are more in line with the FAO-56 PM-based method with a Pearson correlation of 0.916 as compared to LSTM models. The implementation of the proposed solution in real-time environments reveals that the proposed solution is more effective in reducing the soil salinity as compared to the traditional method. © 2013 IEEE.","ensembled LSTM; Evapotranspiration (ET); evapotranspiration for saline soils (ETs); FAO-56 Penman-Monteith; leaching process; long short-term memory model (LSTM); saline soil","Brain; Correlation methods; Crops; Evapotranspiration; Internet of things; Leaching; Learning systems; Long short-term memory; Saline water; Soils; Water conservation; Water supply; Ensembled long short-term memory model; Evapotranspiration; Evapotranspiration for saline soil (ET); FAO-56 penman-monteith; Leaching; Leaching process; Long short-term memory model; Memory modeling; Penman Monteith; Saline soil; Salinity (geophysical); Soil measurement; Irrigation"
"Khan M., Chuenchart W., Surendra K.C., Kumar Khanal S.","Applications of artificial intelligence in anaerobic co-digestion: Recent advances and prospects","10.1016/j.biortech.2022.128501","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144986002&doi=10.1016%2fj.biortech.2022.128501&partnerID=40&md5=c5d23930c19ba2f978974854e857bed3","Anaerobic co-digestion (AcoD) offers several merits such as better digestibility and process stability while enhancing methane yield due to synergistic effects. Operation of an efficient AcoD system, however, requires full comprehension of important operational parameters, such as co-substrates ratio, their composition, volatile fatty acids/alkalinity ratio, organic loading rate, and solids/hydraulic retention time. AcoD process optimization, prediction and control, and early detection of system instability are often difficult to achieve through tedious manual monitoring processes. Recently, artificial intelligence (AI) has emerged as an innovative approach to computational modeling and optimization of the AcoD process. This review discusses AI applications in AcoD process optimization, control, prediction of unknown input/output parameters, and real-time monitoring. Furthermore, the review also compares standalone and hybrid AI algorithms as applied to AcoD. The review highlights future research directions for data preprocessing, model interpretation and validation, and grey-box modeling in AcoD process. © 2022 Elsevier Ltd","Anaerobic co-digestion; Artificial intelligence; Machine learning; Mechanistic modeling; Metaheuristics","Anaerobic digestion; Machine learning; Optimization; Process control; System stability; Anaerobic co-digestion; Digestion process; Machine-learning; Mechanistic models; Metaheuristic; Methane Yield; Operational parameters; Process optimisation; Process stability; Synergistic effect; Volatile fatty acids; fatty acid; methane; biofuel; anaerobic digestion; artificial intelligence; digestibility; instability; methane; optimization; algorithm; anaerobic digestion; artificial intelligence; artificial neural network; multivariate analysis; process optimization; Review; support vector machine; validation study; anaerobic growth; bioreactor; digestion; Anaerobiosis; Artificial Intelligence; Biofuels; Bioreactors; Digestion; Methane"
"Khan M.A., Azhar M., Ibrar K., Alqahtani A., Alsubai S., Binbusayyis A., Kim Y.J., Chang B.","COVID-19 Classification from Chest X-Ray Images: A Framework of Deep Explainable Artificial Intelligence","10.1155/2022/4254631","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134720856&doi=10.1155%2f2022%2f4254631&partnerID=40&md5=60e470e3004a3831b39182afcfe3923f","COVID-19 detection and classification using chest X-ray images is a current hot research topic based on the important application known as medical image analysis. To halt the spread of COVID-19, it is critical to identify the infection as soon as possible. Due to time constraints and the expertise of radiologists, manually diagnosing this infection from chest X-ray images is a difficult and time-consuming process. Artificial intelligence techniques have had a significant impact on medical image analysis and have also introduced several techniques for COVID-19 diagnosis. Deep learning and explainable AI have shown significant popularity among AL techniques for COVID-19 detection and classification. In this work, we propose a deep learning and explainable AI technique for the diagnosis and classification of COVID-19 using chest X-ray images. Initially, a hybrid contrast enhancement technique is proposed and applied to the original images that are later utilized for the training of two modified deep learning models. The deep transfer learning concept is selected for the training of pretrained modified models that are later employed for feature extraction. Features of both deep models are fused using improved canonical correlation analysis that is further optimized using a hybrid algorithm named Whale-Elephant Herding. Through this algorithm, the best features are selected and classified using an extreme learning machine (ELM). Moreover, the modified deep models are utilized for Grad-CAM visualization. The experimental process was conducted on three publicly available datasets and achieved accuracies of 99.1, 98.2, and 96.7%, respectively. Moreover, the ablation study was performed and showed that the proposed accuracy is better than the other methods. © 2022 Muhammad Attique Khan et al.",,"Computer aided diagnosis; Deep learning; Image analysis; Image classification; Image enhancement; Learning systems; Medical imaging; 'current; AI techniques; Artificial intelligence techniques; Chest X-ray image; Contrast Enhancement; Hot research topics; Learning models; Medical image analysis; Original images; Time constraints; COVID-19; artificial intelligence; diagnostic imaging; human; X ray; Artificial Intelligence; COVID-19; COVID-19 Testing; Deep Learning; Humans; X-Rays"
"Khan M.A., Sadman N., Gupta K.D., Ovi J.A.","Interpretable Learning Model for Lower Dimensional Feature Space: A Case study with Brown Spot Detection in Rice Leaf","10.1109/CCWC54503.2022.9720882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127689097&doi=10.1109%2fCCWC54503.2022.9720882&partnerID=40&md5=6cb53aa59d815c71d35faca4f2ae0e4f","Detecting brown spot in rice leaf is an urgent complication in the agricultural field as Brown Spot disease lessen the rice yield remarkably. Several segmentation techniques have been applied to identify and extract the infected portion of the rice-leaf and machine learning algorithms such as decision trees, support vector machines are applied to detect this infection. In particular, a combination of Convolution Neural Networks with these algorithms has also tried to resolve this problem. Although this attempt has achieved success in providing accuracy (96.8%), these kinds of approaches raise issues regarding the size and interpretability of feature space and interpretability of the decision model. Indeed, Deep learning networks automatically create a feature space that usually contains a massive number of features (numerous of them are not necessarily appropriate). This vast number of features extends the non-interpretability of the machine learning model. Furthermore, training the model with these many features is computationally expensive. To resolve these issues, we propose a method to extract a few interpretable features from rice-leaf images and construct a low-dimensional feature space; however, interpretation shows that they deserve significant credit for the decent accuracy of our classification model. © 2022 IEEE.","Artificial Intelligence; Bioinformatics; Biomedical Computing; Explainablity; Image Processing; Interpretabiltiy","Bioinformatics; Deep learning; Image processing; Learning algorithms; Support vector machines; Biomedical computing; Brown spots; Explainablity; Feature space; Images processing; Interpretability; Interpretabiltiy; Learning models; Low dimensional; Rice leaves; Decision trees"
"Khan M.H.U., Wang S., Wang J., Ahmar S., Saeed S., Khan S.U., Xu X., Chen H., Bhat J.A., Feng X.","Applications of Artificial Intelligence in Climate-Resilient Smart-Crop Breeding","10.3390/ijms231911156","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139812820&doi=10.3390%2fijms231911156&partnerID=40&md5=ae412b481e5494511ce2b5e4519f8f8d","Recently, Artificial intelligence (AI) has emerged as a revolutionary field, providing a great opportunity in shaping modern crop breeding, and is extensively used indoors for plant science. Advances in crop phenomics, enviromics, together with the other “omics” approaches are paving ways for elucidating the detailed complex biological mechanisms that motivate crop functions in response to environmental trepidations. These “omics” approaches have provided plant researchers with precise tools to evaluate the important agronomic traits for larger-sized germplasm at a reduced time interval in the early growth stages. However, the big data and the complex relationships within impede the understanding of the complex mechanisms behind genes driving the agronomic-trait formations. AI brings huge computational power and many new tools and strategies for future breeding. The present review will encompass how applications of AI technology, utilized for current breeding practice, assist to solve the problem in high-throughput phenotyping and gene functional analysis, and how advances in AI technologies bring new opportunities for future breeding, to make envirotyping data widely utilized in breeding. Furthermore, in the current breeding methods, linking genotype to phenotype remains a massive challenge and impedes the optimal application of high-throughput field phenotyping, genomics, and enviromics. In this review, we elaborate on how AI will be the preferred tool to increase the accuracy in high-throughput crop phenotyping, genotyping, and envirotyping data; moreover, we explore the developing approaches and challenges for multiomics big computing data integration. Therefore, the integration of AI with “omics” tools can allow rapid gene identification and eventually accelerate crop-improvement programs. © 2022 by the authors.","artificial intelligence (AI); big data; crop breeding; envirotyping; genomics; phenomics","agronomic trait; artificial intelligence; big data; breeding method; climate; crop improvement; data integration; gene identification; genomics; genotype; genotyping; multiomics; phenomics; phenotype; review; artificial intelligence; climate; crop; genetics; plant breeding; procedures; Artificial Intelligence; Climate; Crops, Agricultural; Phenomics; Plant Breeding"
"Khandouzi A., Ariafar A., Mashayekhpour Z., Pazira M., Baleghi Y.","Retinal Vessel Segmentation, a Review of Classic and Deep Methods","10.1007/s10439-022-03058-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137101512&doi=10.1007%2fs10439-022-03058-0&partnerID=40&md5=7633dd1e8c663f63d73bb75ffb140dc1","Retinal illnesses such as diabetic retinopathy (DR) are the main causes of vision loss. In the early recognition of eye diseases, the segmentation of blood vessels in retina images plays an important role. Different symptoms of ocular diseases can be identified by the geometric features of ocular arteries. However, due to the complex construction of the blood vessels and their different thicknesses, segmenting the retina image is a challenging task. There are a number of algorithms that helped the detection of retinal diseases. This paper presents an overview of papers from 2016 to 2022 that discuss machine learning and deep learning methods for automatic vessel segmentation. The methods are divided into two groups: Deep learning-based, and classic methods. Algorithms, classifiers, pre-processing and specific techniques of each group is described, comprehensively. The performances of recent works are compared based on their achieved accuracy in different datasets in inclusive tables. A survey of most popular datasets like DRIVE, STARE, HRF and CHASE_DB1 is also given in this paper. Finally, a list of findings from this review is presented in the conclusion section. © 2022, The Author(s) under exclusive licence to Biomedical Engineering Society.","Blood vessels; Convolutional neural network; Deep learning; Medical imaging; Retinal vessel segmentation","Blood; Convolutional neural networks; Deep neural networks; Eye protection; Image segmentation; Learning systems; Medical imaging; Ophthalmology; Complex construction; Convolutional neural network; Deep learning; Diabetic retinopathy; Different thickness; Eye disease; Geometric feature; Ocular disease; Retinal vessel segmentations; Vision loss; Blood vessels; age related macular degeneration; artificial neural network; branch retinal vein occlusion; CC NET; central retina vein occlusion; classifier; computer assisted diagnosis; continuous wavelet transform; contrast enhancement; convolutional neural network; deep learning; diabetic retinopathy; false negative result; false positive result; feature extraction; Gabor transform; glaucoma; human; image processing; image segmentation; imaging algorithm; intermethod comparison; machine learning; measurement accuracy; melanoma; optical coherence tomography; receiver operating characteristic; retina blood vessel; retina detachment; retina tumor; retina vein occlusion; retinoblastoma; Review; sensitivity and specificity; U Net; algorithm; diagnostic imaging; image processing; machine learning; procedures; retina; Algorithms; Image Processing, Computer-Assisted; Machine Learning; Retina; Retinal Vessels"
"Khourchid A.M., Ajjur S.B., Al-Ghamdi S.G.","Building Cooling Requirements under Climate Change Scenarios: Impact, Mitigation Strategies, and Future Directions","10.3390/buildings12101519","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140707914&doi=10.3390%2fbuildings12101519&partnerID=40&md5=478f2490ce78e9778a9718f62bbec7a7","Climate change affects building cooling demand; however, little has been done to explore this effect and show its variability in different climatic zones. This review organizes and summarizes studies which have simulated the impact of climate change on building cooling requirements, and critically analyzes the effectiveness of the mitigation strategies proposed by these studies to alleviate this impact. The review methodology selected studies that reported cooling demand and discussed mitigation strategies in future climates. The studies were then grouped based on their climate zone and impact period. Analysis showed that climate change will increase building cooling demand in all climatic zones, with the greatest increase occurring in temperate and cold climatic zones. By the middle of the 21st century (2040–2080), the average increase in building cooling demand is expected to reach 33%, 89%, 288% and 376%, in tropical, arid, cold, and temperate climates, respectively. These numbers are expected to increase during the end of the 21st century (2080–2100) to 55%, 302%, 734%, and 1020%, for tropical, arid, cold, and temperate climates, respectively. Some mitigation strategies (e.g., thermal insulation, solar shading) showed a potential to reduce the increase in building cooling demand; however, the reduction varied depending on the strategy and climatic zone. Further research is required to determine if existing cooling systems can handle the future increase in cooling requirements. © 2022 by the authors.","buildings; climate change; cooling requirements; mitigation strategies",
"Kikuchi T., Anzai T., Ouchi T., Okamoto K., Terajima Y.","Assessing the impact of watershed characteristics and management on nutrient concentrations in tropical rivers using a machine learning method","10.1016/j.envpol.2022.120599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141545580&doi=10.1016%2fj.envpol.2022.120599&partnerID=40&md5=5a8cfc19b975ab7b1a3b29b8d1abadee","Excessive loadings of terrestrial nitrogen and phosphorus, as well as their imbalances with silicon, have been recognized as one of the major causes of water quality and ecosystem deterioration in receiving waters. In this study, a periodic water quality monitoring was conducted in the rivers and streams of a tropical island (Ishigaki Island, Japan) to identify the factors controlling the concentrations of dissolved inorganic nitrogen (DIN), total phosphorus (TP) and dissolved silicon (DSi) with a special focus on the catchment characteristics (e.g., land use, surface geology, topography). Random Forest (RF) machine learning algorithm was employed to develop predictive models for nutrient concentrations from the catchment properties. The developed models could predict nutrient concentrations with sufficient accuracy, demonstrating that the studied nutrients are strongly affected by catchment properties. Agricultural land uses (e.g., livestock barn, sugarcane field) were ranked as the most important parameters for DIN and TP, while broadleaf forest was the most influential factor for DSi. Using the RF models, the contributions of DIN originating from sugarcane fields (i.e., fertilizers) and barns (i.e., manure) to riverine DIN were estimated, which were up to 60% in total in the studied river basins. Furthermore, the yield of DIN from sugarcane fields, calculated as the concentration of DIN derived from sugarcane fields divided by the percent area of sugarcane fields, strongly positively correlated with the areal coverage of limestone, suggesting that fertilizer-derived DIN is more prone to leaching out from cropland soil to groundwater and rivers in catchments with a higher dominance of calcareous geology. These results, including the methodology employed, have implications for water quality assessment and management in inland and coastal waters not only at the study site but also other regions. © 2022 Elsevier Ltd","Geology; Land use; Nitrogen; Phosphorus; Random Forest; Silicon","Agricultural pollution; Catchments; Decision trees; Deterioration; Fertilizers; Forestry; Groundwater; Landforms; Lime; Machine learning; Nitrogen; Nutrients; Phosphorus; Random forests; Rivers; Runoff; Silicon; Topography; Tropics; Water quality; Watersheds; Catchment properties; Dissolved inorganic nitrogens; Machine learning methods; Nitrogen and phosphorus; Nutrient concentrations; Random forests; Total phosphorus; Tropical rivers; Watershed characteristics; Watersheds management; Land use; ethylene vinyl acetate copolymer; nitrogen; phosphorus; silicon; assessment method; concentration (composition); land use; machine learning; nitrogen; nutrient; phosphorus; river water; silicon; tropical environment; water quality; watershed; Article; calorimetry; catchment area; inductively coupled plasma atomic emission spectrometry; land use; learning algorithm; machine learning; nutrient concentration; precipitation; temperature; topography; water monitoring; water quality; watershed"
"Kim B.","Classifying Oryza sativa accessions into Indica and Japonica using logistic regression model with phenotypic data","10.7717/peerj.7259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075634177&doi=10.7717%2fpeerj.7259&partnerID=40&md5=15a9dccf6d9f45ef04712ccbbead7692","In Oryza sativa, indica and japonica are pivotal subpopulations, and other subpopulations such as aus and aromatic are considered to be derived from indica or japonica. In this regard, Oryza sativa accessions are frequently viewed from the indica/japonica perspective. This study introduces a computational method for indica/japonica classification by applying phenotypic variables to the logistic regression model (LRM). The population used in this study included 413 Oryza sativa accessions, of which 280 accessions were indica or japonica. Out of 24 phenotypic variables, a set of seven phenotypic variables was identified to collectively generate the fully accurate indica/japonica separation power of the LRM. The resulting parameters were used to define the customized LRM. Given the 280 indica/japonica accessions, the classification accuracy of the customized LRM along with the set of seven phenotypic variables was estimated by 100 iterations of ten-fold cross-validations. As a result, the classification accuracy of 100% was achieved. This suggests that the LRM can be an effective tool to analyze the indica/japonica classification with phenotypic variables in Oryza sativa. © 2019 Kim et al.","Asian cultivated rice; Genetic diversity in rice; Indica; Japonica; Logistic regression; Oryza sativa; Rice breeding; Rice classification","article; breeding; genetic variability; nonhuman; rice"
"Kim J., Bhattarai R., Christianson L.E., Jeong H.","Advanced practice-aided tile drain configuration: A solution to achieving environmentally sustainable agricultural production","10.1016/j.jclepro.2022.134724","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140341873&doi=10.1016%2fj.jclepro.2022.134724&partnerID=40&md5=784959a039343ac7ad1aae179695126c","Alternatives to conventional crop production practices are needed to achieve environmental sustainability. Because tile-drained crop production systems in the Midwestern United States are one of the single largest contributors to environmental degradation, we explored alternative tile drain configurations by changing the tile spacing and depth of tile-drained fields in central Illinois and then by evaluating comprehensively the impacts of different tile drain configurations on crop productivity and environmental sustainability using the Root Zone Water Quality Model 2 (RZWQM2). An analytic hierarchy process (AHP), which is a multicriteria decision analysis (MCDA) tool, was used to evaluate the optimum tile spacing and depth scenario. The model simulations and AHP tested three management schemes designated as “agricultural productivity” (AP), “environmental sustainability” (ES), and “advance in technology” (AT). The schemes were designed based on three criteria: operational cost, crop profit, and environmental control. Analysis showed that deeper tiles and narrower tile spacing resulted in decreases in flow and nitrate loss from runoff, seepage (SP), and lateral flow (LF), and increases in tile flow, total nitrate loss, and crop yields. On the basis of MCDA, the AP management scheme resulted in higher CP and total nitrate loss, whereas opposite outcomes were generated by the ES management scheme. Under the AT management scheme, higher ranked scenarios resulted in higher CP and lower total amounts of nitrate entering streams. Our analysis indicates that the AT scheme can simultaneously enhance crop production and ES through advances in tile drainage water treatment. © 2022 Elsevier Ltd","Crop profits; Decision-making; Nitrate loss; Tile drainage impacts","Analytic hierarchy process; Crops; Cultivation; Environmental management; Hierarchical systems; Nitrates; Productivity; Profitability; Sustainable development; Water quality; Crop production; Crop profit; Decisions makings; Environmental sustainability; Management scheme; Nitrate loss; Tile drainage; Tile drainage impact; Tile drains; Tile spacing; Decision making"
"Kim J.I., Maguire F., Tsang K.K., Gouliouris T., Peacock S.J., McAllister T.A., McArthur A.G., Beiko R.G.","Machine Learning for Antimicrobial Resistance Prediction: Current Practice, Limitations, and Clinical Perspective","10.1128/cmr.00179-21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138458653&doi=10.1128%2fcmr.00179-21&partnerID=40&md5=8e2a71c97a16821ac45c4463b8250955","SUMMARY Antimicrobial resistance (AMR) is a global health crisis that poses a great threat to modern medicine. Effective prevention strategies are urgently required to slow the emergence and further dissemination of AMR. Given the availability of data sets encompassing hundreds or thousands of pathogen genomes, machine learning (ML) is increasingly being used to predict resistance to different antibiotics in pathogens based on gene content and genome composition. A key objective of this work is to advocate for the incorporation of ML into front-line settings but also highlight the further refinements that are necessary to safely and confidently incorporate these methods. The question of what to predict is not trivial given the existence of different quantitative and qualitative laboratory measures of AMR. ML models typically treat genes as independent predictors, with no consideration of structural and functional linkages; they also may not be accurate when new mutational variants of known AMR genes emerge. Finally, to have the technology trusted by end users in public health settings, ML models need to be transparent and explainable to ensure that the basis for prediction is clear. We strongly advocate that the next set of AMR-ML studies should focus on the refinement of these limitations to be able to bridge the gap to diagnostic implementation. © 2022 American Society for Microbiology. All rights reserved.","antimicrobial resistance; machine learning","antibiotic resistance; machine learning; prediction; public health; quantitative analysis; review; structure activity relation; genetics; machine learning; antiinfective agent; Anti-Bacterial Agents; Drug Resistance, Bacterial; Machine Learning"
"Kim J.-Y., Cho S.-B.","Electric energy consumption prediction by deep learning with state explainable autoencoder","10.3390/en12040739","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065911918&doi=10.3390%2fen12040739&partnerID=40&md5=c64f7625b312870773caa15e0072409c","As energy demand grows globally, the energy management system (EMS) is becoming increasingly important. Energy prediction is an essential component in the first step to create a management plan in EMS. Conventional energy prediction models focus on prediction performance, but in order to build an efficient system, it is necessary to predict energy demand according to various conditions. In this paper, we propose a method to predict energy demand in various situations using a deep learning model based on an autoencoder. This model consists of a projector that defines an appropriate state for a given situation and a predictor that forecasts energy demand from the defined state. The proposed model produces consumption predictions for 15, 30, 45, and 60 min with 60-min demand to date. In the experiments with household electric power consumption data for five years, this model not only has a better performance with a mean squared error of 0.384 than the conventional models, but also improves the capacity to explain the results of prediction by visualizing the state with t-SNE algorithm. Despite unsupervised representation learning, we confirm that the proposed model defines the state well and predicts the energy demand accordingly. © 2019 by the authors.","Autoencoder; Deep learning; Electric energy; Energy management system; Energy prediction; Explainable AI","Deep learning; Energy management; Energy utilization; Forecasting; Mean square error; Auto encoders; Conventional models; Electric energies; Electric energy consumption; Electric power consumption; Energy prediction; Mean squared error; Prediction performance; Energy management systems"
"Kim T., Lee D., Shin J., Kim Y., Cha Y.","Learning hierarchical Bayesian networks to assess the interaction effects of controlling factors on spatiotemporal patterns of fecal pollution in streams","10.1016/j.scitotenv.2021.152520","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121913340&doi=10.1016%2fj.scitotenv.2021.152520&partnerID=40&md5=fbf1734d09df4f7ad1188449d2f6c15d","The dynamics of fecal indicator bacteria, such as fecal coliforms (FC) in streams, are influenced by the interactions of a myriad of factors. To predict complex spatiotemporal patterns of FC in streams and assess the relative importance of numerous controlling factors, the adoption of a hierarchical Bayesian network (HBN) was proposed in this study. By introducing latent variables correlated to the observed variables into a Bayesian network, the HBN can represent causal relationships among a large set of variables with a multilevel hierarchy. The study area encompasses 215 sites across the watersheds of the four major rivers in South Korea. The monitoring data collected during the 2012–2019 period included 32 input variables pertaining to meteorology, geography, soil characteristics, land cover, urbanization index, livestock density, and point sources. As model endpoints, the exceedance probability of the FC standard concentration as well as two pollution characteristics (i.e., pollution degree and type), derived from FC load duration curves were used. The probability of exceeding an FC threshold value (200 CFU/100 mL) showed spatiotemporal variations, whereas pollution degree and type showed spatial variations that represent long-term severity and relative dominance of nonpoint and point source fecal pollution, respectively. The conceptual model was validated using structural equation modeling to develop the HBN. The results demonstrate that the HBN effectively simplified the model structure, while showing strong model performance (AUC = 0.81, accuracy = 0.74). The results of the sensitivity analysis indicate that land cover is the most important factor in predicting the probability of exceedance and pollution degree, whereas the urbanization index explains most of the variability in pollution type. Furthermore, the results of the scenario analysis suggest that the HBN provides an interpretable framework in which the interaction of controlling factors has causal relationships at different levels that can be identified and visualized. © 2021","Fecal coliforms; Fecal indicator bacteria; Hierarchical Bayesian network; Land cover; Load duration curve; Structural equation modeling","Agriculture; Bacteria; Factor analysis; Probability; River pollution; Sensitivity analysis; Controlling factors; Faecal indicator bacteria; Fecal Coliform; Fecal pollution; Hierarchical Bayesian networks; Land cover; Load duration curves; Pollution degree; Spatiotemporal patterns; Structural equation models; Bayesian networks; Bayesian analysis; fecal coliform; feces; hierarchical system; land cover; learning; pollution incidence; probability; river pollution; spatiotemporal analysis; streamwater; water quality; adoption; article; Bayesian network; conceptual model; fecal coliform; feces; geography; land use; learning; livestock; meteorology; nonhuman; probability; river; sensitivity analysis; soil; South Korea; structural equation modeling; urbanization; watershed; Bayes theorem; environmental monitoring; feces; microbiology; river; water pollution; Bayes Theorem; Environmental Monitoring; Feces; Rivers; Water Microbiology; Water Pollution"
"Kim Y.W., Kim T., Shin J., Go B., Lee M., Lee J., Koo J., Cho K.H., Cha Y.","Forecasting Abrupt Depletion of Dissolved Oxygen in Urban Streams Using Discontinuously Measured Hourly Time-Series Data","10.1029/2020WR029188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104851570&doi=10.1029%2f2020WR029188&partnerID=40&md5=79f43474acad059f0cf924f6f1e42eb9","Depletion of dissolved oxygen (DO) is a major cause of fish kills in urban streams. Although forecasting short-term DO concentrations in streams prior to hypoxic events is necessary, such efforts have been rarely made. In this study, 24-h forecasting models were developed for DO concentrations in three urban streams of South Korea. To forecast the DO concentrations at the outlet sites, which coincide with fish kill hot spot areas, water quality parameters at the lower reaches and hydrometeorological parameters were used as input variables. The monitoring data were measured hourly between 2017 and 2018 and divided into training and test sets at a ratio of 8:2. Tenfold cross validation was performed for hyperparameter optimization. Due to the dynamic characteristics of DO concentrations and the discontinuity in time-series data, a long short-term memory (LSTM) neural network modeling approach was selected. Overall, a high degree of accuracy was recorded for all study streams. Although hypoxic events were forecast with lower accuracy, the timing and magnitude of abrupt DO depletion were well captured. Water temperature and DO concentrations at the lower reaches and 24-h cumulative precipitation were important variables for forecasting DO concentrations at all stream outlets. In particular, the importance of cumulative precipitation across all streams indicated that the effects of nonpoint sources were critical in depleting DO in urban streams. Monitoring of both lower reaches and outlets in conjunction with a variable importance analysis enhanced interpretability of the LSTM model outputs. This study improves our understanding of precursors of hypoxic events in urban streams. © 2021. American Geophysical Union. All Rights Reserved.","DO depletion; hyperparameter tuning; hypoxic events; LSTM; urban streams; variable importance","Dissolved oxygen; Fish; Forecasting; Long short-term memory; Time series; Water quality; Cumulative precipitation; Dynamic characteristics; High degree of accuracy; Hyper-parameter optimizations; Neural network model; Variable importances; Water quality parameters; Water temperatures; Data streams; concentration (composition); data set; detection method; dissolved organic phosphorus; dissolved oxygen; hypoxic conditions; nonpoint source pollution; stream; water temperature; South Korea"
"Kimori Y.","A Morphological Image Preprocessing Method Based on the Geometrical Shape of Lesions to Improve the Lesion Recognition Performance of Convolutional Neural Networks","10.1109/ACCESS.2022.3187507","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133746183&doi=10.1109%2fACCESS.2022.3187507&partnerID=40&md5=66704ab94767b8e549b235e98e1e0c40","Convolutional neural networks (CNNs) play an important role in computer vision-related tasks for medical imaging. However, the quality of raw images in the dataset can be insufficient for the CNN model to learn the features of the target object. When the input image contains a complex background, the CNN model focuses on regions that are not essential for lesion recognition, such as background structures, leading to less accurate output prediction. This paper shows that this problem can be efficiently solved by an image preprocessing method based on mathematical morphology, which uses a priori knowledge about the lesion shape. The proposed method consists of h-dome transformation based on the geometrical shape information of the lesion region, and subsequent image histogram-modification processes, and has the ability to selectively enhance the lesion region from the background. This allows for the creation of images that explicitly represent the important region to be learned by the CNN model. Experiments on pulmonary nodule classification in chest x-ray images and skin lesion region segmentation in dermatoscopic images demonstrate that the CNN models trained on the preprocessed dataset created by the proposed method achieve remarkable performance improvements compared to the CNN models trained on the original dataset. © 2013 IEEE.","convolutional neural networks; h-dome transformation; mathematical morphology; Medical images","Classification (of information); Convolution; Image enhancement; Image recognition; Mathematical morphology; Mathematical transformations; Medical imaging; Neural networks; <italic xmlns:ali=""; Biomedical imaging; Convolutional neural network; Images segmentations; Lesion; Lung; Medical image; Shape; Transform; Xmlns:mml=""; Xmlns:xlink=""; Xmlns:xsi=""; Image segmentation"
"Kinger S., Kulkarni V.","Explainable AI for deep learning based disease detection","10.1145/3474124.3474154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119099581&doi=10.1145%2f3474124.3474154&partnerID=40&md5=4d1bd27c7a1662e5960ba5cece5d81b8","Deep learning in computer vision has shown remarkable success in the performance of detection systems for plant diseases. However, due to the complexity and deeply nested structure of these models, these are still considered as black-box and explanations are not intuitive for human users. Many researchers have developed deep neural architectures for plant disease detection but have not provided classification explanations. To be used in practical applications, our model needs to explain why the model classified a given image. Explainable Artificial Intelligence (XAI) provides algorithms that can generate human-understandable explanations of AI decisions. In this paper, we summarize recent developments in XAI techniques, develop a plant disease detection system, and most importantly an explainable AI method named Gradient-weighted Class Activation Mapping ++ (GradCAM++) is used to locate the disease and highlight the most important regions on the leaves contributing towards the classification. © 2021 ACM.","Deep Learning; EXplainable AI; Grad-CAM++; Plant Disease","Plants (botany); Black boxes; Deep learning; Detection system; Disease detection; Explainable AI; Grad-CAM++; Human users; Nested structures; Performance; Plant disease; Deep learning"
"Kittichotsatsawat Y., Tippayawong N., Tippayawong K.Y.","Prediction of arabica coffee production using artificial neural network and multiple linear regression techniques","10.1038/s41598-022-18635-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136620773&doi=10.1038%2fs41598-022-18635-5&partnerID=40&md5=d1521a77cb2b39fb291b4a2ca035251a","Crop yield and its prediction are crucial in agricultural production planning. This study investigates and predicts arabica coffee yield in order to match the market demand, using artificial neural networks (ANN) and multiple linear regression (MLR). Data of six variables, including areas, productivity zones, rainfalls, relative humidity, and minimum and maximum temperature, were collected for the recent 180 months between 2004 and 2018. The predicted yield of the cherry coffee crop continuously increases each year. From the dataset, it was found that the prediction accuracy of the R2 and RMSE from ANN was 0.9524 and 0.0784 tons, respectively. The ANN model showed potential in determining the cherry coffee yields. © 2022, The Author(s).",,"article; artificial neural network; cherry; coffee; crop; nonhuman; prediction; productivity; relative humidity; agriculture; Coffea; statistical model; Agriculture; Coffea; Coffee; Linear Models; Neural Networks, Computer"
"Kliangkhlao M., Limsiroratana S., Sahoh B.","The Design and Development of a Causal Bayesian Networks Model for the Explanation of Agricultural Supply Chains","10.1109/ACCESS.2022.3199353","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136677962&doi=10.1109%2fACCESS.2022.3199353&partnerID=40&md5=d0b068f46ea7e610939ae126cef3bb96","The balancing of demand and supply in the market is complex because of the dynamic supply chain and environment. It causes uncertain situations and is a limitation in decisions making systems that cannot produce reasonable descriptions to help decision makers eliminate uncertainties. This study proposes designing and developing a Causal Bayesian Networks (CBNs) model for market understanding, which encodes a human-like approach to explain demand and supply events for decision makers. A framework for generating reasonable descriptions in Agricultural Supply Chains (ASCs) management is proposed. The qualitative and quantitative design of the CBNs model is developed and proved that the CBNs model can reasonably explain events using predictive performance measurement and sensitivity analysis for producing reasonable descriptions. The results illustrate that the CBNs model is suitable for ASCs situation explanation involving uncertain situations and is ready to apply to real-world applications to support decision-making systems. © 2022 IEEE.","big data; causal graph; demand and supply analysis; Explainable artificial intelligence; machine learning; supply chain management","Agriculture; Artificial intelligence; Big data; Commerce; Information management; Learning systems; Meteorology; Sensitivity analysis; Supply chain management; Supply chains; Bayes method; Causal Bayesian network; Causal graph; Decisions makings; Demand and supply; Demand and supply analyse; Explainable artificial intelligence; Machine-learning; Market researches; Uncertainty; Decision making"
"Klimek K., Kapłan M., Syrotyuk S., Bakach N., Kapustin N., Konieczny R., Dobrzyński J., Borek K., Anders D., Dybek B., Karwacka A., Wałowski G.","Investment model of agricultural biogas plants for individual farms in Poland","10.3390/en14217375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118611795&doi=10.3390%2fen14217375&partnerID=40&md5=8e196167c7dbaf1d95585c5be0b54311","The main idea of a circular economy (CE) is to separate economic growth from resource consumption and environmental impacts. The characteristic approach of a CE assumes the minimisation of the amount of waste generated at the design level and, as a standard, includes innovations throughout the value chain. From an agricultural point of view, agricultural biogas plants are particularly important because they enable the management of all waste biomass and its conversion into useful energy and agricultural fertiliser. This paper presents methods for assessing the economic effectiveness of an investment in an agricultural biogas plant. The research goal was to develop a financial model. The authors of this study used available examples of the profitability of commercial ventures. We considered the investment aspects of agricultural biogas plants. Exemplary solutions are discussed, allowing the reader to become acquainted with various methods and proposals for thus far estimated investments. It may seem chaotic, but this is how the biogas market is characterised in the context of the implementation of biogas projects. Guidance is given regarding how to understand investing in this sensitive private farming sector. It is admirable that the renewable energy market has been systematised, and we hypothesise that it is necessary to develop an investment model in Polish conditions. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Agricultural biogas; Assessment methods; Circular economy; Investment; Production; Profitability","Agricultural robots; Biogas; Commerce; Environmental impact; Investments; Profitability; Waste management; Agricultural biogas; Assessment method; Biogas plants; Circular economy; Design levels; Economic growths; Investment models; Minimisation; Resources consumption; Value chains; Agriculture"
"Kobayashi K., Masuda K., Haga C., Matsui T., Fukui D., Machimura T.","Development of a species identification system of Japanese bats from echolocation calls using convolutional neural networks","10.1016/j.ecoinf.2021.101253","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101657483&doi=10.1016%2fj.ecoinf.2021.101253&partnerID=40&md5=8a9c23f2559303e3ad918e37e9dfa1a3","Bats inhabit all continents except Antarctica, and they have enormous potential as bioindicators. Therefore, monitoring bats helps us to understand the surrounding environmental changes. However, bats are nocturnal, which makes it difficult to visually monitor their behavior. This paper proposes a bat species identifier method based on the analysis of ultrasound called echolocation calls, which is a promising method to monitor bats' activity levels effectively. We develop a robust method to identify the bat species with improved accuracy by analyzing their echolocation calls. First, 1400 sound files with four families, 13 genera, and 30 species were recorded in Japan and the Jincheon-gun in South Korea from 1999 to 2019. Bat echolocation calls were detected from the sound files and used to generate 54,525 spectrograms by applying short-time Fourier transform. We developed a deep learning–based bat species identifier using convolutional neural networks with MobileNetV1 used as the model's architecture. Furthermore, we applied nested cross-validation with the Bayesian optimization algorithm to search for the optimal combination of hyperparameters and evaluate the expected performance. We achieved 98.1% accuracy, which outperformed previous studies that treated more than 30 bat species. We visualized important regions of the spectrograms which correspond to prediction using the Guided Grad-CAM. Moreover, we discussed how to treat the noise class and minimize the model training time. Then, we proposed potential solutions to boost the identifier's performance, the generalization of the echolocation call recording protocols, and applicable techniques to improve the identification accuracy. Future perspectives are 1) to change the deep learning algorithm from image classification to object detection and 2) to apply the proposed identifier to unknown bat echolocation calls to evaluate the feasibility of estimating bat fauna and spatial activity distribution. © 2021 Elsevier B.V.","Acoustic monitoring; Convolutional neural networks; Echolocation call; Guided Grad-CAM; Identification","artificial neural network; bat; bioindicator; calling behavior; echolocation; environmental change; identification method; Antarctica; South Korea; Varanidae"
"Koc K., Ekmekcioǧlu Ö., Gurgun A.P.","Developing a National Data-Driven Construction Safety Management Framework with Interpretable Fatal Accident Prediction","10.1061/JCEMD4.COENG-12848","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147141682&doi=10.1061%2fJCEMD4.COENG-12848&partnerID=40&md5=82d599211eb7df2f76edbf5d4490390b","Occupational accidents are frequent in the construction industry, containing significant risks in the working environment. Therefore, early designation, taking preventive actions, and developing a proactive safety risk management plan are of paramount significance in managing safety issues in the construction industry. This study aims to develop a national data-driven safety management framework based on accident outcome prediction, which helps anatomize precursors of fatalities and thereby minimizing fatal accidents on construction sites. A national data set comprising 338,173 occupational accidents recorded in the construction industry across Turkey was used to develop a data-driven model. The random forest algorithm coupled with particle swarm optimization was used for the prediction and the interpretability of the proposed model was augmented through the game theory-based Shapley additive explanations (SHAP) approach. The findings showed that the proposed algorithm achieved satisfactory model performances for detecting construction workers who might face a fatality risk. The SHAP analysis results indicated that both company (such as number of past accidents and workers in the company) and worker-related (such as age, daily wage, experience, shift, and past accident of the workers) attributes were influential in identifying fatalities by detecting which workers might face fatal accidents under which conditions. A construction safety management plan was developed based on the analysis results, which can be used on construction sites to detect workers/conditions that are most susceptible to fatalities. The findings of the present research are expected to contribute to orchestrating effective safety management practices in construction sites by characterizing the root causes of severe accidents. © 2023 American Society of Civil Engineers.","Construction safety management; Interpretable artificial intelligence; Machine learning; Occupational accidents; Occupational health and safety (OHS)","Accident prevention; Accidents; Forecasting; Forestry; Game theory; Human resource management; Industrial hygiene; Machine learning; Occupational risks; Particle swarm optimization (PSO); Risk management; Construction safety; Construction safety management; Fatal accidents; Interpretable artificial intelligence; Machine-learning; Occupational accident; Occupational health and safety; Safety management; Workers'; Construction industry"
"Kong X., Li Z., Zhang Y., Das S.","Bridge Deck Deterioration: Reasons and Patterns","10.1177/03611981221080140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135557633&doi=10.1177%2f03611981221080140&partnerID=40&md5=c6359539b81c9f3c23bc7118afcafa05","The deck condition of bridges is one of the most important factors impacting the connectivity and efficiency of transportation networks. Bridges with quickly deteriorating deck conditions are a huge financial burden for transportation agencies and can downgrade the efficiency of the whole transportation network. This study utilizes an interpretable machine learning framework, Shapley additive explanation (SHAP), to investigate the associations between various factors, such as wearing surface, deck structure, and so forth, and bridges with quickly deteriorating deck conditions nationwide. An XGBoost model is trained to perform the binary classification task on a heavily imbalanced dataset and classify relatively young bridges (less than 20 years old) with poor/fair deck conditions and relatively old bridges (30–40 years old) with good deck conditions in the National Bridge Inventory (NBI) database. The accuracy of the predictive model is 0.91, and the AUC score is about 0.83. After applying this well-performed predictive model on the interpretable machine learning framework, the results revealed that without wearing surface, corrugated steel deck structure, wide bridge structure, and long span are highly associated with bridges with quickly deteriorating decks. The results also show that bridges with a relatively low average daily traffic (ADT) or truck percentage of ADT are in a dilemma zone, where the overall traffic or truck volume of the bridge is not low enough to prevent fast deterioration, but not high enough for eligibility for the funding required for more durable materials during construction or appropriate maintenance. © National Academy of Sciences: Transportation Research Board 2022.","Artificial intelligence; Artificial intelligence and advanced computing applications; Bridge and structures management; Bridge condition data/assessment; Bridge data QC/QA; Bridges and structures; Construction; Data analytics; Data and data science; Infrastructure; Infrastructure management and system preservation; Machine learning (artificial intelligence); Pattern recognition","Classification (of information); Deterioration; Efficiency; Information management; Machine learning; Pattern recognition; Wear of materials; Artificial intelligence and advanced computing application; Bridge and structure; Bridge condition data/assessment; Bridge data QC/QA; Bridge management; Computing applications; Condition; Data analytics; Data and data science; Data assessment; Infrastructure; Infrastructure management and system preservation; Infrastructure managements; Infrastructure systems; Machine learning (artificial intelligence); Machine-learning; Structure management; Data Analytics"
"Kopalle P.K., Gangwar M., Kaplan A., Ramachandran D., Reinartz W., Rindfleisch A.","Examining artificial intelligence (AI) technologies in marketing via a global lens: Current trends and future research opportunities","10.1016/j.ijresmar.2021.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120790815&doi=10.1016%2fj.ijresmar.2021.11.002&partnerID=40&md5=a738095ee6eb903819fc4599808770ba","Artificial intelligence (AI) has captured substantial interest from a wide array of marketing scholars in recent years. Our research contributes to this emerging domain by examining AI technologies in marketing via a global lens. Specifically, our lens focuses on three levels of analysis: country, company, and consumer. Our country-level analysis emphasizes the heterogeneity in economic inequality across countries due to the considerable economic resources necessary for AI adoption. Our company-level analysis focuses on glocalization because while the hardware that underlies these technologies may be global in nature, their application necessitates adaptation to local cultures. Our consumer-level analysis examines consumer ethics and privacy concerns, as AI technologies often collect, store and process a cornucopia of personal data across our globe. Through the prism of these three lenses, we focus on two important dimensions of AI technologies in marketing: (1) human–machine interaction and (2) automated analysis of text, audio, images, and video. We then explore the interaction between these two key dimensions of AI across our three-part global lens to develop a set of research questions for future marketing scholarship in this increasingly important domain. © 2021 The Authors","Artificial intelligence; Audio; Automated analysis of text; Ethics and privacy; Global marketing; Glocalization; Human–machine interaction; Images; Inequality; Video",
"Kora P., Ooi C.P., Faust O., Raghavendra U., Gudigar A., Chan W.Y., Meenakshi K., Swaraja K., Plawiak P., Rajendra Acharya U.","Transfer learning techniques for medical image analysis: A review","10.1016/j.bbe.2021.11.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121976989&doi=10.1016%2fj.bbe.2021.11.004&partnerID=40&md5=8b7afd11b2f283956a868254352a05c4","Medical imaging is a useful tool for disease detection and diagnostic imaging technology has enabled early diagnosis of medical conditions. Manual image analysis methods are labor-intense and they are susceptible to intra as well as inter-observer variability. Automated medical image analysis techniques can overcome these limitations. In this review, we investigated Transfer Learning (TL) architectures for automated medical image analysis. We discovered that TL has been applied to a wide range of medical imaging tasks, such as segmentation, object identification, disease categorization, severity grading, to name a few. We could establish that TL provides high quality decision support and requires less training data when compared to traditional deep learning methods. These advantageous properties arise from the fact that TL models have already been trained on large generic datasets and a task specific dataset is only used to customize the model. This eliminates the need to train the models from scratch. Our review shows that AlexNet, ResNet, VGGNet, and GoogleNet are the most widely used TL models for medical image analysis. We found that these models can understand medical images, and the customization refines the ability, making these TL models useful tools for medical image analysis. © 2021 Nalecz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences","Convolutional neural networks; Machine learning; Medical image; Transfer learning","Alzheimer disease; artificial intelligence; artificial neural network; autism; behavior; biocompatibility; blood brain barrier; breast cancer; breast lesion; cancer screening; computer assisted tomography; convolutional neural network; decision support system; diagnostic imaging; echography; endoscopy; epiluminescence microscopy; genotype; glaucoma; glioma; histopathology; human; human tissue; image analysis; image segmentation; lung adenocarcinoma; lung cancer; lung lesion; mammography; melanoma; mild cognitive impairment; nuclear magnetic resonance imaging; ophthalmoscopy; polymerase chain reaction; positron emission tomography; prostate cancer; prostatectomy; radiography; residual neural network; Review; support vector machine; transfer of learning; ultrasound"
"Korolyova N., Buechling A., Lieutier F., Yart A., Cudlín P., Turčáni M., Jakuš R.","Primary and secondary host selection by Ips typographus depends on Norway spruce crown characteristics and phenolic-based defenses","10.1016/j.plantsci.2022.111319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131115654&doi=10.1016%2fj.plantsci.2022.111319&partnerID=40&md5=af89ace1d641f6fdc91c1a78f8d9c826","Climate change is expected to intensify bark beetle population outbreaks in forests globally, affecting biodiversity and trajectories of change. Aspects of individual tree resistance remain poorly quantified, particularly with regard to the role of phenolic compounds, hindering robust predictions of forest response to future conditions. In 2003, we conducted a mechanical wounding experiment in a Norway spruce forest that coincided with an outbreak of the bark beetle, Ips typographus. We collected phloem samples from 97 trees and monitored tree survival for 5 months. Using high-performance liquid chromatography, we quantified induced changes in the concentrations of phenolics. Classification and regression tools were used to evaluate relationships between phenolic production and bark beetle resistance, in the context of other survival factors. The proximity of beetle source populations was a principal determinant of survival. Proxy measures of tree vigor, such as crown defoliation, mediated tree resistance. Controlling for these factors, synthesis of catechin was found to exponentially increase tree survival probability. However, even resistant trees were susceptible in late season due to high insect population growth. Our results show that incorporating trait-mediated effects improves predictions of survival. Using an integrated analytical approach, we demonstrate that phenolics play a direct role in tree defense to herbivory. © 2022 The Authors","Bark beetle outbreak; Catechin; Crown defoliation; Primary attraction; Resistance; Tree survival","phenol derivative; animal; beetle; herbivory; phloem; physiology; spruce; Animals; Coleoptera; Herbivory; Phenols; Phloem; Picea"
"Koutra S., Ioakimidis C.S.","Unveiling the Potential of Machine Learning Applications in Urban Planning Challenges","10.3390/land12010083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146550105&doi=10.3390%2fland12010083&partnerID=40&md5=ca07fa766bfd34375d594f37b76f8ee9","In a digitalized era and with the rapid growth of computational skills and advancements, artificial intelligence and Machine Learning uses in various applications are gaining a rising interest from scholars and practitioners. As a fast-growing field of Artificial Intelligence, Machine Artificial Intelligence deals with smart designs, data mining and management for complex problem-solving based on experimental data on urban applications (land use and cover, configurations of the built environment and architectural design, etc.), but with few explorations and relevant studies. In this work, a comprehensive and in-depth review is presented to discuss the future opportunities and constraints in meeting the next planning portfolio against the multiple challenges in urban environments in line with Machine Learning progress. Bringing together the theoretical views with practical analyses of cases and examples, the work unveils the huge potential, but also the potential barriers of the complexity of Machine Learning to urban planning strategies. © 2022 by the authors.","case-study analysis; machine learning; urban planning",
"Kozai T.","Towards sustainable plant factories with artificial lighting (PFALs) for achieving SDGs","10.25165/j.ijabe.20191205.5177","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073796790&doi=10.25165%2fj.ijabe.20191205.5177&partnerID=40&md5=0f41cd73f064553bfcf3e2d65af2f08f","The challenges and opportunities for developing sustainable plant factories with artificial lighting (PFALs) are discussed. After examining the production cost and productivity of existing PFALs in Japan, the possibility of introducing a relatively new concept and methodology for considerably improving productivity are discussed in relation to environmental controllability and resource use efficiencies. The fundamental and potential characteristics of ideal or next-generation PFALs (n-PFALs) are then discussed with some suggestions for actualizing n-PFALs. Finally, perspectives of the n-PFALs and technologies to be integrated into the n-PFALs are presented in relation to the Sustainable Development Goals (SDGs) to be achieved by 2030. © 2019, Chinese Society of Agricultural Engineering. All rights reserved.","Plant factory with artificial lighting (PFAL); Production cost; Productivity; SDGs",
"Krenn W.","Safety & security of connected and highly automated robots [Sicherheit vernetzter, hochautomatisierter Roboter]","10.1007/s00502-019-00746-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074631958&doi=10.1007%2fs00502-019-00746-z&partnerID=40&md5=5f2382ad1806e16c0c0b15ecd449df90","The paper presents current challenges to the safety and security of highly automated and connected robots. The term robot is used in its generic from and covers all systems from conventional industrial robots to highly automated vehicles. After a quick introduction to the basic challenges and the current state-of-the-art, the article presents current research and standardisation activities. A special focus is given to cyber security and artificial intelligence (AI) that play important roles for connected and highly automated systems. In the case of AI, the article also looks at the topic of “explainability” that could become an important concept when using AI in safety critical systems. The article is based on research results of the projects Enable-S3 and Productive4.0 and is an extended and updated version of a talk given at the IT-Kolloquium 2019 in Vienna. © 2019, Springer-Verlag GmbH Austria, ein Teil von Springer Nature.","artificial intelligence; cyber security; Enable-S3; Explainable-AI; Productive4.0; robots; Safety & Security; verification","Artificial intelligence; Automation; Industrial robots; Robots; Safety engineering; Verification; Automated systems; Automated vehicles; Cyber security; Enable-S3; Productive4.0; Safety and securities; Safety critical systems; State of the art; Intelligent robots"
"Kresova S., Hess S.","Identifying the Determinants of Regional Raw Milk Prices in Russia Using Machine Learning","10.3390/agriculture12071006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138074944&doi=10.3390%2fagriculture12071006&partnerID=40&md5=ad155665d21d36045b79a7ca81dce469","In this study, official data from Russia’s regions for the period from 2015 to 2019 were analysed on the basis of 12 predictor variables in order to explain the regional raw milk price. Model training and hyperparameter optimisation were performed with a spatiotemporal cross-validation technique using the machine learning (ML) algorithm. The findings of the study showed that the RF algorithm had a good predictive performance Variable importance revealed that drinking milk production, income, livestock numbers and population density are the four most important determinants to explain the variation in regional raw milk prices in Russia. © 2022 by the authors.","machine learning; milk price; random forest; Russia",
"Krinkin K., Shichkina Y., Ignatyev A.","Co-evolutionary hybrid intelligence is a key concept for the world intellectualization","10.1108/K-03-2022-0472","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139970979&doi=10.1108%2fK-03-2022-0472&partnerID=40&md5=6e177ab56f4f344fb19961df94488f91","Purpose: This study aims to show the inconsistency of the approach to the development of artificial intelligence as an independent tool (just one more tool that humans have developed); to describe the logic and concept of intelligence development regardless of its substrate: a human or a machine and to prove that the co-evolutionary hybridization of the machine and human intelligence will make it possible to reach a solution for the problems inaccessible to humanity so far (global climate monitoring and control, pandemics, etc.). Design/methodology/approach: The global trend for artificial intelligence development (has been) was set during the Dartmouth seminar in 1956. The main goal was to define characteristics and research directions for artificial intelligence comparable to or even outperforming human intelligence. It should be able to acquire and create new knowledge in a highly uncertain dynamic environment (the real-world environment is an example) and apply that knowledge to solving practical problems. Nowadays artificial intelligence overperforms human abilities (playing games, speech recognition, search, art generation, extracting patterns from data etc.), but all these examples show that developers have come to a dead end. Narrow artificial intelligence has no connection to real human intelligence and even cannot be successfully used in many cases due to lack of transparency, explainability, computational ineffectiveness and many other limits. A strong artificial intelligence development model can be discussed unrelated to the substrate development of intelligence and its general properties that are inherent in this development. Only then it is to be clarified which part of cognitive functions can be transferred to an artificial medium. The process of development of intelligence (as mutual development (co-development) of human and artificial intelligence) should correspond to the property of increasing cognitive interoperability. The degree of cognitive interoperability is arranged in the same way as the method of measuring the strength of intelligence. It is stronger if knowledge can be transferred between different domains on a higher level of abstraction (Chollet, 2018). Findings: The key factors behind the development of hybrid intelligence are interoperability – the ability to create a common ontology in the context of the problem being solved, plan and carry out joint activities; co-evolution – ensuring the growth of aggregate intellectual ability without the loss of subjectness by each of the substrates (human, machine). The rate of co-evolution depends on the rate of knowledge interchange and the manufacturability of this process. Research limitations/implications: Resistance to the idea of developing co-evolutionary hybrid intelligence can be expected from agents and developers who have bet on and invested in data-driven artificial intelligence and machine learning. Practical implications: Revision of the approach to intellectualization through the development of hybrid intelligence methods will help bridge the gap between the developers of specific solutions and those who apply them. Co-evolution of machine intelligence and human intelligence will ensure seamless integration of smart new solutions into the global division of labor and social institutions. Originality/value: The novelty of the research is connected with a new look at the principles of the development of machine and human intelligence in the co-evolution style. Also new is the statement that the development of intelligence should take place within the framework of integration of the following four domains: global challenges and tasks, concepts (general hybrid intelligence), technologies and products (specific applications that satisfy the needs of the market). © 2022, Emerald Publishing Limited.","AI ethics; Artificial intelligence; Co-evolution; Cognitive functions; Division of labor; Human–machine hybridization; Hybrid intelligence","Artificial intelligence; Brain; Cognitive systems; Computation theory; Interoperability; Speech recognition; AI ethic; Co-evolution; Co-evolutionary; Cognitive functions; Division of labor; Human intelligence; Human-machine; Human–machine hybridization; Hybrid intelligence; Hybridisation; Substrates"
"Krupitzer C., Noack T., Borsum C.","Digital Food Twins Combining Data Science and Food Science: System Model, Applications, and Challenges †","10.3390/pr10091781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138701337&doi=10.3390%2fpr10091781&partnerID=40&md5=6dcb977dd71177431f1ef921cbdfb5cb","The production of food is highly complex due to the various chemo-physical and biological processes that must be controlled for transforming ingredients into final products. Further, production processes must be adapted to the variability of the ingredients, e.g., due to seasonal fluctuations of raw material quality. Digital twins are known from Industry 4.0 as a method to model, simulate, and optimize processes. In this vision paper, we describe the concept of a digital food twin. Due to the variability of the raw materials, such a digital twin has to take into account not only the processing steps but also the chemical, physical, or microbiological properties that change the food independently from the processing. We propose a hybrid modeling approach, which integrates the traditional approach of food process modeling and simulation of the bio-chemical and physical properties with a data-driven approach based on the application of machine learning. This work presents a conceptual framework for our digital twin concept based on explainable artificial intelligence and wearable technology. We discuss the potential in four case studies and derive open research challenges. © 2022 by the authors.","artificial intelligence; digital twin; food processing; Industry 4.0; machine learning; self-aware computing systems",
"Kuang S.-F., Chen Y.-T., Chen J.-J., Peng X.-X., Chen Z.-G., Li H.","Synergy of alanine and gentamicin to reduce nitric oxide for elevating killing efficacy to antibiotic-resistant Vibrio alginolyticus","10.1080/21505594.2021.1947447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109717228&doi=10.1080%2f21505594.2021.1947447&partnerID=40&md5=4d0b038e41f7c78d600316bd0a964c42","The present study explored the cooperative effect of both alanine (Ala) and gentamicin (Gent) on metabolic mechanisms by which exogenous Ala potentiates Gent to kill antibiotic-resistant Vibrio alginolyticus. To test this, GC-MS-based metabolomics was used to characterize Ala-, Gent- and both-induced metabolic profiles, identifying nitric oxide (NO) production pathway as the most key clue to understand metabolic mechanisms. Gent, Ala and both led to low, lower and lowest activity of total nitric oxide synthase (tNOS) and level of NO, respectively. NOS promoter L-arginine and inhibitor NG-Monomethyl-L-arginine inhibited and promoted the killing, respectively, with the elevation and decrease of NOS activity and NO level. The present study further showed that CysJ is the enzyme-producing NO in V. alginolyticus. These results indicate that the cooperative effect of Ala and Gent causes the lowest NO, which plays a key role in Ala-potentiated Gent-mediated killing. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","Ala; Gent; metabolomics; nitric oxide; NOS; V. alginolyticus","alanine; antiinfective agent; arginine; gentamicin; nitric oxide; nitric oxide synthase; antibiotic resistance; drug effect; drug potentiation; homicide; Vibrio alginolyticus; Alanine; Anti-Bacterial Agents; Arginine; Drug Resistance, Bacterial; Drug Synergism; Gentamicins; Homicide; Nitric Oxide; Nitric Oxide Synthase; Vibrio alginolyticus"
"Kumar A., Jain A., Agarwal B., Jain M., Harjule P., Verma R.A.","Pixel-Based Classification of Land Use/Land Cover Built-Up and Non-Built-Up Areas Using Google Earth Engine in an Urban Region (Delhi, India)","10.1201/9781003172772-14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133226647&doi=10.1201%2f9781003172772-14&partnerID=40&md5=7316c682db712d5243e290f74d1b206b",[No abstract available],,
"Kumar C., Podestá G., Kilpatrick K., Minnett P.","A machine learning approach to estimating the error in satellite sea surface temperature retrievals","10.1016/j.rse.2020.112227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099484913&doi=10.1016%2fj.rse.2020.112227&partnerID=40&md5=7a6dedb46659af490cfb6cf6de703b16","Global, repeated, and accurate measurements of Sea Surface Temperature (SST) are critical for weather and climate projections. While thermometers on buoys measure SST relatively accurately, only sensors aboard satellites give global and repeated SST measurements necessary for many applications, including climate modeling. For satellite-based thermal infrared sensors, an atmospheric correction converts calibrated brightness temperatures measured at orbital height into an SST estimate, but imperfect assumptions in the correction algorithm coupled with variability in atmospheric conditions and viewing geometries can lead to a wide range of errors and uncertainties in the satellite-derived SST retrievals. Estimates of the resulting errors are imperative for satellite-derived SST assimilation into climate models. This paper evaluates the use of machine learning Decision Tree algorithms to predict the central tendency and dispersion of errors in satellite-derived SST retrievals. First, using records from the NASA R2014.1 MODIS Aqua SST Matchup Database, which includes matched-up satellite and in situ SST measurements, a set of seven variables was derived that addresses the assumptions and known issues in the satellite SST retrieval process. Then, both Random Forest and Cubist Decision Trees were used to predict the SST residual (satellite SST minus skin-corrected buoy SST) for each matchup. While both Decision Tree methods performed similarly well, the Cubist model is more easily interpreted and yields better predictions of errors for relatively infrequent conditions. Various characteristics of the groups of matchups identified by Cubist were explored, and uncertainty values for the error estimates were derived for each group. Overall, the Cubist model predicted the skin SST residual with a root-mean-squared-error of 0.380 °C across nighttime cloud-filtered domains, demonstrating that a Cubist model is viable for quantitatively and accurately predicting Single Sensor Error Statistics per pixel as required by the Group for High Resolution SST. In this paper, we present the training and testing of both Decision Tree models. Because of its interpretability, we explore in detail the characteristics of the Cubist-derived groups to gain new geophysical insight into the satellite-derived SST retrieval error across different measurement conditions. © 2020 Elsevier Inc.","Cubist; Decision trees; Machine learning; MODIS; Random forests; Sea surface temperature; Single sensor error statistics","Atmospheric temperature; Climate models; Decision trees; Error statistics; Errors; Forecasting; Infrared detectors; Machine learning; Mean square error; NASA; Orbits; Random forests; Satellites; Submarine geophysics; Surface properties; Surface waters; Turing machines; Uncertainty analysis; Atmospheric conditions; Atmospheric corrections; Brightness temperatures; Decision-tree algorithm; Machine learning approaches; Root mean squared errors; Sea surface temperature (SST); Thermal infrared sensors; Oceanography; algorithm; atmospheric correction; calibration; climate change; machine learning; MODIS; numerical model; pixel; random walk method; satellite data; sea surface temperature; sensor; Satellites"
"Kumar Sharma A., Kumar Ghodke P., Goyal N., Nethaji S., Chen W.-H.","Machine learning technology in biohydrogen production from agriculture waste: Recent advances and future perspectives","10.1016/j.biortech.2022.128076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139726534&doi=10.1016%2fj.biortech.2022.128076&partnerID=40&md5=65801dfa395701bafececa5d5172d156","Agricultural waste biomass has shown great potential to deliver green energy produced by biochemical and thermochemical conversion processes to mitigate future energy crises. Biohydrogen has become more interested in carbon-free and high-energy dense fuels among different biofuels. However, it is challenging to develop models based on experience or theory for precise predictions due to the complexity of biohydrogen production systems and the limitations of human perception. Recent advancements in machine learning (ML) may open up new possibilities. For this reason, this critical study offers a thorough understanding of ML's use in biohydrogen production. The most recent developments in ML-assisted biohydrogen technologies, including biochemical and thermochemical processes, are examined in depth. This review paper also discusses the prediction of biohydrogen production from agricultural waste. Finally, the techno-economic and scientific obstacles to ML application in agriculture waste biomass-based biohydrogen production are summarized. © 2022 Elsevier Ltd","Agriculture waste; Biochemical and thermochemical; Biohydrogen production; Machine learning","Agricultural wastes; Agriculture; Biofuels; Energy policy; Fossil fuels; Hydrogen fuels; Agriculture wastes; Bio-hydrogen; Bio-hydrogen production; Biochemical and thermochemical; Future perspectives; Green energy; Machine learning technology; Machine-learning; Thermochemicals; Waste biomass; Hydrogen production; biofuel; carbon; hydrogen; biochemical composition; biofuel; future prospect; machine learning; prediction; solid waste; thermochemistry; agricultural waste; Article; artificial neural network; bioenergy; biomass; bioprocess; energy yield; fermentation; machine learning; nonhuman; theoretical study"
"Kumaraperumal R., Pazhanivelan S., Geethalakshmi V., Nivas Raj M., Muthumanickam D., Kaliaperumal R., Shankar V., Nair A.M., Yadav M.K., Tarun Kshatriya T.V.","Comparison of Machine Learning-Based Prediction of Qualitative and Quantitative Digital Soil-Mapping Approaches for Eastern Districts of Tamil Nadu, India","10.3390/land11122279","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144898875&doi=10.3390%2fland11122279&partnerID=40&md5=893d30a78f68b465b3023e7fa3fba44e","The soil–environmental relationship identified and standardised over the years has expedited the growth of digital soil-mapping techniques; hence, various machine learning algorithms are involved in predicting soil attributes. Therefore, comparing the different machine learning algorithms is essential to provide insights into the performance of the different algorithms in predicting soil information for Indian landscapes. In this study, we compared a suite of six machine learning algorithms to predict quantitative (Cubist, decision tree, k-NN, multiple linear regression, random forest, support vector regression) and qualitative (C5.0, k-NN, multinomial logistic regression, naïve Bayes, random forest, support vector machine) soil information separately at a regional level. The soil information, including the quantitative (pH, OC, and CEC) and qualitative (order, suborder, and great group) attributes, were extracted from the legacy soil maps using stratified random sampling procedures. A total of 4479 soil observations sampled were non-spatially partitioned and intersected with 39 environmental covariate parameters. The predicted maps depicted the complex soil–environmental relationships for the study area at a 30 m spatial resolution. The comparison was facilitated based on the evaluation metrics derived from the test datasets and visual interpretations of the predicted maps. Permutation feature importance analysis was utilised as the model-agnostic interpretation tool to determine the contribution of the covariate parameters to the model’s calibration. The R2 values for the pH, OC, and CEC ranged from 0.19 to 0.38; 0.04 to 0.13; and 0.14 to 0.40, whereas the RMSE values ranged from 0.75 to 0.86; 0.25 to 0.26; and 8.84 to 10.49, respectively. Irrespective of the algorithms, the overall accuracy percentages for the soil order, suborder, and great group class ranged from 31 to 67; 26 to 65; and 27 to 65, respectively. The tree-based ensemble random forest and rule-based tree models’ (Cubist and C5.0) algorithms efficiently predicted the soil properties spatially. However, the efficiency of the other models can be substantially increased by advocating additional parameterisation measures. The range and scale of the quantitative soil attributes, in addition to the sampling frequency and design, greatly influenced the model’s output. The comprehensive comparison of the algorithms can be utilised to support model selection and mapping at a varied scale. The derived digital soil maps will help farmers and policy makers to adopt precision information for making decisions at the farm level leading to productivity enhancements through the optimal use of nutrients and the sustainability of the agricultural ecosystem, ensuring food security. © 2022 by the authors.","digital soil mapping; machine learning; model comparison; SCORPAN; soil spatial predictions",
"Kundu N., Rani G., Dhaka V.S., Gupta K., Nayaka S.C., Vocaturo E., Zumpano E.","Disease detection, severity prediction, and crop loss estimation in MaizeCrop using deep learning","10.1016/j.aiia.2022.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146235933&doi=10.1016%2fj.aiia.2022.11.002&partnerID=40&md5=e86c3133d6887fbfba88f6bd4e627508","The increasing gap between the demand and productivity of maize crop is a point of concern for the food industry, and farmers. Its' susceptibility to diseases such as Turcicum Leaf Blight, and Rust is a major cause for reducing its production. Manual detection, and classification of these diseases, calculation of disease severity, and crop loss estimation is a time-consuming task. Also, it requires expertise in disease detection. Thus, there is a need to find an alternative for automatic disease detection, severity prediction, and crop loss estimation. The promising results of machine learning, and deep learning algorithms in pattern recognition, object detection, and data analysis motivate researchers to employ these techniques for disease detection, classification, and crop loss estimation in maize crop. The research works available in literature, have proven their potential in automatic disease detection using machine learning, and deep learning models. But, there is a lack none of these works a reliable and real-life labelled dataset for training these models. Also, none of the existing works focus on severity prediction, and crop loss estimation. The authors in this manuscript collect the real-life dataset labelled by plant pathologists. They propose a deep learning-based framework for pre-processing of dataset, automatic disease detection, severity prediction, and crop loss estimation. It uses the K-Means clustering algorithm for extracting the region of interest. Next, they employ the customized deep learning model ‘MaizeNet’ for disease detection, severity prediction, and crop loss estimation. The model reports the highest accuracy of 98.50%. Also, the authors perform the feature visualization using the Grad-CAM. Now, the proposed model is integrated with a web application to provide a user-friendly interface. The efficacy of the model in extracting the relevant features, a smaller number of parameters, low training time, high accuracy favors its importance as an assisting tool for plant pathology experts.The copyright for the associated web application ‘Maize-Disease-Detector’ is filed with diary number: 17006/2021-CO/SW. © 2022","Crop loss; Deep learning; Disease detection; Maize; Severity",
"Kundu N., Rani G., Dhaka V.S., Gupta K., Nayak S.C., Verma S., Ijaz M.F., Woźniak M.","Iot and interpretable machine learning based framework for disease prediction in pearl millet","10.3390/s21165386","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112371900&doi=10.3390%2fs21165386&partnerID=40&md5=a8d468231f619dc372692d750fcd5675","Decrease in crop yield and degradation in product quality due to plant diseases such as rust and blast in pearl millet is the cause of concern for farmers and the agriculture industry. The stipulation of expert advice for disease identification is also a challenge for the farmers. The traditional techniques adopted for plant disease detection require more human intervention, are unhandy for farmers, and have a high cost of deployment, operation, and maintenance. Therefore, there is a requirement for automating plant disease detection and classification. Deep learning and IoT-based solutions are proposed in the literature for plant disease detection and classification. However, there is a huge scope to develop low-cost systems by integrating these techniques for data collection, feature visualization, and disease detection. This research aims to develop the ‘Automatic and Intelligent Data Collector and Classifier’ framework by integrating IoT and deep learning. The framework automatically collects the imagery and parametric data from the pearl millet farmland at ICAR, Mysore, India. It automatically sends the collected data to the cloud server and the Raspberry Pi. The ‘Custom-Net’ model designed as a part of this research is deployed on the cloud server. It collaborates with the Raspberry Pi to precisely predict the blast and rust diseases in pearl millet. Moreover, the Grad-CAM is employed to visualize the features extracted by the ‘Custom-Net’. Furthermore, the impact of transfer learning on the ‘Custom-Net’ and state-of-the-art models viz. Inception ResNet-V2, Inception-V3, ResNet-50, VGG-16, and VGG-19 is shown in this manuscript. Based on the experimental results, and features visualization by Grad-CAM, it is observed that the ‘Custom-Net’ extracts the relevant features and the transfer learning improves the extraction of relevant features. Additionally, the ‘Custom-Net’ model reports a classification accuracy of 98.78% that is equivalent to state-of-the-art models viz. Inception ResNet-V2, Inception-V3, ResNet-50, VGG-16, and VGG-19. Although the classification of ‘Custom-Net’ is comparable to state-of-the-art models, it is effective in reducing the training time by 86.67%. It makes the model more suitable for automating disease detection. This proves that the proposed model is effective in providing a low-cost and handy tool for farmers to improve crop yield and product quality. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Context-aware; Deep learning; Interpretable; IoT; Machine learning","Agricultural robots; Cloud computing; Costs; Crops; Data integration; Data visualization; Deep learning; Gems; Internet of things; Predictive analytics; Quality control; Transfer learning; Visualization; Agriculture industries; Classification accuracy; Disease detection; Human intervention; Intelligent data; Relevant features; State of the art; Traditional techniques; Learning systems; agriculture; human; machine learning; Pennisetum; plant disease; Agriculture; Humans; Machine Learning; Pennisetum; Plant Diseases"
"Kusuma A.T., Supangkat S.H.","Metaverse Fundamental Technologies for Smart City: A Literature Review","10.1109/ICISS55894.2022.9915079","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141417930&doi=10.1109%2fICISS55894.2022.9915079&partnerID=40&md5=33024e08c4bbdc87d77bcddbff9972fc","Smart city is a digital city concept that utilizes information technology in city management. The smart city concept will evolve into a metaverse City in the future. Adopting the metaverse without careful planning can spell trouble for the organization. It is because the metaverse concept is broad and evolving. Implementing the metaverse concept cannot be separated from the various technologies that support it, such as the internet, Virtual Reality (VR) and Augmented Reality (AR), loT, Artificial Intelligent (AI), and blockchain. This paper provides an overview of the metaverse supporting technologies and their adaption to smart cities as a reference for related research. The main obj ective of this paper is to provide a better understanding of adopting the metaverse concept to smart cities and the fundamental technologies that support it. © 2022 IEEE.","Blockchain; Digital Twin; Metaverse; Smart City","Augmented reality; Blockchain; Virtual reality; Artificial intelligent; Block-chain; City management; Literature reviews; Metaverses; Supporting technology; Various technologies; Smart city"
"Kuzmin A., Korhonen L., Kivinen S., Hurskainen P., Korpelainen P., Tanhuanpää T., Maltamo M., Vihervaara P., Kumpula T.","Detection of european aspen (populus tremula L.) based on an unmanned aerial vehicle approach in boreal forests","10.3390/rs13091723","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105586543&doi=10.3390%2frs13091723&partnerID=40&md5=ebc2e4600ac363d550b77a27f7eea7d4","European aspen (Populus tremula L.) is a keystone species for biodiversity of boreal forests. Large-diameter aspens maintain the diversity of hundreds of species, many of which are threatened in Fennoscandia. Due to a low economic value and relatively sparse and scattered occurrence of aspen in boreal forests, there is a lack of information of the spatial and temporal distribution of aspen, which hampers efficient planning and implementation of sustainable forest management practices and conservation efforts. Our objective was to assess identification of European aspen at the individual tree level in a southern boreal forest using high-resolution photogrammetric point cloud (PPC) and multispectral (MSP) orthomosaics acquired with an unmanned aerial vehicle (UAV). The structure-from-motion approach was applied to generate RGB imagery-based PPC to be used for individual tree-crown delineation. Multispectral data were collected using two UAV cameras: Parrot Sequoia and MicaSense RedEdge-M. Tree-crown outlines were obtained from watershed segmentation of PPC data and intersected with multispectral mosaics to extract and calculate spectral metrics for individual trees. We assessed the role of spectral data features extracted from PPC and multispectral mosaics and a combination of it, using a machine learning classifier-Support Vector Machine (SVM) to perform two different classifications: discrimination of aspen from the other species combined into one class and classification of all four species (aspen, birch, pine, spruce) simultaneously. In the first scenario, the highest classification accuracy of 84% (F1-score) for aspen and overall accuracy of 90.1% was achieved using only RGB features from PPC, whereas in the second scenario, the highest classification accuracy of 86 % (F1-score) for aspen and overall accuracy of 83.3% was achieved using the combination of RGB and MSP features. The proposed method provides a new possibility for the rapid assessment of aspen occurrence to enable more efficient forest management as well as contribute to biodiversity monitoring and conservation efforts in boreal forests. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Biodiversity; Boreal forest; Deciduous trees; European aspen; Machine learning; Multispectral data; Tree species classification; Uav","Aircraft detection; Antennas; Biodiversity; Data mining; Image segmentation; Learning systems; Support vector machines; Turing machines; Unmanned aerial vehicles (UAV); Biodiversity monitoring; Classification accuracy; Individual tree crown; Southern boreal forests; Spatial and temporal distribution; Structure from motion; Sustainable forest management; Watershed segmentation; Forestry"
"Lacueva-Pérez F.J., Artigas S.I., Barriuso Vargas J.J., Lezaun G.L., Del Hoyo Alonso R.","Multifactorial evolutionary prediction of phenology and pests: Can machine learning help?",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107141126&partnerID=40&md5=bf650ea743bc076a753522cf5179882f","Agriculture is a key primary sector of economy. Developing and applying techniques that support a sustainable development of the fields and maximize their productivity, while guaranteeing the maximum levels of health and quality of the crops, is necessary. Precision agriculture refers to the use of technology to help in the decision-making process and can lead to the achievement of these goals. In this position paper, we argue that machine learning (ML) techniques can provide significant benefits to precision agriculture, but that there exist obstacles that are preventing their widespread adoption and effective application. Particularly, we focus on the prediction of phenology changes and pests, due to their important to ensure the quality of the crops. We analyze the state of the art, present the existing challenges, and outline our specific research goals. Copyright © 2020 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved","Big data; Machine learning; Phenology forecast; Remote sensing; Smart farming","Agricultural robots; Biology; Crops; Decision making; Information systems; Information use; Precision agriculture; Predictive analytics; Decision making process; Maximum levels; Position papers; Research goals; State of the art; Machine learning"
"Lan Y., Wang J., Hu W., Kurbanov E., Cole J., Sha J., Jiao Y., Zhou J.","Spatial pattern prediction of forest wildfire susceptibility in Central Yunnan Province, China based on multivariate data","10.1007/s11069-022-05689-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140999692&doi=10.1007%2fs11069-022-05689-x&partnerID=40&md5=e575a2451f70ad04e8a7de4ac87876e6","Wildfires are an important disturbance factor in forest ecosystems. Assessing the probability of forest wildfires can assist in forest wildfire prevention, control, and supervision. The logistic regression model is widely used to forecast the probability, spatial patterns, and drivers of forest wildfires. This study used logistic regression to establish a spatial prediction model for forest wildfire susceptibility, which was applied to evaluate the risk of forest wildfires in Central Yunnan Province (CYP), China. A forest wildfire risk classification was implemented for CYP using forest burn scar data for 2001 to 2020 and the logistic spatial prediction model for forest wildfire susceptibility. Climate, vegetation, topographical, human activities, and location were selected as forest wildfire prediction variables. The results showed that: (1) The distributions of temperature, vegetation coverage, distance to water bodies, distance to roads, and precipitation were positively correlated with the occurrence of forest wildfires. Elevation, relative humidity, the global vegetation moisture index, wind speed, slope, latitude, and distance to residential areas were negatively correlated with the occurrence of forest wildfires. (2) The results of the logistic spatial prediction model for forest wildfire susceptibility showed a good fit to wildfire data, with an overall simulation probability of 81.6%. The optimal threshold for spatial prediction for forest wildfire susceptibility in CYP was determined to be 0.414. A significance level of a selected model variable of < 0.05 resulted in an area under the receiver operating characteristic curve (AUC) of 0.882–0.890. (3) Forest wildfire prevention efforts should focus on Southwest Yuxi City and southern Qujing City accounted for a high proportion of the areas at high risk of forest wildfires. Other localities should adjust forest wildfire prevention measures according to local conditions and strengthen existing wildfire prevention and emergency resource planning and allocation. (4) Some factors contributing to forest wildfires where different among the different areas. Forest wildfire risk factors had different degrees of impact under different spatial and temporal scales. The spatial relationships between wildfire disasters and influencing factors should be established in areas with heterogeneous environmental conditions for the selection of relevant factors. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.","Central Yunnan Province; Driving factors; Forest wildfire; Logistic regression; Risk grade; Susceptibility",
"Lange M., Feilhauer H., Kühn I., Doktor D.","Mapping land-use intensity of grasslands in Germany with machine learning and Sentinel-2 time series","10.1016/j.rse.2022.112888","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129958717&doi=10.1016%2fj.rse.2022.112888&partnerID=40&md5=f3549935479e161fc799ca5d47de7899","Information on grassland land-use intensity (LUI) is crucial for understanding trends and dynamics in biodiversity, ecosystem functioning, earth system science and environmental monitoring. LUI is a major driver for numerous environmental processes and indicators, such as primary production, nitrogen deposition and resilience to climate extremes. However, large extent, high resolution data on grassland LUI is rare. New satellite generations, such as Copernicus Sentinel-2, enable a spatially comprehensive detection of the mainly subtle changes induced by land-use intensification by their fine spatial and temporal resolution. We developed a methodology quantifying key parameters of grassland LUI such as grazing intensity, mowing frequency and fertiliser application across Germany using Convolutional Neural Networks (CNN) on Sentinel-2 satellite data with 20 m × 20 m spatial resolution. Subsequently, these land-use components were used to calculate a continuous LUI index. Predictions of LUI and its components were validated using comprehensive in situ grassland management data. A feature contribution analysis using Shapley values substantiates the applicability of the methodology by revealing a high relevance of springtime satellite observations and spectral bands related to vegetation health and structure. We achieved an overall classification accuracy of up to 66% for grazing intensity, 68% for mowing, 85% for fertilisation and an r2 of 0.82 for subsequently depicting LUI. We evaluated the methodology's robustness with a spatial 3-fold cross-validation by training and predicting on geographically distinctly separated regions. Spatial transferability was assessed by delineating the models' area of applicability. The presented methodology enables a high resolution, large extent mapping of land-use intensity of grasslands. © 2022 Elsevier Inc.","Classification; Convolutional Neural Networks; Deep learning; Fertilisation; Grazing; Mowing; Optical satellite data; Random Forest","Biodiversity; Classification (of information); Convolution; Decision trees; Deep learning; Earth (planet); Land use; Mapping; Random forests; Satellites; Convolutional neural network; Deep learning; Fertilisation; Grazing; Mapping land; Mowing; Optical satellite data; Optical satellites; Random forests; Satellite data; Convolutional neural networks; algorithm; artificial neural network; fertilizer application; grassland; machine learning; methodology; mowing; satellite data; Germany"
"Lau B.P.L., Marakkalage S.H., Zhou Y., Hassan N.U., Yuen C., Zhang M., Tan U.-X.","A survey of data fusion in smart city applications","10.1016/j.inffus.2019.05.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066074486&doi=10.1016%2fj.inffus.2019.05.004&partnerID=40&md5=38d4bd3f76f9bfdd456998359f5ab57b","The advancement of various research sectors such as Internet of Things (IoT), Machine Learning, Data Mining, Big Data, and Communication Technology has shed some light in transforming an urban city integrating the aforementioned techniques to a commonly known term - Smart City. With the emergence of smart city, plethora of data sources have been made available for wide variety of applications. The common technique for handling multiple data sources is data fusion, where it improves data output quality or extracts knowledge from the raw data. In order to cater evergrowing highly complicated applications, studies in smart city have to utilize data from various sources and evaluate their performance based on multiple aspects. To this end, we introduce a multi-perspectives classification of the data fusion to evaluate the smart city applications. Moreover, we applied the proposed multi-perspectives classification to evaluate selected applications in each domain of the smart city. We conclude the paper by discussing potential future direction and challenges of data fusion integration. © 2019 Elsevier B.V.","Big data; Data fusion; Internet of things; Multi-perspectives classification; Sensor fusion; Smart city","Big data; Data fusion; Data integration; Internet of things; Learning systems; Metadata; Sensor data fusion; Smart city; Communication technologies; Data-sources; Internet of Things (IOT); Multi-perspective; Multiple data sources; Performance based; Sensor fusion; Urban cities; Data mining"
"Lavallin A., Downs J.A.","Machine learning in geography–Past, present, and future","10.1111/gec3.12563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104540531&doi=10.1111%2fgec3.12563&partnerID=40&md5=f95319ab95aabac77407db5bab26f769","This paper concentrates on the different meanings of machine learning (ML) from its origins to the present and potential future, focusing on contributions within the discipline of geography. Understanding the history of ML is important both for understanding current trends and predicting future applications. The 1950s saw the first idea of ML with the Turing Test, which was described as a ‘learning machine’ that could acquire information and become artificially intelligent. This thought prevailed until the 1960s with the release of Perceptron I, which caused a shift to attempt to code computers to learn from input data in order to run like a human brain. The 1980s and 1990s saw the advancement of computing technologies which enabled ML within artificial intelligence to prosper. The development of artificial neural networks during this time shifted ML from a knowledge-driven approach to a data-driven one. The 2000s saw ML becoming more widespread within geography and other disciplines as unsupervised methods enabled the analysis of large data sets. More recently, deep learning emerged to enable processes to be integrated into many software services and applications. Present day ML has been defined by Stanford University (2017) as “the science of getting computers to act without being explicitly programmed”. Academic research alongside industry and government investments in ML now account for some of the most important technological advancements. The use of ML within geography has been increasing at a rapid rate paving the way for future advancements in the discipline. © 2021 John Wiley & Sons Ltd.","artificial intelligence; deep learning; GeoAI; geography; machine learning; supervised; unsupervised","artificial intelligence; artificial neural network; data set; historical perspective; prediction; software; trend analysis"
"Lavorgna A., Middleton S.E., Pickering B., Neumann G.","FloraGuard: Tackling the Online Illegal Trade in Endangered Plants Through a Cross-Disciplinary ICT-Enabled Methodology","10.1177/1043986220910297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082181993&doi=10.1177%2f1043986220910297&partnerID=40&md5=7ca8e5737e655a909c67818ce12bbb83","This article presents a part of the ongoing Economic and Social Research Council (ESRC)-funded project “FloraGuard: Tackling the illegal trade in endangered plants” that relies on cross-disciplinary approaches to analyze online marketplaces for the illegal trade in endangered plants, and explores strategies to develop digital resources to assist law enforcement in countering and disrupting this criminal market. This contribution focuses on how the project brought together computer science, criminology, conservation science, and law enforcement expertise to create a tool for the automatic gathering of relevant online information to be used for research, intelligence, and investigative purposes. The article also discusses the ethical standards applied and proposes the concept of “artificial intelligence (AI) review” to provide a sociotechnical solution that builds trustworthiness in the AI approaches used for this type of cross-disciplinary information and communications technology (ICT)-enabled methodology. © The Author(s) 2020.","ethics in online research; explainable AI; natural language processing; plant crimes; wildlife trafficking",
"Lavrenovs A., Graf R.","Explainable AI for Classifying Devices on the Internet","10.23919/CyCon51939.2021.9467804","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112313887&doi=10.23919%2fCyCon51939.2021.9467804&partnerID=40&md5=a0e9b214b15ef3a5b549fee858fe4cfe","Devices reachable on the Internet pose varying levels of risk to their owners and the wider public, depending on their role and functionality, which can be considered their class. Discussing the security implications of these devices without knowing their classes is impractical. There are multiple AI methods to solve the challenge of classifying devices. Since the number of significant features in device HTTP response was determined to be low in the existing word-embedding neural network, we elected to employ an alternative method of Naive Bayes classification. The Naive Bayes method demonstrated high accuracy, but we recognise the need to explain classification results to improve classification accuracy. The black-box implementation of Artificial Neural Networks has been a serious concern when evaluating the classification results produced in most fields. While devices on the Internet have historically been classified manually or using trivial fingerprinting to match major vendors, these are not feasible anymore because of an ever-increasing variety of devices on the Internet. In the last few years, device classification using Neural Networks has emerged as a new research direction. These research results often claim high accuracy through the validation employed, but through random sampling there always occur devices that cannot be easily classified, that an expert intuitively would classify differently. Addressing this issue is critical for establishing trust in classification results and can be achieved by employing explainable AI. To better understand the models for classifying devices reachable on the Internet and to improve classification accuracy, we developed a novel explainable AI method, which returns the features that are most significant for classification decisions. We employed a Local Interpretable Model-Agnostic Explanations (LIME) framework toexplain Naive Bayes model classification results, and using this method were able to further improve accuracy with a better understanding of the results. © 2021 NATO CCDCOE.","classifying devices on the Internet; explainable AI; machine learning; Naive Bayes","Bayesian networks; Classifiers; HTTP; Lime; Classification accuracy; Classification decision; Classification results; Device classifications; Naive Bayes classification; Naive Bayes models; Research results; Security implications; Neural networks"
"Lavrinenko A., Shmatko N.","Twenty-first century skills in finance: prospects for a profound job transformation","10.17323/2500-2597.2019.2.42.51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071014598&doi=10.17323%2f2500-2597.2019.2.42.51&partnerID=40&md5=75714f91fa55c32980913a8749bab703","This paper analyzes the impact disruptive technologies, such as artificial intelligence (AI), big data, the internet of things, and blockchain, upon conventional banking professions and skill sets. Our conclusions are based upon a large array of data collected over the course of a survey of highly qualified personnel conducted in 2017-2018 using text mining, case studies, and expert interviews. The changing requirements for workers and to their competences were assessed taking into account the level of technological development (including the use of relevant products and services by Russian and international companies) as well as the probability of certain professional skills being substituted by automated solutions in the medium term. The results indicate that impact of technologies upon various functional segments of banks’ operations is varied. While most of the analyzed professions are evolving towards broader functionality, others are sliding into the “obsolete” group. In the next few years, automated systems will take full responsibility for data collection and its initial analysis, though they will not replace bank personnel fully given that they simply remain tools that help boost workers’ productivity and efficiency, extend the information base, accelerate decision-making, cut costs, and reduce risks. © 2019, National Research University, Higher School of Econoimics. All rights reserved.","21st century skills; Banking professions; Breakthrough technologies; Competences for the future; Job automation",
"Lawless W.F., Sofge D.A.","Interdependence and Vulnerability in Systems: A Review of Theory for Autonomous Human-Machine Teams","10.1007/978-3-030-89385-9_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120672037&doi=10.1007%2f978-3-030-89385-9_15&partnerID=40&md5=6509b8fbac88ac984c286f3c02468508","Interdependence exists in all social interactions as constructive or destructive interference. States of interdependence transmit both positive (constructive) and negative (destructive) effects in the interaction. In this chapter, we review the theory of interdependence, and its effects when positive (e.g., innovations, marriages, mergers) or negative (e.g., patent failures, divorces, bankruptcies). We apply the theory to human-machine teams to predict the best and worst teams. And with the theory of interdependence, we review our newest discovery of vulnerability in an opposing team or in our own team. We consider vulnerability to be a fundamental principle of organization in preparation for a competition, during a competition, or in the post-hoc reviews of a competition between teams or organizations. One of the new issues for this chapter is to apply interdependence theory to whether or not convergence has a positive or negative effect in a competition, as with models for system dynamics. We conclude that if a model, concept or leader of a team addresses only a team’s convergence effects, the team will itself be left vulnerable to its opponent and ignorant of the vulnerabilities in its opponent. © 2021, Springer Nature Switzerland AG.","Convergence; Interdependence; Vulnerability","Constructive interference; Convergence; Destructive effects; Destructive interference; Fundamental principles; Human-machine; Interdependence; Modeling concepts; Social interactions; Vulnerability"
"Lawless W.F.","Quantum-like interdependence theory advances autonomous human–machine teams (A-HMTs)","10.3390/e22111227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094607154&doi=10.3390%2fe22111227&partnerID=40&md5=207af6dd14347655f6126aba60f7c6e0","As humanity grapples with the concept of autonomy for human–machine teams (A-HMTs), unresolved is the necessity for the control of autonomy that instills trust. For non-autonomous systems in states with a high degree of certainty, rational approaches exist to solve, model or control stable interactions; e.g., game theory, scale-free network theory, multi-agent systems, drone swarms. As an example, guided by artificial intelligence (AI, including machine learning, ML) or by human operators, swarms of drones have made spectacular gains in applications too numerous to list (e.g., crop management; mapping, surveillance and fire-fighting systems; weapon systems). But under states of uncertainty or where conflict exists, rational models fail, exactly where interdependence theory thrives. Large, coupled physical or information systems can also experience synergism or dysergism from interdependence. Synergistically, the best human teams are not only highly interdependent, but they also exploit interdependence to reduce uncertainty, the focus of this work-in-progress and roadmap. We have long argued that interdependence is fundamental to human autonomy in teams. But for A-HMTs, no mathematics exists to build from rational theory or social science for their design nor safe or effective operation, a severe weakness. Compared to the rational and traditional social theory, we hope to advance interdependence theory first by mapping similarities between quantum theory and our prior findings; e.g., to maintain interdependence, we previously established that boundaries reduce dysergic effects to allow teams to function (akin to blocking interference to prevent quantum decoherence). Second, we extend our prior findings with case studies to predict with interdependence theory that as uncertainty increases in non-factorable situations for humans, the duality in two-sided beliefs serves debaters who explore alternatives with tradeoffs in the search for the best path going forward. Third, applied to autonomous teams, we conclude that a machine in an A-HMT must be able to express itself to its human teammates in causal language however imperfectly. © 2020 by the author. Licensee MDPI, Basel, Switzerland.","Artificial intelligence (AI); Autonomous human–machine teams (A-HMTs); Interdependence; Quantum-likeness; Roadmap; Vulnerability",
"Le T.-T., Nguyen V.-H., Le M.V.","Development of deep learning model for the recognition of cracks on concrete surfaces","10.1155/2021/8858545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104405976&doi=10.1155%2f2021%2f8858545&partnerID=40&md5=001a056a086f66778264096e89653b0d","This paper is devoted to the development of a deep learning- (DL-) based model to detect crack fractures on concrete surfaces. The developed model for the classification of images was based on a DL Convolutional Neural Network (CNN). To train and validate the CNN model, a database containing 40,000 images of concrete surfaces (with and without cracks) was collected from the available literature. Several conditions on the concrete surfaces were taken into account such as illumination and surface finish (i.e., exposed, plastering, and paint). Various error measurement criteria such as accuracy, precision, recall, specificity, and F1-score were employed for accessing the quality of the developed model. Results showed that for the training dataset (50% of the database), the precision, recall, specificity, F1-score, and accuracy were 99.5%, 99.8%, 99.5%, 99.7%, and 99.7%, respectively. On the other hand, for the validating dataset, the precision, recall, specificity, F1-score, and accuracy are 96.5%, 98.8%, 96.6%, 97.7%, and 97.7%, respectively. Thus, the developed CNN model may be considered valid because it performs the classification of cracks well using the testing data. It is also confirmed that the developed DL-based model was robust and efficient, as it can take into account different conditions on the concrete surfaces. The CNN model developed in this study was compared with other works in the literature, showing that the CNN model could improve the accuracy of image classification, in comparison with previously published results. Finally, in further work, such model could be combined with Unmanned Aerial Vehicles (UAVs) to increase the productivity of concrete infrastructure inspection. Copyright © 2021 Tien-Thinh Le et al.",,
"Lee C.","Enhancing the performance of a neural network with entity embeddings: an application to real estate valuation","10.1007/s10901-021-09885-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112807715&doi=10.1007%2fs10901-021-09885-2&partnerID=40&md5=c3b588e760067fa9ee8a7d0cf80134af","In contrast to the brilliant success of deep learning approach in dealing with unstructured data such as image and natural language, it has not shown noticeable achievements in handling structured data, that is, tabular format data. Categorical data types form a considerable portion of structured data, and a neural network, the most universal implementation algorithm for deep learning, is inefficient in processing these data types. This is a reason for the poor performance of the neural network applied to the structured data. In this study, a neural network is used to estimate land prices in the Gyunggi province, South Korea. To enhance the performance of the network when most input variables are categorical, the architecture of the neural network is specified using the entity embedding layers, a technique to reveal the continuity inherent in categorical data. This study demonstrates that information in the categorical data can be efficiently extracted by the entity embedding technique. The network architecture proposed in this study can be applied in valuation practices where categorical data are abundant. In addition, the interpretation of the resultant embedding layers can enhance the explainability of the deep learning approach, promoting its rapid adoption in the real estate industry. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.","Categorical data; Entity embedding; Explainability; Neural network; Real estate valuation","artificial neural network; economic analysis; estimation method; housing market; housing project; land market; performance assessment; price determination; price dynamics; property market; valuation; Kyonggi; South Korea"
"Lee D.-S., Lee T.-G., Bae Y.-S., Park Y.-S.","Occurrence Prediction of Western Conifer Seed Bug (Leptoglossus occidentalis: Coreidae) and Evaluation of the Effects of Climate Change on Its Distribution in South Korea Using Machine Learning Methods","10.3390/f14010117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146820889&doi=10.3390%2ff14010117&partnerID=40&md5=86feb993457c61780a7813f990b4028c","The western conifer seed bug (WCSB; Leptoglossus occidentalis) causes huge ecological and economic problems as an alien invasive species in forests. In this study, a species distribution model (SDM) was developed to evaluate the potential occurrence of the WCSBs and the effects of climate on WCSB distribution in South Korea. Based on WCSB occurrence and environmental data, including geographical and meteorological variables, SDMs were developed with maximum entropy (MaxEnt) and random forest (RF) algorithms, which are machine learning methods, and they showed good performance in predicting WCSB occurrence. On the potential distribution map of WCSBs developed by the model ensemble with integrated MaxEnt and RF models, the WCSB occurrence areas were mostly located at low altitudes, near roads, and in urban areas. Additionally, environmental factors associated with anthropogenic activities, such as roads and night lights, strongly influenced the occurrence and dispersal of WCSBs. Metropolitan cities and their vicinities in South Korea showed a high probability of WCSB occurrence. Furthermore, the occurrence of WCSBs in South Korea is predicted to intensify in the future owing to climate change. © 2023 by the authors.","alien species; global warming; invasive species; maximum entropy; random forest; species distribution model","Climate models; Forestry; Learning systems; Machine learning; Maximum entropy methods; Population distribution; Alien species; Conifer seeds; Ecological and economic; Ecological problem; Invasive species; Machine learning methods; Maximum-entropy; Random forests; South Korea; Species distribution modeling; Global warming; Distribution; Forestry; Korea; Machinery; Methods; Roads; Seeds"
"Lee I., Shin Y.J.","Machine learning for enterprises: Applications, algorithm selection, and challenges","10.1016/j.bushor.2019.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075904823&doi=10.1016%2fj.bushor.2019.10.005&partnerID=40&md5=575a51fc46668d299b7e907d4565f652","Machine learning holds great promise for lowering product and service costs, speeding up business processes, and serving customers better. It is recognized as one of the most important application areas in this era of unprecedented technological development, and its adoption is gaining momentum across almost all industries. In view of this, we offer a brief discussion of categories of machine learning and then present three types of machine-learning usage at enterprises. We then discuss the trade-off between the accuracy and interpretability of machine-learning algorithms, a crucial consideration in selecting the right algorithm for the task at hand. We next outline three cases of machine-learning development in financial services. Finally, we discuss challenges all managers must confront in deploying machine-learning applications. © 2019 Kelley School of Business, Indiana University","Artificial intelligence; Big data; Chatbot; Deep learning; Innovation capability; Machine learning; Neural networks; Resources and capabilities",
"Leon-Garza H., Hagras H., Pena-Rios A., Conway A., Owusu G.","A big bang-big crunch type-2 fuzzy logic system for explainable semantic segmentation of trees in satellite images using HSV color space","10.1109/FUZZ48607.2020.9177611","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090497470&doi=10.1109%2fFUZZ48607.2020.9177611&partnerID=40&md5=c236224c68787ab2a27fa8d971ec93a8","In recent years, new sensor technologies have increased the accessibility of high-resolution satellite images. The information in these images can help to improve activities like urban planning and growth analysis of cities. Additionally, information extracted from these images can be used for taking decisions related to infrastructure planning, e.g. identifying objects that might interfere with network assets like underground cables. To be able to justify the cost of network planning decisions a high degree of interpretability is required. Convolutional Neural Networks (CNNs) are the state of the art for segmenting these images, but like any black box model they do not offer any explanation for their output. In this paper, we present an approach on how to use a Fuzzy Logic System (FLS) for performing explainable semantic segmentation of trees in satellite images. The FLS uses the HSV (hue, saturation, value) of the pixels as inputs and was optimized by using an evolutionary algorithm called Big Bang Big Crunch. The best configuration for the Interval Type-2 FLS has an Intersection over Union metric measure of 60.6%, which is close to the results obtained from neural network, however the proposed FLS provides interpretable outputs which is highly needed for the real-world operation especially in the telecommunication domain. © 2020 IEEE.","Explainable AI; Fuzzy Logic System; Interpretable models; Neural Networks; Satellite images; Semantic segmentation","Color image processing; Computer circuits; Convolutional neural networks; Evolutionary algorithms; Forestry; Fuzzy systems; Image enhancement; Image segmentation; Satellites; Semantics; Underground cables; Urban growth; Fuzzy logic system; High resolution satellite images; Infrastructure planning; Interval type-2 fls; Real world operations; Semantic segmentation; Sensor technologies; Type-2 fuzzy logic system; Fuzzy logic"
"Levering A., Marcos D., Tuia D.","On the relation between landscape beauty and land cover: A case study in the U.K. at Sentinel-2 resolution with interpretable AI","10.1016/j.isprsjprs.2021.04.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110476587&doi=10.1016%2fj.isprsjprs.2021.04.020&partnerID=40&md5=7f1ffc4b3e0d620e8fb1b3580bfee6b7","The environment where we live and recreate can have a significant effect on our well-being. More beautiful landscapes have considerable benefits to both health and quality of life. When we chose where to live or our next holiday destination, we do so according to some perception of the environment around us. In a way, we value nature and assign an ecosystem service to it. Landscape aesthetics, or scenicness, is one such service, which we consider in this paper as a collective perceived quality. We present a deep learning model called ScenicNet for the large-scale inventorisation of landscape scenicness from satellite imagery. We model scenicness with an interpretable deep learning model and learn a landscape beauty estimator based on crowdsourced scores derived from more than two hundred thousand landscape images in the United Kingdom. Our ScenicNet model learns the relationship between land cover types and scenicness by using land cover prediction as an interpretable intermediate task to scenicness regression. It predicts landscape scenicness and land cover from the Corine Land Cover product concurrently, without compromising the accuracy of either task. In addition, our proposed model is interpretable in the sense that it learns to express preferences for certain types of land covers in a manner that is easily understandable by an end-user. Our semantic bottleneck also allows us to further our understanding of crowd preferences for landscape aesthetics. © 2021 The Author(s)","Corine land cover; Deep learning; Interpretable AI; Landscape aesthetics; Sentinel-2","Deep learning; Ecosystems; Semantics; Case-studies; CORINE land cover; Deep learning; Interpretable AI; Land cover; Landscape esthetic; Learn+; Learning models; Sentinel-2; Well being; Satellite imagery; ecosystem service; land cover; landscape change; landscape ecology; perception; Sentinel; United Kingdom"
"Li C., He P., Peng W., Lü F., Du R., Zhang H.","Exploring available input variables for machine learning models to predict biogas production in industrial-scale biogas plants treating food waste","10.1016/j.jclepro.2022.135074","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141815689&doi=10.1016%2fj.jclepro.2022.135074&partnerID=40&md5=56fc617de823d372d1511ed4b89383f3","Anaerobic digestion (AD) of food waste (FW) has been widely used in China and shows great potential in both recovering renewable energy and reducing carbon emissions. Unfortunately, many digesters suffer from unexpected perturbations and low biogas production due to the specific characteristics of food waste. Modeling of AD is crucial to better understand the process and improve efficiency. In this study, five machine learning (ML) algorithms were used to build models to predict biogas production in an industrial-scale biogas plant treating FW. Three categories of routine monitoring indicators (feed amount, feedstock properties, and digester properties), individually or collectively, were used as the input variables. The results showed that the random forest (RF) model achieved the best performance with an average R2 of 0.74 when all the indicators were contained in the dataset. Feature importance analysis revealed that the significance descended in the order of feed amount (45.9%), digester properties (38.6%), and feedstock properties (15.4%). The performance of the predictive models degraded with lag time except for the RF model, which showed the potential to predict biogas production of the next day (R2 = 0.73). The study verified the feasibility of ML models in predicting biogas yield using routine monitoring data from industrial-scale biogas plants treating FW and suggested that the monitoring indicators and frequency be redesigned to build smarter ML predictive models and improve system efficiency. © 2022 Elsevier Ltd","Anaerobic digestion; Biogas plant operation; Machine learning; Online monitoring; Random forest","Biogas; Decision trees; E-learning; Feedstocks; Forecasting; Industrial plants; Machine learning; Random forests; Biogas plant operation; Biogas plants; Biogas production; Food waste; Industrial scale; Input variables; Machine-learning; Online monitoring; Plant operations; Random forests; Anaerobic digestion"
"Li H., Wu P., Zeng N., Liu Y., Alsaadi F.E.","A survey on parameter identification, state estimation and data analytics for lateral flow immunoassay: from systems science perspective","10.1080/00207721.2022.2083262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131695619&doi=10.1080%2f00207721.2022.2083262&partnerID=40&md5=c41223b205cb75977b309b1c1e784c66","Lateral flow immunoassay (LFIA), as a well-known point-of-care testing (POCT) technique, is of vital significance in a variety of application scenarios due to the advantages of convenience and high efficiency. With rapid development of computational intelligence (CI), algorithms have played an important role in enhancing LFIA performance, and it is necessary to summary how algorithms can assist LFIA improvement for providing experiences. However, most existing works on LFIA are from biochemical field which pay more attention to material and reagent. Therefore, in this paper, a systematical survey is proposed to review works on applying mathematical tools to promote LFIA development. Particularly, a novel two-level taxonomy is designed for a better inspection, including LFIA-oriented mathematical modelling, CI-assisted post-processing and quantification in LFIA, and each level is further subdivided for in-depth understanding. In addition, from a higher viewpoint, outlooks of jointly developing POCT with other state-of-the-art techniques are presented from perspectives of implementation principle, technical approach and algorithm application. Moreover, this survey aims to highlight that applying CI methods is competent for boosting POCT development, so as to raise attentions from more areas like information science, extend deeper researches and inspire more interdisciplinary works. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","computational intelligence (CI); Lateral flow immunoassay (LFIA); modelling; point-of-care testing (POCT)","Artificial intelligence; Computational efficiency; Data Analytics; Immunology; Well testing; Application scenario; Computational intelligence; Data analytics; Lateral flow immunoassay; Modeling; Parameters identification; Point-of-care testing; Testing technique; Surveys"
"Li J., Yang Y.","HM-YOLOv5: A fast and accurate network for defect detection of hot-pressed light guide plates","10.1016/j.engappai.2022.105529","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140918023&doi=10.1016%2fj.engappai.2022.105529&partnerID=40&md5=61d2b92e662ae8962ef5baccad46c035","Due to the complex texture background, uneven brightness, various defect sizes and types of hot-pressed light guide plate (LGP) images, the HM-YOLOv5 network for fast and accurate defect detection of hot-pressed LGPs is developed and evaluated in this paper. First, a hybrid attention module (HAM) is constructed by combining the spatial attention of the convolutional block attention module(CBAM) with the channel attention of the efficient channel attention network(ECA-Net), and is introduced behind each C3 module of the backbone network. HAM does not require dimensionality reduction processing, and can better fuse channel and spatial information to focus on defects targets. Therefore, the HAM can enhance the defect feature extraction ability of the network. Second, a multi-expansion convolution module (MCM) is constructed based on the pyramid structure of YOLOv5. MCM can improve the target receptive field, enrich contextual information, reduce loss of information during downsampling and improve the defect detection ability Finally, a self-built dataset is constructed by using the images of hot-pressed LGPs collected from industrial sites, and many experiments are performed using this database. Experimental results show that the mean average precision (mAP) of the network is 98.9%, especially for white point and dark line defects improved by 2.7% and 2.0% respectively, and that the detection speed can reach 417 frames per second(Fps). Compared with the mainstream surface defect detection algorithm, the accuracy and detection time are significantly improved. Moreover, the accuracy and real-time performance meet the industrial detection requirements. © 2022 Elsevier Ltd","Convolutional neural network; Defect detection; HM-YOLOv5; Hot-pressed LGP","Convolutional neural networks; Image enhancement; Light polarization; Plates (structural components); Surface defects; Textures; Back-bone network; Convolutional neural network; Defect detection; Defect size; Defect type; Efficient channels; HM-YOLOv5; Hot-pressed light guide plate; Light guide plate; Spatial attention; Convolution"
"Li J., Suvarna M., Li L., Pan L., Pérez-Ramírez J., Ok Y.S., Wang X.","A review of computational modeling techniques for wet waste valorization: Research trends and future perspectives","10.1016/j.jclepro.2022.133025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134567737&doi=10.1016%2fj.jclepro.2022.133025&partnerID=40&md5=0b015b7ffde59e57352e7d05e76e37f3","The conversion of wet waste (e.g., food waste, sewage sludge, and animal manure) into bioenergy is a promising strategy for sustainable energy generation and waste management. Although experimental efforts have driven waste conversion technologies (WCTs) to various degrees of maturity, computational modeling has equally contributed to this endeavor. This review focuses on the application of modeling techniques, including computational fluid dynamics (CFD), process simulation (PS), and machine learning (ML) on WCTs including anaerobic digestion, hydrothermal carbonization, gasification, pyrolysis and incineration. It addresses in a concise manner on how CFD models aid in understanding of the complex process and their molecular kinetics; while PS and ML models help in understanding the reaction kinetics, variable-response relationship, techno-economic assessment and sensitivity analysis. Relevant modeling approaches with their pros and cons are summarized and case studies are presented for each WCT. Moreover, a comparative evaluation among the three modeling techniques, along with their recent and ongoing developments are highlighted. Hybrid frameworks derived by combining mechanistic and ML models are proposed, which are expected to advance future wet waste valorization strategies for sustainable clean energy production and waste management. © 2022 Elsevier Ltd","Anaerobic fermentation; Computational fluid dynamics; Machine learning; Process modeling; Sustainable energy; Thermal conversion","Anaerobic digestion; Carbonization; Computation theory; Fertilizers; Machine learning; Manures; Reaction kinetics; Sensitivity analysis; Sewage sludge; Waste incineration; Anaerobic fermentation; Computational modelling; Conversion technology; Machine-learning; Modelling techniques; Process-models; Sustainable energy; Thermal conversion; Waste conversion; Waste valorizations; Computational fluid dynamics"
"Li J., Ji Y., Huang Z., Min X., Zhao D.","Data Discretized Representation based on Entity Feature Learning with BERT","10.1109/ICISCAE55891.2022.9927686","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142472921&doi=10.1109%2fICISCAE55891.2022.9927686&partnerID=40&md5=707158a610e00be5c82ad10cc31f0842","The discretized representation of medical data has always been a complex process and plays an important role in the field of intelligent healthcare. However, deep learning has rarely been used for the discretized representation of medical data. In this paper, a BERT representation learning method based on medical entity features is proposed, namely EF-BERT (Entity-Feature BERT). Specifically, the medical data was first pre-processed, including data refilling, data denoising, and uni-form mapping. Then, the Transformer encoder was exploited to extract the key entity features in the medical text. Finally, the BERT model with fused entity features was used to obtain the final patient representation and implement the discretization of medical data. Extensive experiments on a real-world dataset have shown that our model achieves significantly better performance than several classical methods on the classification tasks. © 2022 IEEE.","BERT; Discretized representation; Entity feature; Transformer encoder","Classification (of information); Learning systems; Signal encoding; BERT; Complex Processes; Data de-noising; Discretized representation; Entity feature; Feature learning; Key entity; Learning methods; Medical data; Transformer encoder; Deep learning"
"Li K., Huang G., Zhang X., Lu C., Wang S.","Temporal-Spatial changes of monthly vegetation growth and their driving forces in the ancient Yellow river irrigation system, China","10.1016/j.jconhyd.2021.103911","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118838135&doi=10.1016%2fj.jconhyd.2021.103911&partnerID=40&md5=5220fb84a19e2401b0ed58e9a30d809c","Irrigation systems play vital roles not only in food production but also in supporting ecosystems. Understanding how the ecosystem has evolved in response to human activities is crucial for sustainable food production, especially for arid and semi-arid regions. In this study, we examined the trends of vegetation growth on a monthly basis in the ancient Yellow River irrigation system in Ningxia, China. We used the leaf area index (LAI) to characterize the vegetation growth from 2007 to 2019. The LAI trends were associated with a series of driving forces, explaining the spatial and temporal change of vegetation growth. With the provision of the Wilks feature importance method, 2-month averaged air temperature and irrigation were identified as the two most important variables for monthly LAI simulation. Future climate projections based on the Regional Climate Model system (RegCM) suggested dryer and longer summers under the RCP 8.5 scenario. These changes will increase the crop water demand during the growing months. In the future, water conflict might be further intensified in May, in which the present irrigation water has already led to a decreased crop growth. Our findings demonstrated that the Mann Kendall monthly trend analysis could provide more helpful information for monitoring the vegetation growth than the trend analysis on a yearly and seasonal basis. © 2021 Elsevier B.V.","Leaf area index; Mann Kendall trend analysis; Reginal climate model projection; Stepwise clustered analysis","Crops; Ecosystems; Irrigation; Vegetation; Driving forces; Irrigation systems; Leaf Area Index; Mann kendall trend analyse; Mann-Kendall trends; Reginal climate model projection; Stepwise clustered analyse; Trend analysis; Vegetation growth; Yellow river; Climate models; water; climate modeling; cluster analysis; crop production; environmental change; growth rate; irrigation system; leaf area index; regional climate; spatiotemporal analysis; trend analysis; vegetation structure; air temperature; Article; China; climate change; crop; cropland; irrigation (agriculture); leaf area; plant growth; river; seasonal variation; simulation; spatiotemporal analysis; summer; trend study; vegetation; ecosystem; human; season; China; Yellow River; China; Climate Change; Ecosystem; Humans; Rivers; Seasons"
"Li P., Hao H., Zhang Z., Mao X., Xu J., Lv Y., Chen W., Ge D.","A field study to estimate heavy metal concentrations in a soil-rice system: Application of graph neural networks","10.1016/j.scitotenv.2022.155099","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128233182&doi=10.1016%2fj.scitotenv.2022.155099&partnerID=40&md5=f4322e1997daba2ecbefa0657dcb54c1","Accurate prediction of the concentration of heavy metals is of great significance for assessing the quality of agricultural products and reducing health risks. However, the complexity and interconnectivity of the farmland ecosystem restricts the improvement of the prediction accuracy of traditional methods. This research explored the application potential of graph neural network (GNN) technology, which can extract and learn information in large-scale networks in detail, in the field of heavy metal prediction for the first time. In this study, a heavy metal prediction model for rice, CoNet-GNN, was proposed with 17 environmental factors as input variables using the co-occurrence network and GNN. Experimental results using a dataset from a field study showed that the R2 of CoNet-GNN for predicting Cd, Pb, Cr, As, and Hg had outstanding values of 0.872, 0.711, 0.683, 0.489, and 0.824, respectively. Sensitivity analysis further indicated that CoNet-GNN had good stability and robustness. Compared with random forest, gradient boosting, and multilayer perceptron, CoNet-GNN made a remarkable improvement to the prediction accuracy of all studied heavy metals. Therefore, CoNet-GNN can effectively simulate the rich relationships and laws between various factors in the soil-rice system and effectively characterize the influence diffusion path. Furthermore, it provides new ideas for heavy metal prediction based on network research methods and expands the technical scope of heavy metal evaluation. © 2022","Concentration; Environmental factor; Graph neural network; Heavy metal; Prediction; Sensitivity analysis","Agricultural products; Decision trees; Graph neural networks; Health risks; Heavy metals; Risk assessment; Sensitivity analysis; Accurate prediction; Concentration; Environmental factors; Farmland ecosystem; Field studies; Graph neural networks; Heavy metal concentration; Interconnectivity; Prediction accuracy; System applications; Forecasting; artificial neural network; concentration (composition); estimation method; heavy metal; prediction; sensitivity analysis; soil pollution; heavy metal; China; ecosystem; environmental monitoring; Oryza; risk assessment; soil; soil pollutant; China; Ecosystem; Environmental Monitoring; Metals, Heavy; Neural Networks, Computer; Oryza; Risk Assessment; Soil; Soil Pollutants"
"Li P., Jing R., Shi X.","Apple Disease Recognition Based on Convolutional Neural Networks With Modified Softmax","10.3389/fpls.2022.820146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130405391&doi=10.3389%2ffpls.2022.820146&partnerID=40&md5=4ac8a644a0f47a1c45619b4053db552d","Accurate and rapid identification of apple diseases is the basis for preventing and treating the apple diseases, and is very significant for assessing disease disaster. Apple disease recognition from its diseased leaf images is one of the interesting research areas in computer and agriculture field. An apple disease recognition method is proposed based on modified convolutional neural networks (MCNN). In MCNN, Inception is introduced into MCNN, global average pooling (GAP) operator is employed instead of several fully connected layers to speedup training model, and modified Softmax classifier is used in the output layer to improve the recognition performance. The modified Softmax classifier uses the modified linear element as the activation function in the hidden layer and adds the local response normalization in MCNN to avoid the gradient disappearance problem effectively. A series of experiments are conducted on two kinds of apple disease image datasets. The results show the feasibility of the algorithm. Copyright © 2022 Li, Jing and Shi.","convolutional neural networks; crop disease recognition; disease module identification; modified convolutional neural networks; modified Softmax classifier",
"Li S., Du D., Wang J., Wei Z.","Application progress of intelligent flavor sensing system in the production process of fermented foods based on the flavor properties","10.1080/10408398.2022.2134982","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140211435&doi=10.1080%2f10408398.2022.2134982&partnerID=40&md5=2dff27ceee8417089e74eaed69c28c66","Fermented foods are sensitive to the production conditions because of microbial and enzymatic activities, which requires intelligent flavor sensing system (IFSS) to monitor and optimize the production process based on the flavor properties. As the simulation system of human olfaction and gustation, IFSS has been widely used in the field of food with the characteristics of nondestructive, pollution-free, and real-time detection. This paper reviews the application of IFSS in the control of fermentation, ripening, and shelf life, and the potential in the identification of quality differences and flavor-producing microbes in fermented foods. The survey found that electronic nose (tongue) is suitable to monitor fermentation process and identify food authenticity in real time based on the changes of flavor profile. Gas chromatography-ion mobility spectrometry and nuclear magnetic resonance technology can be used to analyze the flavor metabolism of fermented foods at various production stages and explore the correlation between flavor substances and microorganisms. © 2022 Taylor & Francis Group, LLC.","Electronic nose; electronic tongue; fermentation and ripening control; flavor-producing microorganisms; gas chromatography-ion mobility spectrometry; nuclear magnetic resonance; shelf life and authenticity evaluation","Authentication; Electronic nose; Electronic tongues; Fermentation; Gas chromatography; Ion mobility spectrometers; Microorganisms; Quality control; Spectrometry; Fermentation and ripening control; Fermented foods; Flavor-producing microorganism; Gas chromatography-ion mobility spectrometry; Ion mobility spectrometry; Production process; Property; Sensing systems; Shelf life; Shelf life and authenticity evaluation; Nuclear magnetic resonance"
"Li W., Ye X., Du X.","Imputation of Ammonium Nitrogen Concentration in Groundwater Based on a Machine Learning Method","10.3390/w14101595","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130733139&doi=10.3390%2fw14101595&partnerID=40&md5=2b815cae04e018765e99671fb2ebd64f","Ammonium is one of the main inorganic pollutants in groundwater, mainly due to agri-cultural, industrial and domestic pollution. Excessive ammonium can cause human health risks and environmental consequences. Its temporal and spatial distribution is affected by factors such as meteorology, hydrology, hydrogeology and land use type. Thus, a groundwater ammonium analysis based on limited sampling points produces large uncertainties. In this study, organic matter content, groundwater depth, clay thickness, total nitrogen content (TN), cation exchange capacity (CEC), pH and land-use type were selected as potential contributing factors to establish a machine learning model for fitting the ammonium concentration. The Shapley Additive exPlanations (SHAP) method, which explains the machine learning model, was applied to identify the more significant influencing factors. Finally, the machine learning model established according to the more significant influencing factors was used to impute point data in the study area. From the results, the soil organic matter feature was found to have a substantial impact on the concentration of ammonium in the model, followed by soil pH, clay thickness and groundwater depth. The ammonium concentration generally decreased from northwest to southeast. The highest values were concentrated in the northwest and northeast. The lowest values were concentrated in the southeast, southwest and parts of the east and north. The spatial interpolation based on the machine learning imputation model established according to the influencing factors provides a reliable groundwater quality assessment and was not limited by the number and the geographical location of samplings. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","ammonium nitrogen; machine learning; random forest; SHAP; spatial interpolation","Biogeochemistry; Decision trees; Groundwater pollution; Groundwater resources; Health risks; Hydrogeology; Interpolation; Land use; Machine learning; Nitrogen; Organic compounds; Uncertainty analysis; Water quality; Ammonium concentrations; Ground water depths; Inorganic pollutants; Land use type; Machine learning methods; Machine learning models; Random forests; Shapley; Shapley additive explanation; Spatial interpolation; Groundwater; algorithm; ammonium; concentration (composition); groundwater; groundwater pollution; hydrogeology; interpolation; machine learning; nitrogen"
"Li X., Zhang Z., Xu D., Wu C., Li J., Zheng Y.","A prediction method for animal-derived drug resistance trend using a grey-bp neural network combination model","10.3390/antibiotics10060692","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108435167&doi=10.3390%2fantibiotics10060692&partnerID=40&md5=390a8b33d4e80ff02af26c8a5e25a503","There is an increasing drug resistance of animal-derived pathogens, seriously posing a huge threat to the health of animals and humans. Traditional drug resistance testing methods are expensive, have low efficiency, and are time-consuming, making it difficult to evaluate overall drug resistance. To develop a better approach to detect drug resistance, a small sample of Escherichia coli resistance data from 2003 to 2014 in Chengdu, Sichuan Province was used, and multiple regression interpolation was applied to impute missing data based on the time series. Next, cluster analysis was used to classify anti-E. coli drugs. According to the classification results, a GM(1,1)-BP model was selected to analyze the changes in the drug resistance of E. coli, and a drug resistance prediction system was constructed based on the GM(1,1)-BP Neural Network model. The GM(1,1)-BP Neural Network model showed a good prediction effect using a small sample of drug resistance data, with a determination coefficient R2 of 0.7830 and an RMSE of only 0.0527. This model can be applied for the prediction of drug resistance trends of other animal-derived pathogenic bacteria, and provides the scientific and technical means for the effective assessment of bacterial resistance. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","BP neural network; Drug resistance; GM(1,1)-BP neural network model; Grey system; Microbial","doxycycline; enrofloxacin; gentamicin; ofloxacin; sulfafurazole; tetracycline; animal experiment; animal model; antibiotic resistance; Article; artificial neural network; back propagation neural network; cluster analysis; drug design; Escherichia coli; mathematical parameters; multiple regression; nerve cell network; nonhuman; prediction"
"Liang B., Li X., Zhang Z., Wu C., Liu X., Zheng Y.","Multidrug resistance analysis method for pathogens of cow mastitis based on weighted-association rule mining and similarity comparison","10.1016/j.compag.2021.106411","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114122369&doi=10.1016%2fj.compag.2021.106411&partnerID=40&md5=4bf446cb0a81ab23f1b77ae145a0c19d","Mastitis is one of the most common diseases and causes the greatest economic loss in dairy farming. Antibiotics are the most effective drugs to prevent and treat bacterial infection of mastitis. However, yet the growing problem of drug resistance, especially multidrug resistance (MDR), poses a great threat to disease control. To understand the MDR rules in bacteria of cow mastitis from national level, the main bacteria from cows with mastitis in large-scale farms were isolated and identified in China, and then drug sensitivity tests were conducted to establish a drug resistance data set. Aiming at the problem of numerous and disordered drug resistance data and lack of extensive correlations, a weighted Apriori association rule mining algorithm in conjunction with the bacterial drug resistance prevalence is proposed. We analyzed the associations between different antibiotics of key bacteria, extracted and visualized the key trends of high resistance prevalence and frequent occurrence, and discovered MDR patterns. Finally, a similarity comparison method based on Euclidean measurement was proposed to compare the relative MDR rules of different bacteria from the overall level with support, confidence, and promotion as characteristic parameters. The drug resistance data set showed that staphylococcus were the main bacteria isolated from dairy cow mastitis in China. Then based on the association rule algorithm, the important rules between different antibiotics resistance in this dataset were identified. In addition, the MDR patterns of different bacteria were visualized and analyzed by using the chord diagram. The results showed the bacteria are highly resistant to penicillin, gentamicin, and ampicillin, and most other antibiotics were linked with these three antibiotics. Finally, the high correlations and main rules in different bacteria were confirmed by a similarity comparison method. The assessment model and conclusions of this study are potentially valuable for assessing the evolution of MDR patterns, providing a scientific basis for relevant authorities to guide the rational use of antibiotics in the farming industry. © 2021 Elsevier B.V.","Cow mastitis; Drug resistance; Multidrug resistance; Similarity analysis; Weighted association rule mining","Antibiotics; Association rules; Data mining; Disease control; Diseases; Losses; Statistical tests; Analysis method; Comparison methods; Cow mastiti; Data set; Drug-resistance; Multidrug resistance; Resistance analysis; Similarity analysis; Weighted association rule mining; Weighted association rules; Bacteria; algorithm; antibiotics; dairy farming; data set; disease; drug; drug resistance; pathogen; China; Bacteria (microorganisms); Staphylococcus"
"Liao T., Yang R., Zhao P., Zhou W., He M., Li L.","MDAM-DRNet: Dual Channel Residual Network With Multi-Directional Attention Mechanism in Strawberry Leaf Diseases Detection","10.3389/fpls.2022.869524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134504582&doi=10.3389%2ffpls.2022.869524&partnerID=40&md5=427eef72223a43d3fcbca2093f2e1db9","The growth of strawberry plants is affected by a variety of strawberry leaf diseases. Yet, due to the complexity of these diseases' spots in terms of color and texture, their manual identification requires much time and energy. Developing a more efficient identification method could be imperative for improving the yield and quality of strawberry crops. To that end, here we proposed a detection framework for strawberry leaf diseases based on a dual-channel residual network with a multi-directional attention mechanism (MDAM-DRNet). (1) In order to fully extract the color features from images of diseased strawberry leaves, this paper constructed a color feature path at the front end of the network. The color feature information in the image was then extracted mainly through a color correlogram. (2) Likewise, to fully extract the texture features from images, a texture feature path at the front end of the network was built; it mainly extracts texture feature information by using an area compensation rotation invariant local binary pattern (ACRI-LBP). (3) To enhance the model's ability to extract detailed features, for the main frame, this paper proposed a multidirectional attention mechanism (MDAM). This MDAM can allocate weights in the horizontal, vertical, and diagonal directions, thereby reducing the loss of feature information. Finally, in order to solve the problems of gradient disappearance in the network, the ELU activation function was used in the main frame. Experiments were then carried out using a database we compiled. According to the results, the highest recognition accuracy by the network used in this paper for six types of strawberry leaf diseases and normal leaves is 95.79%, with an F1 score of 95.77%. This proves the introduced method is effective at detecting strawberry leaf diseases. Copyright © 2022 Liao, Yang, Zhao, Zhou, He and Li.","color feature path; detection of strawberry leaf diseases; ELU; multidirectional attention mechanism; multidirectional attention mechanism dual channel residual network; texture feature path",
"Lin C.-W., Huang X., Lin M., Hong S.","SF-CNN: Signal Filtering Convolutional Neural Network for Precipitation Intensity Estimation","10.3390/s22020551","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122707004&doi=10.3390%2fs22020551&partnerID=40&md5=c682e1fc190ca722a451fd4e968e77e0","Precipitation intensity estimation is a critical issue in the analysis of weather conditions. Most existing approaches focus on building complex models to extract rain streaks. However, an efficient approach to estimate the precipitation intensity from surveillance cameras is still challenging. This study proposes a convolutional neural network known as the signal filtering convolutional neural network (SF-CNN) to handle precipitation intensity using surveillance-based images. The SF-CNN has two main blocks, the signal filtering block (SF block) and the gradually decreasing dimension block (GDD block), to extract features for the precipitation intensity estimation. The SF block with the filtering operation is constructed in different parts of the SF-CNN to remove the noise from the features containing rain streak information. The GDD block continuously takes the pair of the convolutional operation with the activation function to reduce the dimension of features. Our main contributions are (1) an SF block considering the signal filtering process and effectively removing the useless signals and (2) a procedure of gradually decreasing the dimension of the feature able to learn and reserve the information of features. Experiments on the self-collected dataset, consisting of 9394 raining images with six precipitation intensity levels, demonstrate the proposed approach’s effectiveness against the popular convolutional neural networks. To the best of our knowledge, the self-collected dataset is the largest dataset for monitoring infrared images of precipitation intensity. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Dimensional reduction; Precipitation intensity; Signal filtering","Convolutional neural networks; Information filtering; Infrared imaging; Median filters; Rain; Security systems; Building complexes; Complex model; Convolutional neural network; Critical issues; Dimensional reduction; Filtering operations; Intensity estimation; Precipitation intensity; Signal filtering; Surveillance cameras; Convolution; learning; Learning; Neural Networks, Computer"
"Lin J., Chen Y., Pan R., Cao T., Cai J., Yu D., Chi X., Cernava T., Zhang X., Chen X.","CAMFFNet: A novel convolutional neural network model for tobacco disease image recognition","10.1016/j.compag.2022.107390","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138454681&doi=10.1016%2fj.compag.2022.107390&partnerID=40&md5=5270117d9153ce23ae955ded1ccad288","For image classification of crops, most convolutional neural network (CNN) models have low accuracy, especially in modern agricultural environments. Furthermore, crop disease images create more difficulties for classification owing to the morphological and physiological changes of organs, tissues, and cells. Here, we propose a CNN model named CAMFFNet (coordinate attention-based multiple feature fusion network) for tobacco disease identification under field conditions. The CAMFFNet model has three multiple feature fusion (MFF) modules. Each module is composed of two residual blocks. The MFF module is concatenated by max-pooling downsampling layers at different locations in the residual blocks to realize a fusion between features of multiple depths, thereby reducing the loss of tobacco disease information. Furthermore, to enhance the ability to extract effective feature information of tobacco diseases and to alleviate the impact of the field environment, coordinate attention (CA) modules are included between each multiple feature fusion module. The obtained results show that the CAMFFNet model achieved an accuracy of 89.71 % on the tobacco disease test set. The accuracy was 3.36 %, 4.7 %, 4.7 %, 2.91 %, 8.05 %, 4.92 %, 10.07 %, and 2.91 % higher than those of the classic CNN models VGG16, GoogLeNet, DenseNet121, ResNet34, MobbileNetV2, MobbileNetV3 Large, ShuffleNetV2 1.0×, and EfficientNetV2 Small, respectively. In addition, the CAMFFNet model's number of parameters is only 2.37 million. The results demonstrate that the CAMFFNet model has a high potential for tobacco disease recognition in mobile and embedded devices. © 2022 Elsevier B.V.","Convolutional neural network; Coordinate attention; Multiple feature fusion module; Tobacco disease image recognition","Convolution; Convolutional neural networks; Crops; Image classification; Neural network models; Tobacco; Agricultural environments; Convolutional neural network; Coordinate attention; Fusion modules; Images classification; Multiple feature fusion; Multiple feature fusion module; Network models; Neural network model; Tobacco disease image recognition; Image recognition; artificial neural network; coordinate; image classification; numerical model; pattern recognition; tobacco"
"Lin M., Chen J., Wu D., Chen K.","Volatile Profile and Biosynthesis of Post-harvest Apples are Affected by the Mechanical Damage","10.1021/acs.jafc.1c03532","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113840044&doi=10.1021%2facs.jafc.1c03532&partnerID=40&md5=c23923282d18369b56e9679a4e2ea58d","Mechanical damage to fruit causes flavor changes during post-harvest supply chains. It is important to identify the main volatiles and explore their biosynthesis mechanism. In this study, the volatile changes in apples caused by mechanical damage were analyzed by gas chromatography-ion mobility spectrometry. Hexanal and ethyl acetate were accumulated and identified as potential volatile biomarkers to detect damaged apples. The study on the lipoxygenase (LOX) pathway and transcription factors (TFs) shows that mechanical damage up-regulated the expression of MdLOX-like, MdLOX3b, MdLOX7b, MdLOX7c, MdLOX2a, and MdAAT in the LOX pathway and that of one MYB TF (MdMYB-like), five ERF TFs (MdERF073, MdERF003, MdERF114, MdERF15, and MdERF2), and five WRKY TFs (MdWRKY23, MdWRKY17, MdWRKY46, MdWRKY48, and MdWRKY71). Notably, MdAAT was significantly correlated to MdMYB-like, MdWRKY23, MdWRKY71, MdERF15, and MdERF2. Thus, TFs may attribute to the accumulation of hexanal and ethyl acetate by regulating the expression of LOX pathway-related genes. © 2021 American Chemical Society.","apple; gene expression; lipoxygenase pathway; mechanical damage; transcription factor; volatile","Biochemistry; Biosynthesis; Gas chromatography; Ion chromatography; Supply chains; Transcription; Volatile fatty acids; Biosynthesis mechanism; Ethyl acetates; Hexanal; Ion mobility spectrometry; Lipoxygenase pathways; Mechanical damages; Post harvest; Volatile profile; Fruits; transcription factor; volatile organic compound; chemistry; fruit; genetics; Malus; mass fragmentography; Fruit; Gas Chromatography-Mass Spectrometry; Malus; Transcription Factors; Volatile Organic Compounds"
"Lin Y.-C., Chen T.-C.T.","Type-II fuzzy approach with explainable artificial intelligence for nature-based leisure travel destination selection amid the COVID-19 pandemic","10.1177/20552076221106322","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132280800&doi=10.1177%2f20552076221106322&partnerID=40&md5=ea63335859bc4cf81b918c38df1c83e6","During the coronavirus disease 2019 (COVID-19) pandemic, it is difficult for travelers to choose suitable nature-based leisure travel destinations because many factors are related to health risks and are highly uncertain. This research proposes a type-II fuzzy approach with explainable artificial intelligence to overcome this difficulty. First, an innovative type-II alpha-cut operations fuzzy collaborative intelligence method was used to derive the fuzzy priorities of factors critical for nature-based leisure travel destination selection. Subsequently, a type-II fuzzy Vise Kriterijumska Optimizacija I Kompromisno Resenje method, which is also novel, was employed to evaluate and compare the overall performance of nature-based leisure travel destinations. Furthermore, several measures were taken to enhance the explainability of the selection process and result. The effectiveness of the proposed type-II fuzzy approach was evaluated in a regional experiment conducted in Taichung City, Taiwan, during the COVID-19 pandemic. © The Author(s) 2022.","alpha-cut operations; explainable artificial intelligence; fuzzy collaborative intelligence; fuzzy Vise Kriterijumska Optimizacija I Kompromisno Resenje; Leisure travel destination; nature-based tourism",
"Lippmann R.","Understanding and Applying Deep Learning","10.1162/neco_a_01518","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138710115&doi=10.1162%2fneco_a_01518&partnerID=40&md5=5a179ed7270a5226deae12acfe30a0bd","The past 10 years have witnessed an explosion in deep learning neural network model development. The most common perceptual models with vision, speech, and text inputs are not general-purpose AI systems but tools. They automatically extract clues from inputs and compute probabilities of class labels. Successful applications require representative training data, an understanding of the limitations and capabilities of deep learning, and careful attention to a complex development process. The goal of this view is to foster an intuitive understanding of convolu-tional network deep learning models and how to use them with the goal of engaging a wider creative community. A focus is to make it possible for experts in areas such as health, education, poverty, and agriculture to understand the process of deep learning model development so they can help transition effective solutions to practice. © 2022 Massachusetts Institute of Technology.",,"Deep learning; Learning systems; AI systems; Class labels; Learning models; Learning neural networks; Model development; Neural network model; Perceptual modelling; Speech input; Text input; Training data; Neural network models"
"Lisha L., Mousa S., Arnone G., Muda I., Huerta-Soto R., Shiming Z.","Natural resources, green innovation, fintech, and sustainability: A fresh insight from BRICS","10.1016/j.resourpol.2022.103119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143989904&doi=10.1016%2fj.resourpol.2022.103119&partnerID=40&md5=38e0b4cab9ca647fd7a0ab825b023daf","Since the industrial revolution, the financial sector has become a significant claimant toward the growth of human society. However, supporting the adverse environmental projects in financial terms has raised several queries about creating a direct linkage between financial market products and the environment.This research examines the nexus between sustainability, green innovations, financial technologies (FinTech), financial development, and natural resources for BRICS economies during 2000–2019. Using the Method of Moments Quantile Regression (MMQR), the results show that FinTech and natural resources adversely impact environmental sustainability across all three ranges of quantiles (0.10th-0.30th, 0.40th-0.60, and 0.70th-0.90th).Conversely, green innovations and financial development promote environmental sustainability across lower to higher-order quantiles (0.10th-0.90th), while economic growth contributes to higher emissions at major quantiles. Similar findings are endorsed using alternative estimators and suggest practical policy implications. © 2022 Elsevier Ltd","BRICS; Fintech; Green innovations; Natural resource; Sustainability","Economics; Finance; Method of moments; Public policy; BRICS; Environmental projects; Environmental sustainability; Financial development; Financial sectors; Green innovations; Human society; Industrial revolutions; Market products; Quantile regression; Sustainable development; economic growth; finance; innovation; natural resource; regression analysis; sustainability; Brazil; China; India; Russian Federation; South Africa"
"Liu B., Huang H., Su Y., Chen S., Li Z., Chen E., Tian X.","Tree Species Classification Using Ground-Based LiDAR Data by Various Point Cloud Deep Learning Methods","10.3390/rs14225733","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142769284&doi=10.3390%2frs14225733&partnerID=40&md5=54bfd61a5d31919f4637544fe813fe63","Tree species information is an important factor in forest resource surveys, and light detection and ranging (LiDAR), as a new technical tool for forest resource surveys, can quickly obtain the 3D structural information of trees. In particular, the rapid and accurate classification and identification of tree species information from individual tree point clouds using deep learning methods is a new development direction for LiDAR technology in forest applications. In this study, mobile laser scanning (MLS) data collected in the field are first pre-processed to extract individual tree point clouds. Two downsampling methods, non-uniform grid and farthest point sampling, are combined to process the point cloud data, and the obtained sample data are more conducive to the deep learning model for extracting classification features. Finally, four different types of point cloud deep learning models, including pointwise multi-layer perceptron (MLP) (PointNet, PointNet++, PointMLP), convolution-based (PointConv), graph-based (DGCNN), and attention-based (PCT) models, are used to classify and identify the individual tree point clouds of eight tree species. The results show that the classification accuracy of all models (except for PointNet) exceeded 0.90, where the PointConv model achieved the highest classification accuracy for tree species classification. The streamlined PointMLP model can still achieve high classification accuracy, while the PCT model did not achieve good accuracy in the tree species classification experiment, likely due to the small sample size. We compare the training process and final classification accuracy of the different types of point cloud deep learning models in tree species classification experiments, further demonstrating the advantages of deep learning techniques in tree species recognition and providing experimental reference for related research and technological development. © 2022 by the authors.","attention; convolution; graph; multi-layer perceptron; point cloud deep learning; transformer; tree species classification","Classification (of information); Data mining; Deep learning; Forestry; Graphic methods; Learning systems; Optical radar; Surveys; Attention; Classification accuracy; Graph; Multilayers perceptrons; Point cloud deep learning; Point-clouds; Species classification; Transformer; Tree species; Tree species classification; Convolution"
"Liu C.-F., Chen Z.-C., Kuo S.-C., Lin T.-C.","Does AI explainability affect physicians’ intention to use AI?","10.1016/j.ijmedinf.2022.104884","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139591826&doi=10.1016%2fj.ijmedinf.2022.104884&partnerID=40&md5=9434f13457690a4e410fe6599086a674","Background: Artificial Intelligence (AI) is increasingly being developed to support clinical decisions for better health service quality, but the adoption of AI in hospitals is not as popular as expected. A possible reason is that the unclear AI explainability (XAI) affects the physicians' consideration of adopting the model. Purpose: To propose and validate an innovative conceptual model aimed at exploring physicians’ intention to use AI with XAI as an antecedent variable of technology trust (TT) and perceived value (PV). Methods: A questionnaire survey was conducted to collect data from physicians of three hospitals in Taiwan. Structural equation modeling (SEM) was used to validate the proposed model and test the hypotheses. Results: A total of 295 valid questionnaires were collected. The research results showed that physicians expressed a high intention to use AI. The XAI was found to be of great importance and had a significant impact both on AI TT and PV. We also observed that TT in AI had a significant impact on PV. Moreover, physicians' PV and TT in AI had a significant impact on their behavioral intention to use AI (BI). However, XAI's impact on BI cannot be proved. Conclusions: The conceptual model developed in this study provides empirical evidence that could be used as guidelines to effectively explore physicians’ intention to use medical AI from the antecedent of XAI. Our findings contribute crucial AI-human interaction insights in health care studies. © 2022 Elsevier B.V.","AI explainability (XAI); Artificial intelligence (AI); Behavioral intention; Perceived value; Physician; Technology trust","Hospitals; Surveys; Artificial intelligence; Artificial intelligence explainability (XAI); Behavioral intention; Clinical decision; Conceptual model; Intention to use; Perceived value; Physician; Technology trusts; Trust values; Artificial intelligence; article; artificial intelligence; conceptual model; human; human experiment; multicenter study; physician; practice guideline; questionnaire; structural equation modeling; Taiwan; trust; behavior; health personnel attitude; Artificial Intelligence; Attitude of Health Personnel; Humans; Intention; Physicians; Surveys and Questionnaires"
"Liu H., Jin Y., Roche L.M., O’Geen A.T., Dahlgren R.A.","Regional differences in the response of California’s rangeland production to climate and future projection","10.1088/1748-9326/aca689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145660462&doi=10.1088%2f1748-9326%2faca689&partnerID=40&md5=a49ad33e2d74b1da8baef4bca2f990d9","Rangelands support many important ecosystem services and are highly sensitive to climate change. Understanding temporal dynamics in rangeland gross primary production (GPP) and how it may change under projected future climate, including more frequent and severe droughts, is critical for ranching communities to cope with future changes. Herein, we examined how climate regulates the interannual variability of GPP in California’s diverse annual rangeland, based on the contemporary records of satellite derived GPP at 500 m resolution since 2001. We built Gradient Boosted Regression Tree models for 23 ecoregion subsections, relating annual GPP with 30 climatic variables, to disentangle the partial dependence of GPP on each climate variable. The machine learning results showed that GPP was most sensitive to growing season (GS) precipitation, with a reduction in GPP up to 200 g cm−2 yr−1 when GS precipitation decreased from 400 to 100 mm yr−1 in one of the driest subsections. We also found that years with more evenly distributed GS precipitation had higher GPP. Warmer winter minimum air temperature enhanced GPP in approximately two-thirds of the subsections. In contrast, average GS air temperatures showed a negative relationship with annual GPP. When the pre-trained models were forced by downscaled future climate projections, changes in the predicted rangeland productivity by mid- and end of century were more remarkable at the ecoregion subsection scale than at the state level. Our machine learning-based analysis highlights key regional differences in GPP vulnerability to climate and provides insights on the intertwining and potentially counteracting effects of seasonal temperature and precipitation regimes. This work demonstrates the potential of using remote sensing to enhance field-based rangeland monitoring and, combined with machine learning, to inform adaptive management and conservation within the context of weather extremes and climate change. © 2022 The Author(s). Published by IOP Publishing Ltd.","climate change; ecosystem productivity; GCM; Gradient Boosted Regression Trees; machine learning; rangelands; remote sensing","Atmospheric temperature; Climate change; Climate models; Ecosystems; Machine learning; Regression analysis; Boosted regression trees; Ecosystem productivity; GCM; Gradient boosted regression tree; Gross primary production; Growing season; Machine-learning; Rangeland; Remote-sensing; Season precipitation; Remote sensing; climate change; ecosystem service; future prospect; general circulation model; machine learning; net ecosystem production; primary production; rangeland; regression analysis; remote sensing; satellite altimetry; California; United States"
"Liu H., Wen J., Xu Y., Wu J., Yu Y., Yang J., Liu H., Fu M.","Evaluation of dynamic changes and formation regularity in volatile flavor compounds in Citrus reticulata ‘chachi’ peel at different collection periods using gas chromatography-ion mobility spectrometry","10.1016/j.lwt.2022.114126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140888271&doi=10.1016%2fj.lwt.2022.114126&partnerID=40&md5=175ff2ce30fde016ec79fe22ed3cafff","Citrus reticulata ‘Chachi’ is a commercially important and predominantly cultivated tangerine cultivar in Xinhui County, Guangdong, China. The dried C. reticulata ‘Chachi’ pericarp (CRCP), known as “Guangchenpi” in Mandarin has unique flavor properties, and has been used as a highly valuable nutritional food source and in traditional medicine for centuries. In this study, headspace-gas chromatography-ion mobility spectrometry (HS-GC-IMS) and partial least squares-discriminant analysis (PLS-DA) were adopted to rapidly and comprehensively evaluate the flavor compounds of dried CRCP, and to identify their dynamic changes at different fruit picking stages. Results revealed a total of 71 volatile compound in the samples at six different fruit picking stages. The C6–C9 alcohols and aldehydes with aromatic green grass profiles had higher concentrations in the early fruit picking stages (from July to October), while most terpenes, ketones, and esters with typical aromas of mature flowers and fruits were highly accumulated in the late fruit picking stages (from November to December). PLS-DA results showed that samples picked in different stages could effectively be divided into relatively independent clusters, and the variable importance in projection (VIP) models identified 12 representative flavor compounds, which could be used as flavor markers for distinguishing CRCP samples picked at different stages. © 2022 The Authors","Different collection periods; Dried Citrus reticulata ‘Chachi’ pericarp; Gas chromatography−ion mobility spectrometry; Partial least squares discriminant analysis; Variable importance in the projection","Citrus fruits; Discriminant analysis; Electronic nose; Flavor compounds; Ion mobility spectrometers; Ketones; Least squares approximations; Odors; Spectrometry; Different collection period; Different stages; Dried citrus reticulata ‘chachi’ pericarp; Dynamic changes; Gas chromatography−ion mobility spectrometry; Ion mobility spectrometry; Partial least squares discriminant analyses (PLSDA); Variable importance in the projection; Variable importances; Volatile flavor compounds; Gas chromatography"
"Liu H., Jin Y., Roche L.M., O'Geen A.T., Dahlgren R.A.","Understanding spatial variability of forage production in California grasslands: Delineating climate, topography and soil controls","10.1088/1748-9326/abc64d","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100118352&doi=10.1088%2f1748-9326%2fabc64d&partnerID=40&md5=b6777dcd589e7914c0bc104bdc908b43","Rangelands are a key global resource, providing a broad range of ecological services and economic benefits. California's predominantly annual rangelands cover ∼12% of the state's land area, and the forage production is highly heterogeneous, making balancing economic (grazing), conservation (habitat) and environmental (erosion/water quality) objectives a big challenge. Herein, we examined how climate and environmental factors regulate annual grassland forage production spatially across the state and among four ecoregions using machine learning models. We estimated annual forage production at 30 m resolution over a 14 year period (2004-2017) using satellite images and data fusion techniques. Our satellite-based estimation agreed well with independent field measurements, with a R2 of 0.83 and RMSE of 682 kg ha-1. Forage production (14 year average) showed large spatial variability (2940 ± 934 kg ha-1 yr-1; CV = 35%) across the study area. The gradient boosted regression tree with 11 feature variables explained 67% of the variability in forage production across the state. Precipitation amount, especially in November (germination) and April (rapid growth), was found as the dominant driver for spatial variation in forage production, especially in drier ecoregions and during drier years. Seasonal distribution of precipitation and minimum air temperature showed a relatively stronger control on forage production in wetter regions and during wet years. Additionally, solar energy became more important in wetter ecoregions. Drought reduced forage production from the long-term mean, i.e. a 33% ± 19% decrease in production (2397 ± 926 kg ha-1yr-1; CV = 38%) resulting from a 29% ± 5% decrease in precipitation. The machine learning based spatial analysis using 'big data' provided insights on impacts of climate and environmental factors on forage production variation at various scales. This study demonstrates a cost-effective approach for rapid mapping and assessment of annual forage production with the potential for near real-time application. © 2021 The Author(s).","Data fusion; Ecosystem productivity; Gradient boosted regression trees; Rangelands; Remote sensing; Spatial variability","Balancing; Cost effectiveness; Data fusion; Machine learning; Solar energy; Topography; Boosted regression trees; Cost-effective approach; Data fusion technique; Ecological services; Environmental factors; Machine learning models; Seasonal distributions; Spatial variability; Climate models; climate change; crop production; forage; grassland soil; spatial variation; topography; California; United States"
"Liu L., Zhan X.","Analysis of Financing Efficiency of Chinese Agricultural Listed Companies Based on Machine Learning","10.1155/2019/9190273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071103285&doi=10.1155%2f2019%2f9190273&partnerID=40&md5=6671acfb6c3ff9807b6a8a07480bceec","Agricultural enterprises play a significant role in China's economic development. However, compared with other enterprises, agricultural enterprises are facing serious financial problems. Financing difficulty is essentially a question of financing efficiency. Based on the DEA method, this paper evaluates the financing efficiency of 39 agricultural listed companies in China from 2013 to 2017. The results suggest that the financing efficiency is generally low, and the Total Factor Productivity of agricultural enterprises' financing has a tendency to decrease first and then increase. The influencing factors of financing efficiency are analyzed using the Tobit regression model and the random forest regression model. And we find the following: (1) The random forest regression model significantly outperformed the Tobit regression model, with determination coefficients (R2) greater than 0.9 in full sample sets. (2) Total liability, financial expenses, return on total assets, and inventory turnover rate are important factors affecting financing efficiency of agricultural listed companies. (3) Return on total assets and inventory turnover rate promote the financing efficiency, while total liability and financial expenses reduce financing efficiency. Finally, the paper makes some suggestions for the financing of agricultural enterprises. © 2019 Lixia Liu and Xueli Zhan.",,"Agriculture; Decision trees; Efficiency; Machine learning; Regression analysis; Agricultural enterprise; Determination coefficients; Economic development; Financial problems; Inventory turnover; Regression model; Tobit regression; Total factor productivity; Finance"
"Liu P., Wen Y., Huang L., Zhu X., Wu R., Ai S., Xue T., Ge Y.","An emerging machine learning strategy for the assisted‐design of high-performance supercapacitor materials by mining the relationship between capacitance and structural features of porous carbon","10.1016/j.jelechem.2021.115684","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114790427&doi=10.1016%2fj.jelechem.2021.115684&partnerID=40&md5=b58b4a614bdfa08b30eacf25fd67a448","How to design high-performance materials by mining the relationship between properties and structure features of materials is a major challenge today. We developed a new strategy for the assisted‐design of high-performance supercapacitor materials by mining the relationship between capacitance and structural features of porous carbon materials (PCMs) using machine learning (ML) on the basis of hundreds of experimental data in the literature. Six ML models were selected to predict capacitance with the closely related structural features of PCMs. XGBoost demonstrates best predictive performance of supercapacitor (R = 0.892) among all ML models. The accurate predicted ability of the developed models could significantly reduce experiment workload for the assisted‐design of high-performance supercapacitor materials. Smicro/SSA, SSA, and PS provided more contribution to the capacitive performance among all porous structural features. The overall results of this study will provide a new idea for design high-performance materials by mining the relationship between properties and structure features of materials using an emerging ML strategy. © 2021 Elsevier B.V.","Extreme gradient boosting; Machine learning; Porous carbon materials; Supercapacitor","Adaptive boosting; Capacitance; Carbon; Machine learning; Porous materials; Structural design; Extreme gradient boosting; Gradient boosting; High performance material; Machine learning models; Performance; Porous carbon materials; Porous carbons; Property; Structural feature; Structure features; Supercapacitor"
"Liu W., He H., Wu X., Ren X., Zhang L., Zhu X., Feng L., Lv Y., Chang Q., Xu Q., Zhang M., Zhang Y., Wang T.","Spatiotemporal Changes and Driver Analysis of Ecosystem Respiration in the Tibetan and Inner Mongolian Grasslands","10.3390/rs14153563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137063840&doi=10.3390%2frs14153563&partnerID=40&md5=d2b72054f32f3ae72578e5068389bd71","Ecosystem respiration (RE) plays a critical role in terrestrial carbon cycles, and quantification of RE is important for understanding the interaction between climate change and carbon dynamics. We used a multi-level attention network, Geoman, to identify the relative importance of environmental factors and to simulate spatiotemporal changes in RE in northern China’s grasslands during 2001–2015, based on 18 flux sites and multi-source spatial data. Results indicate that Geoman performed well (R2 = 0.87, RMSE = 0.39 g C m−2 d−1, MAE = 0.28 g C m−2 d−1), and that grassland type and soil texture are the two most important environmental variables for RE estimation. RE in alpine grasslands showed a decreasing gradient from southeast to northwest, and that of temperate grasslands showed a decreasing gradient from northeast to southwest. This can be explained by the enhanced vegetation index (EVI), and soil factors including soil organic carbon density and soil texture. RE in northern China’s grasslands showed a significant increase (1.81 g C m−2 yr−1) during 2001–2015. The increase rate of RE in alpine grassland (2.36 g C m−2 yr−1) was greater than that in temperate grassland (1.28 g C m−2 yr−1). Temperature and EVI contributed to the interannual change of RE in alpine grassland, and precipitation and EVI were the main contributors in temperate grassland. This study provides a key reference for the application of advanced deep learning models in carbon cycle simulation, to reduce uncertainties and improve understanding of the effects of biotic and climatic factors on spatiotemporal changes in RE. © 2022 by the authors.","alpine grasslands; deep learning model; ecosystem respiration; environment control; spatiotemporal changes; temperate grasslands","Deep learning; Ecosystems; Learning systems; Organic carbon; Soils; Textures; Alpine grasslands; Deep learning model; Ecosystem respiration; Enhanced vegetation index; Environment control; Learning models; Northern China; Soil textures; Spatio-temporal changes; Temperate grasslands; Climate change"
"Liu Y., Fang D., Yang K., Xu T., Su C., Li R., Xiao X., Wang Z.","Sodium dehydroacetate confers broad antibiotic tolerance by remodeling bacterial metabolism","10.1016/j.jhazmat.2022.128645","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126280763&doi=10.1016%2fj.jhazmat.2022.128645&partnerID=40&md5=a6c0ce75c24e86e7c78c45536a6cd0b0","Antibiotic tolerance has been a growing crisis that is seriously threatening global public health. However, little is known about the exogenous factors capable of triggering the development of antibiotic tolerance, particularly in vivo. Here we uncovered that an previously approved food additive termed sodium dehydroacetate (DHA-S) supplementation remarkably impaired the activity of bactericidal antibiotics against various bacterial pathogens. Mechanistic studies indicated that DHA-S induced glyoxylate shunt and reduced bacterial cellular respiration by inhibiting the enzymatic activity of α-ketoglutarate dehydrogenase (α-KGDH). Furthermore, DHA-S mitigated oxidative stress imposed by bactericidal antibiotics and enhanced the function of multidrug efflux pumps. These actions worked together to induce bacterial tolerance to antibiotic killing. Interestingly, the addition of five exogenous amino acids, particularly cysteine and proline, effectively reversed antibiotic tolerance elicited by DHA-S both in vitro and in mouse models of infection. Taken together, these findings advance our understanding of the potential risks of DHA-S in the treatment of bacterial infections, and shed new insights into the relationships between antibiotic tolerance and bacterial metabolism. © 2022 Elsevier B.V.","Antibiotic killing; Antibiotic tolerance; Bacteria; DHA-S; Metabolism","Amino acids; Metabolism; Sodium compounds; Antibiotic killing; Antibiotic tolerances; Bacterial metabolism; Bacterial pathogens; DHA-S; Exogenous factors; Global public health; Glyoxylate; In-vivo; Mechanistic studies; Antibiotics; acid; antibiotic agent; ciprofloxacin; clindamycin; colistin; dehydroacetic acid; florfenicol; kanamycin; meropenem; oxoglutarate dehydrogenase; proline; tetracycline; tylosin; antiinfective agent; dehydroacetic acid; pyrone derivative; acetate; antibiotic resistance; bacterium; induced response; metabolism; oxidative stress; respiration; animal experiment; antimicrobial activity; Article; bacterial metabolism; bacterial strain; chemical structure; controlled study; drug tolerance; enzyme activity; flow cytometry; Gram negative bacterium; in vitro study; liquid chromatography-mass spectrometry; male; minimum inhibitory concentration; molecular weight; mouse; nonhuman; outer membrane; practice guideline; real time reverse transcription polymerase chain reaction; single nucleotide polymorphism; whole genome sequencing; animal; bacterium; microbial sensitivity test; Animals; Anti-Bacterial Agents; Bacteria; Mice; Microbial Sensitivity Tests; Pyrones"
"Liu Y., Gao G., Zhang Z.","Crop Disease Recognition Based on Modified Light-Weight CNN With Attention Mechanism","10.1109/ACCESS.2022.3216285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140760495&doi=10.1109%2fACCESS.2022.3216285&partnerID=40&md5=f1641323083bb9961e09eafde90ab60d","The agricultural production is greatly affected by various plant diseases. Classifying the severity of crop diseases is the requirement for formulating disease prevention and control strategies. However, the differences between different severity of the same crop disease are very tiny. It increases the difficulty of correct crop disease recognition. For example, at the early stage of the disease, the lesions on the leaves are not obvious. And it is very difficult to extract the features of the lesions. However, these very small color and texture differences of the lesions are the key patterns to distinguish different kinds of diseases of the same species. In order to achieve better performance in the fine-grained classification of the crop diseases, a modified light-weight convolution neural network was proposed. Multi-scale convolution kernel and coordinate attention mechanism are introduced in SqueezeNext to extract the features of the lesions accurately. The performance of the proposed model was evaluated using the AI challenger 2018 plant disease recognition dataset, and the recognition accuracy can reach 91.94%, which is 3.02% point higher than the original SqueezeNext model. In order to verify the effectiveness of the proposed model, comparative experiments were carried out using ReseNet50, Xception and mobilenetv2. The experimental results showed that the accuracy of the proposed method was slightly better than Xception, while the model size is only 2.83 MB, which is only 3.45% of Xception. The proposed method balances the performance and efficiency very well. Thus, it is suitable for deployment on mobile terminals and other embedded resource-constrained devices, which help to promote the popularization of smart agriculture application. © 2013 IEEE.","attention mechanism; Crop disease recognition; light-weight CNN; SqueezeNext","Bandpass filters; Convolution; Crops; Disease control; Feature extraction; Neural networks; Plants (botany); Textures; Attention mechanisms; Convolutional neural network; Crop disease; Crop disease recognition; Features extraction; Information filter; Light weight; Light-weight CNN; Neural-networks; Plant; Squeezenext; Image recognition"
"Liu Y., Yang K., Jia Y., Shi J., Tong Z., Wang Z.","Thymine Sensitizes Gram-Negative Pathogens to Antibiotic Killing","10.3389/fmicb.2021.622798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101005673&doi=10.3389%2ffmicb.2021.622798&partnerID=40&md5=f5bf99009d0e27d01b7e046992556cab","Diminished antibiotic susceptibility of bacterial pathogens is an increasingly serious threat to human and animal health. Alternative strategies are required to combat antibiotic refractory bacteria. Bacterial metabolic state has been shown to play a critical role in its susceptibility to antibiotic killing. However, the adjuvant potential of nucleotides in combination with antibiotics to kill Gram-negative pathogens remains unknown. Herein, we found that thymine potentiated ciprofloxacin killing against both sensitive and resistant-E. coli in a growth phase-independent manner. Similar promotion effects were also observed for other bactericidal antibiotics, including ampicillin and kanamycin, in the fight against four kinds of Gram-negative bacteria. The mechanisms underlying this finding were that exogenous thymine could upregulate bacterial metabolism including increased TCA cycle and respiration, which thereby promote the production of ATP and ROS. Subsequently, metabolically inactive bacteria were converted to active bacteria and restored its susceptibility to antibiotic killing. In Galleria mellonella infection model, thymine effectively improved ciprofloxacin activity against E. coli. Taken together, our results demonstrated that thymine potentiates bactericidal antibiotics activity against Gram-negative pathogens through activating bacterial metabolism, providing a universal strategy to overcome Gram-negative pathogens. © Copyright © 2021 Liu, Yang, Jia, Shi, Tong and Wang.","antibiotic resistance; antibiotic tolerance; Gram-negative bacteria; metabolism; thymine","ampicillin; ciprofloxacin; cytochrome c oxidase; fumarate hydratase; isocitrate dehydrogenase; kanamycin; malate dehydrogenase; oxoglutarate dehydrogenase; phosphoenolpyruvate carboxykinase (GTP); proton transporting adenosine triphosphate synthase; pyruvate kinase; reactive oxygen metabolite; reduced nicotinamide adenine dinucleotide (phosphate) dehydrogenase (quinone); superoxide dismutase; tetracycline; thiourea; thymine; Acinetobacter baumannii; antibacterial activity; antibiotic resistance; antimicrobial activity; Article; bacterial growth; bacterial metabolism; bacterial strain; bactericidal activity; bacteriostatic activity; broth dilution; cell viability; citric acid cycle; colony forming unit; energy metabolism; Escherichia coli; Galleria mellonella; Gram negative bacterium; growth curve; growth inhibition; minimum inhibitory concentration; mRNA expression level; multidrug resistant Escherichia coli; nonhuman; Pseudomonas aeruginosa; real time polymerase chain reaction; respiratory chain; Salmonella enterica serovar Enteritidis; survival rate"
"Liu Y., Yang K., Zhang H., Jia Y., Wang Z.","Combating Antibiotic Tolerance Through Activating Bacterial Metabolism","10.3389/fmicb.2020.577564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095681118&doi=10.3389%2ffmicb.2020.577564&partnerID=40&md5=f136b2abd6c99314ff5410a21e936634","The emergence of antibiotic tolerance enables genetically susceptible bacteria to withstand the killing by clinically relevant antibiotics. As is reported, an increasing body of evidence sheds light on the critical and underappreciated role of antibiotic tolerance in the disease burden of bacterial infections. Considering this tense situation, new therapeutic strategies are urgently required for combating antibiotic tolerance. Herein, we provide an insightful illustration to distinguish between antibiotic resistance and tolerance, and highlight its clinical significance and complexities of drug-tolerant bacteria. Then, we discuss the close relationship between antibiotic tolerance and bacterial metabolism. As such, a bacterial metabolism-based approach was proposed to counter antibiotic tolerance. These exogenous metabolites including amino acids, tricarboxylic acid cycle (TCA cycle) metabolites, and nucleotides effectively activate bacterial metabolism and convert the tolerant cells to sensitive cells, and eventually restore antibiotic efficacy. A better understanding of molecular mechanisms of antibiotic tolerance particularly in vivo would substantially drive the development of novel strategies targeting bacterial metabolism. © Copyright © 2020 Liu, Yang, Zhang, Jia and Wang.","antibiotic efficacy; antibiotic resistance; antibiotic tolerance; bacteria; metabolism; metabolites","antibiotic agent; artemisinin; cefepime; colistin; gentamicin; glutathione; heavy metal; imipenem; isoniazid; kanamycin; menaquinone; nucleotide; peroxynitrite; rifampicin; tigecycline; tobramycin; tricarboxylic acid; Acinetobacter baumannii; antibiotic resistance; antibiotic sensitivity; antibiotic tolerance; antimicrobial activity; bacterial gene; bacterial growth; bacterial infection; bacterial metabolism; bacterial strain; bacterial translocation; bacterium identification; biofilm; cancer resistance; carbon metabolism; citric acid cycle; DNA damage; DNA replication; drug efficacy; drug tolerance; Edwardsiella tarda; Escherichia coli; glycolysis; immune response; in vivo study; Klebsiella pneumoniae; Listeria monocytogenes; metabolomics; methicillin resistant Staphylococcus aureus; minimum bactericidal concentration; minimum inhibitory concentration; mitochondrial biogenesis; multidrug resistance; Mycobacterium smegmatis; nonhuman; nucleotide metabolism; oxidative phosphorylation; plant growth; protein synthesis; proteomics; Pseudomonas aeruginosa; pyrimidine synthesis; Review; upregulation; urinary tract infection; vaginitis"
"Liu Y., Yang K., Jia Y., Shi J., Tong Z., Wang Z.","Cysteine potentiates bactericidal antibiotics activity against gram-negative bacterial persisters","10.2147/IDR.S263225","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088986048&doi=10.2147%2fIDR.S263225&partnerID=40&md5=2214c40e94314484518dd3a39064c97e","Purpose: Bacterial metabolism regulators offer a novel productive strategy in the eradication of antibiotic refractory bacteria, particularly bacterial persisters. However, the potential of amino acids in the fight against Gram-negative bacterial persisters has not been fully explored. The aim of this study is to investigate the potentiation of amino acids to antibiotics in combating Gram-negative bacterial persisters and to reveal the underlying mechanisms of action. Methods: Bactericidal activity of antibiotics in the absence or presence of amino acids was evaluated through detecting the reduction of bacterial CFUs. The ratio of NAD+/NADH in E. coli B2 persisters was determined using assay kit with WST-8. Bacterial respiration and ROS production were measured by the reduction of iodonitrotetrazolium chloride and fluorescent probe 2′,7′-dichlorodihydrofluorescein diacetate, respectively. Results: In this study, we found that cysteine possesses excellent synergistic bactericidal activity with ciprofloxacin against multiple Gram-negative bacterial persisters. Furthermore, the potentia-tion of cysteine was evaluated in exponential and stationary-phase E. coli ATCC 25922 and E. coli B2. Interestingly, cysteine significantly improves three bactericidal antibiotics killing against stationary-phase bacteria, but not exponential-phase bacteria, implying that the effect of cysteine correlates with the metabolic state of bacteria. Mechanistic studies revealed that cysteine accel-erates the bacterial TCA cycle and promotes bacterial respiration and ROS production. These metabolic regulation effects of cysteine re-sensitive bacterial persisters to antibiotic killing. Conclusion: Collectively, our study highlights the synergistic bactericidal activity of bacterial metabolism regulators such as cysteine with commonly used antibiotics against Gram-negative bacterial persisters. © 2020 Liu et al.","Amino acids; Bacterial persisters; Bactericidal antibiotics; Cysteine; Gram-negative bacteria","antibiotic agent; ciprofloxacin; cysteine; fluorescent dye; reactive oxygen metabolite; reduced nicotinamide adenine dinucleotide; Article; bacterial metabolism; bactericidal activity; chromatography by stationary phase; colony forming unit; controlled study; drug mechanism; drug potentiation; Escherichia coli; metabolic regulation; minimum inhibitory concentration; nonhuman"
"Ljubobratović D., Vuković M., Bakarić M.B., Jemrić T., Matetić M.","Utilization of explainable machine learning algorithms for determination of important features in ‘suncrest’ peach maturity prediction","10.3390/electronics10243115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121441161&doi=10.3390%2felectronics10243115&partnerID=40&md5=6e5ad21b604e1699c1e3262d00208155","Peaches (Prunus persica (L.) Batsch) are a popular fruit in Europe and Croatia. Maturity at harvest has a crucial influence on peach fruit quality, storage life, and consequently consumer acceptance. The main goal of this study is to develop a machine learning model that will detect the most important features for predicting peach maturity by first training models and then using the importance ratings of these models to detect nonlinear (and linear) relationships. Thus, the most important peach features at a given stage of its ripening could be revealed. To date, this method has not been used for this purpose, and at the same time, it has the potential to be applied to other similar peach varieties. A total of 33 fruit features are measured on the harvested peaches, and three imbalanced datasets are created using firmness thresholds of 1.84, 3.57, and 4.59 kg·cm−2. These datasets are balanced using the SMOTE and ROSE techniques, and the Random Forest machine learning model is trained on them. Permutation Feature Importance (PFI), Variable Importance (VI), and LIME interpretability methods are used to detect variables that most influence predictions in the given machine learning models. PFI shows that the h◦ and a* ground color parameters, COL ground color index, SSC/TA, and TA inner quality parameters are among the top ten most contributing variables in all three models. Meanwhile, VI shows that this is the case for the a* ground color parameter, COL and CCL ground color indexes, and the SSC/TA inner quality parameter. The fruit flesh ratio is highly positioned (among the top three according to PFI) in two models, but it is not even among the top ten in the third. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Ground color; Imbalanced datasets; Interpretable machine learning; Machine learning; Peach maturity; Random forest; Variable importance",
"Ljubobratović D., Zhang G., Bakarić M.B., Jemrić T., Matetić M.","Predicting peach fruit ripeness using explainable machine learning","10.2507/31st.daaam.proceedings.099","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098107458&doi=10.2507%2f31st.daaam.proceedings.099&partnerID=40&md5=56271af4be1ef3205d526dd323433aa9","Predicting fruit ripeness allows us to choose the optimal time to harvest. The parameter by which peach ripeness is commonly represented is its firmness. As traditional methods for determining firmness of peaches are destructive, this paper uses an alternative method for determining peach ripeness which is based on peach impedance, as recommended by the domain expert. The data set on which the data analysis is performed contains measurements obtained from a couple of hundred fruit measurements, which also include peach impedance. In our data analysis, we use one of the high accuracy machine learning models, which are called black box models and which are characterized by low interpretability. The paper presents the results of applying a black box type machine learning method, as well as methods for interpreting black box models which facilitate understanding of the model behavior for domain experts, i.e. Variable importance, Tree Surrogate, Local Interpretable Model-Agnostic Explanations and Break Down. © 2020 Danube Adria Association for Automation and Manufacturing, DAAAM. All rights reserved.","Explainable machine learning; Interpretability; Peach impedance; Predicting fruit ripeness","Data handling; Information analysis; Machine learning; Black-box model; Domain experts; Fruit ripeness; Interpretability; Machine learning methods; Machine learning models; Modeling behavior; Variable importances; Fruits"
"Lo Piano S.","Ethical principles in machine learning and artificial intelligence: cases from the field and possible ways forward","10.1057/s41599-020-0501-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089573060&doi=10.1057%2fs41599-020-0501-9&partnerID=40&md5=2abf791ae57f9f6536612f114eb25544","Decision-making on numerous aspects of our daily lives is being outsourced to machine-learning (ML) algorithms and artificial intelligence (AI), motivated by speed and efficiency in the decision process. ML approaches—one of the typologies of algorithms underpinning artificial intelligence—are typically developed as black boxes. The implication is that ML code scripts are rarely scrutinised; interpretability is usually sacrificed in favour of usability and effectiveness. Room for improvement in practices associated with programme development have also been flagged along other dimensions, including inter alia fairness, accuracy, accountability, and transparency. In this contribution, the production of guidelines and dedicated documents around these themes is discussed. The following applications of AI-driven decision-making are outlined: (a) risk assessment in the criminal justice system, and (b) autonomous vehicles, highlighting points of friction across ethical principles. Possible ways forward towards the implementation of governance on AI are finally examined. © 2020, The Author(s).",,
"Lochtefeld J., Schlager S., Bryan S., Harbour S., Colter J.","Human Vs. Autonomous Agents: Drone racing and Obstacle Avoidance","10.1109/DASC55683.2022.9925887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141939121&doi=10.1109%2fDASC55683.2022.9925887&partnerID=40&md5=60d9fdbd506b44254869cda5152730a9","With the increase of autonomy in aircraft systems over the past decade, the question of whether autonomous agents provide better performance when compared to human operators is of utmost importance. Current research using machine learning for obstacle avoidance in small Unmanned Aircraft Systems has gained extensive attention in recent years, but who is faster, the human or the machine? This study leverages programmable coding languages using Unmanned Aircraft Systems (UAS) to navigate a fabricated obstacle course environment. By applying various methods of intelligent agent training, human pilots were compared to the performance of the automated system. The Artificial Intelligence (AI) training ensured that the automated flight path and speed for the Unmanned Aircraft System were optimized for the course environment. We collected a dataset from a sample size of 12 participants, including zero knowledge of flight training, to experienced pilots. The findings of this work aimed to show the performance comparison, including Key System Attributes and Key Performance Parameters, by considering drone speed, pilot skill level, and course crashes between man and machine to determine which is a safer and faster solution. © 2022 IEEE.",,"Air navigation; Aircraft accidents; Automation; Drones; Training aircraft; Vehicle performance; 'current; Aircraft systems; Coding languages; Human operator; Machine-learning; Obstacles avoidance; Performance; Small unmanned aircrafts; Training humans; Unmanned aircraft system; Autonomous agents"
"Loddo A., Meloni G., Pes B.","Using Artificial Intelligence for COVID-19 Detection in Blood Exams: A Comparative Analysis","10.1109/ACCESS.2022.3221750","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142811024&doi=10.1109%2fACCESS.2022.3221750&partnerID=40&md5=60a5a516278256bdf5a076a82234958a","COVID-19 is an infectious disease that was declared a pandemic by the World Health Organization (WHO) in early March 2020. Since its early development, it has challenged health systems around the world. Although more than 12 billion vaccines have been administered, at the time of writing, it has more than 623 million confirmed cases and more than 6 million deaths reported to the WHO. These numbers continue to grow, soliciting further research efforts to reduce the impacts of such a pandemic. In particular, artificial intelligence techniques have shown great potential in supporting the early diagnosis, detection, and monitoring of COVID-19 infections from disparate data sources. In this work, we aim to make a contribution to this field by analyzing a high-dimensional dataset containing blood sample data from over forty thousand individuals recognized as infected or not with COVID-19. Encompassing a wide range of methods, including traditional machine learning algorithms, dimensionality reduction techniques, and deep learning strategies, our analysis investigates the performance of different classification models, showing that accurate detection of blood infections can be obtained. In particular, an F-score of 84% was achieved by the artificial neural network model we designed for this task, with a rate of 87% correct predictions on the positive class. Furthermore, our study shows that the dimensionality of the original data, i.e. the number of features involved, can be significantly reduced to gain efficiency without compromising the final prediction performance. These results pave the way for further research in this field, confirming that artificial intelligence techniques may play an important role in supporting medical decision-making. © 2013 IEEE.","artificial intelligence; Covid-19 detection; deep learning; feature selection; machine learning","Blood; Decision making; Deep learning; Diagnosis; Feature Selection; Learning algorithms; Learning systems; Medical imaging; Neural networks; Biomedical imaging; Clinical diagnosis; Covid-19 detection; Deep learning; Features extraction; Features selection; Machine-learning; Pandemic; COVID-19"
"Lohith R., Cholachgudda K.E., Biradar R.C.","PyTorch Implementation and Assessment of Pre-Trained Convolutional Neural Networks for Tomato Leaf Disease Classification","10.1109/TENSYMP54529.2022.9864390","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138493305&doi=10.1109%2fTENSYMP54529.2022.9864390&partnerID=40&md5=b3c29daff1081f3575f85dcce62d4bfe","Plant diseases detection and management practices are a major concern in the agriculture sector. Automating the process of plant disease detection with acceptable accuracy and speed using computer-aided systems could help develop an early diagnosis while substantially reducing economic losses. Recent advancements in deep neural networks have allowed researchers to drastically improve the accuracy of image classification and recognition systems. This paper presents a comprehensive assessment of the deep-learning approaches based on the pre-trained convolutional neural network models and the PyTorch framework to classify disease infections in tomato plants. Models such as EfficientNet-B0, ResNext-50_32x4d and MobileNet-V2, which relatively exhibit improved performance under different trade-offs, were tested using images captured with the natural background. Key performance indices were evaluated with varying hyperparameters during training and validation on a GPU-based system. The results show that ResNext-50_32x4d delivers the best accuracy of 90.14% (0.001 LR; 8 Batch Size), with the right hyperparameter optimization, and MobileNet-V2 delivers the lowest loss of 0.356 (0.001 LR; 16 Batch Size) during model validation for the given dataset and system constraints. ResNext-50_32x4d also performs better in inference than the other two models tested. The assessment performed in this paper will help researchers and developers decide on selecting an appropriate model for precision agriculture and smart farming deployments. © 2022 IEEE.","Convolutional Neural Network; Hyperparameter Tuning; Image Classification; Plant Disease Detection; PyTorch","Computer aided diagnosis; Convolution; Convolutional neural networks; Deep neural networks; Economic and social effects; Fruits; Image enhancement; Losses; Batch sizes; Convolutional neural network; Disease detection; Hyper-parameter; Hyperparameter tuning; Images classification; Plant disease; Plant disease detection; Pytorch; Tomato leaf; Image classification"
"Lowe M., Qin R., Mao X.","A Review on Machine Learning, Artificial Intelligence, and Smart Technology in Water Treatment and Monitoring","10.3390/w14091384","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129715615&doi=10.3390%2fw14091384&partnerID=40&md5=48625653b9ff6379b27e517898c67373","Artificial-intelligence methods and machine-learning models have demonstrated their ability to optimize, model, and automate critical water-and wastewater-treatment applications, natural-systems monitoring and management, and water-based agriculture such as hydroponics and aquaponics. In addition to providing computer-assisted aid to complex issues surrounding water chemistry and physical/biological processes, artificial intelligence and machine-learning (AI/ML) applications are anticipated to further optimize water-based applications and decrease capital expenses. This review offers a cross-section of peer reviewed, critical water-based applications that have been coupled with AI or ML, including chlorination, adsorption, membrane filtration, water-quality-index monitoring, water-quality-parameter modeling, river-level monitoring, and aquaponics/hydroponics automation/monitoring. Although success in control, optimization, and modeling has been achieved with the AI methods, ML models, and smart technologies (including the Internet of Things (IoT), sensors, and systems based on these technologies) that are reviewed herein, key challenges and limitations were common and pervasive throughout. Poor data management, low explainability, poor model reproducibility and standardization, as well as a lack of academic transparency are all important hurdles to overcome in order to successfully implement these intelligent applications. Recommendations to aid explainability, data management, reproducibility, and model causality are offered in order to overcome these hurdles and continue the successful implementation of these powerful tools. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","artificial intelligence; hydroponics; Internet of Things; machine learning; monitoring; water treatment","Internet of things; Machine learning; Microfiltration; Wastewater treatment; Water filtration; Water quality; Aquaponic; Artificial intelligence methods; Artificial intelligence technologies; Hydroponic; Machine learning models; Machine-learning; On-machines; Reproducibilities; Smart technology; Water based; Information management; literature review; machine learning; monitoring system; technological development; water treatment"
"Lu K., Liu L., Xu Z., Xie W.","The analysis of volatile compounds through flavoromics and machine learning to identify the origin of traditional Chinese fermented shrimp paste from different regions","10.1016/j.lwt.2022.114096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141001669&doi=10.1016%2fj.lwt.2022.114096&partnerID=40&md5=1378e9cf50293c802637d2c9a53cb999","Traditional Chinese fermented shrimp paste is a national geographical indication product with a distinctly regional flavor. The great commercial value and highly appreciated aroma urgently require establishing reliable methods to define the origin of shrimp paste and dissect the aroma essence. Therefore, in this study, flavoromics, chemometrics, and data augmented machine learning were performed to analyze shrimp paste from different regions of Bohai Bay, China. The results showed that shrimp paste contained several volatile compounds, including sulfur-containing compounds, nitrogen-containing compounds, aldehydes, and alcohols. In addition, chemometric and flavor association networks indicated that higher salt content produces some volatile compounds, such as 2-heptanone and phenylethanol. Furthermore, the prominent fruitiness and fermented aromas were associated with some key aroma substances, such as (E)-2-octenal and phenylethanol. Finally, a classification model for the origin identification of shrimp paste was developed. The results showed that seven trained machine learning models, including random forest (RF), support vector machine (SVM), and artificial neural network (ANN), were able to accurately (100%) identify the origin of shrimp paste. In summary, this study provides a theoretical support and application basis for identifying the origin and protection of the characteristic geographical flavor of shrimp paste. © 2022 The Authors","Chemometrics; HS-SPME-GC-MS; Machine learning; Origin identification; Traditional fermented shrimp paste","Electronic nose; Ethanol; Flavor compounds; Learning systems; Neural networks; Odors; Sulfur compounds; Support vector machines; Volatile organic compounds; Bohai Bay; Chemometrices; HS-SPME/GC-MS; Machine-learning; Origin identification; Phenylethanol; Reliable methods; Sulphur containing compounds; Traditional fermented shrimp paste; Volatile compounds; Decision trees"
"Lu T., Han B., Chen L., Yu F., Xue C.","A generic intelligent tomato classification system for practical applications using DenseNet-201 with transfer learning","10.1038/s41598-021-95218-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111997502&doi=10.1038%2fs41598-021-95218-w&partnerID=40&md5=24650a5b7a18f4e98bab77786d8a6c9f","A generic intelligent tomato classification system based on DenseNet-201 with transfer learning was proposed and the augmented training sets obtained by data augmentation methods were employed to train the model. The trained model achieved high classification accuracy on the images of different quality, even those containing high levels of noise. Also, the trained model could accurately and efficiently identify and classify a single tomato image with only 29 ms, indicating that the proposed model has great potential value in real-world applications. The feature visualization of the trained models shows their understanding of tomato images, i.e., the learned common and high-level features. The strongest activations of the trained models show that the correct or incorrect target recognition areas by a model during the classification process will affect its final classification accuracy. Based on this, the results obtained in this study could provide guidance and new ideas to improve the development of intelligent agriculture. © 2021, The Author(s).",,"agriculture; article; human; noise; nonhuman; tomato; transfer of learning"
"Lu Y., Li Z., Zhao X., Lv S., Wang X., Wang K., Ni H.","Recognition of rice sheath blight based on a backpropagation neural network","10.3390/electronics10232907","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119657115&doi=10.3390%2felectronics10232907&partnerID=40&md5=f3978f4a320ea651adfc89dce18b661f","Rice sheath blight is one of the main diseases in rice production. The traditional detection method, which needs manual recognition, is usually inefficient and slow. In this study, a recognition method for identifying rice sheath blight based on a backpropagation (BP) neural network is posed. Firstly, the sample image is smoothed by median filtering and histogram equalization, and the edge of the lesion is segmented using a Sobel operator, which largely reduces the background information and significantly improves the image quality. Then, the corresponding feature parameters of the image are extracted based on color and texture features. Finally, a BP neural network is built for training and testing with excellent tunability and easy optimization. The results demonstrate that when the number of hidden layer nodes is set to 90, the recognition accuracy of the BP neural network can reach up to 85.8%. Based on the color and texture features of the rice sheath blight image, the recognition algorithm constructed with a BP neural network has high accuracy and can effectively make up for the deficiency of manual recognition. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","BP neural network; Feature extraction; Image preprocessing; Image recognition; Rice sheath blight",
"Lu Y.","Artificial intelligence: a survey on evolution, models, applications and future trends","10.1080/23270012.2019.1570365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061841131&doi=10.1080%2f23270012.2019.1570365&partnerID=40&md5=4f7a47202a27a793bad8a54985a8c6e5","Artificial intelligence (AI) is one of the core drivers of industrial development and a critical factor in promoting the integration of emerging technologies, such as graphic processing unit, Internet of Things, cloud computing, and the blockchain, in the new generation of big data and Industry 4.0. In this paper, we construct an extensive survey over the period 1961–2018 of AI and deep learning. The research provides a valuable reference for researchers and practitioners through the multi-angle systematic analysis of AI, from underlying mechanisms to practical applications, from fundamental algorithms to industrial achievements, from current status to future trends. Although there exist many issues toward AI, it is undoubtful that AI has become an innovative and revolutionary assistant in a wide range of applications and fields. © 2019, © 2019 Antai College of Economics and Management, Shanghai Jiao Tong University.","artificial intelligence; big data; deep learning; graphic processing unit; Industry 4.0; Internet of Things","Artificial intelligence; Big data; Deep learning; Industrial research; Industry 4.0; Internet of things; Surveys; Critical factors; Current status; Emerging technologies; Future trends; Graphic processing units; Industrial development; Multi angle; Systematic analysis; Graphics processing unit"
"Lu Z.","Data-driven integrated assessment of global wild-caught seafood exported to Hong Kong by 2030 in different representative concentration and shared socioeconomic pathways","10.1016/j.accre.2022.05.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132721410&doi=10.1016%2fj.accre.2022.05.002&partnerID=40&md5=699c25879127d7f7308e08a9b4afe6a9","Wild-caught seafood is an important commodity traded globally. As climate change and socioeconomic development is affecting global marine capture fisheries, the impact on regional supply remains unexplored, especially for areas like Hong Kong relying on global trading to meet high seafood consumption. However, it is challenging to assess the global marine capture fisheries production using complex process-based models. In this study, a data-driven integrated assessment approach was developed to evaluate the change of global seafood supply from wild catch. With the catch data available from 1990 to 2014, machine learning models were trained and tested including environmental, socioeconomic, geographic, and technological features to estimate the catch by ocean grid cells for individual species. Nine popular seafood categories in Hong Kong were studied, which include 68 species in total. Important input features for estimating the catch were compared across species and the impacts of these input features were interpreted using partial dependence plots. The global marine wild catch of the 68 species by countries and the export to Hong Kong were projected by 2030 in RCP2.6-SSP1, RCP4.5-SSP2, RCP7.0-SSP3, and RCP8.5-SSP5. Performances of machine learning models demonstrate the reliability of data-driven methods to estimate the catch by ocean grid cells. The importance of geographic features rank top for the estimate while that of climate change and socioeconomic development varies significantly across species. The projection reflects a drop of squid exported to Hong Kong due to the reduction of squid supply from China's mainland during 2015–2019. The export of wild-caught seafood of the nine categories to Hong Kong will have a slight decline by about 16% from the 2020 level by 2030. The projection also suggests no significant differences among the four climatic-socioeconomically interrelated scenarios regarding the export to Hong Kong before 2030. Top producers include China's mainland, United States, and Japan. However, China's mainland and Japan will suffer from the decline. The data-driven integrated assessment approach can be improved to provide more insights into the long-term change and sustainable management. © 2022 The Authors","Climate change; Export to Hong Kong; Integrated assessment; Machine learning; Socioeconomic development; Wild-caught seafood",
"Luo J., Zhang P., Loo Y.T., Ma J., Wu S., Marriott P.J., Howell K.","Can wine quality be predicted by small volatile compounds? A study based on performance of wine show entries and their volatile profiles","10.1002/ffj.3720","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138144862&doi=10.1002%2fffj.3720&partnerID=40&md5=f6c3cc881831f35fb1d15bccd88234c6","It is widely recognized that wine aroma critically influences wine quality, yet the extent to which volatile compound composition in wine determines wine quality has proven difficult to define, beyond the negative influence of taint compounds. While some relationships between concentration of volatile aroma compounds and wine quality have been made, this has been usually based on single molecules, in laboratory wines and without reference to experienced wine panels. Here, we collected and analysed 157 commercial Shiraz wines from a competitive show over 2 years. We found significant (P <.05) correlations between specific volatiles and the panel's wine quality scores. However, these correlations were not always consistent between years. We could not explain medals given to wine entries solely based on multivariate analysis of their composite volatile composition. Here, we suggest that aroma determination in judging wine quality does not completely explain the assessment of wine, and appearance (colour, clarity) and taste may be more influential factors. There are considerable practical difficulties in establishing a convincing wine quality prediction model based on analysis of volatile compounds alone. © 2022 The Authors. Flavour and Fragrance Journal published by John Wiley & Sons Ltd.","Shiraz; SPME-GC–MS; volatiles; wine quality; wine show","Multivariant analysis; Odors; Quality control; Volatile organic compounds; Flavor and fragrances; Performance; Shiraz; SPME-GC/MS; Volatile; Volatile compounds; Volatile profile; Wine aromas; Wine quality; Wine show; Wine; 1,1,6 trimethyl 1,2 dihydronaphthalene; 2 heptanol; 2 pentylfuran; 3 ethyl 2 pentanol; 3 methylbutyl acetate; 3 methylbutyl hexanoate; 3 methylbutyl octanoate; acetic acid; acetic acid ethyl ester; acetoin; benzyl alcohol; beta damascenone; beta ionone; butanol; butyric acid; butyric acid ethyl ester; butyrolactone; cymene; decanoic acid; decanol; diethyl succinate; ethyl 2 methylbutanoate; ethyl 3 methylbutanoate; ethyl 3 methylbutyl succinate; ethyl 9 decenoate; ethyl benzeneacetate; ethyl decanoate; ethyl dodecanoate; ethyl heptanoate; ethyl hexadecanoate; ethyl hexanoate; ethyl nonanoate; ethyl octoate; ethyl pentanoate; ethyl tetradecanoate; eugenol; geraniol; hexanoic acid; hexanol; hexyl acetate; isobutanol; isopentyl alcohol; lactic acid ethyl ester; limonene; linalool; methionol; methyl decanoate; methyl hexanoate; nerol; nonanoic acid; nonanol; octanoic acid; phenethyl alcohol; rose oxide; terpineol; theaspirane; unclassified drug; volatile agent; aroma; Article; chemical composition; concentration (parameter); controlled study; food color; food quality; human; mass fragmentography; odor; prediction; sensory analysis; taste; wine"
"Luo X., Tong Z., Xie Y., An R., Yang Z., Liu Y.","Land Use Change under Population Migration and Its Implications for Human–Land Relationship","10.3390/land11060934","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132820879&doi=10.3390%2fland11060934&partnerID=40&md5=aef17889dbae93b90fc2a41e4ff70ef7","With the rural-to-urban population migration under the new era of rapid urbanization, China has experienced dramatic rural land change, especially the change in cultivated land and rural residential land, resulting in the serious uncoordinated human–land relationships in rural areas. The efficient use of these two kinds of land resources becomes one of the paramount challenges for governments to achieve sustainable and balanced rural development. This challenge highlights the need for quantifying the formation mechanism of the relationship between cultivated land and rural residential land (RCR) and exploring the corresponding relation between human–land relationships with RCR to guide the high-efficiency rural land use structure and coordinated development of human–land relationships. This study aims to quantitatively characterize the matching modes of RCR and the underlying formation mechanism via a grid-based, integrated decoupling model and multiclass explainable boosting machine analysis method. The findings are as follows: (1) The variation in cultivated land and rural residential land is characterized by quantity match and spatial mismatch. The six matching modes of RCR are strong decoupling (SD) (33.36%), weak decoupling (9.86%), recessive decoupling (4.15%), expansive negative decoupling (15.05%), weak negative decoupling (4.92%), and strong negative decoupling (SND) (18.65%). (2) Average grain product per cultivated land and population variation have the highest relative importance and play the greatest role in determining the type of matching modes. A concomitant phenomenon is noted in the matching modes; that is, SD occurs with recessive decoupling and weak negative decoupling, and the weak decoupling and expansive negative decoupling occur with SND in the same conditions. (3) A significant corresponding relationship exists between the matching modes and human–land relationship, indicating that the six matching modes correspond to four different stages of the human– land relationship. The study could provide some decision-making guidance for sustainable rural development, so as to improve the differentiated land management and regional response strategies. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","decoupling relationship; formation mechanism; multiclass explainable boosting machine",
"Lv H., Yan K., Guo Y., Zou Q., Hesham A.E.-L., Liu B.","AMPpred-EL: An effective antimicrobial peptide prediction model based on ensemble learning","10.1016/j.compbiomed.2022.105577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129938113&doi=10.1016%2fj.compbiomed.2022.105577&partnerID=40&md5=f159701e633f1589f609e6ab516c3dc5","Antimicrobial peptides (AMPs) are important for the human immune system and are currently applied in clinical trials. AMPs have been received much attention for accurate recognition. Recently, several computational methods for identifying AMPs have been proposed. However, existing methods have difficulty in accurately predicting AMPs. In this paper, we propose a novel AMP prediction method called AMPpred-EL based on an ensemble learning strategy. AMPred-EL is constructed based on ensemble learning combined with LightGBM and logistic regression. Experimental results demonstrate that AMPpred-EL outperforms several state-of-the-art methods on the benchmark datasets and then improves the efficiency performance. © 2022 Elsevier Ltd","AMP prediction; Ensemble learning; LightGBM; Logistic regression","Benchmarking; Forecasting; Microorganisms; Peptides; Regression analysis; Antimicrobial peptide; Antimicrobial peptide prediction; Clinical trial; Ensemble learning; Human immune systems; Lightgbm; Logistics regressions; Model-based OPC; Peptide prediction; Prediction modelling; Learning systems; polypeptide antibiotic agent; Article; Bayesian learning; decision tree; hidden Markov model; k nearest neighbor; learning; logistic regression analysis; prediction; random forest; receiver operating characteristic; sequence alignment; support vector machine; human; machine learning; Antimicrobial Peptides; Humans; Machine Learning"
"Lysov M., Maximova I., Vasiliev E., Getmanskaya A., Turlapov V.","Entropy as a High-Level Feature for XAI-Based Early Plant Stress Detection","10.3390/e24111597","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141733439&doi=10.3390%2fe24111597&partnerID=40&md5=a044a9e6d6b3c94ce18b8a94397b995a","This article is devoted to searching for high-level explainable features that can remain explainable for a wide class of objects or phenomena and become an integral part of explainable AI (XAI). The present study involved a 25-day experiment on early diagnosis of wheat stress using drought stress as an example. The state of the plants was periodically monitored via thermal infrared (TIR) and hyperspectral image (HSI) cameras. A single-layer perceptron (SLP)-based classifier was used as the main instrument in the XAI study. To provide explainability of the SLP input, the direct HSI was replaced by images of six popular vegetation indices and three HSI channels (R630, G550, and B480; referred to as indices), along with the TIR image. Furthermore, in the explainability analysis, each of the 10 images was replaced by its 6 statistical features: min, max, mean, std, max–min, and the entropy. For the SLP output explainability, seven output neurons corresponding to the key states of the plants were chosen. The inner layer of the SLP was constructed using 15 neurons, including 10 corresponding to the indices and 5 reserved neurons. The classification possibilities of all 60 features and 10 indices of the SLP classifier were studied. Study result: Entropy is the earliest high-level stress feature for all indices; entropy and an entropy-like feature (max–min) paired with one of the other statistical features can provide, for most indices, 100% accuracy (or near 100%), serving as an integral part of XAI. © 2022 by the authors.","early diagnosis; entropy; explainable artificial intelligence; high-level explainable feature; plant stress",
"Lysov M., Pukhky K., Turlapov V.","Combined processing of hyperspectral and thermal images of plants in soil for the early diagnosis of drought",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121234822&partnerID=40&md5=58dae781eeb2cf564d6a7a217f5c3070","The possibilities of explainable artificial intelligence (XAI) in the early diagnosis of drought in plants based on hyperspectral images (HSI) are investigated. To provide the explainability and high accuracy to the result, we used the markup of HSI by superimposed Thermal IR (TIR) images of the last day of the experiment. Traditional HSI-based NDVI (Normalized Difference Vegetation Index) images were also constructed. The markup of HSIs based on their clustering by the k-means method into 5 classes was also objectified: wet plants; plants in a state of drought; wet soil; dry soil; background. For HSI, on the day of the experiment started, the number of clusters was set to 2 less to reflect the absence of drought circumstances. For use in training and testing, all HSIs channels are marked up with the results of clustering. The HIS-TIR-combination made it possible to determine the temperature for each plant pixel in HSI, and as the result to determine the number of days without watering. A fully connected Double Layer Perceptron (DLP) neural network was used to solve classification and regression problems. The trained DLP-regressor showed the average accuracy of predicting the temperature of plants on the control days of the experiment RMSE = 0.52 degrees, providing an error in predicting the day of the beginning of the drought for near 2 days. The DLP-classifier was able to classify the drought of the plant in the early stages (the fifth day) with an accuracy of 97.3%. Software tools: pytorch, scikit-learn, pysptools. © 2021 Copyright for this paper by its authors.","Double Layer Perceptron; Early drought diagnosis; Explainable artificial intelligence; Hyperspectral imaging; Plant diseases; Thermal IR imaging","Diagnosis; Drought; Infrared imaging; K-means clustering; Multilayer neural networks; Soils; Spectroscopy; Clusterings; Double layer perceptron; Double layers; Early diagnosis; Early drought diagnose; Explainable artificial intelligence; IR-imaging; Plant disease; Thermal IR; Thermal IR imaging; Hyperspectral imaging"
"Lyu W., Yuan B., Liu S., Simon J.E., Wu Q.","Assessment of lemon juice adulteration by targeted screening using LC-UV-MS and untargeted screening using UHPLC-QTOF/MS with machine learning","10.1016/j.foodchem.2021.131424","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117752514&doi=10.1016%2fj.foodchem.2021.131424&partnerID=40&md5=190372989e8cc77c25dea5c96858b8d9","The aim of this work was to develop an approach combining LC-MS-based metabolomics and machine learning to distinguish between and predict authentic and adulterated lemon juices. A targeted screening of six major flavonoids was first conducted using ultraviolet ion trap MS. To improve the prediction accuracy, an untargeted methodology was carried out using UHPLC-QTOF/MS. Based on the acquired metabolic profiles, both PCA and PLS-DA were conducted. Results exhibited a cluster pattern and a separation potential between authentic and adulterated samples. Five machine learning models were then developed to further analyze the data. The model of support vector machine achieved the highest prediction power, with accuracy up to 96.7 ± 7.5% for the cross-validation set and 100% for the testing set. In addition, 79 characteristic m/z were tentatively identified. This work demonstrated that untargeted screening coupled with machine learning models can be a powerful tool to facilitate detection of lemon juice adulteration. © 2021 Elsevier Ltd","Flavonoids; Food safety; Metabolomics; PCA; PLSA; Predictive modelling; Quality control","Citrus fruits; Forecasting; Support vector machines; Flavonoid; Food-safety; Ion traps; Lemon juice; Machine learning models; Metabolomics; PCA; PLSA; Predictive models; Targeted screenings; Flavonoids; dimethyl ether; eriocitrin; flavonoid; hesperidin; lucenin 2,4' methyl ether; orientin; orientin 4' methyl ether; phytochemical; scoparin; unclassified drug; vicenin 2; Article; food analysis; food quality; food safety; ion trap mass spectrometry; lemon juice; liquid chromatography-mass spectrometry; machine learning; measurement accuracy; metabolomics; prediction; retention time (chromatography); screening; standard; support vector machine; time of flight mass spectrometry; ultra performance liquid chromatography; ultraviolet radiation; fruit and vegetable juice; high performance liquid chromatography; liquid chromatography; machine learning; mass spectrometry; Chromatography, High Pressure Liquid; Chromatography, Liquid; Fruit and Vegetable Juices; Machine Learning; Mass Spectrometry; Metabolomics"
"Lyu W., Rodriguez D., Ferruzzi M.G., Pasinetti G.M., Murrough J.W., Simon J.E., Wu Q.","Chemical, Manufacturing, and Standardization Controls of Grape Polyphenol Dietary Supplements in Support of a Clinical Study: Mass Uniformity, Polyphenol Dosage, and Profiles","10.3389/fnut.2021.780226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122043758&doi=10.3389%2ffnut.2021.780226&partnerID=40&md5=77dbaa0fe70b8f41041aebecafc2be45","Bioactive dietary polyphenols in grape (Vitis vinifera) have been used in Dietary Supplements (DSs) with the aim to prevent numerous diseases, including cardiovascular and neurodegenerative diseases, and to reduce depression and anxiety. Given prior recognition that DSs can be quality challenged from the purity, authentication, adulteration, and actual concentration of targeted bioactives, to ensure consumer health protection as well as the quality and safety of grape polyphenol-based DSs, the present investigation was aimed at establishing a comprehensive quality control (QC) approach for grape polyphenol-based DSs in support of a human clinical study. In this study, the manufactured grape seed polyphenol extract (GSPE) and trans-resveratrol (RSV) capsules and Concord Grape Juice (CGJ) along with the corresponding original drug materials were analyzed using the developed different liquid chromatography/UV-visible spectroscopy/mass spectrometry (LC/UV-Vis/MS) methods. The weight variation of GSPE and RSV capsules was also evaluated according to the US Pharmacopeia (USP) tests. The results indicate that the total identified polyphenol content in each grape seed extract (GSE) capsule/CGJ is very similar and all GSE/RSV capsules pass the content/weight uniformity test. Given the complexity of these and many botanical products from the issues of purity, quality, adulteration, consistency, and their coupling to the complex chemistry in each grape-derived botanical, quality assurance and the steps needed to ensure grape-derived DSs being well homogeneous and stable and containing the known and expected bioactives at specific concentration ranges are fundamental to any research study and in particular to a clinical trial. Each of these issues is essential to provide a solid foundation upon which clinical trials with botanicals can be conducted with the goal of realizing measurable mental health outcomes such as reducing depression and anxiety as well as understanding of their underlying biological mechanisms. Copyright © 2021 Lyu, Rodriguez, Ferruzzi, Pasinetti, Murrough, Simon and Wu.","authentication; botanicals; grape juice; grape seed extract (GSE); LC/UV-Vis/MS; product quality; quality control; resveratrol",
"Lyu W., Yuan B., Liu S., Simon J.E., Wu Q.","Assessment of lemon juice quality and adulteration by ultra-high performance liquid chromatography/ triple quadrupole mass spectrometry with interactive and interpretable machine learning","10.38212/2224-6614.3356","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110323430&doi=10.38212%2f2224-6614.3356&partnerID=40&md5=1199b4b21c22c20cfc1ae5aa215720bb","A total of 81 lemon juices samples were detected using an optimized UHPLC-QqQ-MS/MS method and colorimetric assays. Concentration of 3 organic acids (ascorbic acid, malic acid and citric acid), 3 saccharides (glucose, fructose and sucrose) and 6 phenolic acids (trans-p-coumaric acid, 3-hydroxybenzoic acid, 4-hydroxybenzoic acid, 3,4-dihydrox-ybenzoic acid, caffeic acid) were quantified. Their total polyphenol, antioxidant activity and Ferric reducing antioxidant power were also measured. For the prediction of authentic and adulterated lemon juices and commercially sourced lemonade beverages based on the acquired metabolic profile, machine learning models including linear discriminant analysis, Gaussian naïve Bayes, lasso-regularized logistic regression, random forest (RF) and support vector machine were developed based on training (70%)-cross-validation-testing (30%) workflow. The predicted accuracy on the testing set is 73-86% for different models. Individual conditional expectation analysis (how predicted probabilities change when the feature magnitude changes) was applied for model interpretation, which in particular revealed the close association of RF-probability prediction with nuance characteristics of the density distribution of metabolic features. Using established models, an open-source online dashboard was constructed for convenient classification prediction and interactive visualization in real practice. © 2021 Taiwan Food and Drug Administration.","Citrus limon; Interpretable machine learning; Quality control; R shiny application; UHPLC-QqQ-MS/MS","3 hydroxybenzoic acid; 4 hydroxybenzoic acid; ascorbic acid; caffeic acid; citric acid; fructose; glucose; malic acid; para coumaric acid; polyphenol; protocatechuic acid; sucrose; antioxidant activity; Article; Bayes theorem; calibration; chemical structure; colorimetry; cross validation; discriminant analysis; ferric reducing antioxidant power; kernel method; lemon juice; logistic regression analysis; machine learning; multiple reaction monitoring; random forest; retention time; sensitivity analysis; support vector machine; triple quadrupole mass spectrometry; ultra performance liquid chromatography"
"Ma F., Du C., Zheng S., Du Y.","In Situ Monitoring of Nitrate Content in Leafy Vegetables Using Attenuated Total Reflectance − Fourier-Transform Mid-infrared Spectroscopy Coupled with Machine Learning Algorithm","10.1007/s12161-021-02048-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107265133&doi=10.1007%2fs12161-021-02048-7&partnerID=40&md5=f8bae9f3eee458e605ab0ab266b9746c","Vegetables are one of the most important nitrate sources of human diary diet. Establishing of fast and accurate in situ nitrate monitoring approaches that could be used in the plant growth process and vegetable markets is essential. Incorporating the unique feature of N − O asymmetric stretch absorption in the mid-infrared region (1500–1200 cm−1), portable attenuated total reflectance–Fourier-transform infrared (ATR-FTIR) spectroscopic instrument, along with the Euclidean distance-modified extreme learning machine (ED-ELM) model, was firstly employed to evaluate the nitrate contents in leafy vegetables. A total of 1224 samples of four popular vegetables (Chinese cabbage, water spinach, celery, and lettuce) were analyzed. The results indicated that the coefficient of variation of nitrate contents between different vegetable samples was large (20–30%) and the value of mean values has highly exceeded the World Health Organization (WHO)–specified maximum tolerance limits. Chinese cabbage: 7550 ± 1664 mg kg−1; water spinach: 4219 ± 1029 mg kg−1; celery: 4164 ± 1214 mg kg−1; lettuce: 4322 ± 1024 mg kg−1). Moreover, The ED-ELM model showed a better performance with the RMSEP of 799.7 mg kg−1 (calibration range from 805 to 14,104 mg kg−1 and validation range from 2132 to 11,793 mg kg−1), R2 of 0.93, RPD of 2.22, the optimized calibration dataset number of 100, and the number of hidden neurons of 30. The results confirmed that ATR-FTIR, along with the suitable model algorithms, could be used as a potential rapid and accurate method to monitor the nitrate contents in the fields of agriculture and food safety. Graphical Abstract: [Figure not available: see fulltext.] © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Extreme learning machine; Leafy vegetables; Mid-infrared attenuated total reflectance; Nitrate","Absorption spectroscopy; Agricultural robots; Calibration; Fourier transform infrared spectroscopy; Infrared devices; Machine learning; Nitrates; Reflection; Supersaturation; Vegetables; Attenuated total reflectance; Coefficient of variation; Extreme learning machine; Fourier transform infra reds; Fourier transform mid infrared spectroscopy; Number of hidden neurons; Spectroscopic instrument; World Health Organization; Learning algorithms"
"Ma J., Zheng B., He Y.","Applications of a Hyperspectral Imaging System Used to Estimate Wheat Grain Protein: A Review","10.3389/fpls.2022.837200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128653888&doi=10.3389%2ffpls.2022.837200&partnerID=40&md5=0bec828a25be2ccf4887faab14389f7a","Recent research advances in wheat have focused not only on increasing grain yields, but also on establishing higher grain quality. Wheat quality is primarily determined by the grain protein content (GPC) and composition, and both of these are affected by nitrogen (N) levels in the plant as it develops during the growing season. Hyperspectral remote sensing is gradually becoming recognized as an economical alternative to traditional destructive field sampling methods and laboratory testing as a means of determining the N status within wheat. Currently, hyperspectral vegetation indices (VIs) and linear nonparametric regression are the primary tools for monitoring the N status of wheat. Machine learning algorithms have been increasingly applied to model the nonlinear relationship between spectral data and wheat N status. This study is a comprehensive review of available N-related hyperspectral VIs and aims to inform the selection of VIs under field conditions. The combination of feature mining and machine learning algorithms is discussed as an application of hyperspectral imaging systems. We discuss the major challenges and future directions for evaluating and assessing wheat N status. Finally, we suggest that the underlying mechanism of protein formation in wheat grains as determined by using hyperspectral imaging systems needs to be further investigated. This overview provides theoretical and technical support to promote applications of hyperspectral imaging systems in wheat N status assessments; in addition, it can be applied to help monitor and evaluate food and nutrition security. Copyright © 2022 Ma, Zheng and He.","grain protein; hyperspectral imaging; machine learning; vegetation index; wheat",
"Maas M.M.","Regulating for 'Normal AI Accidents': Operational Lessons for the Responsible Governance of Artificial Intelligence Deployment","10.1145/3278721.3278766","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061048031&doi=10.1145%2f3278721.3278766&partnerID=40&md5=7a41bf427f71da6042c413f724411fc5","New technologies, particularly those which are deployed rapidly across sectors, or which have to operate in competitive conditions, can disrupt previously stable technology governance regimes. This leads to a precarious need to balance caution against performance while exploring the resulting 'safe operating space'. This paper will argue that Artificial Intelligence is one such critical technology, the responsible deployment of which is likely to prove especially complex, because even narrow AI applications often involve networked (tightly coupled, opaque) systems operating in complex or competitive environments. This ensures such systems are prone to 'normal accident'-type failures which can cascade rapidly, and are hard to contain or even detect in time. Legal and governance approaches to the deployment of AI will have to reckon with the specific causes and features of such 'normal accidents'. While this suggests that large-scale, cascading errors in AI systems are inevitable, an examination of the operational features that lead technologies to exhibit 'normal accidents' enables us to derive both tentative principles for precautionary policymaking, and practical recommendations for the safe(r) deployment of AI systems. This may help enhance the safety and security of these systems in the public sphere, both in the short- and in the long term. © 2018 ACM.","ai and law; ethical design and development of ai systems; normal accident theory; trust and explanations in ai systems","Artificial intelligence; Philosophical aspects; AI and law; AI systems; Competitive environment; Critical technologies; LEAD Technologies; Normal accident theory; Practical recommendation; Safety and securities; Accidents"
"MacLeod N., Canty R.J., Polaszek A.","Morphology-Based Identification of Bemisia tabaci Cryptic Species Puparia via Embedded Group-Contrast Convolution Neural Network Analysis","10.1093/sysbio/syab098","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136074173&doi=10.1093%2fsysbio%2fsyab098&partnerID=40&md5=132dbb23bd58b32a2215014e8677cdbe","The Bemisia tabaci species complex is a group of tropical-subtropical hemipterans, some species of which have achieved global distribution over the past 150 years. Several species are regarded currently as among the world's most pernicious agricultural pests, causing a variety of damage types via direct feeding and plant-disease transmission. Long considered a single variable species, genetic, molecular and reproductive compatibility analyses have revealed that this ""species""is actually a complex of between 24 and 48 morphologically cryptic species. However, determinations of which populations represent distinct species have been hampered by a failure to integrate genetic/molecular and morphological species-diagnoses. This, in turn, has limited the success of outbreak-control and eradication programs. Previous morphological investigations, based on traditional and geometric morphometric procedures, have had limited success in identifying genetic/molecular species from patterns of morphological variation in puparia. As an alternative, our investigation focused on exploring the use of a deep-learning convolution neural network (CNN) trained on puparial images and based on an embedded, group-contrast training protocol as a means of searching for consistent differences in puparial morphology. Fifteen molecular species were selected for analysis, all of which had been identified via DNA barcoding and confirmed using more extensive molecular characterizations and crossing experiments. Results demonstrate that all 15 species can be discriminated successfully based on differences in puparium morphology alone. This level of discrimination was achieved for laboratory populations reared on both hairy-leaved and glabrous-leaved host plants. Moreover, cross-tabulation tests confirmed the generality and stability of the CNN discriminant system trained on both ecophenotypic variants. The ability to identify B. tabaci species quickly and accurately from puparial images has the potential to address many long-standing problems in B. tabaci taxonomy and systematics as well as playing a vital role in ongoing pest-management efforts. [Aleyrodidae; entomology; Hemiptera; machine learning; morphometrics; pest control; systematics; taxonomy; whiteflies.] © 2021 The Author(s). Published by Oxford University Press, on behalf of the Society of Systematic Biologists.",,
"Maddikunta P.K.R., Pham Q.-V., B P., Deepa N., Dev K., Gadekallu T.R., Ruby R., Liyanage M.","Industry 5.0: A survey on enabling technologies and potential applications","10.1016/j.jii.2021.100257","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125862007&doi=10.1016%2fj.jii.2021.100257&partnerID=40&md5=043dd2fed4f082e0f6f99afab5fcd8bc","Industry 5.0 is regarded as the next industrial evolution, its objective is to leverage the creativity of human experts in collaboration with efficient, intelligent and accurate machines, in order to obtain resource-efficient and user-preferred manufacturing solutions compared to Industry 4.0. Numerous promising technologies and applications are expected to assist Industry 5.0 in order to increase production and deliver customized products in a spontaneous manner. To provide a very first discussion of Industry 5.0, in this paper, we aim to provide a survey-based tutorial on potential applications and supporting technologies of Industry 5.0. We first introduce several new concepts and definitions of Industry 5.0 from the perspective of different industry practitioners and researchers. We then elaborately discuss the potential applications of Industry 5.0, such as intelligent healthcare, cloud manufacturing, supply chain management and manufacturing production. Subsequently, we discuss about some supporting technologies for Industry 5.0, such as edge computing, digital twins, collaborative robots, Internet of every things, blockchain, and 6G and beyond networks. Finally, we highlight several research challenges and open issues that should be further developed to realize Industry 5.0. © 2021 Elsevier Inc.","6G; Edge computing; Enabling technologies; Industry 5.0; Internet of Things; Pervasive AI","Edge computing; Industry 4.0; Supply chain management; Surveys; 6g; Edge computing; Enabling technologies; Human expert; Industrial evolution; Industry 5.0; Manufacturing solutions; Pervasive AI; Resource-efficient; Supporting technology; Internet of things"
"Madhumathi R., Arumuganathan T., Shruthi R.","Soil Nutrient Detection and Recommendation Using IoT and Fuzzy Logic","10.32604/csse.2022.023792","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129025762&doi=10.32604%2fcsse.2022.023792&partnerID=40&md5=53366cad7adad939038db51b839c30a8","Precision agriculture is a modern farming practice that involves the usage of Internet of Things (IoT) to provide an intelligent farm management system. One of the important aspects in agriculture is the analysis of soil nutrients and balancing these inputs are essential for proper crop growth. The crop productivity and the soil fertility can be improved with effective nutrient management and precise application of fertilizers. This can be done by identifying the deficient nutrients with the help of an IoT system. As traditional approach is time consuming, an IoT-enabled system is developed using the colorimetry principle which analyzes the amount of nutrients present in the soil and a fuzzy expert system is designed to recommend the quantity of fertilizers to be added in the soil. A set of 27 IF-THEN rules are framed using the Mamdani inference system by relating the input and output membership functions based on the linguistic variable for fertilizer recommendation. The experiments are conducted using MATLAB for different ranges of Nitrogen (N), Phosphorous (P) and Potassium (K). The NPK data retrieved by the system is sent to the ThingSpeak cloud and displayed on a mobile application that assists the farmers to know the nutrient information of their field. This system delivers the required nutrient information to farmers which results in efficient green farming. © 2022 CRL Publishing. All rights reserved.","fertilizer recommendation; fuzzy logic; internet of things; nutrient detection; Precision agriculture","Computer circuits; Crops; Expert systems; Internet of things; Membership functions; Nitrogen fertilizers; Nutrients; Precision agriculture; Soils; Analysis of soils; Crop growth; Farm management systems; Farming practices; Fertilizer recommendation; Fuzzy-Logic; Nutrient detection; Precision Agriculture; Soil nutrient detection; Soil nutrients; Fuzzy logic"
"Mahato P.K., Narayan A.","Robust Supply Chains with Gradient Boosted Trees","10.1109/SSCI47803.2020.9308150","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099697203&doi=10.1109%2fSSCI47803.2020.9308150&partnerID=40&md5=0e123107dde80d572424b09e9e7aa32e","Supply chain networks often experience various internal and external events that lead to shipment failures. Despite advancements in various machine learning models, the problem of avoiding service level failures remains intricate and hard to solve. While multiple attempts have been made by various researchers to make supply chains resilient, this is still an open problem. Moreover, explainability in the field of machine learning is a challenging task that assists in decision formation along with transparency.We develop a machine learning pipeline with gradient boosted decision trees to mitigate service level failures in supply chains. Our framework is simple, easy to implement, and provides a promising result. It provides explainability to prevent service level failure in time sensitive supply chains such as food manufacturing. Our model can be used for rapid deployment with state-of-the-art prediction accuracy while establishing trust within the decision-makers. © 2020 IEEE.","explainable AI; extreme gradient boosting (XGBoost); gradient boosting decision tree (GBDT); light gradient boosting machine (LightGBM); machine learning; Supply chain management","Decision making; Decision trees; Forestry; Intelligent computing; Machine learning; Turing machines; Boosted decision trees; Failure-in-time; Food manufacturing; Machine learning models; Prediction accuracy; Rapid deployments; State of the art; Supply chain network; Supply chains"
"Mahmood U., Li X., Fan Y., Chang W., Niu Y., Li J., Qu C., Lu K.","Multi-omics revolution to promote plant breeding efficiency","10.3389/fpls.2022.1062952","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144989979&doi=10.3389%2ffpls.2022.1062952&partnerID=40&md5=c6a5c968bdcac9aca7a768f2c97bb092","Crop production is the primary goal of agricultural activities, which is always taken into consideration. However, global agricultural systems are coming under increasing pressure from the rising food demand of the rapidly growing world population and changing climate. To address these issues, improving high-yield and climate-resilient related-traits in crop breeding is an effective strategy. In recent years, advances in omics techniques, including genomics, transcriptomics, proteomics, and metabolomics, paved the way for accelerating plant/crop breeding to cope with the changing climate and enhance food production. Optimized omics and phenotypic plasticity platform integration, exploited by evolving machine learning algorithms will aid in the development of biological interpretations for complex crop traits. The precise and progressive assembly of desire alleles using precise genome editing approaches and enhanced breeding strategies would enable future crops to excel in combating the changing climates. Furthermore, plant breeding and genetic engineering ensures an exclusive approach to developing nutrient sufficient and climate-resilient crops, the productivity of which can sustainably and adequately meet the world’s food, nutrition, and energy needs. This review provides an overview of how the integration of omics approaches could be exploited to select crop varieties with desired traits. Copyright © 2022 Mahmood, Li, Fan, Chang, Niu, Li, Qu and Lu.","breeding; genomics; metabolomics; multi-omics; proteomics; transcriptomics",
"Mahmoud H.A.H., Hakami N.A., Hafez A.M.","An Intelligent Deep Learning Model for CO2 Adsorption Prediction","10.1155/2022/8136302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130693682&doi=10.1155%2f2022%2f8136302&partnerID=40&md5=483890073f77b836da89a078e8598b87","In this paper, we propose a supervised deep learning neural network (D-CNN) approach to predict CO2 adsorption form the textural and compositional features of biomass porous carbon waste and adsorption features. Both the textural and compositional features of biomass porous carbon waste are utilized as inputs for the D-CNN architecture. A deep learning neural network (D-CNN) is proposed to predict the adsorption rate of CO2 on zeolites. The adsorbed amount will be classified and predicted by the D-CNN. Three tree machine learning models, namely, gradient decision model (GDM), scalable boosting tree model (SBT), and gradient variant decision tree model (GVD), were fused. A feature importance metric was proposed using feature permutation, and the effect of each feature on the target output variable was investigated. The important extracted features from the three employed model were fused and used as the fusion feature set in our proposed model: fusion matrix deep learning model (FMDL). A dataset of 1400 data items, on adsorbent type and various adsorption pressure, is used as inputs for the D-CNN model. Comparison of the proposed model is done against the three tree models, which utilizes a single training layer. The error measure of the D-CNN and the tree model architectures utilize the mean square error confirming the efficiency of 0.00003 for our model, 0.00062 for the SBT, 0.00091 for the GDM, and 0.00098 for the GVD, after 150 epochs. The produced weight matrix was able to predict the CO2 adsorption under diverse process settings with high accuracy of 96.4%. © 2022 Hanan Ahmed Hosni Mahmoud et al.",,"Adaptive boosting; Adsorption; Carbon; Carbon dioxide; Decision trees; Deep learning; Matrix algebra; Mean square error; Network architecture; Porous materials; Zeolites; Adsorption rates; Boosting trees; CO2 adsorption; Compositional features; Decision modeling; Learning models; Learning neural networks; Porous carbons; Textural feature; Tree modeling; Forecasting"
"Majid M., Habib S., Javed A.R., Rizwan M., Srivastava G., Gadekallu T.R., Lin J.C.-W.","Applications of Wireless Sensor Networks and Internet of Things Frameworks in the Industry Revolution 4.0: A Systematic Literature Review","10.3390/s22062087","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125951647&doi=10.3390%2fs22062087&partnerID=40&md5=16fdd1a051699a413166d8b12f4a16dc","The 21st century has seen rapid changes in technology, industry, and social patterns. Most industries have moved towards automation, and human intervention has decreased, which has led to a revolution in industries, named the fourth industrial revolution (Industry 4.0). Industry 4.0 or the fourth industrial revolution (IR 4.0) relies heavily on the Internet of Things (IoT) and wireless sensor networks (WSN). IoT and WSN are used in various control systems, including environmental monitoring, home automation, and chemical/biological attack detection. IoT devices and applications are used to process extracted data from WSN devices and transmit them to remote locations. This systematic literature review offers a wide range of information on Industry 4.0, finds research gaps, and recommends future directions. Seven research questions are addressed in this article: (i) What are the contributions of WSN in IR 4.0? (ii) What are the contributions of IoT in IR 4.0? (iii) What are the types of WSN coverage areas for IR 4.0? (iv) What are the major types of network intruders in WSN and IoT systems? (v) What are the prominent network security attacks in WSN and IoT? (vi) What are the significant issues in IoT and WSN frameworks? and (vii) What are the limitations and research gaps in the existing work? This study mainly focuses on research solutions and new techniques to automate Industry 4.0. In this research, we analyzed over 130 articles from 2014 until 2021. This paper covers several aspects of Industry 4.0, from the designing phase to security needs, from the deployment stage to the classification of the network, the difficulties, challenges, and future directions. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Computer networks; Industrial revolution 4.0 (IR 4.0); Internet of Things (IoT); Network security; State-of-the-art; Systematic literature review (SLR); Wireless sensor networks (WSN)","Chemical detection; Computer crime; Industry 4.0; Internet of things; Network security; Industrial revolution 4.0; Industrial revolutions; Internet of thing; Networks security; Research gaps; State of the art; Systematic literature review; Technology industry; Wireless sensor network; Wireless sensor networks; human; wireless communication; Humans; Internet of Things; Wireless Technology"
"Majumdar S., Smith R., Butler J.J., Jr., Lakshmi V.","Groundwater Withdrawal Prediction Using Integrated Multitemporal Remote Sensing Data Sets and Machine Learning","10.1029/2020WR028059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096221284&doi=10.1029%2f2020WR028059&partnerID=40&md5=dfd452f10eb988a189848be021d1e41f","Effective monitoring of groundwater withdrawals is necessary to help mitigate the negative impacts of aquifer depletion. In this study, we develop a holistic approach that combines water balance components with a machine learning model to estimate groundwater withdrawals. We use both multitemporal satellite and modeled data from sensors that measure different components of the water balance and land use at varying spatial and temporal resolutions. These remote sensing products include evapotranspiration, precipitation, and land cover. Due to the inherent complexity of integrating these data sets and subsequently relating them to groundwater withdrawals using physical models, we apply random forests—a state of the art machine learning algorithm—to overcome such limitations. Here, we predict groundwater withdrawals per unit area over a highly monitored portion of the High Plains aquifer in the central United States at 5 km resolution for the Years 2002–2019. Our modeled withdrawals had high accuracy on both training and testing data sets (R2 ≈ 0.99 and R2 ≈ 0.93, respectively) during leave-one-out (year) cross validation with low mean absolute error (MAE) ≈ 4.31 mm and root-mean-square error (RMSE) ≈ 13.50 mm for the year 2014. Moreover, we found that even for the extreme drought year of 2012, we have a satisfactory test score (R2 ≈ 0.84) with MAE ≈ 9.72 mm and RMSE ≈ 24.17 mm. Therefore, the proposed machine learning approach should be applicable to similar regions for proactive water management practices. ©2020. American Geophysical Union. All Rights Reserved.","Estimation and forecasting; Geospatial; Groundwater hydrology; Machine learning; Remote sensing; Time series analysis","Aquifers; Decision trees; Groundwater resources; Land use; Learning algorithms; Mean square error; Predictive analytics; Remote sensing; Turing machines; Water management; Groundwater withdrawal; Machine learning approaches; Machine learning models; Multi-temporal remote sensing; Multitemporal satellites; Root mean square errors; Spatial and temporal resolutions; Water balance components; Machine learning; aquifer; complexity; drought; holistic approach; land use change; machine learning; remote sensing; water management; Great Plains"
"Makridis G., Heyrman E., Kotios D., Mavrepis P., Callens B., De Vijver R.V., Maselyne J., Aluwé M., Kyriazis D.","Evaluating machine learning techniques to define the factors related to boar taint","10.1016/j.livsci.2022.105045","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135929528&doi=10.1016%2fj.livsci.2022.105045&partnerID=40&md5=148e40c36a8cd85318ebf9b8fe0ca70e","Several industries and sectors such as health care, agriculture, and finance exploit the added value of data to produce valuable insights for decision-making. The case of so-called ’boar taint’, the unwanted taste and odor that can be present in meat of entire male pigs, is one real-life scenario that showcases the added value of utilizing collected data. This information may yield insights for pig farmers about how they could adjust their management to reduce boar taint. This study examines multiple predictive data-driven approaches coupled with eXplainable AI (XAI) methods, evaluating them against various explainable metrics while trying to generate actionable insights and recommendations. Specifically, in this approach, the examined use case was modeled as a binary classification task resulting in a highly imbalanced dataset. This yielded some functional attributes regarding the farm/stable and slaughterhouse conditions, such as the type of feed, type of ventilation system, pharmaceutical treatment, floor type, and the duration of waiting in lairage. © 2022 Elsevier B.V.","Boar taint; Data analytics; Feature importance; Imbalanced data; Machine learning","agricultural land; agricultural worker; animal care; animal food; Article; artificial intelligence; boar (male pig); boar taint; building; controlled study; deep learning; evaluation research; factor analysis; food processing; genetic algorithm; information processing; lairage; machine learning; male; meat industry; nonhuman; organoleptic property; pharmaceutical care; pork; predictive model; room ventilation; slaughterhouse; statistical analysis"
"Malhi A., Apopei V., Madhikermi M., Mandeep, Främling K.","Smartphone Based Grape Leaf Disease Diagnosis and Remedial System Assisted with Explanations","10.1007/978-3-031-15565-9_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140485328&doi=10.1007%2f978-3-031-15565-9_4&partnerID=40&md5=be9d695909e6bc31235441e4988cdad4","Plant diseases are one of the biggest challenges faced by the agricultural sector due to the damage and economic losses in crops. Despite the importance, crop disease diagnosis is challenging because of the limited-resources farmers have. Subsequently, the early diagnosis of plant diseases results in considerable improvement in product quality. The aim of the proposed work is to design an ML-powered mobile-based system to diagnose and provide an explanation based remedy for the diseases in grape leaves using image processing and explainable artificial intelligence. The proposed system will employ the computer vision empowered with Machine Learning (ML) for plant disease recognition and explains the predictions while providing remedy for it. The developed system uses Convolutional Neural networks (CNN) as an underlying machine/deep learning engine for classifying the top disease categories and Contextual Importance and Utility (CIU) for localizing the disease areas based on prediction. The user interface is developed as an IOS mobile app, allowing farmers to capture a photo of the infected grape leaves. The system has been evaluated using various performance metrics such as classification accuracy and processing time by comparing with different state-of-the-art algorithms. The proposed system is highly compatible with the Apple ecosystem by developing IOS app with high prediction and response time. The proposed system will act as a prototype for the plant disease detector robotic system. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Agriculture; Grape leaf detection; Machine learning; Mobile app","Computer vision; Crops; Diagnosis; E-learning; Learning systems; Losses; Machine learning; Plants (botany); Smartphones; User interfaces; Agricultural sector; Disease diagnosis; Economic loss; Grape leaf detection; Grape leaves; Leaf disease; Machine-learning; Mobile app; Plant disease; Smart phones; Forecasting"
"Malik U.M., Javed M.A., Zeadally S., Islam S.U.","Energy-Efficient Fog Computing for 6G-Enabled Massive IoT: Recent Trends and Future Opportunities","10.1109/JIOT.2021.3068056","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103237714&doi=10.1109%2fJIOT.2021.3068056&partnerID=40&md5=d978d1837890b19e0007501083e4f075","Fog computing is a promising technology that can provide storage and computational services to future 6G networks. To support the massive Internet-of-Things (IoT) applications in 6G, fog computing will play a vital role. IoT devices and fog nodes have energy limitations and hence, energy-efficient techniques are needed for storage and computation services. We present an overview of massive IoT and 6G-enabling technologies. We discuss different energy-related challenges that arise while using fog computing in 6G-enabled massive IoT. We categorize different energy-efficient fog computing solutions for IoT and describe the recent work done in these categories. Finally, we discuss future opportunities and open challenges in designing energy-efficient techniques for fog computing in the future 6G massive IoT network. © 2014 IEEE.","6G; Energy efficiency; fog computing; massive Internet of Things (IoT); offloading","Energy efficiency; Fog; Internet of things; Storage as a service (STaaS); Computation service; Computing solutions; Enabling technologies; Energy efficient; Energy limitations; Energy-efficient techniques; Internet of Things (IOT); Recent trends; Fog computing"
"Maloney K.O., Buchanan C., Jepsen R.D., Krause K.P., Cashman M.J., Gressler B.P., Young J.A., Schmid M.","Explainable machine learning improves interpretability in the predictive modeling of biological stream conditions in the Chesapeake Bay Watershed, USA","10.1016/j.jenvman.2022.116068","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137046863&doi=10.1016%2fj.jenvman.2022.116068&partnerID=40&md5=cd21f218c02d1f1418f2f291894b7cc0","Anthropogenic alterations have resulted in widespread degradation of stream conditions. To aid in stream restoration and management, baseline estimates of conditions and improved explanation of factors driving their degradation are needed. We used random forests to model biological conditions using a benthic macroinvertebrate index of biotic integrity for small, non-tidal streams (upstream area ≤200 km2) in the Chesapeake Bay watershed (CBW) of the mid-Atlantic coast of North America. We utilized several global and local model interpretation tools to improve average and site-specific model inferences, respectively. The model was used to predict condition for 95,867 individual catchments for eight periods (2001, 2004, 2006, 2008, 2011, 2013, 2016, 2019). Predicted conditions were classified as Poor, FairGood, or Uncertain to align with management needs and individual reach lengths and catchment areas were summed by condition class for the CBW for each period. Global permutation and local Shapley importance values indicated percent of forest, development, and agriculture in upstream catchments had strong impacts on predictions. Development and agriculture negatively influenced stream condition for model average (partial dependence [PD] and accumulated local effect [ALE] plots) and local (individual condition expectation and Shapley value plots) levels. Friedman's H-statistic indicated large overall interactions for these three land covers, and bivariate global plots (PD and ALE) supported interactions among agriculture and development. Total stream length and catchment area predicted in FairGood conditions decreased then increased over the 19-years (length/area: 66.6/65.4% in 2001, 66.3/65.2% in 2011, and 66.6/65.4% in 2019). Examination of individual catchment predictions between 2001 and 2019 showed those predicted to have the largest decreases in condition had large increases in development; whereas catchments predicted to exhibit the largest increases in condition showed moderate increases in forest cover. Use of global and local interpretative methods together with watershed-wide and individual catchment predictions support conservation practitioners that need to identify widespread and localized patterns, especially acknowledging that management actions typically take place at individual-reach scales. © 2022","Benthic macroinvertebrates; Individual conditional expectation plots; Interpretable machine learning; Partial dependence and accumulated local effect plots; Random forests; Shapley values","machine learning; agriculture; article; catchment area; climate model; expectation; forest; human; land use; machine learning; macroinvertebrate; nonhuman; North America; physician; prediction; random forest; seashore; stream (river); bay; ecosystem; environmental monitoring; machine learning; procedures; river; Atlantic Ocean; Bay; Chesapeake Bay; North America; Somalia; United States; United States; Agriculture; Bays; Ecosystem; Environmental Monitoring; Machine Learning; Rivers"
"Maloney K.O., Krause K.P., Buchanan C., Hay L.E., McCabe G.J., Smith Z.M., Sohl T.L., Young J.A.","Disentangling the potential effects of land-use and climate change on stream conditions","10.1111/gcb.14961","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081759083&doi=10.1111%2fgcb.14961&partnerID=40&md5=7d284e0c6b99581364ef28f876ed7d97","Land-use and climate change are significantly affecting stream ecosystems, yet understanding of their long-term impacts is hindered by the few studies that have simultaneously investigated their interaction and high variability among future projections. We modeled possible effects of a suite of 2030, 2060, and 2090 land-use and climate scenarios on the condition of 70,772 small streams in the Chesapeake Bay watershed, United States. The Chesapeake Basin-wide Index of Biotic Integrity, a benthic macroinvertebrate multimetric index, was used to represent stream condition. Land-use scenarios included four Special Report on Emissions Scenarios (A1B, A2, B1, and B2) representing a range of potential landscape futures. Future climate scenarios included quartiles of future climate changes from downscaled Coupled Model Intercomparison Project - Phase 5 (CMIP5) and a watershed-wide uniform scenario (Lynch2016). We employed random forests analysis to model individual and combined effects of land-use and climate change on stream conditions. Individual scenarios suggest that by 2090, watershed-wide conditions may exhibit anywhere from large degradations (e.g., scenarios A1B, A2, and the CMIP5 25th percentile) to small degradations (e.g., scenarios B1, B2, and Lynch2016). Combined land-use and climate change scenarios highlighted their interaction and predicted, by 2090, watershed-wide degradation in 16.2% (A2 CMIP5 25th percentile) to 1.0% (B2 Lynch2016) of stream kilometers. A goal for the Chesapeake Bay watershed is to restore 10% of stream kilometers over a 2008 baseline; our results suggest meeting and sustaining this goal until 2090 may require improvement in 11.0%–26.2% of stream kilometers, dependent on land-use and climate scenario. These results highlight inherent variability among scenarios and the resultant uncertainty of predicted conditions, which reinforces the need to incorporate multiple scenarios of both land-use (e.g., development, agriculture, etc.) and climate change in future studies to encapsulate the range of potential future conditions. © 2020 The Authors. Global Change Biology published by John Wiley & Sons Ltd","benthic macroinvertebrates; Chesapeake Bay watershed; Chessie BIBI; prediction; projection","benthos; climate change; climate effect; freshwater ecosystem; land use change; macroinvertebrate; prediction; stream; watershed; Chesapeake Bay; United States"
"Mancipe-Castro L., Gutiérrez-Carvajal R.E.","Prediction of environment variables in precision agriculture using a sparse model as data fusion strategy","10.1016/j.inpa.2021.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109427669&doi=10.1016%2fj.inpa.2021.06.007&partnerID=40&md5=883a0dd3b3833573a6c9e65ef9ebf153","Precision agriculture seeks to optimize production processes by monitoring and analyzing environmental variables. For example, establishing farming actions on the crop requires analyzing variables such as temperature, ambient humidity, soil moisture, solar irradiance, and Rainfall. Although these signals might contain valuable information, it is vital to mix up the monitored signals and analyze them as a whole to provide more accurate information than analyzing the signals separately. Unfortunately, monitoring all these variables results in high costs. Hence it is necessary to establish an appropriate method that allows the infer variables behavior without the direct measurement of all of them. This paper introduces a multi-sensor data fusion technique, based on a sparse representation, to find the most straightforward and complete linear equation to predict and understand a particular variable behavior based on other monitored environmental variables measurements. Moreover, this approach aims to provide an interpretable model that allows understanding how these variables are combined to achieve such results. The fusion strategy explained in this manuscript follows a four-step process that includes 1. data cleaning, 2. redundant variable detection, 3. dictionary generation, and 4. sparse regression. The algorithm requires a target variable and two highly correlated signals. It is essential to point out that the developed method has no restrictions to specific variables. Consequently, it is possible to replicate this method for the semiautomatic prediction of multiple critical environmental variables. As a case study, this work used the SML2010 data set of the UCI machine learning repository to predicted the humidity's derivative trend function with an error rate lower than 17% and a mean absolute error lower than 6%. The experiment results show that even though sparse model predictions might not be the most accurate compared to those of linear regression (LR), support vector machine (SVM), and extreme learning machine (ELM) since it is not a black-box model, it guarantees greater interpretability of the problem. © 2021 China Agricultural University","Humidity; Inference of variables; Multi-sensor data fusion; Precision agriculture; Sparse representation","Agricultural robots; Forecasting; Precision agriculture; Sensor data fusion; Soil moisture; Support vector machines; Support vector regression; Data fusion strategy; Environmental variables; Extreme learning machine; Mean absolute error; Multisensor data fusion; Redundant variables; Sparse representation; UCI machine learning repository; Learning systems; air temperature; crop; environmental factor; humidity; irradiance; precision agriculture; prediction; rainfall; soil moisture"
"Manning L., Brewer S., Craigon P.J., Frey J., Gutierrez A., Jacobs N., Kanza S., Munday S., Sacks J., Pearson S.","Artificial intelligence and ethics within the food sector: Developing a common language for technology adoption across the supply chain","10.1016/j.tifs.2022.04.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129961048&doi=10.1016%2fj.tifs.2022.04.025&partnerID=40&md5=224469ae18f1670d458319cdb1de0b8c","Background: The use of artificial intelligence (AI) is growing in food supply chains. The ethical language associated with food supply and technology is contextualised and framed by the meaning given to it by stakeholders. Failure to differentiate between these nuanced meanings can create a barrier to technology adoption and reduce the benefit derived. Scope and approach: The aim of this review paper is to consider the embedded ethical language used by stakeholders who collaborate in the adoption of AI in food supply chains. Ethical perspectives frame this literature review and provide structure to consider how to shape a common discourse to build trust in, and frame more considered utilisation of, AI in food supply chains to the benefit of users, and wider society. Key findings and conclusions: Whilst the nature of data within the food system is much broader than the personal data covered by the European Union General Data Protection Regulation (GDPR), the ethical issues for computational and AI systems are similar and can be considered in terms of particular aspects: transparency, traceability, explainability, interpretability, accessibility, accountability and responsibility. The outputs of this research assist in giving a more rounded understanding of the language used, exploring the ethical interaction of aspects of AI used in food supply chains and also the management activities and actions that can be adopted to improve the applicability of AI technology, increase engagement and derive greater performance benefits. This work has implications for those developing AI governance protocols for the food supply chain as well as supply chain practitioners. © 2022 The Authors","Accessibility; Accountability; Artificial intelligence; Explainability; Interoperability; Responsibility","Economic and social effects; Ethical technology; Food supply; Supply chains; Accountability; Common languages; Ethical perspectives; Explainability; Food sector; Food supply chain; Literature reviews; Responsibility; Review papers; Technology adoption; Artificial intelligence"
"Mao D., Sun H., Li X., Yu X., Wu J., Zhang Q.","Real-time fruit detection using deep neural networks on CPU (RTFD): An edge AI application","10.1016/j.compag.2022.107517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145582517&doi=10.1016%2fj.compag.2022.107517&partnerID=40&md5=b7c249a9bbd4879ec72a992754df4e4f","Intelligent harvesting can greatly reduce the manual labor for fruit harvesting and is one of the main application areas of intelligent agricultural machinery. Smart edge sensors must detect the growth status of tomatoes and strawberries in real-time for intelligent harvesting to be possible. Due to edge devices' relatively low image processing power, it remains challenging to implement deep learning algorithms for real-time detection in field applications. Therefore, scholars are strongly interested in utilizing computationally small, accurate, and quick models for edge harvesting machinery. In this research, we propose RTFD, a lightweight algorithm for edge CPU devices that detects fruit. Based on the PicoDet-S model, RTFD optimizes the efficiency of real-time detection for edge CPU computing devices by enhancing the model's structure, loss function and activation function. The experimental results demonstrate that the mAP of RTFD for tomato and strawberry datasets at various growth phases is 0.78 and 0.96, respectively, with a computational effort of 1.44 GFLOPs. RTFD improves mAP by 1.9% and 2.3% on the tomato and strawberry datasets, respectively, with minimal loss in computation and model parameters, making it more suitable for edge device deployment. Meanwhile, we proposed an approach for 8-bit quantization-aware training of the Conv2D and Linear layers of the model for improved edge deployment. This approach quantizes 32-bit floating-point values in the Conv2D and Linear layers into 8-bit integers, thereby reducing the model's size and accelerating detection speed. The testing findings indicate that the quantized RTFD model has a size of 1.33 MB and a CPU detection speed of around 11 FPS. Using the quantified trained model, we developed the Android application RTFD-CPU to evaluate the model's performance in test scenarios. RTFD-CPU was assessed on the smartphone Redmi K30pro (Qualcomm Snapdragon 865 CPU and 8 GB of RAM) with a detection speed of 19 FPS utilizing only the CPU. In summary, the proposed RTFD has great potential for intelligent picking machines, and the concept of redesigning the model structure, loss function, and activation function, as well as training by quantization to speed up the detection of deep neural networks, is anticipated to be successfully implemented in edge computing. © 2022 Elsevier B.V.","Android; Edge devices; Lightweight; PicoDet-S; Quantization","Android (operating system); Chemical activation; Convolution; Digital arithmetic; Fruits; Image processing; Learning algorithms; Signal detection; Activation functions; Android; Detection speed; Edge device; Lightweight; Loss functions; Picodet-S; Quantisation; Real- time; Real-time detection; Deep neural networks; algorithm; artificial neural network; detection method; fruit; image processing; real time"
"Marcinko C.L.J., Samanta S., Basu O., Harfoot A., Hornby D.D., Hutton C.W., Pal S., Watmough G.R.","Earth observation and geospatial data can predict the relative distribution of village level poverty in the Sundarban Biosphere Reserve, India","10.1016/j.jenvman.2022.114950","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127178386&doi=10.1016%2fj.jenvman.2022.114950&partnerID=40&md5=9e05da2af4cf4ef2a5dc7ed8f84b0a08","There is increasing interest in leveraging Earth Observation (EO) and geospatial data to predict and map aspects of socioeconomic conditions to support survey and census activities. This is particularly relevant for the frequent monitoring required to assess progress towards the UNs' Sustainable Development Goals (SDGs). The Sundarban Biosphere Reserve (SBR) is a region of international ecological importance, containing the Indian portion of the world's largest mangrove forest. The region is densely populated and home to over 4.4 million people, many living in chronic poverty with a strong dependence on nature-based rural livelihoods. Such livelihoods are vulnerable to frequent natural hazards including cyclone landfall and storm surges. In this study we examine associations between environmental variables derived from EO and geospatial data with a village level multidimensional poverty metric using random forest machine learning, to provide evidence in support of policy formulation in the field of poverty reduction. We find that environmental variables can predict up to 78% of the relative distribution of the poorest villages within the SBR. Exposure to cyclone hazard was the most important variable for prediction of poverty. The poorest villages were associated with relatively small areas of rural settlement (<∼30%), large areas of agricultural land (>∼50%) and moderate to high cyclone hazard. The poorest villages were also associated with less productive agricultural land than the wealthiest. Analysis suggests villages with access to more diverse livelihood options, and a smaller dependence on agriculture may be more resilient to cyclone hazard. This study contributes to the understanding of poverty-environment dynamics within Low-and middle-income countries and the associations found can inform policy linked to socio-environmental scenarios within the SBR and potentially support monitoring of work towards SDG1 (No Poverty) across the region. © 2022 The Authors","Population environment; Poverty; Random forest; Remote sensing; SDGs; Socio-ecological systems","agricultural land; census; environmental factor; livelihood; machine learning; mangrove; natural hazard; poverty; prediction; rural area; socioeconomic conditions; Sustainable Development Goal; United Nations; vulnerability; agricultural land; agriculture; article; biosphere; ecosystem; human; India; machine learning; middle income country; poverty; prediction; random forest; remote sensing; storm surge; sustainable development goal; developing country; environmental protection; income; India; questionnaire; rural population; socioeconomics; India; Sundarbans National Park; West Bengal; Agriculture; Conservation of Natural Resources; Developing Countries; Humans; Income; India; Poverty; Rural Population; Socioeconomic Factors; Surveys and Questionnaires"
"Martin J.G., Muros F.J., Maestre J.M., Camacho E.F.","Multi-robot task allocation clustering based on game theory","10.1016/j.robot.2022.104314","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144537183&doi=10.1016%2fj.robot.2022.104314&partnerID=40&md5=182593b321ea70411f3f06ed0130dbe2","A cooperative game theory framework is proposed to solve multi-robot task allocation (MRTA) problems. In particular, a cooperative game is built to assess the performance of sets of robots and tasks so that the Shapley value of the game can be used to compute their average marginal contribution. This fact allows us to partition the initial MRTA problem into a set of smaller and simpler MRTA subproblems, which are formed by ranking and clustering robots and tasks according to their Shapley value. A large-scale simulation case study illustrates the benefits of the proposed scheme, which is assessed using a genetic algorithm (GA) as a baseline method. The results show that the game theoretical approach outperforms GA both in performance and computation time for a range of problem instances. © 2022 The Author(s)","Clustering; Cooperative game theory; Multi-robot systems (MRS); Multi-robot task allocation (MRTA); Shapley value; Task planning","Computation theory; Game theory; Industrial robots; Multipurpose robots; Robot programming; Allocation problems; Clusterings; Cooperative game theory; Multi-robot system; Multi-robot systems; Multi-robot task allocation; Performance; Shapley value; Task planning; Genetic algorithms"
"Martin T., Fuentes V., Valtchev P., Diallo A.B., Lacroix R., Boukadoum M., Leduc M.","Graph pattern mining on top of a domain ontology - Preliminary results from a dairy production application","10.1016/j.procs.2021.08.126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116918419&doi=10.1016%2fj.procs.2021.08.126&partnerID=40&md5=27e326dd963597300959d651a8ae32c0","A domain ontology (DO) is a machine-readable knowledge repository which, whenever properly exploited, can help to discover meaningful and intelligible patterns from compatible datasets. Yet since such data is naturally graph-shaped, the corresponding task amounts to mining what we call ontologically-generalized graph patterns. We study the underlying problem within a dairy production context where a dedicated DO has been designed beforehand. Two alternative mining approaches have been designed, both representing adaptations of methods from the literature. We evaluated them on an excerpt from our dairy production dataset and report here their respective limitations. We also sketch a way to approach the design of ontology-powered graph miner. © 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of KES International.","Dairy production; Generalized patterns; Graph data; Knowledge discovery from data; Ontologies; Pattern mining; Precision agriculture","Data mining; Precision agriculture; Dairy production; Domain ontologies; Generalized graphs; Generalized pattern; Graph data; Knowledge discovery from data; Knowledge repository; Ontology's; Pattern mining; Precision Agriculture; Ontology"
"Martin T., Diallo A.B., Valtchev P., Lacroix R.","Bridging the gap between an ontology and deep neural models by pattern mining",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095593537&partnerID=40&md5=f5932448c118de66392c6490555c1dd1","A domain ontology (DO) is a machine-readable knowledge repository compatible with the popular knowledge graph (KG) format. An intriguing question is how to leverage a DO plus a KG in a neural learning process. We propose to use ontology-rooted graph patterns mined from a DO-compatible graph translation of the raw data as a vector for injecting some domain knowledge into the neural network. Such patterns represent a frequently occurring regularities in the data yet they are expressed in terms of the ontological entities (classes, properties, etc.) and reflect additional knowledge from the KG. Using them as an additional input to the learning process seems a promising way to guide it towards improved explainability, accuracy and convergence, as well as, in a more general vein, increase the generalization power of the neural models. Copyright © 2020 for this paper by its authors.","Graph pattern mining; Knowledge graphs; Neural models; Ontologies","Data mining; Knowledge representation; Ontology; Turing machines; Additional knowledge; Domain knowledge; Domain ontologies; Graph translation; Intriguing questions; Knowledge graphs; Knowledge repository; Learning process; Learning systems"
"Martinetti D., Soubeyrand S.","Identifying lookouts for epidemio-surveillance: Application to the emergence of xylella fastidiosa in France","10.1094/PHYTO-07-18-0237-FI","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061128094&doi=10.1094%2fPHYTO-07-18-0237-FI&partnerID=40&md5=3212a9424a9dc29e8c999f27320436ee","Recent detections of Xylella fastidiosa in Corsica Island, France, has raised concerns on its possible spread to mainland France and the rest of the Mediterranean Basin. Early detection of infected plants is paramount to prevent the spread of the bacteria, but little is known about this pathosystem in European environments, hence standard surveillance strategies may be ineffective. We present a new methodological approach for the design of risk-based surveillance strategies, adapted to the emerging risk caused by X. fastidiosa. Our proposal is based on a combination of machine learning techniques and network analysis that aims at understanding the main abiotic drivers of the infection, produce risk maps and identify lookouts for the design of future surveillance plans. The identified drivers coincide with known results in laboratory studies about the correlation between environmental variables, such as water stress and temperature, and the presence of the bacterium in plants. Furthermore, the produced risk maps overlap nicely with detected foci of infection, while they also highlight other susceptible regions where X. fastidiosa has not been found yet. We conclude the paper presenting a list of recommended regions for a risk-based surveillance campaign based on the predicted spread and probability of early detection of the disease. © 2019 The American Phytopathological Society.","Epidemiology","France; microbiology; plant disease; Xylella; France; Plant Diseases; Xylella"
"Martinez-Millana A., Saez-Saez A., Tornero-Costa R., Azzopardi-Muscat N., Traver V., Novillo-Ortiz D.","Artificial intelligence and its impact on the domains of universal health coverage, health emergencies and health promotion: An overview of systematic reviews","10.1016/j.ijmedinf.2022.104855","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136110685&doi=10.1016%2fj.ijmedinf.2022.104855&partnerID=40&md5=221e072ad9976aa5ed8f121d7622e6c6","Background: Artificial intelligence is fueling a new revolution in medicine and in the healthcare sector. Despite the growing evidence on the benefits of artificial intelligence there are several aspects that limit the measure of its impact in people's health. It is necessary to assess the current status on the application of AI towards the improvement of people's health in the domains defined by WHO's Thirteenth General Programme of Work (GPW13) and the European Programme of Work (EPW), to inform about trends, gaps, opportunities, and challenges. Objective: To perform a systematic overview of systematic reviews on the application of artificial intelligence in the people's health domains as defined in the GPW13 and provide a comprehensive and updated map on the application specialties of artificial intelligence in terms of methodologies, algorithms, data sources, outcomes, predictors, performance, and methodological quality. Methods: A systematic search in MEDLINE, EMBASE, Cochrane and IEEEXplore was conducted between January 2015 and June 2021 to collect systematic reviews using a combination of keywords related to the domains of universal health coverage, health emergencies protection, and better health and wellbeing as defined by the WHO's PGW13 and EPW. Eligibility criteria was based on methodological quality and the inclusion of practical implementation of artificial intelligence. Records were classified and labeled using ICD-11 categories into the domains of the GPW13. Descriptors related to the area of implementation, type of modeling, data entities, outcomes and implementation on care delivery were extracted using a structured form and methodological aspects of the included reviews studies was assessed using the AMSTAR checklist. Results: The search strategy resulted in the screening of 815 systematic reviews from which 203 were assessed for eligibility and 129 were included in the review. The most predominant domain for artificial intelligence applications was Universal Health Coverage (N = 98) followed by Health Emergencies (N = 16) and Better Health and Wellbeing (N = 15). Neoplasms area on Universal Health Coverage was the disease area featuring most of the applications (21.7 %, N = 28). The reviews featured analytics primarily over both public and private data sources (67.44 %, N = 87). The most used type of data was medical imaging (31.8 %, N = 41) and predictors based on regions of interest and clinical data. The most prominent subdomain of Artificial Intelligence was Machine Learning (43.4 %, N = 56), in which Support Vector Machine method was predominant (20.9 %, N = 27). Regarding the purpose, the application of Artificial Intelligence I is focused on the prediction of the diseases (36.4 %, N = 47). With respect to the validation, more than a half of the reviews (54.3 %, N = 70) did not report a validation procedure and, whenever available, the main performance indicator was the accuracy (28.7 %, N = 37). According to the methodological quality assessment, a third of the reviews (34.9 %, N = 45) implemented methods for analysis the risk of bias and the overall AMSTAR score below was 5 (4.01 ± 1.93) on all the included systematic reviews. Conclusion: Artificial intelligence is being used for disease modelling, diagnose, classification and prediction in the three domains of GPW13. However, the evidence is often limited to laboratory and the level of adoption is largely unbalanced between ICD-11 categoriesand diseases. Data availability is a determinant factor on the developmental stage of artificial intelligence applications. Most of the reviewed studies show a poor methodological quality and are at high risk of bias, which limits the reproducibility of the results and the reliability of translating these applications to real clinical scenarios. The analyzed papers show results only in laboratory and testing scenarios and not in clinical trials nor case studies, limiting the supporting evidence to transfer artificial intelligence to actual care delivery. © 2022","European region; Health and well-being; Health emergencies; Machine learning; Universal health coverage","Decision making; Diagnosis; Medical imaging; Data-source; European program; European regions; Health and well-being; Health emergencies; Machine-learning; Programme of work; Systematic Review; Universal health coverage; Well being; Machine learning; A Measurement Tool to Assess Systematic Reviews; algorithm; artificial intelligence; deep learning; emergency; health care delivery; health insurance; health promotion; human; machine learning; methodology; neoplasm; outcome assessment; quality control; Review; support vector machine; systematic review; emergency; health promotion; reproducibility; Artificial Intelligence; Emergencies; Health Promotion; Humans; Reproducibility of Results; Systematic Reviews as Topic; Universal Health Insurance"
"Martinsen K.T., Sand-Jensen K.","Predicting water quality from geospatial lake, catchment, and buffer zone characteristics in temperate lowland lakes","10.1016/j.scitotenv.2022.158090","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136588372&doi=10.1016%2fj.scitotenv.2022.158090&partnerID=40&md5=b5bf5c234c2845c87fa63c5cc5b4ad43","Lakes provide essential ecosystem services and strongly influence landscape nutrient and carbon cycling. Therefore, monitoring water quality is essential for the management of element transport, biodiversity, and public goods in lakes. We investigated the ability of machine learning models to predict eight important water quality variables (alkalinity, pH, total phosphorus, total nitrogen, chlorophyll a, Secchi depth, color, and pCO2) using monitoring data from 924 to 1054 lakes. The geospatial predictor variables comprise a wide range of potential drivers at the lake, buffer zone, and catchment level. We compared the performance of nine predictive models of varying complexity for each of the eight water quality variables. The best models (Random Forest and Support Vector Machine in six and two cases, respectively) generally performed well on the test set (R2 = 0.28–0.60). Models were then used to predict water quality for all 180,377 mapped Danish lakes. Additionally, we trained models to predict each water quality variable by using the predictions we had generated for the remaining seven variables. This improved model performance (R2 = 0.45–0.78). Overall, the uncovered relationships were in line with the findings of previous studies, e.g., total nitrogen was positively related to catchment agriculture and chlorophyll a, Secchi depth, and alkalinity were influenced by soil type and landscape history. Remarkably, buffer zone geomorphology (curvature, ruggedness, and elevation) had a strong influence on nutrients, chlorophyll a, and Secchi depth, e.g., curvature was positively related to nutrients and chlorophyll a and negatively to Secchi depth. Lake area was a strong predictor of multiple variables, especially its relationship with pH (positive), pCO2 (negative), and color (negative). Our analysis shows that the combination of machine learning methods and geospatial data can be used to predict lake water quality and improve national upscaling of predictions related to nutrient and carbon cycling. © 2022 The Authors","Carbon dioxide; Geomorphology; Machine learning; Nutrients; Predictive modeling; Watershed","Alkalinity; Antennas; Biodiversity; Carbon dioxide; Catchments; Chlorophyll; Ecosystems; Forecasting; Geomorphology; Lakes; Landforms; Nitrogen; Nutrients; Runoff; Support vector machines; Water quality; Buffer zones; Carbon cycling; Chlorophyll a; Geo-spatial; Machine-learning; Nutrients cycling; Predictive models; Secchi depth; Total nitrogen; Water quality variables; Decision trees; carbon dioxide; chlorophyll a; nitrogen; phosphorus; carbon; chlorophyll a; nitrogen; phosphorus; carbon dioxide; catchment; geomorphology; lowland environment; machine learning; nutrient dynamics; prediction; temperate environment; water quality; watershed; agriculture; alkalinity; Article; catchment area (hydrology); environmental monitoring; geomorphology; lake; machine learning; pH; prediction; random forest; support vector machine; water quality; watershed; ecosystem; procedures; soil; Carbon; Chlorophyll A; Ecosystem; Environmental Monitoring; Nitrogen; Phosphorus; Soil; Water Quality"
"Marzi D., Dell'acqua F.","An Experiment on Extended, Satellite-Based Traceability of Organic Crops in North-Western Italy","10.1109/IGARSS46834.2022.9883883","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140363624&doi=10.1109%2fIGARSS46834.2022.9883883&partnerID=40&md5=ff2a3386835cb50f7aaf65ee9932071f","In this work, we investigate how time series of the Normal-ized Differential Vegetation Index (NDVI) can provide use-ful clues to enhance the traceability of organic food, and dis-cuss the possibility to use machine learning in this context. Crop rotation, non-chemical weed control operations such as 'green mulching', fertilization, water supply management, all reflect into variables that are observable from space and may help reassuring the consumer that the traceable food they are purchasing matches the declared standards of sustainability and organic compliance. In this study we address detection of green mulching and weeding, based on experiments on a set of rice fields in North-ern Italy. Our findings suggest that the cover crops associated with green mulching can be confirmed and weeding can be detected using data from the Sentinel-2 satellite constellation, whereas fertilization is far more difficult to detect correctly. The cost associated with procuring training data seems to dis-courage the use of machine learning at this stage. © 2022 IEEE.","Copernicus; Machine Learning; Organic farming; Remote sensing; Sentinel-2; Traceability","Crop rotation; Machine learning; Regulatory compliance; Water management; Water supply; Weed control; Copernicu; Fertilisation; Machine-learning; Organic farming; Organics; Remote-sensing; Sentinel-2; Times series; Traceability; Vegetation index; Remote sensing"
"Masuda K., Suzuki M., Baba K., Takeshita K., Suzuki T., Sugiura M., Niikawa T., Uchida S., Akagi T.","Noninvasive diagnosis of seedless fruit using deep learning in persimmon","10.2503/hortj.UTD-248","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105264981&doi=10.2503%2fhortj.UTD-248&partnerID=40&md5=d0835e438bbfbf315bc7db3b58d10af3","Noninvasive diagnosis of internal traits in fruit crops is a high unmet need; however it generally requires time, costs, and special methods or facilities. Recent progress in deep neural network (or deep learning) techniques would allow easy, but highly accurate diagnosis with single RGB images, and the latest applications enable visualization of “the reasons for each diagnosis” by backpropagation of neural networks. Here, we propose an application of deep learning for image diagnosis on the classification of internal fruit traits, in this case seedlessness, in persimmon fruit (Diospyros kaki). We examined the classification of seedlessness in persimmon fruit by using four convolutional neural networks (CNN) models with various layer structures. With only 599 pictures of ‘Fuyu’ persimmon fruit from the fruit apex side, the neural networks successfully made a binary classification of seedless and seeded fruits with up to 85% accuracy. Among the four CNN models, the VGG16 model with the simplest layer structure showed the highest classification accuracy of 89%. Prediction values for the binary classification of seeded fruits were significantly increased in proportion to seed numbers in all four CNN models. Furthermore, explainable AI methods, such as Gradient-weighted Class Activation Mapping (Grad-CAM) and Guided Grad-CAM, allowed visualization of the parts and patterns contributing to the diagnosis. The results indicated that finer positions surrounding the apex, which correspond to hypothetical bulges derived from seeds, are an index for seeded fruits. These results suggest the novel potential of deep learning for noninvasive diagnosis of fruit internal traits using simple RGB images and also provide novel insights into previously unrecognized features of seeded/seedless fruits. © 2021 The Japanese Society for Horticultural Science (JSHS), All rights reserved.","Convolution neural network; Fruit internal trait; Image diagnosis; Seed number; Visual explanations",
"Mateo-Sanchis A., Piles M., Amorós-López J., Muñoz-Marí J., Adsuara J.E., Moreno-Martínez Á., Camps-Valls G.","Learning main drivers of crop progress and failure in Europe with interpretable machine learning","10.1016/j.jag.2021.102574","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121716230&doi=10.1016%2fj.jag.2021.102574&partnerID=40&md5=0c4ca82f01e9a5a919f7245a4fcce127","A wide variety of methods exist nowadays to address the important problem of estimating crop yields from available remote sensing and climate data. Among the different approaches, machine learning (ML) techniques are being increasingly adopted, since they allow exploiting all the information on crop progress and environmental conditions and their relations with crop yield, achieving reliable and accurate estimations. However, interpreting the relationships learned by the ML models, and hence getting insights about the problem, remains a complex and usually unexplored task. Without accountability, confidence and trust in the ML models can be compromised. Here, we develop interpretable ML approaches for crop yield estimation that allow us investigating the most informative agro-ecological drivers and influencial regions learned by the models. We conduct a set of experiments to learn the selection of agro-ecological drivers leading to best estimations of main crops grown in Europe: corn, barley and wheat. As input data, we consider a variety of multi-scale Earth observation products sensitive to canopy greenness (e.g. EVI and LAI), its water-uptake dynamics (e.g. VOD) and available water (soil moisture), as well as climatic variables from the ERA5-Land reanalysis (e.g. temperature and radiation). Our results show that the best performances (R2&gt;0.55 for corn and R2&gt;0.8 for both barley and wheat) are obtained when descriptors of soil, vegetation, and atmosphere status are used as input in the ML models. This combination of variables outperforms the results obtained using single variables as inputs or all variables altogether. We then further analyze the relations of input features with crop yield in the developed models by means of Gaussian Process Regression (GPR). We show how the information learned by the GPR model allows us to identify atypical or anomalous crop seasons across the study region, and investigate the underlying factors behind crop progress and failure in Europe. © 2021","Crop Yield Estimation; ERA5-Land; Gaussian Process; Interpretability; Machine Learning; MODIS; Optical and Passive Microwave sensors","crop yield; environmental conditions; Gaussian method; machine learning; MODIS; remote sensing; sensor; Europe"
"Mathew S., Pulugurtha S.S.","Comparative Assessment of Geospatial and Statistical Methods to Estimate Local Road Annual Average Daily Traffic","10.1061/JTEPBS.0000542","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105893535&doi=10.1061%2fJTEPBS.0000542&partnerID=40&md5=7fceecbe834772394c72d737e09efe8b","Collecting traffic data and/or estimating and reporting annual average daily traffic (AADT) is important for planning, designing, building, and maintaining the road infrastructure. However, AADT is not available for most local functionally classified roads (referred to as local roads in this paper), which comprise a major proportion of the roads in the United States. The AADT of a local road depends on geospatial data such as road density, socioeconomic and demographic characteristics, and proximity to the nearest nonlocal road. The suitability of these explanatory variables for modeling local road AADT has not been widely explored, nor have methodological approaches been comprehensively compared in the past. Therefore, the focus of this research is on exploring geospatial and statistical methods and conducting a comparative assessment to estimate local road AADT. The AADT based on traffic counts collected at 12,899 stations on local roads in North Carolina during 2014, 2015, and 2016 was considered in model development and validation. The road, socioeconomic, and demographic characteristics based on the data gathered from the North Carolina Department of Transportation (NCDOT) for 2015 were considered as the explanatory variables. Five different modeling methods were examined and compared to estimate AADT on local road links. They include traditional ordinary least squares (OLS) regression, geographically weighted regression (GWR), and geospatial interpolation methods such as kriging, inverse distance weighting (IDW), and natural neighbor interpolation. The model development and validation results showed that the GWR model performed better compared with the other considered geospatial and statistical methods. The GWR model can better capture the effect of geospatial variations in the data, by geographic location, when estimating local road AADT. Local road AADT estimates help practitioners in planning and prioritizing road infrastructure projects for future improvements and air quality estimates, in addition to Highway Safety Improvement Program (HSIP) and Highway Performance Monitoring System (HPMS) reporting. © 2021 American Society of Civil Engineers.","Annual average daily traffic (AADT); Geographic information system (GIS); Geographically weighted regression (GWR); Kriging; Local road","Air quality; Interpolation; Inverse problems; Least squares approximations; Motor transportation; Population statistics; Roads and streets; Annual average daily traffics; Demographic characteristics; Geographically weighted regression; Geospatial interpolations; Highway performance monitoring systems; Inverse distance weighting; Natural neighbor interpolation; North carolina department of transportations; Highway planning; comparative study; estimation method; GIS; kriging; regression analysis; road traffic; road transport; North Carolina; United States; Rosa carolina carolina"
"Maximova I., Vasiliev E., Getmanskaya A., Kior D., Sukhov V., Vodeneev V., Turlapov V.","Study of XAI-capabilities for early diagnosis of plant drought","10.1109/IJCNN52387.2021.9534105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116465963&doi=10.1109%2fIJCNN52387.2021.9534105&partnerID=40&md5=a3f361e4404f254b20adb4fd0721d878","The Single Layer Perceptron (SLP) has been studied as an Explainable Artificial Intelligence (XAI) Interactive Unit. On the basis of SLP(N), with an arbitrary number N of neurons on the hidden layer, two models were built: classification and regression. To achieve interactivity, the training on images is replaced by training on its feature vectors. The feature vector includes the results of image processing in three different ways, forming 3 feature groups: STAT mean, std, min, max; HIST - values of the quantized histogram; GLCM (gray-level co-occurrence matrix) - textural features. To give XAI properties to the models, they are equipped with tools for analyzing and visualizing the weight and efficiency of the components of the feature vector. It is also possible to optimize the classifier and regressor by the number of neurons, features, and quantization levels (histogram bins and gray levels for GLCM). The study was carried out on the example of the problem of early diagnosis of drought stress in wheat plants, recorded by sensors of two different types: Thermal IR (TIR) and RGB. The problems of stress classification and prediction (regression) of the duration of a plant being under stress are solved. The SLP classifier and the SLP regressor are also used as tools for analyzing the stress features efficiency. Two groups of grayscale NDVI (normalized difference vegetation index) images were used as source data: TIR-based; RGB-based. Replacing source images onto their feature vectors gave to reduce the training time of the models to a fraction of a second. The weights and the influence of drought stress features on the efficiency of classification and regression for both types of source images were shown, and SLP models were optimized. Software tools: pytorch, scikit-image, scikit-learn. © 2021 IEEE.","early diagnosis; explainable artificial intelligence; plant drought; wheat","Artificial intelligence; Diagnosis; Efficiency; Graphic methods; Image processing; Regression analysis; Vectors; Drought stress; Early diagnosis; Explainable artificial intelligence; Features vector; Gray-level co-occurrence matrix; Grey-level co-occurrence matrixes; Plant drought; Single-layer perceptrons; Thermal IR; Wheat; Drought"
"Maxwell A.E., Shobe C.M.","Land-surface parameters for spatial predictive mapping and modeling","10.1016/j.earscirev.2022.103944","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124210447&doi=10.1016%2fj.earscirev.2022.103944&partnerID=40&md5=626402aadbb1b3b4bdee433e22cb002c","Land-surface parameters derived from digital land surface models (DLSMs) (for example, slope, surface curvature, topographic position, topographic roughness, aspect, heat load index, and topographic moisture index) can serve as key predictor variables in a wide variety of mapping and modeling tasks relating to geomorphic processes, landform delineation, ecological and habitat characterization, and geohazard, soil, wetland, and general thematic mapping and modeling. However, selecting features from the large number of potential derivatives that may be predictive for a specific feature or process can be complicated, and existing literature may offer contradictory or incomplete guidance. The availability of multiple data sources and the need to define moving window shapes, sizes, and cell weightings further complicate selecting and optimizing the feature space. This review focuses on the calculation and use of DLSM parameters for empirical spatial predictive modeling applications, which rely on training data and explanatory variables to make predictions of landscape features and processes over a defined geographic extent. The target audience for this review is researchers and analysts undertaking predictive modeling tasks that make use of the most widely used terrain variables. To outline best practices and highlight future research needs, we review a range of land-surface parameters relating to steepness, local relief, rugosity, slope orientation, solar insolation, and moisture and characterize their relationship to geomorphic processes. We then discuss important considerations when selecting such parameters for predictive mapping and modeling tasks to assist analysts in answering two critical questions: What landscape conditions or processes does a given measure characterize? How might a particular metric relate to the phenomenon or features being mapped, modeled, or studied? We recommend the use of landscape- and problem-specific pilot studies to answer, to the extent possible, these questions for potential features of interest in a mapping or modeling task. We describe existing techniques to reduce the size of the feature space using feature selection and feature reduction methods, assess the importance or contribution of specific metrics, and parameterize moving windows or characterize the landscape at varying scales using alternative methods while highlighting strengths, drawbacks, and knowledge gaps for specific techniques. Recent developments, such as explainable machine learning and convolutional neural network (CNN)-based deep learning, may guide and/or minimize the need for feature space engineering and ease the use of DLSMs in predictive modeling tasks. © 2022 The Authors","Digital elevation model; Digital land surface model; Geomorphometry; Land-surface parameters; Landforms; machine learning; Spatial predictive modeling","artificial neural network; digital elevation model; geomorphology; land surface; machine learning; modeling; morphometry; parameterization; thematic mapping"
"Mazhar T., Irfan H.M., Haq I., Ullah I., Ashraf M., Shloul T.A., Ghadi Y.Y., Imran, Elkamchouchi D.H.","Analysis of Challenges and Solutions of IoT in Smart Grids Using AI and Machine Learning Techniques: A Review","10.3390/electronics12010242","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145886934&doi=10.3390%2felectronics12010242&partnerID=40&md5=609d748f1d064d7f860f71e3859444b0","With the assistance of machine learning, difficult tasks can be completed entirely on their own. In a smart grid (SG), computers and mobile devices may make it easier to control the interior temperature, monitor security, and perform routine maintenance. The Internet of Things (IoT) is used to connect the various components of smart buildings. As the IoT concept spreads, SGs are being integrated into larger networks. The IoT is an important part of SGs because it provides services that improve everyone’s lives. It has been established that the current life support systems are safe and effective at sustaining life. The primary goal of this research is to determine the motivation for IoT device installation in smart buildings and the grid. From this vantage point, the infrastructure that supports IoT devices and the components that comprise them is critical. The remote configuration of smart grid monitoring systems can improve the security and comfort of building occupants. Sensors are required to operate and monitor everything from consumer electronics to SGs. Network-connected devices should consume less energy and be remotely monitorable. The authors’ goal is to aid in the development of solutions based on AI, IoT, and SGs. Furthermore, the authors investigate networking, machine intelligence, and SG. Finally, we examine research on SG and IoT. Several IoT platform components are subject to debate. The first section of this paper discusses the most common machine learning methods for forecasting building energy demand. The authors then discuss IoT and how it works, in addition to the SG and smart meters, which are required for receiving real-time energy data. Then, we investigate how the various SG, IoT, and ML components integrate and operate using a simple architecture with layers organized into entities that communicate with one another via connections. © 2023 by the authors.","Artificial Intelligence (AI); Internet of Things (IoT); machine learning; smart buildings; Smart Grid (SG)",
"McAllister R., Sheppard J.","Exploring Transferability in Deep Neural Networks with Functional Data Analysis and Spatial Statistics","10.1109/IJCNN.2019.8851994","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073214843&doi=10.1109%2fIJCNN.2019.8851994&partnerID=40&md5=676e86f29a7ece1e738b1b459a601199","Recent advances in machine learning have brought with them considerable attention in applying such methods to complex prediction problems. However, in extremely large datas-paces, a single neural network covering that space may not be effective, and generating large numbers of deep neural networks is not feasible. In this paper, we analyze deep networks trained from stacked autoencoders in a spatio-temporal application area to determine the extent to which knowledge can be transferred to similar regions. Our analysis applies methods from functional data analysis and spatial statistics to identify such correlation. We apply this work in the context of numerical weather prediction in analyzing large-scale data from Hurricane Sandy. Results of our analysis indicate high likelihood that spatial correlation can be exploited if it can be identified prior to training. © 2019 IEEE.",,"Data handling; Hurricanes; Information analysis; Spatial variables measurement; Weather forecasting; Autoencoders; Functional data analysis; Large scale data; Numerical weather prediction; Prediction problem; Spatial correlations; Spatial statistics; Spatio-temporal applications; Deep neural networks"
"McCormick R.F., Truong S.K., Rotundo J., Gaspar A.P., Kyle D., Van Eeuwijk F., Messina C.D.","Intercontinental prediction of soybean phenology via hybrid ensemble of knowledge-based and data-driven models","10.1093/insilicoplants/diab004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107972460&doi=10.1093%2finsilicoplants%2fdiab004&partnerID=40&md5=1cdca4434e3a77ef5b67bcfd820fa3e2","The timing of crop development has significant impacts on management decisions and subsequent yield formation. A large intercontinental dataset recording the timing of soybean developmental stages was used to establish ensembling approaches that leverage both knowledge-based, human-defined models of soybean phenology and data-driven, machine-learned models to achieve accurate and interpretable predictions. We demonstrate that the knowledge-based models can improve machine learning by generating expert-engineered features. The collection of knowledge-based and data-driven models was combined via super learning to both improve prediction and identify the most performant models. Stacking the predictions of the component models resulted in a mean absolute error of 4.41 and 5.27 days to flowering (R1) and physiological maturity (R7), providing an improvement relative to the benchmark knowledge-based model error of 6.94 and 15.53 days, respectively, in cross-validation. The hybrid intercontinental model applies to a much wider range of management and temperature conditions than previous mechanistic models, enabling improved decision support as alternative cropping systems arise, farm sizes increase and changes in the global climate continue to accelerate. © 2021 The Author(s) 2021. Published by Oxford University Press on behalf of the Annals of Botany Company.","crop model; ensemble; machine learning; phenology; soybean; super learner",
"Meena P., Kumar G.","Online food delivery companies' performance and consumers expectations during Covid-19: An investigation using machine learning approach","10.1016/j.jretconser.2022.103052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137529140&doi=10.1016%2fj.jretconser.2022.103052&partnerID=40&md5=729b14b86714b430f38472bbe679d463","Online food delivery (OFD) businesses flourished during COVID-19; however, OFD companies experienced different challenges and customers' expectations. This paper uses social media data to explore OFD companies' performance and customers' expectations during the COVID-19 pandemic. The most important topics in developed and developing countries are identified using machine learning. Results show that customers in India are more concerned about social responsibility, while financial aspects are more important in the US. Overall, customers in India are more satisfied with OFD companies during the COVID-19 pandemic than the US customers. We further find that factors such as OFD companies' brand, market size, country, and COVID-19 waves play a crucial role in moderating customer sentiment. The results of the study offer several managerial insights. © 2022 Elsevier Ltd","Consumer sentiment; COVID-19; Online food delivery; Performance; Social responsibility; Topic modeling","consumption behavior; corporate social responsibility; COVID-19; food market; industrial performance; machine learning; modeling; service sector; social media; India; United States"
"Mehdizadeh S., Mohammadi B., Ahmadi F.","Establishing Coupled Models for Estimating Daily Dew Point Temperature Using Nature-Inspired Optimization Algorithms","10.3390/hydrology9010009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123742521&doi=10.3390%2fhydrology9010009&partnerID=40&md5=e1fceb5da74757cecbe8b55e08162e51","Potential of a classic adaptive neuro-fuzzy inference system (ANFIS) was evaluated in the current study for estimating the daily dew point temperature (Tdew). The study area consists of two stations located in Iran, namely the Rasht and Urmia. The daily Tdew time series of the studied stations were modeled through the other effective variables comprising minimum air temperature (Tmin), extraterrestrial radiation (Ra), vapor pressure deficit (VPD), sunshine duration (n), and relative humidity (RH). The correlation coefficients between the input and output parameters were utilized to determine the most effective inputs. Furthermore, novel hybrid models were proposed in this study in order to increase the estimation accuracy of Tdew. For this purpose, two optimization algorithms named bee colony optimization (BCO) and dragonfly algorithm (DFA) were coupled on the classic ANFIS. It was concluded that the hybrid models (i.e., ANFIS-BCO and ANFIS-DFA) demonstrated better performances compared to the classic ANFIS. The full-input pattern of the coupled models, specifically the ANFIS-DFA, was found to present the most accurate results for both the selected stations. Therefore, the developed hybrid models can be proposed as alternatives to the classic ANFIS to accurately estimate the daily Tdew. © 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https:// creativecommons.org/licenses/by/ 4.0/).","Artificial intelligence; Bee colony optimization; Dew point temperature; Dragonfly algorithm; Hydrological modeling; Soft computing",
"Mehedi M.H.K., Hosain A.K.M.S., Ahmed S., Promita S.T., Muna R.K., Hasan M., Reza M.T.","Plant Leaf Disease Detection using Transfer Learning and Explainable AI","10.1109/IEMCON56893.2022.9946513","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143639147&doi=10.1109%2fIEMCON56893.2022.9946513&partnerID=40&md5=5ece4c4b9b3b9e3345210d36d8a6bfd7","Among the major occupational sectors around the world, agriculture has the highest level of involvement. Every year, this sector faces a substantial loss in production and profit due to a large number of diseases in crops and plants. If those diseases are not detected early and taken measures for prevention, it can bring about a devastating result that can financially burden agriculture personnel. Traditional methods of detecting diseases in plants and crops offer high accuracy. However, the procedure is time-consuming, which might be insidious in most cases. Crop diseases need to be detected and cured as soon as possible as most diseases are highly contagious among crops and plants. In this paper, we have used the transfer learning approach with three pre-trained models: EfficientNetV2L, MobileNetV2, and ResNet152V2, to detect various plant diseases. We have proposed a framework to detect 38 types of leaf diseases in 14 different plants, compared the three pre-trained models based on various quantitative performance evaluation parameters, and demonstrated that EfficientNetV2L performed best with 99.63% accuracy. In the end, Explainable Artificial Intelligence (XAI) technique: LIME has been implemented in our model to understand the insight view of the model EfficeintNetV2L's for such prediction. It is used to make our model's predictions more reliable and gives a clear explanation about the reason of such decision. © 2022 IEEE.","EfficientNetV2L; LIME; MobileNetV2; Plant Leaf Disease; ResNet152V2; Transfer Learning; XAI","Crops; Transfer learning; Efficientnetv2l; High-accuracy; Leaf disease; Leaf disease detections; Mobilenetv2; Plant leaf disease; Plant leaves; Resnet152v2; Transfer learning; XAI; Lime"
"Mehrab Z., Adiga A., Marathe M.V., Venkatramanan S., Swarup S.","Evaluating the Utility of High-Resolution Proximity Metrics in Predicting the Spread of COVID-19","10.1145/3531006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146430303&doi=10.1145%2f3531006&partnerID=40&md5=6ecd48c08e3fe532d198229548e0feb8","High resolution mobility datasets have become increasingly available in the past few years and have enabled detailed models for infectious disease spread including those for COVID-19. However, there are open questions on how such mobility data can be used effectively within epidemic models and for which tasks they are best suited. In this paper, we extract a number of graph-based proximity metrics from high resolution cellphone trace data from X-Mode and use it to study COVID-19 epidemic spread in 50 land grant university counties in the US. We present an approach to estimate the effect of mobility on cases by fitting an ordinary differential equation based model and performing multivariate linear regression to explain the estimated time varying transmissibility. We find that, while mobility plays a significant role, the contribution is heterogeneous across the counties, as exemplified by a subsequent correlation analysis. We also evaluate the metrics' utility for case surge prediction defined as a supervised classification problem, and show that the learnt model can predict surges with 95% accuracy and an 87% F1-score. © 2022 Copyright held by the owner/author(s).","big data; computational epidemiology; COVID-19; individual mobility; machine learning","Big data; Epidemiology; Forecasting; Graphic methods; Ordinary differential equations; Supervised learning; Computational epidemiologies; Detailed models; Disease spread; Epidemic modeling; High resolution; Individual mobility; Infectious disease; Machine-learning; Mobility datum; Proximity metrics; COVID-19; COVID-19; disease spread; epidemic; epidemiology; viral disease; United States"
"Mehta P., Dwivedi R., Feeney C., Patel P., Ali M.I., Breslin J.","Towards Designing an Explainable-AI based Solution for Livestock Mart Industry","10.1145/3430984.3431071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098852676&doi=10.1145%2f3430984.3431071&partnerID=40&md5=146578469e099ed9fd0048af2fa2fe32","A model capable of explaining the different factors that impact the price point is essential for the needs of the market. It can also inspire confidence in buyers and sellers about the price point offered. To achieve these objectives, we have been working with the team at MartEye, a startup based in Portershed in Galway City, Ireland. Through this paper, we report our work-in-progress research towards building a smart video analytic platform, leveraging Explainable AI techniques. © 2021 Owner/Author.","AWS; Cloud; Explainable AI; Internet of Things; Video Analytics","Data Science; AI techniques; Buyers and sellers; Ireland; Work in progress; Agriculture"
"Meijering E.","A bird's-eye view of deep learning in bioimage analysis","10.1016/j.csbj.2020.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090406675&doi=10.1016%2fj.csbj.2020.08.003&partnerID=40&md5=deeeedb6cdb92c9ec9052b20f90ed47f","Deep learning of artificial neural networks has become the de facto standard approach to solving data analysis problems in virtually all fields of science and engineering. Also in biology and medicine, deep learning technologies are fundamentally transforming how we acquire, process, analyze, and interpret data, with potentially far-reaching consequences for healthcare. In this mini-review, we take a bird's-eye view at the past, present, and future developments of deep learning, starting from science at large, to biomedical imaging, and bioimage analysis in particular. © 2020 The Author(s)","Artificial neural networks; Bioimage analysis; Computer vision; Deep learning; Microscopy imaging","Birds; Medical imaging; Metadata; Analysis problems; Biology and medicine; Biomedical imaging; Bird's eye view; De facto standard; Learning technology; Science and engineering; Deep learning; artificial neural network; bird; computer vision; data analysis; deep learning; microscopy; nonhuman; review"
"Mejia J.M.R., Rawat D.B.","Recent Advances in a Medical Domain Metaverse: Status, Challenges, and Perspective","10.1109/ICUFN55119.2022.9829645","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135207374&doi=10.1109%2fICUFN55119.2022.9829645&partnerID=40&md5=d970ae020dc5b2b0030193f2b7175136","The Meta-verse is the new, innovative platform in which is being investigated by every industry. The thought of simulating reality in a digital platform was never inconceivable but seemed distant. Now, it is taking over every industry like wildfire and the possibilities seem endless. Recently, the healthcare industry is looking into implementing the qualities of the metaverse within specialties and practices of medical professionals. This space encompasses a variety of factors such as virtual reality, augmented reality, and secured spaces for communication and processes. The healthcare industry has been looking into methods to increase patient experience and broadening the accessibility of medical care. Although the concept of the metaverse is not new, the uses are still unexplored and has to many unknowns. In an industry where patient data is critical and remains at the upmost level of privacy, it is unsure that it will remain with its integrity still intact. This paper is aiming to explore the use of the meta-verse in the healthcare industry along with the current status, challenges, and perspective of applicable technology and practices. To be more specific, we focused on the outpatient telemedicine practice experience using body sensor networks and the challenges of maintaining privacy in a healthcare metaverse space. © 2022 IEEE.","healthcare; Metaverse; privacy; vulnerabilities","Body sensor networks; Health care; Hospital data processing; Virtual reality; Digital platforms; Healthcare; Healthcare industry; Medical domains; Medical professionals; Metaverses; Patient data; Patient experiences; Privacy; Vulnerability; Augmented reality"
"Mendez K.M., Broadhurst D.I., Reinke S.N.","The application of artificial neural networks in metabolomics: a historical perspective","10.1007/s11306-019-1608-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073500593&doi=10.1007%2fs11306-019-1608-0&partnerID=40&md5=3d6d0c3b9f8dc6d27c83417902647c44","Background: Metabolomics data, with its complex covariance structure, is typically modelled by projection-based machine learning (ML) methods such as partial least squares (PLS) regression, which project data into a latent structure. Biological data are often non-linear, so it is reasonable to hypothesize that metabolomics data may also have a non-linear latent structure, which in turn would be best modelled using non-linear equations. A non-linear ML method with a similar projection equation structure to PLS is artificial neural networks (ANNs). While ANNs were first applied to metabolic profiling data in the 1990s, the lack of community acceptance combined with limitations in computational capacity and the lack of volume of data for robust non-linear model optimisation inhibited their widespread use. Due to recent advances in computational power, modelling improvements, community acceptance, and the more demanding needs for data science, ANNs have made a recent resurgence in interest across research communities, including a small yet growing usage in metabolomics. As metabolomics experiments become more complex and start to be integrated with other omics data, there is potential for ANNs to become a viable alternative to linear projection methods. Aim of review: We aim to first describe ANNs and their structural equivalence to linear projection-based methods, including PLS regression. We then review the historical, current, and future uses of ANNs in the field of metabolomics. Key scientific concept of review: Is metabolomics ready for the return of artificial neural networks? © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Artificial neural network; Deep learning; Machine learning; Metabolomics; Partial least squares","artificial neural network; data science; deep learning; metabolic fingerprinting; metabolomics; partial least squares regression; review; algorithm; least square analysis; machine learning; Algorithms; Least-Squares Analysis; Machine Learning; Metabolomics; Neural Networks, Computer"
"Meola A., Winkler M., Weinrich S.","Metaheuristic optimization of data preparation and machine learning hyperparameters for prediction of dynamic methane production","10.1016/j.biortech.2023.128604","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146919707&doi=10.1016%2fj.biortech.2023.128604&partnerID=40&md5=c61012f98af11a700a01a1d09c975119","Machine learning algorithms provide detailed description of the anaerobic digestion process, but the impact of data preparation procedures and hyperparameter optimization has rarely been investigated. A genetic algorithm was developed for optimizing data preparation and model hyperparameters to simulate dynamic methane production from steady-state anaerobic digestion of agricultural residues at full-scale. A long short-term memory neural network was used as prediction model. Results indicate that batch size, learning rate and number of neurons are the most important model parameters for accurate description of methane production rates, whereas combination of hyperparameter and data preparation optimization shows best model efficiencies, with a root mean square scaled error of 76.5 %. Mass of solid feed, time and mass of volatile solids are the most relevant input features. This study provides fundamental steps for optimal prediction of dynamic biomethane production, as a reliable basis for improving bioconversion efficiency during anaerobic digestion of agricultural residues. © 2023 Elsevier Ltd","Anaerobic digestion; Artificial intelligence; Biogas technology; Data processing; Parameter estimation","Agricultural wastes; Agriculture; Biogas; Data handling; Efficiency; Forecasting; Genetic algorithms; Learning algorithms; Machine learning; Methane; Anaerobic digestion process; Biogas technologies; Data preparation; Hyper-parameter; Machine learning algorithms; Machine-learning; Metaheuristic optimization; Methane production; Parameters estimation; Preparation procedures; Anaerobic digestion; methane; anaerobic digestion; artificial intelligence; biogas; data processing; genetic algorithm; machine learning; methane; parameter estimation; anaerobic digestion; Article; autoencoder; biotransformation; controlled study; data processing; feature selection; machine learning; measurement error; metaheuristics; nerve cell; prediction; prediction error; process model; root mean squared error; sensitivity analysis; simulation"
"Messina C.D., Van Eeuwijk F., Tang T., Truong S.K., McCormick R.F., Technow F., Powell O., Mayor L., Gutterson N., Jones J.W., Hammer G.L., Cooper M.","CROP IMPROVEMENT for CIRCULAR BIOECONOMY SYSTEMS","10.13031/ja.14912","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129974058&doi=10.13031%2fja.14912&partnerID=40&md5=4cb67a903ec6aa3911865b402d50d67d","Contemporary agricultural systems are poised to transition from linear to circular, adopting concepts of recycling, repurposing, and regeneration. This transition will require changing crop improvement objectives to consider the entire system, and thus provide solutions to improve complex systems for higher productivity, resource use efficiency, and environmental quality. The methods and approaches that underpinned the doubling of yields during the last century may no longer be fully adequate to target crop improvement for circular agricultural systems. Here we propose a multidimensional framework for prediction with outcomes useful to assess both crop performance traits and environmental sustainability of the designed agricultural systems. The study focuses on maize harvestable grain yield and total carbon production, water use, and use efficiency for yield and carbon. The framework builds on the crop growth model whole genome prediction system, which is enabled by advanced phenomics and the integration of symbolic and sub-symbolic artificial intelligence. We demonstrate the approach and prediction accuracy advantages over a standard statistical genomic prediction approach used to breed maize hybrids for yield, flowering time, and kernel set using a dataset comprised of 7004 hybrids, 103 breeding populations, and 62 environments resulting from six years of experimentation in maize drought breeding in the U.S. We propose this framework to motivate a dialogue for how to enable circularity in agriculture through prediction-based systems design. © 2022 American Society of Agricultural and Biological Engineers.","Circular bioeconomy; Circular economy; Crop improvement; Crop models; Drought; Gene editing; Genomic prediction; Maize; Plant breeding","Carbon; Crops; Drought; Efficiency; Forecasting; Population statistics; Sustainable development; Agricultural system; Circular bioeconomy; Circular economy; Crop improvement; Crop modeling; Gene editing; Genomic predictions; Maize; Plant breeding; Use efficiency; Genes; agricultural modeling; alternative agriculture; crop improvement; drought; maize; plant breeding; spatiotemporal analysis; United States"
"Mhlanga D.","Financial inclusion in emerging economies: The application of machine learning and artificial intelligence in credit risk assessment","10.3390/ijfs9030039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111698468&doi=10.3390%2fijfs9030039&partnerID=40&md5=8aafcce26f605e23a75a1b77a5bb5483","In banking and finance, credit risk is among the important topics because the process of issuing a loan requires a lot of attention to assessing the possibilities of getting the loaned money back. At the same time in emerging markets, the underbanked individuals cannot access traditional forms of collateral or identification that is required by financial institutions for them to be granted loans. Using the literature review approach through documentary and conceptual analysis to investigate the impact of machine learning and artificial intelligence in credit risk assessment, this study discovered that artificial intelligence and machine learning have a strong impact on credit risk assessments using alternative data sources such as public data to deal with the problems of information asymmetry, adverse selection, and moral hazard. This allows lenders to do serious credit risk analysis, to assess the behaviour of the customer, and subsequently to verify the ability of the clients to repay the loans, permitting less privileged people to access credit. Therefore, this study recommends that financial institutions such as banks and credit lending institutions invest more in artificial intelligence and machine learning to ensure that financially excluded households can obtain credit. © 2021 by the author. Licensee MDPI, Basel, Switzerland.","Application; Artificial intelligence; Credit risk assessment; Emerging economies; Financial inclusion; Machine learning",
"Migabo E.M., Djouani K.D., Kurien A.M.","The Narrowband Internet of Things (NB-IoT) Resources Management Performance State of Art, Challenges, and Opportunities","10.1109/ACCESS.2020.2995938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086068717&doi=10.1109%2fACCESS.2020.2995938&partnerID=40&md5=a3dc625a12e8b1f0bd96942eb7a66079","The Narrowband Internet of Things (NB-IoT) has been introduced in the 3rd Generation Partnership Project (3GPP) Rel-13 with the aim to provide low-cost, low-power, wide-area cellular connectivity for the Internet of Things. With the exponentially increasing number of connected wireless devices in the order of 100 billion, it has become crucial that researchers develop efficient resource management techniques to meet the 5th Generation (5G) quality of service (QoS) requirements. Recently, several research challenges including the low modulation data rates, energy-expensive channel coding techniques, and the fast-growing number of connected devices have been identified as some of the main issues encountered in the design and deployment of NB-IoT systems. In addition, several techniques have emerged in the literature to resolve some of these challenges of NB-IoT systems. However, the research activities towards the enhancement of the NB-IoT resource management are yet to continue in the next half-decade before, high data rates, energy-efficient, and scalable NB-IoT specifications can be released for the standardisation and commercialisation. Considering the limited number of existing surveys of such technical enhancement approaches in a broader perspective (i.e. energy efficiency, data rate performance and scalability) and also the non-existence, to the best of our knowledge, of a comparative survey, this paper seeks to elaborate, describe and compare the performances of such resources management approaches. Of the multiple NB-IoT resources, the focus of this paper is on the data rate, energy efficiency, and scalability enhancement schemes that have been proposed for the last three years. The contribution of the paper lies in the analysis, synthesis, comparison and summarised alignments of some of the major existing schemes towards identifying challenges faced by the NB-IoT development. Finally, this work seeks to identify research challenges, open questions, and opportunities that could arise from the existing techniques analysed. © 2013 IEEE.","challenges; Data rates; energy efficient; narrowband IoT (NB-IoT); opportunities; reliability; resources; scalability","5G mobile communication systems; Arts computing; Energy efficiency; Information management; Mobile telecommunication systems; Natural resources management; Quality of service; Resource allocation; Scalability; Surveys; 3rd generation partnership project (3GPP); Cellular connectivity; Channel-coding techniques; Qualityof-service requirement (QoS); Research challenges; Resource management techniques; Resources management; Technical enhancements; Internet of things"
"Miller L., Bolton M., Boulton J., Mintrom M., Nicholson A., Rudiger C., Skinner R., Raven R., Webb G.I.","AI for monitoring the Sustainable Development Goals and supporting and promoting action and policy development","10.1109/AI4G50087.2020.9311014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100347342&doi=10.1109%2fAI4G50087.2020.9311014&partnerID=40&md5=395c254e71620cf000bbf4657b01f49e","The United Nations sustainable development goals (SDGs) were ratified with much enthusiasm by all UN member states in 2015. However, subsequent progress to meet these goals has been hampered by a lack of data available to measure the SDG indicators (SDIs), and a lack of evidence-based insights to inform effective policy responses. We outline an interdisciplinary program of research into the use of artificial intelligence techniques to support measurement of the SDIs, using both machine learning methods to model SDI measurements and explainable AI techniques to present the outputs in a human-friendly manner. As well as addressing the technical concerns, we will investigate the governance issues of what forms of evidence, methods of collecting that evidence and means of its communication will most usefully inform effective policy development. By addressing these fundamental challenges, we aim to provide policy makers with the evidence needed to take effective action towards realising the Sustainable Development Goals. © 2020 IEEE.","Artificial Intelligence; Earth Observation; Policy Development; United Nations Sustainable Development Goals","Environmental protection; Learning systems; Planning; Sustainable development; AI techniques; Artificial intelligence techniques; Evidence-based; Human-friendly; Interdisciplinary programs; Machine learning methods; Policy development; United Nations; Artificial intelligence"
"Mir U.B., Sharma S., Kar A.K., Gupta M.P.","Critical success factors for integrating artificial intelligence and robotics","10.1108/DPRG-03-2020-0032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089253688&doi=10.1108%2fDPRG-03-2020-0032&partnerID=40&md5=162bc14764408c1bac42d26d7655810a","Purpose: This paper aims to enlighten stakeholders about critical success factors (CSFs) in developing intelligent autonomous systems (IASs) by integrating artificial intelligence (AI) with robotics. It suggests a prioritization hierarchy model for building sustainable ecosystem for developing IASs. Design/methodology/approach: This paper is based on the existing literature and on the opinion of 15 experts. All the experts have minimum of eight years of experience in AI and related technologies. The CSF theory is used as a theoretical lens and total interpretative structure modelling (TISM) is used for the prioritization of CSFs. Findings: Developing countries like India could leverage IASs and associated technologies for solving different societal problems. Policymakers need to develop basic policies regarding data collection, standardized hardware, skilled manpower, funding and start-up culture that can act as building blocks in undertaking sustainable ecosystem for developing IASs and implementing national AI strategy. Clear-cut regulations need to be in place for the proper functioning of the ecosystem. Any technology that can function properly in India has better chances of working at the global level considering the size of the population. Research limitations/implications: This paper had all its experts from India only, and that makes the limitation of this paper, as there is a possibility that some of the factors identified may not hold same significance in other countries. Practical implications: Stakeholders will understand the critical factors that are important in developing sustainable ecosystem for IASs and what should be the possible order of activities corresponding to each CSF. Originality/value: The paper is the first of its kind that has used the CSF theory and TISM methodology for the identification and prioritization of CSFs in developing IASs. Further, eight significant factors, that is, emerging economy multinational enterprises (EMNEs), governance, utility, manpower, capital, software, data and hardware, have come up as the most important factors in integrating AI with robotics in India. © 2020, Emerald Publishing Limited.","Artificial intelligence; Autonomous systems; Critical success factors; CSF; Industry 4.0; Integrated systems; Robotics; TISM",
"Mishra N., Mishra S., Tripathy H.K.","Rice Yield Estimation Using Deep Learning","10.1007/978-3-031-23233-6_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146682365&doi=10.1007%2f978-3-031-23233-6_28&partnerID=40&md5=ad2b4cda134f8eccc55b2a122b9a0f98","Global and regional food security heavily relies on effective yield estimation results. Thus precise and on-time rice yield estimate or prediction is a pivotal factor not only to ensure food security but also for sustainable development of agricultural resources. Machine learning and deep learning are proving to be exemplary support tools for decision making for rice yield estimation or prediction, such as selection of the rice varieties that need to be grown and also decisions involving the management of crops during growing season. Several researchers have put forth a variety of deep learning as well as machine learning algorithms that have helped estimate rice yield time and again. This paper proposes a LSTM based model to predict the Rice yield of the data collected for all 314 blocks of Odisha by ICAR - National Rice Research Institute (NRRI), Odisha. In this study, we get 0.07 RMSE score for training data and 0.21 RMSE score for test data. The model is also evaluated based on the various performance metrics for three rice datasets. The overall performance for the rice datasets is evaluated to be 0.989 recall, 0.979 precision, 0.989 accuracy and 0.984 F1 score. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Deep learning; Food security; Machine learning; Rice yield estimation; Sustainable development","Agriculture; Decision making; Food supply; Forecasting; Learning algorithms; Long short-term memory; Agricultural resources; Decisions makings; Deep learning; Estimation results; Food security; Machine-learning; Rice yield; Rice yield estimation; Support tool; Yield estimation; Sustainable development"
"Misitano G.","Interactively Learning the Preferences of a Decision Maker in Multi-objective Optimization Utilizing Belief-rules","10.1109/SSCI47803.2020.9308316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099710504&doi=10.1109%2fSSCI47803.2020.9308316&partnerID=40&md5=33447ba0866aaa70c0f240e6505c039d","Many real life problems can be modelled as multi-objective optimization problems. Such problems often consist of multiple conflicting objectives to be optimized simultaneously. Multiple optimal solutions exist to these problems, and a single solution cannot be said to be the best without preferences given by a domain expert. Preferences can be used to find satisfying solutions: optimal solutions, which best match the expert's preferences. To model the preferences of the expert, and aid him/her in finding satisfying solutions, a novel method is proposed. The method utilizes machine learning combined with belief-rule based systems to adaptively train a belief-rule based system to learn a domain expert's preferences using preference information gathered during an interactive process. Belief-rule based systems are explainable generalized expert systems, which have not been used before in the manner described in this paper to model preferences of a domain expert for a multi-objective optimization problem. In the case study conducted, the satisfying solutions found using learned preferences are concluded to be compatible with the preferences of the expert, which support the proposed method's viability as a decision making support tool. © 2020 IEEE.","belief-rule based systems; decision making; machine learning; multiple objective optimization; preference modelling; Python","Decision making; Expert systems; Intelligent computing; Knowledge acquisition; Optimal systems; Belief rule-based systems; Conflicting objectives; Decision making support; Interactive process; Multi-objective optimization problem; Multiple optimal solutions; Preference information; Real-life problems; Multiobjective optimization"
"Mittal R., Arora S., Kuchhal P., Bhatia M.P.S.","An Insight into Tool and Software Used in AI, Machine Learning and Data Analytics","10.1007/978-981-33-4412-9_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132802362&doi=10.1007%2f978-981-33-4412-9_2&partnerID=40&md5=32d2c3e133195e7a00cb44fb5f5e9729","Machine learning is a fantastic development on the off chance that you use it correctly. We can use machine learning models to demonstrate the importance of predictions on various projects. Acing machine learning tools would let you play with the information, train your models, find new systems, and make your computations efficiently. The pace of AI is overgrowing, and it is getting more noteworthy than some other time in late memory to perceive what choices you have for AI tools, libraries, stages, and so forward. Moreover, the need for investigation of critical information has opened various avenues in machine learning. Various open-source tools can be explored for performing analysis tasks as they are more renowned, straightforward, and executed orchestrated than the paid version. Many open-source tools do not require any coding and make sense of passing on the best results compared to paid structures. In this book chapter, we discuss the role of machine learning analytics in artificial intelligence. We survey the various kinds of open-source tools available on the Internet to take up projects in this field. Besides elucidating the application domains in which these analytics tools can be used, we also validate the results using a case study performed to detect fraudulent transactions. The chapter reviews data analytics tools, libraries, and software, what they are typically used for, what points of interest, and inconveniences they offer to choose from them based on his convenience. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Artificial intelligence; Data analytics; Machine learning; Software’s; Tools","Libraries; Machine learning; Open source software; Analytic tools; Applications domains; Case-studies; Data analytics; Learning tool; Machine data; Machine learning models; Machine-learning; Open source tools; Software’s; Data Analytics"
"Moges G., McDonnell K., Delele M.A., Ali A.N., Fanta S.W.","Development and comparative analysis of ANN and SVR-based models with conventional regression models for predicting spray drift","10.1007/s11356-022-23571-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140444908&doi=10.1007%2fs11356-022-23571-y&partnerID=40&md5=f3d2da6b8c581e904153262cbdb8eb3b","As monitoring of spray drift during application can be expensive, time-consuming, and labor-intensive, drift predicting models may provide a practical complement. Several mechanistic models have been developed as drift prediction tool for various types of application equipment. Nevertheless, mechanistic models are quite often intricate and complex with a large number of input parameters required. Quite often, the detailed data needed for such models are not readily available. In this study, two advanced machine learning models (artificial neural network (ANN) and support vector regression (SVR)) were developed for pesticide drift prediction and compared with three conventional regression-based models: multiple linear regression (MLR), generalized linear model (GLM), and generalized nonlinear least squares (GNLS). The models were evaluated in fivefold cross-validation and by external validation using the coefficient of determination (R2), root mean square error (RMSE), mean absolute error (MAE), and mean absolute bias (MAB). From regression-based models, GLM and GNLS models performed very well when evaluated by cross-validation with R2 = 0.96 and 0.95 and RMSE = 0.70 and 0.82 respectively, while MLR performed less with R2 of 0.65 and RMSE of 2.25. Simultaneously, ANN and SVR models performed very well with R2 = 0.98 and 0.97 and RMSE = 0.58 and 0.71 respectively. Overall, ANN model performed best compared to the other four models followed by SVR. A comparison was also made between the high-performing model, ANN, and two previously published empirical models. The ANN model outperformed the two previously published empirical models and can be used to predict pesticide drift. Therefore, the ANN model is a potentially promising new approach for predicting ground drift that merits further study. In conclusion, our work demonstrated that the new approach, ANN and SVR-based models, for pesticide drift modeling has better predictive power than conventional regression models. Their ability to model complex relationships is a clear benefit in pesticide drift modeling where the variability in pesticide drift is often affected by a number of variables and the relationships between drift and predictors are very complicated. We believe such insights will pave better way for the application of machine learning towards spray drift modeling. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Artificial neural network; Regression; Spray drift model; Support vector regression",
"Mohsin R.B., Ramisa S.A., Saad M., Rabbani S.H., Tamkin S., Ashraf F.B., Reza T.","Classifying Insect Pests from Image Data using Deep Learning","10.1109/CISP-BMEI56279.2022.9979872","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146228491&doi=10.1109%2fCISP-BMEI56279.2022.9979872&partnerID=40&md5=46472f91ea06195e35067bb9300a824a","The fact that insecticidal pests impair significant agricultural productivity has become one of the main challenges in agriculture. Several prerequisites, however, exist for a high-performance automated system capable of detecting nuisance insects from massive amounts of visual data. We employed deep learning approaches to correctly identify insect species from large volumes of data in this study model and explainable AI to decide which part of the photos is used to categorize the insects from the data. We chose to deal with the large-scale IP102 dataset since we worked with a large dataset. There are almost 75,000 pictures in this collection, divided into 102 categories. We ran state-of-the-art tests on the unique IP102 data set to evaluate our proposed solution. We used five different Deep Neural Networks (DNN) models for image classification: VGG19, ResNet50, EfficientNetB5, DenseNet121, InceptionV3, and implemented the LIME-based XAI (Explainable Artificial Intelligence) framework. DenseNet121 outperformed all other networks, and we also implemented it to classify specific crop insect species. The classification accuracy ranged from 46.31 percent to 95.36 percent for eight crops. Moreover, we have compared our prediction to that of earlier articles to assess the efficacy of our research. © 2022 IEEE.","Data augmentation; Insect pest classification; IP102 dataset; Transfer learning","Automation; Convolutional neural networks; Crops; Deep neural networks; Image classification; Large dataset; Lime; Statistical tests; Transfer learning; Agricultural productivity; Automated systems; Data augmentation; Image data; Insect pest classification; Insects pests; Ip102 dataset; Performance; Transfer learning; Visual data; Classification (of information)"
"Molisse G., Emin D., Costa H.","Implementation of a Sentinel-2 Based Exploratory Workflow for the Estimation of Above Ground Biomass","10.1109/M2GARSS52314.2022.9839897","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136348703&doi=10.1109%2fM2GARSS52314.2022.9839897&partnerID=40&md5=5bfb72a4299de2aae5b17ed9e21fa6b5","This work presents a Sentinel-2 based exploratory workflow for the estimation of Above Ground Biomass (AGB) in a Mediterranean forest. Up-to-date and reliable mapping of AGB has been increasingly required by international commitments under the climate convention, and in the last decades, remote sensing-based studies on the topic have been widely investigated. After the generation of several vegetation and topographic features, the proposed approach consists of 4 major steps: 1) Feature selection 2) AGB prediction with k-Nearest Neighbour (kNN), Random Forest (RF), Extreme Gradient Boosting (XGB), and Artificial Neural Networks (ANN); 3) hyper-parameters fine-tuning with Bayesian Optimization; and finally, 4) model explanation with the SHapley Additive exPlanations (SHAP) package. The following results were obtained: 1) before hyper-parameters optimization, the Deep Neural Network (DNN) yielded the best performance with a Root Mean Squared Error (RMSE) of 42.30 t/ha; 2) after hyper-parameters fine-tuning with Bayesian Optimization, the Extreme Gradient Boosting (XGB) model yielded the best performance with a RMSE of 37.79 t/ha; 3) model explanation with SHAP allowed for a deeper understanding of the features impact on the model predictions. Finally, the predicted AGB throughout the study area showed an average value of 83 t/ha, ranging from 0t/ha to 346.56 t/ha. © 2022 IEEE.","Above Ground Biomass; Extreme Gradient Boosting; Sentinel-2; SHAP","Bayesian networks; Biomass; Deep neural networks; Forestry; Mean square error; Nearest neighbor search; Remote sensing; Aboveground biomass; Bayesian optimization; Extreme gradient boosting; Fine tuning; Gradient boosting; Hyper-parameter; Sentinel-2; Shapley; Shapley additive explanation; Work-flows; Decision trees"
"Mondal S., Jayaraman P.P., Delir Haghighi P., Hassani A., Georgakopoulos D.","Situation-Aware IoT Data Generation towards Performance Evaluation of IoT Middleware Platforms","10.3390/s23010007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145565665&doi=10.3390%2fs23010007&partnerID=40&md5=e2ac36751a50981a6522ed6ee65ac104","With the increasing growth of IoT applications in various sectors (e.g., manufacturing, healthcare, etc.), we are witnessing a rising demand of IoT middleware platform that host such IoT applications. Hence, there arises a need for new methods to assess the performance of IoT middleware platforms hosting IoT applications. While there are well established methods for performance analysis and testing of databases, and some for the Big data domain, such methods are still lacking support for IoT due to the complexity, heterogeneity of IoT application and their data. To overcome these limitations, in this paper, we present a novel situation-aware IoT data generation framework, namely, SA-IoTDG. Given a majority of IoT applications are event or situation driven, we leverage a situation-based approach in SA-IoTDG for generating situation-specific data relevant to the requirements of the IoT applications. SA-IoTDG includes a situation description system, a SySML model to capture IoT application requirements and a novel Markov chain-based approach that supports transition of IoT data generation based on the corresponding situations. The proposed framework will be beneficial for both researchers and IoT application developers to generate IoT data for their application and enable them to perform initial testing before the actual deployment. We demonstrate the proposed framework using a real-world example from IoT traffic monitoring. We conduct experimental evaluations to validate the ability of SA-IoTDG to generate IoT data similar to real-world data as well as enable conducting performance evaluations of IoT applications deployed on different IoT middleware platforms using the generated data. Experimental results present some promising outcomes that validate the efficacy of SA-IoTDG. Learning and lessons learnt from the results of experiments conclude the paper. © 2022 by the authors.","benchmarking; Fuzzy Situation Inference; IoT; IoT data generation; IoT middleware platforms; performance evaluation; situation transition","Internet of things; Markov processes; Middleware; Well testing; Data generation; Fuzzy situation inference; IoT; IoT data generation; IoT middleware platform; Middleware platforms; Performances evaluation; Real-world; Situation transition; Situation-aware; Benchmarking; article; benchmarking; drug efficacy; learning; Markov chain"
"Mora D., Zimmermann R., Cirqueira D., Bezbradica M., Helfert M., Auinger A., Werth D.","Who Wants to Use an Augmented Reality Shopping Assistant Application?",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108113079&partnerID=40&md5=ea001aed1627c64c9e3b52cb71f9ad6b","Brick-and-mortar retailers need to stay competitive to the convenience provided by online channels. Technologies, such as personalized shopping assistants on smartphones can empower customers in-store towards a similar experience as in an online scenario. For instance, an augmented reality shopping assistance application with explainable recommendations (XARSAA) can mimic the behavior of recommender systems in personalizing offers to consumers in physical shops. However, before deploying such technologies, it is essential that retailers get to know the demographics of their customer base. Existing literature rarely addresses the influence of customers demographics towards XARSAA technologies. Therefore, we follow a design science approach, and develop an instantiation of a XARSAA artifact, which is artificially evaluated through a controlled online user experiment with 315 participants. Results illustrate multiple demographics which influence customers attitude towards an augmented reality shopping assistant application in brick-and-mortar stores. Additionally, we provide insights into the design of such technology to guide researchers in its implementation. Copyright © 2020 by SCITEPRESS-Science and Technology Publications, Lda. All rights reserved.","Brick-and-mortar; Digital retail; Digital shopping assistant; Explainable artificial intelligence; Recommender systems; Retail sales","Augmented reality; Brick; Consumer behavior; Human computer interaction; Interactive computer systems; Mortar; Population statistics; Customerbase; Design science; Online channels; Online users; Shopping assistance; Sales"
"Moradkhani M.A., Hosseini S.H., Ranjbar K.","Universal intelligent models for liquid density of CO2 + hydrocarbon mixtures","10.1016/j.fuel.2022.126642","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142161187&doi=10.1016%2fj.fuel.2022.126642&partnerID=40&md5=e805a65b9fb948b687bea53e4912bfb8","Developing precise predictive methods for liquid density of CO2 + hydrocarbon mixtures is vital to model, optimize, and design of the enhanced oil recovery (EOR) and the CO2 storage processes. The CO2 injection into the oil reservoir can noticeably change the density of solution. In addition, forecasting this parameter over a wide range of conditions is extremely challenging due to the complicated behaviors of hydrocarbons. The earlier empirical models are only valid for specific hydrocarbons under very restricted conditions. Therefore, in this study, three robust machine learning based approaches were implemented to build robust and universal models based on an immense databank, comprising 17,168 experimental data extracted from 52 independent studies. The databank covered 46 varied mixtures at a broad range of conditions, including temperature, pressure and CO2 mole fraction. The statistical and the cumulative frequency analyzes showed that the radial basis function (RBF) model provides the best results among the all approaches, with an average absolute relative error of 1.61 % and a relative root mean squared error (RRMSE) of 4.29 %, respectively for the test data samples. It also provided favorable predictions for physical attitudes of the mixture density under different operating conditions, and properly described the “density crossover” phenomenon at high CO2 concentrations. The RBF-based model outperformed earlier empirical correlations in terms of precision, applicability, and generality. Overall, the machine learning-based models developed in this study are efficient and reliable methods to assist the designers and engineers involved with in CO2-EOR process. © 2022 Elsevier Ltd","CO2 + hydrocarbon mixtures; EOR process; Intelligent models; Liquid density","Carbon dioxide; Density of liquids; Digital storage; Hydrocarbons; Learning algorithms; Liquids; Mean square error; Mixtures; Petroleum reservoir engineering; Petroleum reservoirs; Radial basis function networks; CO2 + hydrocarbon mixture; Condition; Databanks; Enhanced oil recovery process; Enhanced-oil recoveries; Hydrocarbons mixtures; Intelligent models; Liquid density; Machine-learning; Oil recovery process; Enhanced recovery"
"Morales N.V., Jimenez E.I., Rivera R.G., Garcia R.C.","Sack Detection and Counting Using Deep Learning","10.1109/ICECET55527.2022.9872638","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138905685&doi=10.1109%2fICECET55527.2022.9872638&partnerID=40&md5=c6a9f1c259d51e16220d8adc086d4ed7","In this paper, a grain sack detection and counting system is developed to help the logistics management of a warehouse stock. As main objective is to construct an electronic device that performs the counting of sacks with great precision through the most advanced artificial vision techniques. The device will count the total number of sacks that make up a stowage, calculate the volume, and eventually estimate the amount of mass, these results are transferred to an Excel sheet for constant monitoring and easy handling for users. The detection model is carried out with Python, PyTorch and YOLOv3, obtaining as a result a mean Average Precision (mPA) of 0.92. In addition, a sacks stowage arrangement was established that allows the volume result to be as accurate as possible, likewise, a program that performs the calculation was developed. © 2022 IEEE.","artificial intelligence; deep learning; image processing; sack detection; volume","Deep learning; Image processing; Navigation; Counting system; Deep learning; Detection system; Electronics devices; Images processing; Logistic management; Sack detection; Vision technique; Volume; Warehouse stock; Python"
"Morando L., Recchiuto C.T., Calla J., Scuteri P., Sgorbissa A.","Thermal and Visual Tracking of Photovoltaic Plants for Autonomous UAV Inspection","10.3390/drones6110347","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141795763&doi=10.3390%2fdrones6110347&partnerID=40&md5=aadad45a237352bf903d27de783639a8","Because photovoltaic (PV) plants require periodic maintenance, using unmanned aerial vehicles (UAV) for inspections can help reduce costs. Usually, the thermal and visual inspection of PV installations works as follows. A UAV equipped with a global positioning system (GPS) receiver is assigned a flight zone, which the UAV will cover back and forth to collect images to be subsequently composed in an orthomosaic. When doing this, the UAV typically flies at a height above the ground that is appropriate to ensure that images overlap even in the presence of GPS positioning errors. However, this approach has two limitations. First, it requires covering the whole flight zone, including “empty” areas between PV module rows. Second, flying high above the ground limits the resolution of the images to be subsequently inspected. The article proposes a novel approach using an autonomous UAV with an RGB and a thermal camera for PV module tracking through segmentation and visual servoing, which does not require a GPS except for measuring the “small” relative displacement between a PV module row and the next one. With this solution, the UAV moves along PV module rows at a lower height than usual and inspects them back and forth in a boustrophedon way by ignoring “empty” areas with no PV modules. Experimental tests performed in simulation and at an actual PV plant are reported, showing a tracking error lower than 0.2 m in most situations when moving at 1.2 m/s. © 2022 by the authors.","autonomous vehicle navigation; localization and visual serving; photovoltaic (PV) plant inspection",
"Morris C.E., Géniaux G., Nédellec C., Sauvion N., Soubeyrand S.","One Health concepts and challenges for surveillance, forecasting, and mitigation of plant disease beyond the traditional scope of crop production","10.1111/ppa.13446","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112286319&doi=10.1111%2fppa.13446&partnerID=40&md5=4eff5ed3f92b2e58348ec56fb9670ff0","The One Health approach to understanding disease epidemiology and achieving surveillance and prevention is holistic, while focusing on zoonotic diseases. Many of its principles are similar to those espoused in agroecology, begetting the question of what One Health can contribute—in practice—to preventing plant disease. Here we describe four knowledge challenges for plant health management that have arisen from the One Health experience for zoonotic diseases that could boost prospects for novel approaches to plant disease surveillance, prediction, and prevention. The challenges are to (a) uncover reservoirs and revise pathogen life histories, (b) elucidate drivers of virulence beyond the context of direct host–pathogen interactions, (c) account for the natural highways of long-distance dissemination (i.e., surface water and air mass movement), and (d) update disease forecasts in the face of changing land use, cultivation practices, and climate. Furthermore, we note that implementation of a One Health approach to disease surveillance and prevention will require mobilization of tools to deal with the representation and accessibility of massive and heterogeneous data and knowledge; with knowledge inference, data science, modelling, and pattern recognition; and multi-actor approaches that unite different sectors of society as well as different scientific disciplines. The infrastructure to build and the obstacles to overcome for a bona fide One Health approach to disease surveillance and prevention are key commonalities where actors in the efforts to prevent zoonotic diseases and plant disease can work together for the management of biodiversity and consequently human, animal, and plant health. © 2021 British Society for Plant Pathology","agroecology; disease forecasting; knowledge inference; long-distance dissemination; spillover; virulence drivers","air mass; biodiversity; crop production; disease control; epidemiology; groundwater-surface water interaction; host-pathogen interaction; public health; surface water; virulence"
"Mostafa S., Mondal D., Beck M.A., Bidinosti C.P., Henry C.J., Stavness I.","Leveraging Guided Backpropagation to Select Convolutional Neural Networks for Plant Classification","10.3389/frai.2022.871162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130684341&doi=10.3389%2ffrai.2022.871162&partnerID=40&md5=3fbb2f53c59215a88681c700e464f4a9","The development of state-of-the-art convolutional neural networks (CNN) has allowed researchers to perform plant classification tasks previously thought impossible and rely on human judgment. Researchers often develop complex CNN models to achieve better performances, introducing over-parameterization and forcing the model to overfit on a training dataset. The most popular process for evaluating overfitting in a deep learning model is using accuracy and loss curves. Train and loss curves may help understand the performance of a model but do not provide guidance on how the model could be modified to attain better performance. In this article, we analyzed the relation between the features learned by a model and its capacity and showed that a model with higher representational capacity might learn many subtle features that may negatively affect its performance. Next, we showed that the shallow layers of a deep learning model learn more diverse features than the ones learned by the deeper layers. Finally, we propose SSIM cut curve, a new way to select the depth of a CNN model by using the pairwise similarity matrix between the visualization of the features learned at different depths by using Guided Backpropagation. We showed that our proposed method could potentially pave a new way to select a better CNN model. Copyright © 2022 Mostafa, Mondal, Beck, Bidinosti, Henry and Stavness.","convolutional neural network; deep learning—artificial neural network; explainable AI; Guided Backpropagation; neural network visualization",
"Moussaid A., El Fkihi S., Zennayi Y., Lahlou O., Kassou I., Bourzeix F., El Mansouri L., Imani Y.","Machine Learning Applied to Tree Crop Yield Prediction Using Field Data and Satellite Imagery: A Case Study in a Citrus Orchard","10.3390/informatics9040080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144714365&doi=10.3390%2finformatics9040080&partnerID=40&md5=8d51d70e9ce3574962614981f8cd5349","The overall goal of this study is to define an intelligent system for predicting citrus fruit yield before the harvest period. This system uses a machine learning algorithm trained on historical field data combined with spectral information extracted from satellite images. To this end, we used 5 years of historical data for a Moroccan orchard composed of 50 parcels. These data are related to climate, amount of water used for irrigation, fertilization products by dose, phytosanitary treatment dose, parcel size, and root-stock type on each parcel. Additionally, two very popular indices, the normalized difference vegetation index and normalized difference water index were extracted from Sentinel 2 and Landsat satellite images to improve prediction scores. We managed to build a total dataset composed of 250 rows, representing the 50 parcels over a period of 5 years labeled with the yield of each parcel. Several machine learning algorithms were tested with the necessary parameter optimization, while the orthonormal automatic pursuit algorithm gave good prediction scores of 0.2489 (MAE: Mean Absolute Error) and 0.0843 (MSE: Mean Squared Error). Finally, the approach followed in this study shows excellent potential for fruit yield prediction. In fact, the test was performed on a citrus orchard, but the same approach can be used on other tree crops to achieve the same goal. © 2022 by the authors.","agricultural data; machine learning; precision farming; spectral data; yield prediction",
"Moyeenudin H.M., Anandan R.","Artificial intelligence for knowing the anticipation of client from online food delivery using big data",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109058086&partnerID=40&md5=940d41186d5fe8c431fab08fa387b72b","Big data analytics carried out with various methods in a systematic way to identify the data variables performances and in this arena the data has many ways to get separate from each other, this type of analysis are applicable to organize data files that are extremely large or composite to be structured by regular analytical tools. The innovative stage of recent technologies influences the strategic practices of an organization for competitive scenario. The amount of data is growing in a fast phase throughout the various sections of business operations. Likewise, the swift of big data is noticed with the online food delivery units. This paper is comprised with explicit information through a detailed research on identifying the tools which assist in knowing online food delivery expectation from their clients, as the flexibly of food industry is confounded, in light of different guidelines with the varied interest on ordering food; in this way, the perceivability of user for time consumption on receiving their food order, apparently saving their cash based on budget over comparison with similar items. Nevertheless, food delivery vendors can't utilize all the assembled data and are not using the potential that is conceivable. Thus the primary objective of this big data analysis is to obtain an effective and efficient classification of data for knowing the anticipation of users from online food delivery applications. Furthermore on knowing the tools and methods that are suitable for analyzing big data. © 2021 Nova Science Publishers, Inc.","Analytical tools; Data analytics; Machine learning; Online food ordering",
"Mukhamediev R.I., Popova Y., Kuchin Y., Zaitseva E., Kalimoldayev A., Symagulov A., Levashenko V., Abdoldina F., Gopejenko V., Yakunin K., Muhamedijeva E., Yelis M.","Review of Artificial Intelligence and Machine Learning Technologies: Classification, Restrictions, Opportunities and Challenges","10.3390/math10152552","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136820960&doi=10.3390%2fmath10152552&partnerID=40&md5=e1b0a36268caad97b264666226233b3a","Artificial intelligence (AI) is an evolving set of technologies used for solving a wide range of applied issues. The core of AI is machine learning (ML)—a complex of algorithms and methods that address the problems of classification, clustering, and forecasting. The practical application of AI&ML holds promising prospects. Therefore, the researches in this area are intensive. However, the industrial applications of AI and its more intensive use in society are not widespread at the present time. The challenges of widespread AI applications need to be considered from both the AI (internal problems) and the societal (external problems) perspective. This consideration will identify the priority steps for more intensive practical application of AI technologies, their introduction, and involvement in industry and society. The article presents the identification and discussion of the challenges of the employment of AI technologies in the economy and society of resource-based countries. The systematization of AI&ML technologies is implemented based on publications in these areas. This systematization allows for the specification of the organizational, personnel, social and technological limitations. This paper outlines the directions of studies in AI and ML, which will allow us to overcome some of the limitations and achieve expansion of the scope of AI&ML applications. © 2022 by the authors.","AI challenges; artificial intelligence; deep learning; explainable machine learning; machine learning",
"Mukhamediev R.I., Assanov I., Yelis M., Symagulov A., Kuchin Y., Yakunin K., Margulan A., Tabynbayeva L., Sedlacek P.","Rapid bibliometric analysis in deep learning domain","10.1109/IDT52577.2021.9497591","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112418877&doi=10.1109%2fIDT52577.2021.9497591&partnerID=40&md5=2c97dbc0d98d09fdd67afab1276c210b","The paper systematizes the Deep Learning domain and calculates the dynamics of changes in the number of scientific articles according to Google Scholar. The method of data acquisition and calculation of dynamic indicators of changes in publication activity is described: speed (DI) and acceleration of growth (D2) of scientific publications. Analysis of publication activity, in particular, showed a high interest in modern transformer models, the development of datasets for some industries, and a sharp increase in interest in methods of explicable machine learning. Relatively small research domains are receiving increasing attention, as evidenced by the negative correlation between the number of articles and Dl and D2 scores. The results show that, despite the limitations of the method, it is possible to identify fast-growing areas of research regardless of the number of articles. The paper presents result for more than 400 search queries related to classified research areas. Calculation results and software can be downloaded https://www.dropbox.com/sh/fkfw3a1hkf0suvc/AACRZ7v9qympen_ht00jeiF6a?dl=0. © 2021 IEEE.","bibliometric indicators; convolution neural networks; deep learning; explainable machine learning; machine learning; recurrent neural networks; transfer learning; transformers","Data acquisition; Learning systems; Bibliometric analysis; Calculation results; Dynamic indicators; Negative correlation; Publication activities; Scientific articles; Scientific publications; Transformer models; Deep learning"
"Mukhamediev R.I., Symagulov A., Kuchin Y., Yakunin K., Yelis M.","From classical machine learning to deep neural networks: A simplified scientometric review","10.3390/app11125541","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108847863&doi=10.3390%2fapp11125541&partnerID=40&md5=9b18968c5ee4b63b774674173840fe72","There are promising prospects on the way to widespread use of AI, as well as problems that need to be overcome to adapt AI&ML technologies in industries. The paper systematizes the AI sections and calculates the dynamics of changes in the number of scientific articles in machine learning sections according to Google Scholar. The method of data acquisition and calculation of dynamic indicators of changes in publication activity is described: growth rate (D1) and acceleration of growth (D2) of scientific publications. Analysis of publication activity, in particular, showed a high interest in modern transformer models, the development of datasets for some industries, and a sharp increase in interest in methods of explainable machine learning. Relatively small research domains are receiving increasing attention, as evidenced by the negative correlation between the number of articles and D1 and D2 scores. The results show that, despite the limitations of the method, it is possible to (1) identify fast-growing areas of research regardless of the number of articles, and (2) predict publication activity in the short term with satisfactory accuracy for practice (the average prediction error for the year ahead is 6%, with a standard deviation of 7%). This paper presents results for more than 400 search queries related to classified research areas and the application of machine learning models to industries. The proposed method evaluates the dynamics of growth and the decline of scientific domains associated with certain key terms. It does not require access to large bibliometric archives and allows to relatively quickly obtain quantitative estimates of dynamic indicators. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; Bibliometric indicators; Convolution neural networks; Deep learning; Explainable machine learning; Machine learning; Recurrent neural networks; Scientometrics; Transfer learning; Transformers",
"Müller M., Olsson P.-O., Eklundh L., Jamali S., Ardö J.","Features predisposing forest to bark beetle outbreaks and their dynamics during drought","10.1016/j.foreco.2022.120480","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137171153&doi=10.1016%2fj.foreco.2022.120480&partnerID=40&md5=5e216331b8d1d3c4c78b2d8587eb9b0f","Climate change is estimated to increase the risk of the bark beetle (Ips typographus L.) mass outbreaks in Norway Spruce (Picea abies (L.) Karst) forests. Habitats that are thermally suitable for bark beetles may expand, and an increase in the frequency and intensity of droughts can promote drought stress on host trees. Drought affects tree vigor and in unison with environmental features it influences the local predisposition risk of forest stands to bark beetle attacks. We aimed to study how various environmental features influence the risk of bark beetle attacks during a drought year and the following years with more normal weather conditions but with higher bark beetle populations. We included features representing local forest stand attributes, topography, soil type and wetness, the proximity of clear-cuts and previous bark beetle attacks, and a machine learning algorithm (random forest) was applied to study the variation of predisposition risk across a 48,600 km2 study area in SE Sweden. Forest stands with increased risk of bark beetle attack were distinguished with high accuracy both during drought and in normal weather conditions. The results show that during both study periods, spruce and mixed coniferous forests had elevated risk of attack, while forests with a mix of deciduous and coniferous trees had a lower risk. Forests with high average canopy height were strongly predisposed to bark beetle attacks. However, during the drought year risk was more similar between stands with lower and higher canopy height, suggesting that during drought periods younger trees can be predisposed to bark beetle attacks. The importance of soil moisture and position within the local landscape were highlighted as important features during the drought year. Identifying areas with increased risk, supported by information on how environmental features control the predisposition risk during drought, could aid adaptation strategies and forest management intervention efforts. We conclude that geospatial data and machine learning have the potential to further support the digitalization of the forest industry, facilitating development of methods capable to quantify importance and dynamics of environmental features controlling the risk in local context. Corresponding methods could help to direct management actions more effectively and offer information for decision-making in changing climate. © 2022 The Authors","Attack risk; Drought; European spruce bark beetle; Interpretable machine learning; Random forest","Climate change; Decision trees; Drought; Forestry; Plants (botany); Random forests; Risk perception; Soil moisture; Topography; Attack risk; Bark beetle; Bark beetle attacks; Environmental features; European spruce bark beetle; Forest stand; Interpretable machine learning; Machine-learning; Random forests; Spruce bark beetles; Machine learning"
"Müller R., Gögel C., Bönsel R.","Data or interpretations: Impacts of information presentation strategies on diagnostic processes","10.1002/hfm.20838","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081336611&doi=10.1002%2fhfm.20838&partnerID=40&md5=ed4b0376b2810fdd6e1f3f593d351344","Industrial fault diagnosis can be supported by assistance systems that infer fault causes from sensor data. The present study asked what information these algorithms should make available to operators. In a computer-based experiment about fault diagnosis in a packaging machine, three information presentation strategies were compared regarding their impacts on information sampling, performance, and knowledge acquisition: Providing only sensor data, sensor data along with three possible interpretations, or only the most likely interpretation. Before submitting a diagnosis, participants could sample process parameters, one of which indicated the fault cause. We hypothesized that providing only sensor data would lead to more parameter checking and slower solutions than interpretations. While providing only one interpretation was expected to enable efficient performance for correct interpretations, it should lead to either of two types of performance costs for incorrect interpretations: Errors if participants refrain from checking parameters, or slowdowns in performance if they keep on checking. The results confirmed that participants with only sensor data performed inefficiently. Participants with only one interpretation thoroughly checked parameters but still were fastest when the interpretation was correct, while when it was incorrect they were three times slower than participants with only sensor data. Participants with three interpretations (one of which was always correct) performed almost as efficiently as those with only one correct interpretation. The results indicate that highly preprocessed information leads to efficient performance when it is correct but prevents learning about fault causes. Overall, providing several possible interpretations seemed to be the best strategy. © 2020 The Authors. Human Factors and Ergonomics in Manufacturing & Service Industries published by Wiley Periodicals, Inc.","automation bias; degree of automation; fault diagnosis; information sampling; operator assistance","Computer aided analysis; Failure analysis; Automation bias; Degree of automation; Diagnostic process; Information presentation; Information samplings; operator assistance; Parameter checking; Process parameters; Fault detection"
"Munawar H.S., Inam H., Ullah F., Qayyum S., Kouzani A.Z., Mahmud M.A.P.","Towards smart healthcare: Uav‐based optimized path planning for delivering covid‐19 self‐testing kits using cutting edge technologies","10.3390/su131810426","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115393921&doi=10.3390%2fsu131810426&partnerID=40&md5=1902c5e39a41970536bb8ccaab78fc3b","Coronavirus Disease 2019 (COVID‐19) has emerged as a global pandemic since late 2019 and has affected all forms of human life and economic developments. Various techniques are used to collect the infected patients’ sample, which carries risks of transferring the infection to others. The current study proposes an AI‐powered UAV‐based sample collection procedure through self‐col-lection kits delivery to the potential patients and bringing the samples back for testing. Using a hypothetical case study of Islamabad, Pakistan, various test cases are run where the UAVs paths are optimized using four key algorithms, greedy, intra‐route, inter‐route, and tabu, to save time and reduce carbon emissions associated with alternate transportation methods. Four cases with 30, 50, 100, and 500 patients are investigated for delivering the self‐testing kits to the patients. The results show that the Tabu algorithm provides the best‐optimized paths covering 31.85, 51.35, 85, and 349.15 km distance for different numbers of patients. In addition, the algorithms optimize the number of UAVs to be used in each case and address the studied cases patients with 5, 8, 14, and 71 UAVs, respectively. The current study provides the first step towards the practical handling of COVID‐19 and other pandemics in developing countries, where the risks of spreading the infections can be minimized by reducing person‐to‐person contact. Furthermore, the reduced carbon foot-prints of these UAVs are an added advantage for developing countries that struggle to control such emissions. The proposed system is equally applicable to both developed and developing countries and can help reduce the spread of COVID‐19 through minimizing the person‐to‐person contact, thus helping the transformation of healthcare to smart healthcare. © 2021 by the authors.","Artificial intelligence (AI); COVID‐19; Delivery systems; Healthcare; Route optimi-zation; Self‐testing kits; Smart healthcare; Unmanned aerial vehicles (UAVs)","algorithm; COVID-19; economic development; emission control; health care; health policy; health risk; optimization; unmanned vehicle; Islamabad [Pakistan]; Pakistan; Coronavirus"
"Munro L.J., Kell D.B.","Intelligent host engineering for metabolic flux optimisation in biotechnology","10.1042/BCJ20210535","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119978259&doi=10.1042%2fBCJ20210535&partnerID=40&md5=17e100dab5149acde4d943e38cece972","Optimising the function of a protein of length N amino acids by directed evolution involves navigating a 'search space' of possible sequences of some 20N. Optimising the expression levels of P proteins that materially affect host performance, each of which might also take 20 (logarithmically spaced) values, implies a similar search space of 20P. In this combinatorial sense, then, the problems of directed protein evolution and of host engineering are broadly equivalent. In practice, however, they have different means for avoiding the inevitable difficulties of implementation. The spare capacity exhibited in metabolic networks implies that host engineering may admit substantial increases in flux to targets of interest. Thus, we rehearse the relevant issues for those wishing to understand and exploit those modern genome-wide host engineering tools and thinking that have been designed and developed to optimise fluxes towards desirable products in biotechnological processes, with a focus on microbial systems. The aim throughput is 'making such biology predictable'. Strategies have been aimed at both transcription and translation, especially for regulatory processes that can affect multiple targets. However, because there is a limit on how much protein a cell can produce, increasing kcat in selected targets may be a better strategy than increasing protein expression levels for optimal host engineering. © 2021 Portland Press Ltd. All rights reserved.",,"biotechnology; genetic transcription; human; human experiment; molecular evolution; protein expression level; protein function; review; thinking; bacterial genome; biotechnology; directed molecular evolution; epistasis; fungal genome; genetic association study; genetics; metabolic engineering; metabolism; metabolomics; microbiology; procedures; protein engineering; protein synthesis; proteomics; bacterial protein; fungal protein; Bacterial Proteins; Biotechnology; Directed Molecular Evolution; Epistasis, Genetic; Fungal Proteins; Genetic Association Studies; Genome, Bacterial; Genome, Fungal; Industrial Microbiology; Metabolic Engineering; Metabolic Networks and Pathways; Metabolomics; Protein Biosynthesis; Protein Engineering; Proteomics; Transcription, Genetic"
"Murray B., Anderson D.T., Havens T.C.","Actionable XAI for the Fuzzy Integral","10.1109/FUZZ45933.2021.9494563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114692741&doi=10.1109%2fFUZZ45933.2021.9494563&partnerID=40&md5=6f4a964f42f20584d1daa814199f7cf0","The adoption of artificial intelligence (AI) into domains that impact human life (healthcare, agriculture, security and defense, etc.) has led to an increased demand for explainable AI (XAI). Herein, we focus on an under represented piece of the XAI puzzle, information fusion. To date, a number of low-level XAI explanation methods have been proposed for the fuzzy integral (FI). However, these explanations are tailored to experts and its not always clear what to do with the information they return. In this article we review and categorize existing FI work according to recent XAI nomenclature. Second, we identify a set of initial actions that a user can take in response to these low-level statistical, graphical, local, and linguistic XAI explanations. Third, we investigate the design of an interactive user friendly XAI report. Two case studies, one synthetic and one real, show the results of following recommended actions to understand and improve tasks involving classification. © 2021 IEEE.","artificial intelligence; Choquet integral; explainable AI; fuzzy integral; linguistic summarization; XAI","Agricultural robots; Classification (of information); Fuzzy systems; Integral equations; Case-studies; Fuzzy integral; Human lives; Under-represented; User friendly; Artificial intelligence"
"Mutasa S., Yi P.H.","Deciphering musculoskeletal artificial intelligence for clinical applications: how do I get started?","10.1007/s00256-021-03850-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121939207&doi=10.1007%2fs00256-021-03850-4&partnerID=40&md5=2997a1f5d0eb02762b54f012dcb6f42a","Artificial intelligence (AI) represents a broad category of algorithms for which deep learning is currently the most impactful. When electing to begin the process of building an adequate fundamental knowledge base allowing them to decipher machine learning research and algorithms, clinical musculoskeletal radiologists currently have few options to turn to. In this article, we provide an introduction to the vital terminology to understand, how to make sense of data splits and regularization, an introduction to the statistical analyses used in AI research, a primer on what deep learning can or cannot do, and a brief overview of clinical integration methods. Our goal is to improve the readers’ understanding of this field. © 2021, ISS.","Artificial intelligence; Deep learning; Introduction; Machine learning; Musculoskeletal radiology","artificial intelligence; deep learning; human; knowledge base; musculoskeletal radiologist; nomenclature; radiology; review; algorithm; machine learning; radiologist; Algorithms; Artificial Intelligence; Humans; Machine Learning; Radiologists; Radiology"
"Nafarzadegan A.R., Ebrahimi-Khusfi Z., Kazemi M.","Spatial characterization of dust emission prone arid regions using feature extraction and predictive algorithms","10.1016/j.apgeog.2021.102495","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108429580&doi=10.1016%2fj.apgeog.2021.102495&partnerID=40&md5=c8232d1eb253c303bc49e029142a612e","Aeolian dust emission is a serious environmental hazard in central Iran. We attempted to map the dust emission prone (DEP) areas in this region of Iran using the most accurate model among the random forest (RF), conditional RF (CRF), parallel RF (PRF), and extremely randomized trees (ERT) models. These models were evaluated using the Taylor diagram, Nash Sutcliffe coefficient, and Kling–Gupta efficiency. The generated map of DEP areas was also validated based on an aerosols optical depth (AOD) dataset. The Shapely values were used to determine the contribution of factors controlling dust events in DEP areas. The high performance and reliability of the ERT model for mapping DEP territories were confirmed by both error assessment statistics and reclassified AOD map. Using the ERT-generated map, five dust generation susceptibility classes including very low (20.16%), low (19.99%), moderate (19.82%), high (24.11%), and very high (15.92%) were identified in the study region. Drought severity, solar radiation, soil moisture, geology, soil sand content, bulk density, vegetation cover, land use, and slope were detected as the key features controlling dust emissions in central Iran. These results are useful for developing programs to reduce dust emissions hazards in DEP areas, particularly in central Iran. © 2021 Elsevier Ltd","Arid environments; Boruta algorithm; Dust-source areas; Game theory; Land susceptibility; Remote sensing","aerosol; algorithm; arid environment; dust; eolian deposit; game theory; prediction; remote sensing; Iran"
"Nafii A., Taleb A., El Mesbahi M., Ezzaouini M.A., El Bilali A.","Early Forecasting Hydrological and Agricultural Droughts in the Bouregreg Basin Using a Machine Learning Approach","10.3390/w15010122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145974467&doi=10.3390%2fw15010122&partnerID=40&md5=836ec4452a511c521f67949dfa7d86c8","Water supply for drinking and agricultural purposes in semi-arid regions is confronted with severe drought risks, which impact socioeconomic development. However, early forecasting of drought indices is crucial in water resource management to implement mitigation measures against its consequences. In this study, we attempt to develop an integrated approach to forecast the agricultural and hydrological drought in a semi-arid zone to ensure sustainable agropastoral activities at the watershed scale and drinking water supply at the reservoir scale. To that end, we used machine learning algorithms to forecast the annual SPEI and we embedded it into the hydrological drought by implementing a correlation between the reservoir’s annual inflow and the annual SPEI. The results showed that starting from December we can forecast the annual SPEI and so the annual reservoir inflow with an NSE ranges from 0.62 to 0.99 during the validation process. The proposed approach allows the decision makers not only to manage agricultural drought in order to ensure pastoral activities “sustainability at watershed scale” but also to manage hydrological drought at a reservoir scale. © 2022 by the authors.","agricultural drought; artificial neural network; Bouregreg basin; hydrological drought; SPEI","Agriculture; Decision making; Drought; Forecasting; Learning algorithms; Machine learning; Neural networks; Potable water; Water management; Water supply; Watersheds; Agricultural drought; Agricultural purpose; Bouregreg basin; Drought risks; Hydrological droughts; Machine learning approaches; Semi-arid region; Socio-economic development; SPEI; Watershed scale; Reservoirs (water); artificial neural network; drinking water; drought; forecasting method; index method; integrated approach; machine learning; resource management; water resource; water supply; watershed"
"Nageshwari K., Senthamizhan V., Balasubramanian P.","Sustaining struvite production from wastewater through machine learning based modelling and process validation","10.1016/j.seta.2022.102608","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136090445&doi=10.1016%2fj.seta.2022.102608&partnerID=40&md5=a0bf09c7f110f58f0d528af82e1621ac","The looming scarcity of phosphorus rock and intensification of its extraction for fertilizing applications has triggered the researchers to work upon a potential alternative such as struvite precipitation from wastewaters. Struvite production at commercial scale requires the support of novel prediction tools to smoothen the planning and execution processes. The present work aims at predicting the struvite recovery using several machine learning algorithms such as linear regression model, polynomial regression model, random forest regression model and eXtreme Gradient Boosting (XGB) regression model. Datasets for ten significant process parameters such as pH, temperature, concentrations of phosphate, ammonium and magnesium, stirring speed, reaction and retention time, drying temperature and time of various wastewater sources were collected for predicting the recovery. To minimize the loss function, extensive grid search hyperparameter tuning was performed to optimize the model. XGB was found to be the most robust method for prediction of nutrient recovery as struvite. The highest regression coefficient (R2) of 0.9683 and 0.9483 were achieved for phosphate and ammonium recoveries, respectively. The key influencing factors on target output were studied using SHapley Additive exPlanations (SHAP) plots that depicts the interactive effect of each of the input parameters on phosphate and ammonium recovery. Experimental validation was carried out to further support the model predictions. © 2022 Elsevier Ltd","Ammonium recovery; eXtreme Gradient Boosting; Machine learning method; Phosphorus recovery; Struvite","Adaptive boosting; Decision trees; Forecasting; Machine learning; Phosphorus; Random forests; Regression analysis; Ammonium recovery; Extreme gradient boosting; Gradient boosting; Learning Based Models; Machine learning methods; Machine-learning; Model validation; Phosphorus recovery; Regression modelling; Struvites; Recovery; algorithm; ammonium; machine learning; modeling; phosphorus; regression analysis; struvite; wastewater"
"Nagitta P.O., Mugurusi G., Obicci P.A., Awuor E.","Human-centered artificial intelligence for the public sector: The gate keeping role of the public procurement professional","10.1016/j.procs.2022.01.308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127772806&doi=10.1016%2fj.procs.2022.01.308&partnerID=40&md5=0238610da5d2177e1afc4300ebdba784","The increasing deployment of artificial intelligence (AI) powered solutions for the public sector is hoped to change how developing countries deliver services in key sectors such as agriculture, healthcare, education, and social sectors. And yet AI has a high potential for abuse and creates risks, which if not managed and monitored will jeopardize respect and dignity of the most vulnerable in society. In this study, we argue for delineating public procurements' role in the human-centred AI (HCAI) discourses, focusing on the developing countries. The study is based on an exploratory inquiry and gathered data among procurement practitioners in Uganda and Kenya, which have similar country procurement regimes: where traditional forms of competition in procurement apply compared to more recent pre-commercial procurement mechanisms that suit AI procurement. We found limited customization in AI technologies, a lack of developed governance frameworks, and little knowledge and distinction between AI procurement and other typical technology procurement processes. We proposed a framework, which in absence of good legal frameworks can allow procurement professionals to embed HCAI principles in AI procurement processes. © 2022 The Authors. Published by Elsevier B.V.","developing countries; Ethical AI; Explainable AI(XAI); Human-centered artificial intelligence (AI); public procurement; Responsible AI","Developing countries; Ethical technology; Agriculture sectors; Ethical artificial intelligence; Explainable artificial intelligence(XAI); Healthcare sectors; Human-centered artificial intelligence; Procurement process; Procurement professionals; Public procurement; Public sector; Responsible artificial intelligence; Artificial intelligence"
"Naidoo L., Main R., Cho M.A., Madonsela S., Majozi N.","Machine learning modelling of crop structure within the Maize Triangle of South Africa","10.1080/01431161.2021.1998714","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122698484&doi=10.1080%2f01431161.2021.1998714&partnerID=40&md5=b67ee345d54d06c9c9e9e96030ba2c1e","Maize has been identified as a strategic commodity for the reduction of poverty and enhancement of food security in the African continent. Climate variability and difficult economic conditions are pressuring farmers to produce higher (maize) yields with fewer inputs, per hectare. The remote sensing of crop specific structural parameters are essential in identifying the particular growth stages of the maize crop which require specific tasks from the farmer (e.g. weed control, top dressing, pesticide application for disease and borer control and critical moisture phase). This study sought to assess the performance of multiple linear regression (LR), Random Forest (RF) and Gaussian Process Regression (GPR) in the estimation of four maize crop structural parameters in a study area in the Vereeniging region of the Maize Triangle of South Africa. These parameters were leaf area index (LAI), stem height (HT), stem diameter (DIA) and stem density (SD). An additional aim was to investigate whether the combination of selected spectral vegetation indices (red-edge, chlorophyll, senescence and greenness) with Sentinel-2 reflectance bands as modelling predictors yielded improved results over the individual spectral bands alone. Combining reflectance bands and vegetation indices as modelling predictors yielded the highest validation accuracy, over other scenarios, for only one out of the four crop structural parameters (DAI). The reflectance bands only scenario yielded the highest validation accuracies for two crop structural parameters (HT and SD). The use of spectral vegetation indices alone as modelling predictors yielded the highest modelling accuracies for the LAI crop parameter than the other scenarios. These trends indicate that the combination of Sentinel-2 reflectance bands and derived vegetation indices do not always yield improved modelling results for the four crop structural parameters under investigation. As a result, reflectance bands (mostly) or indices alone could suffice for nearly all of the parameters. With respect to the modelling algorithms, LR yielded the highest accuracies for DIA and SD (Standard Error of Prediction or SEP values of 22.40%±4.65 and 34.15%±2.72 respectively). GPR yielded the highest accuracies for LAI and HT (SEP values of 28.69%±3.84 and 23.19%±2.27 respectively) while RF did not yield the highest validation accuracy for any of the crop structural parameters. © 2022 Informa UK Limited, trading as Taylor & Francis Group.",,"Decision trees; Disease control; Food supply; Linear regression; Machine learning; Reflection; Remote sensing; Vegetation; Weed control; Gaussian process regression; High-accuracy; Leaf Area Index; Machine learning models; Random forests; South Africa; Spectral vegetation indices; Stem density; Structural parameter; Vegetation index; Crops; growth rate; leaf area index; machine learning; maize; modeling; remote sensing; Sentinel; stem; vegetation index; South Africa"
"Nair D., Cohen K., Kumar M.","Classification of Rice Using Genetic Fuzzy Cascading System","10.1007/978-3-031-16038-7_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140477254&doi=10.1007%2f978-3-031-16038-7_17&partnerID=40&md5=19c7f7eb272f2029755e32154dc31e95","Classification can be done using various AI methods currently available in the literature. However most of the AI techniques are black boxes. We do not know what is going on inside them and hence explainability of the model is very limited. A fuzzy system can increase the explainability to a certain degree. In this paper, we classify two different types of rice with the use of a genetic fuzzy cascading system and compare the accuracy with other methods. A total of rice grain images are converted to greyscale images and with help of computer vision, the attributes are obtained. These data are used for classification using a 7 input 2 output Fuzzy Inference System (FIS) with multiple levels of cascading. Each of the input, output membership functions and the rule base are tuned using Genetic Algorithm. Our current approach was able to produce 94% accuracy in the validation set. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Classification of rice; Fuzzy; Genetic Algorithm; Soft computing",
"Najjar A., Hosseini-Kivanani N., Tchappi Haman I., Mualla Y., Van Der Peijl E., Karpati D., Schommer C.","XAI: Using Smart Photobooth for Explaining History of Art","10.1145/3527188.3563914","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144603729&doi=10.1145%2f3527188.3563914&partnerID=40&md5=a97b5ef10071edc7feb59b6cc5237459","The rise of Artificial Intelligence has led to advancements in daily life, including applications in industries, telemedicine, farming, and smart cities. It is necessary to have human-AI synergies to guarantee user engagement and provide interactive expert knowledge, despite AI's success in ""less technical""fields. In this article, the possible synergies between humans and AI to explain the development of art history and artistic style transfer are discussed. This study is part of the ""Smart Photobooth""project that is able to automatically transform a user's picture into a well-known artistic style as an interactive approach to introduce the fundamentals of the history of art to the common people and provide them with a concise explanation of the various art painting styles. This study investigates human-AI synergies by combining the explanation produced by an explainable AI mechanism with a human expert's insights to provide reasons for school students and a larger audience. © 2022 Owner/Author.","User Experience; User-Centred Design","Arts computing; User experience; Art history; Art paintings; Artistic style transfer; Daily lives; Expert knowledge; Human expert; Interactive approach; Technical fields; User engagement; Users' experiences; User centered design"
"Nakata T., Chen S., Nakamura M.","Uni-Messe: Unified Rule-Based Message Delivery Service for Efficient Context-Aware Service Integration†","10.3390/en15051729","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125179312&doi=10.3390%2fen15051729&partnerID=40&md5=ebf17df47557b90381ae8acdc5e75234","Rule-based systems, which are the typical technology used to realize context-aware services, have been independently implemented in various smart services. The challenges of these systems are the versatility of action, looseness, and the coding that is needed to describe the conditional branches. The purpose of this study was to support the realization of service coordination and smart services using context-aware technology by converting rule-based systems into services. In the proposed method, we designed and implemented the architecture of a new service: Unified Rule-Based Message Delivery Service (Uni-messe), which is an application-neutral rule management and evaluation service for rule-based systems. The core part of the Uni-messe proposal is the combination of a Pub/Sub and a rule-based system, and the proposal of a new event–condition–route (ECR) rule-based system. We applied Uni-messe to an audio information presentation system (ALPS) and indoor location sensing technology to construct concrete smart services, and then compared and evaluated the implementation to “if this then that” (IFTTT), which is a typical service coordination technology. Moreover, we analyzed the characteristics of other rule-based systems that have been serviced in previous studies and compared them to Uni-messe. This study shows that Uni-messe can provide services that simultaneously combine versatility, ease of conditional description, looseness, context independence, and user interface (UI), which cannot be achieved using conventional rule-based system services. By using Uni-messe, advanced heterogeneous distributed service coordination using rule-based systems and the construction of context-aware services can be performed easily. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Context-aware service; Heterogeneous distributed service; Rule-based system; Smart service integration; Value-added service","Knowledge based systems; Location based services; Telecommunication services; User interfaces; Context-aware service; Distributed service; Heterogeneous distributed service; Message delivery; Rule based; Rules based systems; Services integrations; Smart service integration; Smart services; Value added service; Information services"
"Nakhle F., Harfouche A.L.","Extended reality gives digital agricultural biotechnology a new dimension","10.1016/j.tibtech.2022.09.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143995305&doi=10.1016%2fj.tibtech.2022.09.005&partnerID=40&md5=2af15541197e55dccf02b2772a5c355a","Facing up to the global challenges of designing climate-resilient biotech crops involves a great deal of out-of-the-box thinking. Extended reality is coming of age in digital agricultural biotechnology. Here, we seek to stimulate technological innovation by empowering future innovators, researchers, academics, and startups to think and partner creatively. © 2022 Elsevier Ltd","3D representations; augmented reality; explainable artificial intelligence; extended reality; mixed reality; virtual reality","artificial intelligence; augmented reality; biotechnology; human; human experiment; note; virtual reality; agriculture; climate; crop; invention; Agriculture; Biotechnology; Climate; Crops, Agricultural; Inventions"
"Nakhle F., Harfouche A.L.","Ready, Steady, Go AI: A practical tutorial on fundamentals of artificial intelligence and its applications in phenomics image analysis","10.1016/j.patter.2021.100323","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121116396&doi=10.1016%2fj.patter.2021.100323&partnerID=40&md5=dc4e55d63cc066ee5c98b6f934ebb8fa","High-throughput image-based technologies are now widely used in the rapidly developing field of digital phenomics and are generating ever-increasing amounts and diversity of data. Artificial intelligence (AI) is becoming a game changer in turning the vast seas of data into valuable predictions and insights. However, this requires specialized programming skills and an in-depth understanding of machine learning, deep learning, and ensemble learning algorithms. Here, we attempt to methodically review the usage of different tools, technologies, and services available to the phenomics data community and show how they can be applied to selected problems in explainable AI-based image analysis. This tutorial provides practical and useful resources for novices and experts to harness the potential of the phenomic data in explainable AI-led breeding programs. © 2021 The Authors","algorithms; deep learning; DSML 4: Production Data science output is validated, understood, and regularly used for multiple domains/platforms; explainable artificial intelligence; image analysis; integrated development environments; machine learning; phenomics; programming languages; software frameworks; software libraries","Application programs; Deep learning; Digital libraries; Learning algorithms; Deep learning; DSML 4: production data science output be validated, understand, and regularly used for multiple domain/platform; Explainable artificial intelligence; Image-analysis; Integrated development environment; Multiple domains; Phenomic; Production data; Programming language; Software frameworks; Software libraries; Image analysis"
"Nan T., Cao W.","Effect of Ecological Water Supplement on Groundwater Restoration in the Yongding River Based on Multi-Model Linkage","10.3390/w15020374","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146746756&doi=10.3390%2fw15020374&partnerID=40&md5=55eaea42b218b4f82487b14fe5b3acc4","Evaluating the effect of ecological water supplement on groundwater restoration quantitatively could produce positive contributions to both water cycle theory and surface–groundwater conjunctive management. Therefore, in this paper, a groundwater flow numerical model has been established after calculating the river section seepage rate using a fuzzy mathematical method in the Yongding River channel. The simulated results show that the model could accurately reflect the real groundwater dynamic features. Then, a data-driven random forest(RF) model has been established to quantitatively evaluate the contributions of the factors which influence the groundwater level variation. The Nash-Sutcliffe efficiency coefficient(NSE) of the RF model is 0.93. It shows excellent ability to identify the rising zone of groundwater level. The study shows that the infiltration capacity is strong in the upstream area of the Yongding River, and the seepage rate is over 0.7. The lowest seepage rate is 0.19 at the downstream end, while the seepage rate in the middle area is basically between 0.4 and 0.7. From 2018 to 2019, the ecological water supplement of the Yongding River has played a significant role in raising the groundwater level along the river channel. Additionally, its contribution analyzed by the RF model to the change of groundwater level is 25%. Groundwater exploitation is the most important variable affecting the groundwater level variation. The impact depth of groundwater level fluctuation reaches about 10 m. The impact range where the groundwater level average uplifts 1.86 m is 502.13 km2. The influence direction gradually changes from around the ecological water supplement section to along the Yongding River channel. The groundwater level variation along the tangential direction of the Yongding River is slowing down. The groundwater level would entirely uplift with 170 × 106 m3/year ecological water supplement of the Yongding River and 35.77 × 106 m3/year groundwater mining reduction in the downstream area until 2035. © 2023 by the authors.","ecological water supplement; fuzzy mathematics; groundwater numerical model; random forest; Yongding River","Ecology; Groundwater flow; Mining; Numerical methods; Numerical models; Restoration; Rivers; Seepage; Ecological water supplement; Fuzzy mathematics; Ground water level; Groundwater level variation; Groundwater numerical models; Random forest modeling; Random forests; River channels; Seepage rate; Yongding river; Groundwater; groundwater flow; hydrological cycle; infiltration; numerical method; uplift; Yongding River [China]"
"Nandutu I., Atemkeng M., Okouma P.","Intelligent Systems Using Sensors and/or Machine Learning to Mitigate Wildlife–Vehicle Collisions: A Review, Challenges, and New Perspectives","10.3390/s22072478","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126791943&doi=10.3390%2fs22072478&partnerID=40&md5=c0f4d1fa32ba92213a3bd981929ae232","Worldwide, the persistent trend of human and animal life losses, as well as damage to properties due to wildlife–vehicle collisions (WVCs) remains a significant source of concerns for a broad range of stakeholders. To mitigate their occurrences and impact, many approaches are being adopted, with varying successes. Because of their increased versatility and increasing efficiency, Artificial Intelligence-based methods have been experiencing a significant level of adoption. The present work extensively reviews the literature on intelligent systems incorporating sensor technologies and/or machine learning methods to mitigate WVCs. Included in our review is an investigation of key factors contributing to human–wildlife conflicts, as well as a discussion of dominant state-of-the-art datasets used in the mitigation of WVCs. Our study combines a systematic review with bibliometric analysis. We find that most animal detection systems (excluding autonomous vehicles) are relying neither on state-of-the-art datasets nor on recent breakthrough machine learning approaches. We, therefore, argue that the use of the latest datasets and machine learning techniques will minimize false detection and improve model performance. In addition, the present work covers a comprehensive list of associated challenges ranging from failure to detect hotspot areas to limitations in training datasets. Future research directions identified include the design and development of algorithms for real-time animal detection systems. The latter provides a rationale for the applicability of our proposed solutions, for which we designed a continuous product development lifecycle to determine their feasibility. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Animal behavior; Animal detection systems; Human behavior; Human–wildlife; Intelligent systems; Machine learning; Machine learning datasets; Sensor; Wildlife–vehicle collisions","Animals; Behavioral research; Life cycle; Machine learning; Real time systems; Vehicles; Animal behaviour; Animal detection system; Detection system; Human behaviors; Human–wildlife; Machine learning dataset; Sensor; State of the art; Vehicles collision; Wildlife–vehicle collision; Intelligent systems; algorithm; animal; artificial intelligence; machine learning; technology; wild animal; Algorithms; Animals; Animals, Wild; Artificial Intelligence; Machine Learning; Technology"
"Nanushi O., Sitokonstantinou V., Tsoumas I., Kontoes C.","Pest Presence Prediction Using Interpretable Machine Learning","10.1109/IVMSP54334.2022.9816284","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135200313&doi=10.1109%2fIVMSP54334.2022.9816284&partnerID=40&md5=72be95d280ab881f001aa27df07f84ae","Helicoverpa Armigera, or cotton bollworm, is a serious insect pest of cotton crops that threatens the yield and the quality of lint. The timely knowledge of the presence of the insects in the field is crucial for effective farm interventions. Meteo-climatic and vegetation conditions have been identified as key drivers of crop pest abundance. In this work, we applied an interpretable classifier, i.e., Explainable Boosting Machine, which uses earth observation vegetation indices, numerical weather predictions and insect trap catches to predict the onset of bollworm harmfulness in cotton fields in Greece. The glass-box nature of our approach provides significant insight on the main drivers of the model and the interactions among them. Model interpretability adds to the trustworthiness of our approach and therefore its potential for rapid uptake and context-based implementation in operational farm management scenarios. Our results are satisfactory and the importance of drivers, through our analysis on global and local explainability, is in accordance with the literature. © 2022 IEEE.","helicoverpa armigera; interpretable machine learning; numerical weather predictions; pest insect appearance; precision agriculture; vegetation indices","Crops; Forecasting; Machine learning; Precision agriculture; Vegetation; Climatic conditions; Helicoverpa armigera; Insects pests; Interpretable machine learning; Machine-learning; Numerical weather prediction; Pest insect appearance; Precision Agriculture; Vegetation condition; Vegetation index; Cotton"
"Narita K., Matsui Y., Matsushita T., Shirasaki N.","Screening priority pesticides for drinking water quality regulation and monitoring by machine learning: Analysis of factors affecting detectability","10.1016/j.jenvman.2022.116738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141753891&doi=10.1016%2fj.jenvman.2022.116738&partnerID=40&md5=4fa2ea0a7e1b53117673f9fd369cbf35","Proper selection of new contaminants to be regulated or monitored prior to implementation is an important issue for regulators and water supply utilities. Herein, we constructed and evaluated machine learning models for predicting the detectability (detection/non-detection) of pesticides in surface water as drinking water sources. Classification and regression models were constructed for Random Forest, XGBoost, and LightGBM, respectively; of these, the LightGBM classification model had the highest prediction accuracy. Furthermore, its prediction performance was superior in all aspects of Recall, Precision, and F-measure compared to the detectability index method, which is based on runoff models from previous studies. Regardless of the type of machine learning model, the number of annual measurements, sales quantity of pesticide for rice-paddy field, and water quality guideline values were the most important model features (explanatory variables). Analysis of the impact of the features suggested the presence of a threshold (or range), above which the detectability increased. In addition, if a feature (e.g., quantity of pesticide sales) acted to increase the likelihood of detection beyond a threshold value, other features also synergistically affected detectability. Proportion of false positives and negatives varied depending on the features used. The superiority of the machine learning models is their ability to represent nonlinear and complex relationships between features and pesticide detectability that cannot be represented by existing risk scoring methods. © 2022 Elsevier Ltd","Drinking water source; Guideline; Monitoring; Pesticide concentration; Prediction; Screening","drinking water; pesticide; surface water; drinking water; pesticide; concentration (composition); drinking water; machine learning; paddy field; pesticide; runoff; surface water; water quality; water supply; Article; cultivated land; environmental impact; false positive result; health hazard; limit of quantitation; machine learning; paddy field; performance indicator; prediction; predictive value; random forest; water monitoring; water quality; water supply; environmental monitoring; machine learning; water pollutant; water quality; Drinking Water; Environmental Monitoring; Machine Learning; Pesticides; Water Pollutants, Chemical; Water Quality"
"Nasr D., Babagoli R., Rezaei M., Borujeni P.R.","Evaluating the substitution potential of SBS with crumb rubber-polypropylene blends as asphalt binder and mixture modifiers","10.1016/j.conbuildmat.2022.129503","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140338194&doi=10.1016%2fj.conbuildmat.2022.129503&partnerID=40&md5=c9107b7bfecdbe8073e1686cfc53b9d8","The study aimed to assess the suitability of substituting styrene–butadienestyrene with waste crumb rubber-polypropylene blends as modifiers to enhance the performance characteristics of asphalt binders and mixtures. Six crumb rubber-polypropylene blends including three styrene–butadienestyrene percentages were used to modify a base binder and then the modified binders were used to fabricate asphalt concrete mixtures. To obtain the physical and compatibility behavior of the unmodified and modified binders, various conventional binder tests such as softening point, penetration, and storage stability were employed. Dynamic shear rheometer, multiple stress creep recovery, and linear amplitude strain tests were performed on unaged and long-term aged samples to achieve a broad understating of rheological characteristics at high and intermediate temperatures. In order to assess the influence of the modifiers on asphalt mixtures, various test methods were implemented including indirect tensile strength, resilient modulus, and four-point beam fatigue and dynamic creep tests. The findings of the physical tests represented a decline in penetration and a rise in softening point by the crumb rubber-polypropylene and styrene–butadienestyrene modifications compared with the base one. Results of the storage stability test proved that only 3% styrene–butadienestyrene modified was a storage-stable blend at high construction temperatures and the instability increased by incorporating more polymer content. According to the rotational viscosity test, all of the modifications increased the viscosity, reducing the workability of the modified mixture. Based on the rheological tests, the addition of the modifiers resulted in a reduction in phase angles, and an increase in complex modulus at high temperatures, thereby decreasing binder sensitivity to permanent deformation. With increasing the percentage of the polymer, more improvement would be obtained regarding rutting resistance. At intermediate temperatures, however, the complex modulus of modified binders decreased while no notable changes were observed for phase angle compared to the base binder. Considering the mechanical test results, the crumb rubber-polypropylene and styrene–butadienestyrene modified mixtures resulted in an enhancement in indirect tensile strength, resilient modulus, four-point beam fatigue, and dynamic creep tests results which would cause better resistance against rutting, fatigue damage, and moisture susceptibility compared with the base one. Besides, a radial bias function neural network model was designed to predict tensile strength ratio, and fracture energy ratio. The results showed the high performance of this method in the estimation of these values. © 2022 Elsevier Ltd","ANN; Performance; Prediction; Radial bias function neural network; Waste tire rubber","Asphalt concrete; Asphalt pavements; Binders; Complex networks; Concrete mixtures; Creep; Dynamics; Fatigue of materials; Forecasting; Mixtures; Polypropylenes; Rubber; Tensile strength; Viscosity; ANN; Asphalt binders; Crumb rubber; Modified binders; Neural-networks; Performance; Polypropylene blends; Radial bias function neural network; Softening points; Waste tyre rubbers; Styrene"
"Nay Z., Huggins A., Deane F.","Automated Decision-Making and Environmental Impact Assessments: Decisions, Data Analysis and Predictions","10.5204/lthj.1846","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130272766&doi=10.5204%2flthj.1846&partnerID=40&md5=739eeb9a4e0a54935f1583f486fbae8a","This article critically examines the opportunities and challenges that automated decision-making (ADM) poses for environmental impact assessments (EIAs) as a crucial aspect of environmental law. It argues that while fully or partially automating discretionary EIA decisions is legally and technically problematic, there is significant potential for data-driven decision-making tools to provide superior analysis and predictions to better inform EIA processes. Discretionary decision-making is desirable for EIA decisions given the inherent complexity associated with environmental regulation and the prediction of future impacts. This article demonstrates that current ADM tools cannot adequately replicate human discretionary processes for EIAs—even if there is human oversight and review of automated outputs. Instead of fully or partially automating EIA decisions, data-driven decision-making can be more appropriately deployed to enhance data analysis and predictions to optimise EIA decision-making processes. This latter type of ADM can augment decision-making processes without displacing the critical role of human discretion in weighing the complex environmental, social and economic considerations inherent in EIA determinations. © The Author/s 2021","automated decision making; data-driven decision making; discretionary decisions; Environmental impact assessments",
"Nayak H.S., Silva J.V., Parihar C.M., Krupnik T.J., Sena D.R., Kakraliya S.K., Jat H.S., Sidhu H.S., Sharma P.C., Jat M.L., Sapkota T.B.","Interpretable machine learning methods to explain on-farm yield variability of high productivity wheat in Northwest India","10.1016/j.fcr.2022.108640","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136105635&doi=10.1016%2fj.fcr.2022.108640&partnerID=40&md5=a31a6a981128f19927d6044c21d89363","The increasing availability of complex, geo-referenced on-farm data demands analytical frameworks that can guide crop management recommendations. Recent developments in interpretable machine learning techniques offer opportunities to use these methods in agronomic studies. Our objectives were two-fold: (1) to assess the performance of different machine learning methods to explain on-farm wheat yield variability in the Northwestern Indo-Gangetic Plains of India, and (2) to identify the most important drivers and interactions explaining wheat yield variability. A suite of fine-tuned machine learning models (ridge and lasso regression, classification and regression trees, k-nearest neighbor, support vector machines, gradient boosting, extreme gradient boosting, and random forest) were statistically compared using the R2, root mean square error (RMSE), and mean absolute error (MAE). The best performing model was again fine-tuned using a grid search approach for the bias-variance trade-off. Three post-hoc model agnostic techniques were used to interpret the best performing model: variable importance (a variable was considered “important” if shuffling its values increased or decreased the model error considerably), interaction strength (based on Friedman's H-statistic), and two-way interaction (i.e., how much of the total variability in wheat yield was explained by a particular two-way interaction). Model outputs were compared against empirical data to contextualize results and provide a blueprint for future analysis in other production systems. Tree-based and decision boundary-based methods outperformed regression-based methods in explaining wheat yield variability. Random forest was the best performing method in terms of goodness-of-fit and model precision and accuracy with RMSE, MAE, and R2 ranging between 367 and 470 kg ha−1, 276–345 kg ha−1, and 0.44–0.63, respectively. Random forest was then used for selection of important variables and interactions. The most important management variables explaining wheat yield variability were nitrogen application rate and crop residue management, whereas the average of monthly cumulative solar radiation during February and March (coinciding with reproductive phase of wheat) was the most important biophysical variable. The effect size of these variables on wheat yield ranged between 227 kg ha−1 for nitrogen application rate to 372 kg ha−1 for cumulative solar radiation during February and March. The effect of important interactions on wheat yield was detected in the data namely the interaction between crop residue management and disease management and, nitrogen application rate and seeding rate. For instance, farmers’ fields with moderate disease incidence yielded 750 kg ha−1 less when crop residues were removed than when crop residues were retained. Similarly, wheat yield response to residue retention was higher under low seed and N application rates. As an inductive research approach, the appropriate application of interpretable machine learning methods can be used to extract agronomically actionable information from large-scale farmer field data. © 2022 The Authors","Accumulated local effect plot; Big data; Interaction strength; Partial dependency plot; Quantile regression; Random forest; Variable importance","crop yield; disease incidence; machine learning; productivity; regression; India"
"Nazar M., Alam M.M., Yafi E., Su'Ud M.M.","A Systematic Review of Human-Computer Interaction and Explainable Artificial Intelligence in Healthcare with Artificial Intelligence Techniques","10.1109/ACCESS.2021.3127881","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119430656&doi=10.1109%2fACCESS.2021.3127881&partnerID=40&md5=48b8c8ad4f320230a1a6fd0c3642eba7","Artificial intelligence (AI) is one of the emerging technologies. In recent decades, artificial intelligence (AI) has gained widespread acceptance in a variety of fields, including virtual support, healthcare, and security. Human-Computer Interaction (HCI) is a field that has been combining AI and human-computer engagement over the past several years in order to create an interactive intelligent system for user interaction. AI, in conjunction with HCI, is being used in a variety of fields by employing various algorithms and employing HCI to provide transparency to the user, allowing them to trust the machine. The comprehensive examination of both the areas of AI and HCI, as well as their subfields, has been explored in this work. The main goal of this article was to discover a point of intersection between the two fields. The understanding of Explainable Artificial Intelligence (XAI), which is a linking point of HCI and XAI, was gained through a literature review conducted in this research. The literature survey encompassed themes identified in the literature (such as XAI and its areas, major XAI aims, and XAI problems and challenges). The study's other major focus was on the use of AI, HCI, and XAI in healthcare. The poll also addressed the shortcomings in XAI in healthcare, as well as the field's future potential. As a result, the literature indicates that XAI in healthcare is still a novel subject that has to be explored more in the future. © 2013 IEEE.","Artificial intelligence; deep learning; explainable artificial intelligence; healthcare; human-centered design; human-computer interaction; machine learning; usability; user-centered design","Deep learning; Human computer interaction; Intelligent systems; Surveys; User centered design; Virtual reality; Artificial intelligence techniques; Comprehensive examination; Deep learning; Emerging technologies; Explainable artificial intelligence; Human-centred designs; Interactive intelligent systems; Machine-learning; Systematic Review; User interaction; Health care"
"Ngie H.M., Nderu L., Mutanu L., Gicuku D.M.","Mitigating preconception in machine learning classifiers","10.1109/ICECCME52200.2021.9591043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119421282&doi=10.1109%2fICECCME52200.2021.9591043&partnerID=40&md5=9fd9b6bb62cdbaaae9f635f8c6c06d2a","Modern Machine Learning (ML) approaches are aimed at enhancing model performance (behaviors and accuracy) through historical data available for the specific model. Continued use of machine learning has been witnessed in the real-world business including self-driving cars, health diagnosis systems, fraud detection, and customer churn predictions among other areas demanding intense safety and testing. Amid the intense application of the technology, however lies a growing user concern and interest in insights and decisions made by a classifier due to the increasingly complex models known for hiding crucial information regarding their outcome generation. Overreliance in model performance therefore can no longer be considered a sure metric to model performance due to the underlying trust issues and therefore the need for model interpretation or explanation to extend and make machine models potential sources of knowledge. This research paper delves into the understanding of the various approaches to successful model interpretation, further proposing enhancement of Local Interpretable Model-agnostic Explainer (LIME) via 'Calculus Local Interpretable Model-agnostic Explainer' (C-LIME) as an intuitive approach to black-box ML model interpretation. We further evaluate the framework performance demonstrating significant enhancement in black-box model interpretations without compromising prediction accuracy. © 2021 IEEE.","C-LIME; Classifier Explainability; Classifier interpretability; Explainable AI; Machine learning; Model Transparency","Calculations; Classification (of information); Lime; Safety testing; Calculus local interpretable model-agnostic explainer'; Classifier explainability; Classifier interpretability; Explainable AI; Interpretability; Machine learning approaches; Model interpretations; Model transparency; Modeling performance; Modern machines; Machine learning"
"Ngo Q.H., Kechadi T., Le-Khac N.-A.","OAK4XAI: Model Towards Out-of-Box eXplainable Artificial Intelligence for Digital Agriculture","10.1007/978-3-031-21441-7_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144818103&doi=10.1007%2f978-3-031-21441-7_17&partnerID=40&md5=233e903264e3efd6724fe09b3db20875","Recent machine learning approaches have been effective in Artificial Intelligence (AI) applications. They produce robust results with a high level of accuracy. However, most of these techniques do not provide human-understandable explanations for supporting their results and decisions. They usually act as black boxes, and it is not easy to understand how decisions have been made. Explainable Artificial Intelligence (XAI), which has received much interest recently, tries to provide human-understandable explanations for decision-making and trained AI models. For instance, in digital agriculture, related domains often present peculiar or input features with no link to background knowledge. The application of the data mining process on agricultural data leads to results (knowledge), which are difficult to explain. In this paper, we propose a knowledge map model and an ontology design as an XAI framework (OAK4XAI) to deal with this issue. The framework does not only consider the data analysis part of the process, but it takes into account the semantics aspect of the domain knowledge via an ontology and a knowledge map model, provided as modules of the framework. Many ongoing XAI studies aim to provide accurate and verbalizable accounts for how given feature values contribute to model decisions. The proposed approach, however, focuses on providing consistent information and definitions of concepts, algorithms, and values involved in the data mining models. We built an Agriculture Computing Ontology (AgriComO) to explain the knowledge mined in agriculture. AgriComO has a well-designed structure and includes a wide range of concepts and transformations suitable for agriculture and computing domains. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Agriculture computing ontology; Digital agriculture; Explainable AI; Knowledge management; Knowledge map","Agriculture; Data mining; Decision making; Domain Knowledge; Knowledge engineering; Knowledge management; Semantics; Agriculture computing ontology; Agriculture-related; Black boxes; Decisions makings; Digital agriculture; Explainable artificial intelligence; Intelligence models; Knowledge map; Machine learning approaches; Ontology's; Ontology"
"Nguyen D.C., Cheng P., DIng M., Lopez-Perez D., Pathirana P.N., Li J., Seneviratne A., Li Y., Poor H.V.","Enabling AI in Future Wireless Networks: A Data Life Cycle Perspective","10.1109/COMST.2020.3024783","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101823242&doi=10.1109%2fCOMST.2020.3024783&partnerID=40&md5=609ec7adb09ed3b85142f5d6315ee5db","Recent years have seen rapid deployment of mobile computing and Internet of Things (IoT) networks, which can be mostly attributed to the increasing communication and sensing capabilities of wireless systems. Big data analysis, pervasive computing, and eventually artificial intelligence (AI) are envisaged to be deployed on top of the IoT and create a new world featured by data-driven AI. In this context, a novel paradigm of merging AI and wireless communications, called Wireless AI that pushes AI frontiers to the network edge, is widely regarded as a key enabler for future intelligent network evolution. To this end, we present a comprehensive survey of the latest studies in wireless AI from the data-driven perspective. Specifically, we first propose a novel Wireless AI architecture that covers five key data-driven AI themes in wireless networks, including Sensing AI, Network Device AI, Access AI, User Device AI and Data-provenance AI. Then, for each data-driven AI theme, we present an overview on the use of AI approaches to solve the emerging data-related problems and show how AI can empower wireless network functionalities. Particularly, compared to the other related survey papers, we provide an in-depth discussion on the Wireless AI applications in various data-driven domains wherein AI proves extremely useful for wireless network design and optimization. Finally, research challenges and future visions are also discussed to spur further research in this promising area. © 1998-2012 IEEE.","artificial intelligence; data-driven AI; deep learning; machine learning; Wireless networks","Internet of things; Life cycle; Surveys; Ubiquitous computing; Wireless networks; Future wireless networks; Internet of Things (IOT); Network functionality; Rapid deployments; Research challenges; Wireless communications; Wireless network design; Wireless systems; Artificial intelligence"
"Nguyen T.K., Dang L.M., Song H.-K., Moon H., Lee S.J., Lim J.H.","Wild Chrysanthemums Core Collection: Studies on Leaf Identification","10.3390/horticulturae8090839","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138622661&doi=10.3390%2fhorticulturae8090839&partnerID=40&md5=6bdcec469fdc75035bfcfc451f29f6fa","Wild chrysanthemums mainly present germplasm collections such as leaf multiform, flower color, aroma, and secondary compounds. Wild chrysanthemum leaf identification is critical for farm owners, breeders, and researchers with or without the flowering period. However, few chrysanthemum identification studies are related to flower color recognition. This study contributes to the leaf classification method by rapidly recognizing the varieties of wild chrysanthemums through a support vector machine (SVM). The principal contributions of this article are: (1) an assembled collection method and verified chrysanthemum leaf dataset that has been achieved and improved; (2) an adjusted SVM model that is offered to deal with the complex backgrounds presented by smartphone pictures by using color and shape classification results to be more attractive than the original process. As our study presents, the proposed method has a viable application in real-picture smartphones and can help to further investigate chrysanthemum identification. © 2022 by the authors.","chrysanthemum breeding; color classification; neural networks; shape classification; support vector machine",
"Nguyen V.-H., Le T.-T., Truong H.-S., Le M.V., Ngo V.-L., Nguyen A.T., Nguyen H.Q.","Applying Bayesian Optimization for Machine Learning Models in Predicting the Surface Roughness in Single-Point Diamond Turning Polycarbonate","10.1155/2021/6815802","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108973806&doi=10.1155%2f2021%2f6815802&partnerID=40&md5=d15a9122e9d281c4705b0b2734fc3e1d","This paper deals with the prediction of surface roughness in manufacturing polycarbonate (PC) by applying Bayesian optimization for machine learning models. The input variables of ultraprecision turning-namely, feed rate, depth of cut, spindle speed, and vibration of the X-, Y-, and Z-axis- A re the main factors affecting surface quality. In this research, six machine learning-(ML-) based models- A rtificial neural network (ANN), Cat Boost Regression (CAT), Support Vector Machine (SVR), Gradient Boosting Regression (GBR), Decision Tree Regression (DTR), and Extreme Gradient Boosting Regression (XGB)-were applied to predict the surface roughness (Ra). The predictive performance of the baseline models was quantitatively assessed through error metrics: Root means square error (RMSE), mean absolute error (MAE), and coefficient of determination (R2). The overall results indicate that the XGB and CAT models predict Ra with the greatest accuracy. In improving baseline models such as XGB and CAT, the Bayesian optimization (BO) is next used to determine their best hyperparameters, and the results indicate that XGB is the best model according to the evaluation metrics. Results have shown that the performance of the models has been improved significantly with BO. For example, the values of RMSE and MAE of XGB have decreased from 0.0076 to 0.0047 and from 0.0063 to 0.0027, respectively, for the training dataset. Using the testing dataset, the values of RMSE and MAE of XGB have decreased from 0.4033 to 0.2512 and from 0.2845 to 0.2225, respectively. Moreover, the vibrations of the X, Y, and Z axes and feed rate are the most significant feature in predicting the results, which is in high accordance with the literature. We find that, in a specified value domain, the vibration of the axes has a greater influence on the surface quality than does the cutting condition. © 2021 Van-Hai Nguyen et al.",,"Adaptive boosting; Decision trees; Errors; Forecasting; Polycarbonates; Statistical tests; Support vector machines; Support vector regression; Surface properties; Surface roughness; Coefficient of determination; Decision tree regression; Machine learning models; Predictive performance; Root-means-square errors; Single point diamond turning; Surface roughness (Ra); Ultra-precision turnings; Learning systems"
"Nie S., Li L., Wang Y., Wu Y., Li C., Chen S., Zhao Y., Wang D., Xiang H., Wei Y.","Discrimination and characterization of volatile organic compound fingerprints during sea bass (Lateolabrax japonicas) fermentation by combining GC-IMS and GC-MS","10.1016/j.fbio.2022.102048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139723233&doi=10.1016%2fj.fbio.2022.102048&partnerID=40&md5=c65ae649cac5d814996dca1de1e9b8b3","Volatile organic compounds are important indicators of the characteristic flavor of traditional fermented fish products. In the present study, gas chromatography-ion mobility mass spectrometry (GC-IMS) and gas chromatography-mass spectrometry (GC-MS) were used to identify and quantify the volatile organic compounds (VOCs) in fermented sea bass. Thirty-six and 104 VOCs were identified by GC-IMS and GC-MS, respectively. Aldehydes were the principal contributors to the formation of the overall flavor of fermented sea bass. The characteristic VOCs in fermented sea bass were identified based on loading plots. GC-IMS and GC-MS, along with variable influence on projection (VIP), identified six and four VOCs as biomarkers, respectively, in fermented sea bass. This investigation demonstrated that GC-IMS could rapidly detect VOCs in a simple manner in fermented sea bass. The results of the present study also provide a theoretical basis for determining flavor formation in fermented sea bass. © 2022 Elsevier Ltd","Gas chromatography-ion mobility mass spectrometry; Gas chromatography-mass spectrometry; Sea bass fermentation; Volatile organic compounds",
"Nimmy S.F., Hussain O.K., Chakrabortty R.K., Hussain F.K., Saberi M.","Explainability in supply chain operational risk management: A systematic literature review","10.1016/j.knosys.2021.107587","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118479625&doi=10.1016%2fj.knosys.2021.107587&partnerID=40&md5=efc370aba1ebb26a0156209feb8a2745","It is important to manage operational disruptions to ensure the success of supply chain operations. To achieve this aim, researchers have developed techniques that determine the occurrence of operational risk events which assists supply chain operational risk managers develop plans to manage them by detection/monitoring, mitigation/management, or optimization techniques. Various artificial intelligence (AI) approaches have been used to develop such techniques in the broad activities of operational risk management. However, all of these techniques are black box in their working nature. This means that the chosen technique cannot explain why it has given that output and whether it is correct and free from bias. To address this, researchers argue the need for supply chain management professionals to move towards using explainable AI methods for operational risk management. In this paper, we conduct a systematic literature review on the techniques used to determine operational risks and analyse whether they satisfy the requirement of them being explainable. The findings highlight the shortcomings and inspires directions for future research. From a managerial perspective, the paper encourages risk managers to choose techniques for supply chain operational risk management that can be auditable as this will ensure that the risk managers know why they should take a particular risk management action rather than just what they should do to manage the operational risks. © 2021 Elsevier B.V.","Artificial Intelligence (AI); Big data; Explainable AI (XAI); Supply chain operational risk management (SCORM)","Artificial intelligence; Managers; Risk management; Supply chain management; Artificial intelligence; Explainable artificial intelligence (XAI); Management techniques; Operational risk managements; Operational risks; Optimization techniques; Risk manager; Supply chain operation; Supply chain operational risk management; Systematic literature review; Big data"
"Nino-Adan I., Portillo E., Landa-Torres I., Manjarres D.","Normalization Influence on ANN-Based Models Performance: A New Proposal for Features' Contribution Analysis","10.1109/ACCESS.2021.3110647","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114737274&doi=10.1109%2fACCESS.2021.3110647&partnerID=40&md5=e2019df25bcc5c29bedd46160f093ab0","Artificial Neural Networks (ANNs) are weighted directed graphs of interconnected neurons widely employed to model complex problems. However, the selection of the optimal ANN architecture and its training parameters is not enough to obtain reliable models. The data preprocessing stage is fundamental to improve the model's performance. Specifically, Feature Normalisation (FN) is commonly utilised to remove the features' magnitude aiming at equalising the features' contribution to the model training. Nevertheless, this work demonstrates that the FN method selection affects the model performance. Also, it is well-known that ANNs are commonly considered a 'black box' due to their lack of interpretability. In this sense, several works aim to analyse the features' contribution to the network for estimating the output. However, these methods, specifically those based on network's weights, like Garson's or Yoon's methods, do not consider preprocessing factors, such as dispersion factors, previously employed to transform the input data. This work proposes a new features' relevance analysis method that includes the dispersion factors into the weight matrix analysis methods to infer each feature's actual contribution to the network output more precisely. Besides, in this work, the Proportional Dispersion Weights (PWD) are proposed as explanatory factors of similarity between models' performance results. The conclusions from this work improve the understanding of the features' contribution to the model that enhances the feature selection strategy, which is fundamental for reliably modelling a given problem. © 2013 IEEE.","Artificial neural networks; explainability; feature contribution; feature normalization","Directed graphs; Dispersions; Contribution analysis; Data preprocessing; Dispersion factor; Interpretability; Model complexes; Model performance; Relevance analysis; Weighted directed graph; Neural networks"
"Niu L.","Analysis of Multimodal Teaching of College English under the Background of Artificial Intelligence","10.1155/2022/3833106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137075609&doi=10.1155%2f2022%2f3833106&partnerID=40&md5=a5c4e5d8de501547c1864efa1c618561","As the Internet drives the spread of digitalization and the further improvement of computing power, the traditional college English teaching mode can no longer adapt to the needs of teaching in the age of artificial intelligence. Single or lesser modality is gradually replaced by multimodality, an emerging teaching mode. The study of multimodal discourse is a new hot spot in language research and a key issue of concern for English classroom teaching reform. Based on the analysis of the practical application dilemmas of multimodality in college English teaching culture, context, content (meaning + form), and expression, this article proposes a path to innovate multimodal discourse teaching in college English classroom in the era of artificial intelligence. It includes familiarizing with multimode integrated platform for teaching tools and developing intercultural communication abilities. Multimode situational lectures with the help of modern information technology are developed. At the content level, we should adhere to the unity and coordination of the meaning and form of multimodal teaching. Use language and nonlanguage in a way that will enhance learning at the multimode media level. Additionally, AI enriches English teaching methods, changes the intelligence of English teachers, and improves the efficiency of English teaching. AI helps to create a more relevant and interactive English learning environment, improve many aspects of English teaching, including teaching evaluation, and effectively improve the face of college English teaching. © 2022 Lu Niu.",,"Artificial intelligence; Computing power; Learning systems; Modal analysis; Teaching; College English; College english teachings; Computing power; English teaching; Hotspots; Multi-modal; Multi-modality; Multimodal teachings; Multimodes; Teaching modes; Computer aided instruction"
"Noon S.K., Amjad M., Qureshi M.A., Mannan A.","Handling Severity Levels of Multiple Co-Occurring Cotton Plant Diseases Using Improved YOLOX Model","10.1109/ACCESS.2022.3232751","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146219817&doi=10.1109%2fACCESS.2022.3232751&partnerID=40&md5=9b061478680454933e371e05f8ff633d","Automatic detection of plant diseases has emerged as a challenging field in the last decade. Computer vision-based advancements have helped in the timely and accurate identification of diseases, making possible an appropriate treatment and hence ensuring an increased yield. Diseases attack in different formations on a plant; the most severe being multiple diseases appearing on a single leaf. Moreover, as various diseases progress, they generate similar-looking symptoms making the task of identification further difficult. This work addresses these two problems with the help of an improved YOLOX model. We propose a modified Spatial Pyramid Pooling (SPP) layer to effectively extract relevant features at various scales from the training data. It is achieved by concatenating multilevel features pooled from smaller to larger scales. To enhance the generalization capability of the design, various skip connections are also introduced. To improve the network convergence and detection accuracy, IoU based regression loss function was employed. A dataset composed of 1, 112 cotton plant images with co-occurring diseases along with their progressive severity levels was collected from the Southern Punjab region of Pakistan. Apart from healthy images, the dataset comprises three severity stages of cotton leaf curl with co-occurring cotton sooty mold stress on a single leaf image. Experimental results revealed that our proposed improved SPP-based YOLOX-s model achieved 73.13% mAP on our self-collected dataset and achieved 3.27% better test accuracy than the original YOLOX model. © 2013 IEEE.","cotton plant; disease severity classification; multiple stress; Plant disease; YOLOX model","Classification (of information); Deep learning; Feature extraction; Image classification; Job analysis; Statistical tests; Cotton plants; Deep learning; Disease severity; Disease severity classification; Features extraction; Image color analysis; Multiple stress; Plant disease; Task analysis; YOLOX model; Cotton"
"Nuñez Y., Lovisolo L., da Silva Mello L., Orihuela C.","On the interpretability of machine learning regression for path-loss prediction of millimeter-wave links[Formula presented]","10.1016/j.eswa.2022.119324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143329000&doi=10.1016%2fj.eswa.2022.119324&partnerID=40&md5=2c25bd4f22b422765fef567db7df97c2","Millimeter-wave communication systems design requires accurate path-loss (PL) prediction, which is critical to determining coverage area and system capacity. In this work, four machine learning (ML) algorithms are proposed for PL prediction in an indoor environment for 5G millimeter-wave frequencies, from 26.5 to 40 GHz. They are artificial neural network (ANN), support vector regression (SVR), random forest (RF), and gradient tree boosting (GTB). We compare their performances, including also the empirical PL models ABG and CIF incorporating the number of crossed walls, as we propose. For the ML models, we present a methodology to select the predictor coalition by examining the marginal performance and the interpretability gains. The methodology allows choosing the most appropriate predictor coalition for building machines while not overlooking the non-linear connections between predictors and the path-loss. The results show that the ML techniques improve the prediction accuracy of empirical models. Among the ML algorithms employed, considering the optimal subset of predictors, the GTB model presents the best prediction and generalization capacities. © 2022 Elsevier Ltd","Ensemble methods; Machine learning; Model selection; Path-loss","5G mobile communication systems; Adaptive boosting; Decision trees; Forecasting; Millimeter waves; Neural networks; Random forests; Ensemble methods; Gradient tree boosting; Interpretability; Machine learning algorithms; Machine-learning; Model Selection; Path loss; Path loss prediction; Performance; Wave links; Machine learning"
"Nurgazina Z., Guo Q., Ali U., Kartal M.T., Ullah A., Khan Z.A.","Retesting the Influences on CO2 Emissions in China: Evidence From Dynamic ARDL Approach","10.3389/fenvs.2022.868740","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131875442&doi=10.3389%2ffenvs.2022.868740&partnerID=40&md5=4fbbc1184d3c73e62cc5d2dd24b8e122","This study aims to demonstrate the impact of economic growth and energy consumption on environmental degradation in China, the top country that produced the highest carbon dioxide (CO2) emissions, by considering that environmental degradation is one of the extreme challenges that the world and China have been facing. Parallel to this aim, this study uses dynamic ARDL (DYNARDL) simulations to investigate the long-run and short-run cointegration amongst the selected parameters from 1979 to 2019. The results of the long-run and short-run simulations illustrate that 1) economic growth increases environmental degradation; 2) growth in energy consumption worsens the environmental degradation situation; 3) urbanization improves the environmental situation in the long run, whereas growth in urban population increases CO2 emissions in the short-run. The research argues that improved energy production and management should be included in economic policy planning and the government should invest more in renewable energy to prevent environmental degradation. Copyright © 2022 Nurgazina, Guo, Ali, Kartal, Ullah and Khan.","DYNARDL model; economic growth; energy consumption; environmental degradation; urbanization",
"Ojo M.O., Viola I., Baratta M., Giordano S.","Practical experiences of a smart livestock location monitoring system leveraging gnss, lorawan and cloud services","10.3390/s22010273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121857791&doi=10.3390%2fs22010273&partnerID=40&md5=784520b6782c524581f1b8933d4582f3","Livestock farming is, in most cases in Europe, unsupervised, thus making it difficult to ensure adequate control of the position of the animals for the improvement of animal welfare. In addition, the geographical areas involved in livestock grazing usually have difficult access with harsh orography and lack of communications infrastructure, thus the need to provide a low-power livestock localization and monitoring system is of paramount importance, which is crucial not for a sustainable agriculture, but also for the protection of native breeds and meats thanks to their controlled supervision. In this context, this work presents an Internet of things (IoT)-based system integrating low-power wide area (LPWA) technology, cloud, and virtualization services to provide real-time livestock location monitoring. Taking into account the constraints coming from the environment in terms of energy supply and network connectivity, our proposed system is based on a wearable device equipped with inertial sensors, Global Positioning System (GPS) receiver, and LoRaWAN transceiver, which can provide a satisfactory compromise between performance, cost, and energy consumption. At first, this article provides the state-of-the-art localization techniques and technologies applied to smart livestock. Then, we proceed to provide the hardware and firmware co-design to achieve very low energy consumption, thus providing a significant positive impact to the battery life. The proposed platform has been evaluated in a pilot test in the northern part of Italy, evaluating different configurations in terms of sampling period, experimental duration, and number of devices. The results are analyzed and discussed for packet delivery ratio, energy consumption, localization accuracy, battery discharge measurement, and delay. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","AWS architecture; Cloud computing; Livestock monitoring; LoRaWAN; Smart agriculture","Agriculture; Animals; Cloud computing; Electric batteries; Energy utilization; Firmware; Global positioning system; Internet of things; Wide area networks; AWS architecture; Cloud-computing; Energy-consumption; Livestock monitoring; Location monitoring; LoRaWAN; Low Power; Monitoring system; Practical experience; Smart agricultures; Monitoring; agricultural land; animal; cloud computing; livestock; physiologic monitoring; Animals; Cloud Computing; Farms; Internet of Things; Livestock; Monitoring, Physiologic"
"Okajima Y., Sadamasa K.","Deep neural networks constrained by decision rules",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066091139&partnerID=40&md5=41f39ee157e069d0b9a87786c1152d42","Deep neural networks achieve high predictive accuracy by learning latent representations of complex data. However, the reasoning behind their decisions is difficult for humans to understand. On the other hand, rule-based approaches are able to justify the decisions by showing the decision rules leading to them, but they have relatively low accuracy. To improve the interpretability of neural networks, several techniques provide post-hoc explanations of decisions made by neural networks, but they cannot guarantee that the decisions are always explained in a simple form like decision rules because their explanations are generated after the decisions are made by neural networks. In this paper, to balance the accuracy of neural networks and the interpretability of decision rules, we propose a hybrid technique called rule-constrained networks, namely, neural networks that make decisions by selecting decision rules from a given ruleset. Because the networks are forced to make decisions based on decision rules, it is guaranteed that every decision is supported by a decision rule. Furthermore, we propose a technique to jointly optimize the neural network and the ruleset from which the network select rules. The log likelihood of correct classifications is maximized under a model with hyper parameters about the ruleset size and the prior probabilities of rules being selected. This feature makes it possible to limit the ruleset size or prioritize human-made rules over automatically acquired rules for promoting the interpretability of the output. Experiments on datasets of time-series and sentiment classification showed rule-constrained networks achieved accuracy as high as that achieved by original neural networks and significantly higher than that achieved by existing rule-based models, while presenting decision rules supporting the decisions. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org).",,"Classification (of information); Deep neural networks; Hybrid techniques; Hyper-parameter; Interpretability; Predictive accuracy; Prior probability; Rule-based approach; Rule-based models; Sentiment classification; Neural networks"
"Okunlaya R.O., Syed Abdullah N., Alias R.A.","Artificial intelligence (AI) library services innovative conceptual framework for the digital transformation of university education","10.1108/LHT-07-2021-0242","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125897567&doi=10.1108%2fLHT-07-2021-0242&partnerID=40&md5=84246a98c628473fd766f517c6c50bac","Purpose: Artificial intelligence (AI) is one of the latest digital transformation (DT) technological trends the university library can use to provide library users with alternative educational services. AI can foster intelligent decisions for retrieving and sharing information for learning and research. However, extant literature confirms a low adoption rate by the university libraries in using AI to provide innovative alternative services, as this is missing in their strategic plan. The research develops (AI-LSICF) an artificial intelligence library services innovative conceptual framework to provide new insight into how AI technology can be used to deliver value-added innovative library services to achieve digital transformation. It will also encourage library and information professionals to adopt AI to complement effective service delivery. Design/methodology/approach: This study adopts a qualitative content analysis to investigate extant literature on how AI adoption fosters innovative services in various organisations. The study also used content analysis to generate possible solutions to aid AI service innovation and delivery in university libraries. Findings: This study uses its findings to develop an Artificial Intelligence Library Services Innovative Conceptual Framework (AI-LSICF) by integrating AI applications and functions into the digital transformation framework elements and discussed using a service innovation framework. Research limitations/implications: In research, AI-LSICF helps increase an understanding of AI by presenting new insights into how the university library can leverage technology to actualise innovation in service provision to foster DT. This trail will be valuable to scholars and academics interested in addressing the application pathways of AI library service innovation, which is still under-explored in digital transformation. Practical implications: In practice, AI-LSICF could reform the information industry from its traditional brands into a more applied and resolutely customer-driven organisation. This reformation will awaken awareness of how librarians and information professionals can leverage technology to catch up with digital transformation in this age of the fourth industrial revolution. Social implications: The enlightenment of AI-LSICF will motivate library professionals to take advantage of AI's potential to enhance their current business model and achieve a unique competitive advantage within their community. Originality/value: AI-LSICF development serves as a revelation, motivating university libraries and information professionals to consider AI in their strategic plan to enable technology to support university education. This act will enable alternative service delivery in the face of unforeseen circumstances like technological disruption and the present global COVID-19 pandemic that requires non-physical interaction. © 2022, Emerald Publishing Limited.","Artificial intelligence; COVID-19 pandemic; Digital transformation; Digital transformation framework; Digital transformation technology; Fourth industrial revolution (4IR); Service innovation framework; University library services transformation",
"Oladipo I.D., AbdulRaheem M., Awotunde J.B., Bhoi A.K., Adeniyi E.A., Abiodun M.K.","Machine Learning and Deep Learning Algorithms for Smart Cities: A Start-of-the-Art Review","10.1007/978-3-030-82715-1_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121814838&doi=10.1007%2f978-3-030-82715-1_7&partnerID=40&md5=8df0e1e90b6d27aae4afbcf1912e5881","The development in our urban cities has increased significant risks with everyday lives, like traffic congestion, pollution of the atmosphere, energy use, and public safety among others. Internet of Things (IoT) system has been used to tackle different research issues in a smart city. With the rapid development of IoT technologies, researchers have been motivated to develop smart services that extract knowledge from big data generated from IoT-based devices/sensors. The development of various models like forecast, preparation, monitoring, and ambiguity exploration in smart cities has been enhanced by the applications of deep learning (DL) and machine learning (ML) techniques, and for the urban development. These have also yielded greater results in the process of the huge data and input variables coming from IoT-based cognitive cities. Therefore, this chapter reviews the applicability of the state-of-the-art ML and DL in smart cities’ developments. It also discusses the novel application taxonomy of ML and DL smart cities and environmental planning that includes terms that are used interchangeably. Research shows that urban transportation, energy, and healthcare system are the main areas of applications that ML and DL techniques contributed in addressing their problems. The finding from the reviews reveals that ML and DL methods that are mostly applicable, and used in smart cities and urban development, are decision trees, support vector machine, artificial neural network, Bayesian, neuro-fuzzy, ensembles, and their hybridizations. Due to the complexities of both ML and DL with broad coverage of smart city applications, the study shows that there are various challenges ahead in applying these algorithms for this emerging field. The chapter discusses a range of potential directions related to ML and DL efficacy, evolving frameworks, convergence of information, and protection of privacy hoping that these would take the relevant research one step further to fully develop data analytics for smart cities. © 2022, Springer Nature Switzerland AG.","Artificial intelligence; Cloud computing; Deep learning; Machine learning; Smart cities; Urban development","Data Analytics; Decision trees; Deep learning; Internet of things; Learning algorithms; Neural networks; Support vector machines; Traffic congestion; Urban growth; Urban transportation; Cloud-computing; Deep learning; Energy use; Internet of things technologies; Machine-learning; Public safety; Research issues; Smart services; Urban cities; Urban development; Smart city"
"Olaniyan O.T., Adetunji C.O., Dare A., Adeyomoye O., Adeniyi M.J., Enoch A.","Cognitive therapy for brain diseases using artificial intelligence models","10.1016/B978-0-323-90277-9.00013-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142845114&doi=10.1016%2fB978-0-323-90277-9.00013-4&partnerID=40&md5=dbed564e37f2f7ddeefdeea8ebb78752","Studies have shown that artificial intelligence is a novel realm of science and technology rapidly expanding globally across many industrial sectors. The recent advances in the artificial intelligence system in medicine and healthcare systems, particularly neuroscience and clinical practice, have presented extraordinary opportunities such as disease prediction, communication, and treatment strategies. There are many genetic tests, existing software, personal monitoring devices, editing tools, online platforms, personalized digital models, companion and surgical robotics, and augmented reality devices adopted in medical practice to monitor and analyze cognitive therapy. Artificial intelligence has been utilized to implement and analyze medical images, videos, nodules, lesions, and signals. Thus, this chapter will give a detailed account of different artificial intelligence models for risk assessment, classification, segmentation tasks, prognosis, diagnosis, and prediction of therapy reaction in cognitive therapy. © 2023 Elsevier Inc. All rights reserved.","Artificial intelligence; Cognitive therapy; Diagnosis; Medicine; Neuroscience",
"Ooge J., Verbert K.","Visually Explaining Uncertain Price Predictions in Agrifood: A User-Centred Case-Study","10.3390/agriculture12071024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138099935&doi=10.3390%2fagriculture12071024&partnerID=40&md5=086f64b80158dd7a74e9002137393a91","The rise of ‘big data’ in agrifood has increased the need for decision support systems that harvest the power of artificial intelligence. While many such systems have been proposed, their uptake is limited, for example because they often lack uncertainty representations and are rarely designed in a user-centred way. We present a prototypical visual decision support system that incorporates price prediction, uncertainty, and visual analytics techniques. We evaluated our prototype with 10 participants who are active in different parts of agrifood. Through semi-structured interviews and questionnaires, we collected quantitative and qualitative data about four metrics: usability, usefulness and needs, model understanding, and trust. Our results reveal that the first three metrics can directly and indirectly affect appropriate trust, and that perception differences exist between people with diverging experience levels in predictive modelling. Overall, this suggests that user-centred approaches are key for increasing uptake of visual decision support systems in agrifood. © 2022 by the authors.","decision support systems; explainable artificial intelligence; mixed-methods; thematic analysis; uncertainty; visual analytics; visualisation",
"Ooge J., Verbert K.","Explaining Artificial Intelligence with Tailored Interactive Visualisations","10.1145/3490100.3516481","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127782847&doi=10.1145%2f3490100.3516481&partnerID=40&md5=5a1a838bff9eff0c75aa00acdd80af96","Artificial intelligence (AI) is becoming ubiquitous in the lives of both researchers and non-researchers, but AI models often lack transparency. To make well-informed and trustworthy decisions based on these models, people require explanations that indicate how to interpret the model outcomes. This paper presents our ongoing research in explainable AI, which investigates how visual analytics interfaces and visual explanations, tailored to the target audience and application domain, can make AI models more transparent and allow interactive steering based on domain expertise. First, we present our research questions and methods, contextualised by related work at the intersection of AI, human-computer interaction, and information visualisation. Then, we discuss our work so far in healthcare, agriculture, and education. Finally, we share our research ideas for additional studies in these domains. © 2022 Owner/Author.","algorithmic transparency; explainability; information visualisation; interpretability; XAI","Artificial intelligence; Human computer interaction; Visualization; Algorithmic transparency; Algorithmics; Decision-based; Explainability; Information visualization; Intelligence models; Interactive visualizations; Interpretability; Visual analytics; XAI; Transparency"
"Ooge J., Verbert K.","Trust in Prediction Models: a Mixed-Methods Pilot Study on the Impact of Domain Expertise","10.1109/TREX53765.2021.00007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123757634&doi=10.1109%2fTREX53765.2021.00007&partnerID=40&md5=a253a6f6e5113e06be274391633d6902","People's trust in prediction models can be affected by many factors, including domain expertise like knowledge about the application domain and experience with predictive modelling. However, to what extent and why domain expertise impacts people's trust is not entirely clear. In addition, accurately measuring people's trust remains challenging. We share our results and experiences of an exploratory pilot study in which four people experienced with predictive modelling systematically explore a visual analytics system with an unknown prediction model. Through a mixed-methods approach involving Likert-type questions and a semi-structured interview, we investigate how people's trust evolves during their exploration, and we distil six themes that affect their trust in the prediction model. Our results underline the multi-faceted nature of trust, and suggest that domain expertise alone cannot fully predict people's trust perceptions. © 2021 IEEE.",,"Application experiences; Applications domains; Domain expertise; Mixed method; Pilot studies; Prediction modelling; Predictive models; Semi structured interviews; Visual analytics systems; Forecasting"
"Ornek A.H., Ceylan M.","CodCAM: A new ensemble visual explanation for classification of medical thermal images","10.1080/17686733.2023.2167459","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147262610&doi=10.1080%2f17686733.2023.2167459&partnerID=40&md5=c38f007595cb839811c0f80b5a639fb5","Early diagnosis systems have vital importance to monitor and follow-up the conditions of neonates. Thermal imaging as a non-invasive and non-contact method has been used to monitor neonates for over decades. In this study, we train a convolutional neural network (CNN) model that classifies medical thermograms as healthy and unhealthy using real neonatal thermal images captured within a year from the Neonatal Intensive Care Unit (NICU), Faculty of Medicine at Selcuk University, Turkey. The trained model achieved 99.91% accuracy for train, 99.47% accuracy for validation, and 99.82% accuracy for test data. The test data were never used during training. Although the trained model achieves over 99% accuracy, how it works was not known because of the CNNs’ ”Black-Box” nature. The four visual Explainable Artificial Intelligence methods that are GradCAM, GradCAM++, LayerCAM, and EigenCAM and a new ensemble visual explanation method named CodCAM are used to visualise the important parts of the neonatal thermal images for classification. Therefore, medical specialists are going to know which regions of the thermograms (i.e. parts of the neonates) affect the trained CNN’s decision so as to build trust in AI models and evaluate the results. © 2023 Informa UK Limited, trading as Taylor & Francis Group.","Class activation mapping; deep learning; explainable artificial intelligence; healthcare; medicine; neonate","Computer aided diagnosis; Convolutional neural networks; Deep learning; Image classification; Infrared imaging; Intensive care units; Medical imaging; Temperature measuring instruments; Thermography (temperature measurement); Activation mapping; Class activation mapping; Convolutional neural network; Deep learning; Early diagnosis; Explainable artificial intelligence; Healthcare; Neonate; Test data; Thermal images; Neural network models"
"Ortíz-Barrios M.A., Garcia-Constantino M., Nugent C., Alfaro-Sarmiento I.","A Novel Integration of IF-DEMATEL and TOPSIS for the Classifier Selection Problem in Assistive Technology Adoption for People with Dementia","10.3390/ijerph19031133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122940347&doi=10.3390%2fijerph19031133&partnerID=40&md5=214648688eb37678526636427a340d38","The classifier selection problem in Assistive Technology Adoption refers to selecting the classification algorithms that have the best performance in predicting the adoption of technology, and is often addressed through measuring different single performance indicators. Satisfactory clas-sifier selection can help in reducing time and costs involved in the technology adoption process. As there are multiple criteria from different domains and several candidate classification algorithms, the classifier selection process is now a problem that can be addressed using Multiple-Criteria De-cision-Making (MCDM) methods. This paper proposes a novel approach to address the classifier selection problem by integrating Intuitionistic Fuzzy Sets (IFS), Decision Making Trial and Evaluation Laboratory (DEMATEL), and the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS). The step-by-step procedure behind this application is as follows. First, IF-DE-MATEL was used for estimating the criteria and sub-criteria weights considering uncertainty. This method was also employed to evaluate the interrelations among classifier selection criteria. Finally, a modified TOPSIS was applied to generate an overall suitability index per classifier so that the most effective ones can be selected. The proposed approach was validated using a real-world case study concerning the adoption of a mobile-based reminding solution by People with Dementia (PwD). The outputs allow public health managers to accurately identify whether PwD can adopt an assistive technology which results in (i) reduced cost overruns due to wrong classification, (ii) improved quality of life of adopters, and (iii) rapid deployment of intervention alternatives for non-adopters. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Classifier; Decision Making Trial and Evaluation Laboratory (DEMATEL); Intuitionistic Fuzzy Sets (IFS); Multi-criteria decision making (MCDM); People with Dementia (PwD); Public health; Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS); Technology adoption","algorithm; fuzzy mathematics; mental disorder; multicriteria analysis; public health; technology adoption; Article; assistive technology; classification algorithm; classifier; Decision Making Trial and Evaluation Laboratory; decision support system; dementia; human; Intuitionistic Fuzzy Sets; manager; multicriteria decision analysis; public health; quality of life; support vector machine; technique for order preference by similarity to ideal solution; uncertainty; decision making; self help device; Decision Making; Dementia; Humans; Quality of Life; Self-Help Devices; Uncertainty"
"Ortiz-Severín J., Stuardo C.J., Jiménez N.E., Palma R., Cortés M.P., Maldonado J., Maass A., Cambiazo V.","Nutrient Scarcity in a New Defined Medium Reveals Metabolic Resistance to Antibiotics in the Fish Pathogen Piscirickettsia salmonis","10.3389/fmicb.2021.734239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117731913&doi=10.3389%2ffmicb.2021.734239&partnerID=40&md5=eddbfc06e8486e03e0bc3ed85ac155d9","Extensive use of antibiotics has been the primary treatment for the Salmonid Rickettsial Septicemia, a salmonid disease caused by the bacterium Piscirickettsia salmonis. Occurrence of antibiotic resistance has been explored in various P. salmonis isolates using different assays; however, P. salmonis is a nutritionally demanding intracellular facultative pathogen; thus, assessing its antibiotic susceptibility with standardized and validated protocols is essential. In this work, we studied the pathogen response to antibiotics using a genomic, a transcriptomic, and a phenotypic approach. A new defined medium (CMMAB) was developed based on a metabolic model of P. salmonis. CMMAB was formulated to increase bacterial growth in nutrient-limited conditions and to be suitable for performing antibiotic susceptibility tests. Antibiotic resistance was evaluated based on a comprehensive search of antibiotic resistance genes (ARGs) from P. salmonis genomes. Minimum inhibitory concentration assays were conducted to test the pathogen susceptibility to antibiotics from drug categories with predicted ARGs. In all tested P. salmonis strains, resistance to erythromycin, ampicillin, penicillin G, streptomycin, spectinomycin, polymyxin B, ceftazidime, and trimethoprim was medium-dependent, showing resistance to higher antibiotic concentrations in the CMMAB medium. The mechanism for antibiotic resistance to ampicillin in the defined medium was further explored and was proven to be associated to a decrease in the bacterial central metabolism, including the TCA cycle, the pentose-phosphate pathway, energy production, and nucleotide metabolism, and it was not associated with decreased growth rate of the bacterium or with the expression of any predicted ARG. Our results suggest that nutrient scarcity plays a role in the bacterial antibiotic resistance, protecting against the detrimental effects of antibiotics, and thus, we propose that P. salmonis exhibits a metabolic resistance to ampicillin when growing in a nutrient-limited medium. © Copyright © 2021 Ortiz-Severín, Stuardo, Jiménez, Palma, Cortés, Maldonado, Maass and Cambiazo.","antibiotic resistance; defined medium; fish pathogen; metabolic resistance; nutrient scarcity; P. salmonis","alanine; amino acid mixture; ampicillin; antibiotic agent; asparagine; ceftazidime; chloramphenicol; divalent cation; erythromycin; florfenicol; flumequine; glucose; glutamic acid; iron; oxolinic acid; oxytetracycline; penicillin G; polymyxin B; protein histidine kinase; rifampicin; sodium hydroxide; sodium proton exchange protein; spectinomycin; streptomycin; tetracycline; trimethoprim; tryptophan; tyrosine; vitamin; animal experiment; animal tissue; antibiotic resistance; antibiotic sensitivity; area under the curve; Article; bacterial growth; bacterial strain; bioinformatics; cell motility; chemotaxis; citric acid cycle; cloverleaf skull; controlled study; effusion; energy yield; gene ontology; genomics; growth curve; infectious pancreatic necrosis; load carrying capacity; metabolic syndrome X; metabolism; metagenomics; minimum inhibitory concentration; mobile genetic element; MTT assay; nonhuman; nucleotide metabolism; nutrient availability; pentose phosphate cycle; pH measurement; phenotype; Piscirickettsia salmonis; principal component analysis; prophage; protein secretion; real time polymerase chain reaction; transcriptomics; transposon; whole genome sequencing"
"Orynbaikyzy A., Gessner U., Mack B., Conrad C.","Crop type classification using fusion of sentinel-1 and sentinel-2 data: Assessing the impact of feature selection, optical data availability, and parcel sizes on the accuracies","10.3390/RS12172779","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090503761&doi=10.3390%2fRS12172779&partnerID=40&md5=79ffd8a714ef35913c5cd38f29e57445","Crop type classification using Earth Observation (EO) data is challenging, particularly for crop types with similar phenological growth stages. In this regard, the synergy of optical and Synthetic-Aperture Radar (SAR) data enables a broad representation of biophysical and structural information on target objects, enhancing crop type mapping. However, the fusion of multi-sensor dense time-series data often comes with the challenge of high dimensional feature space. In this study, we (1) evaluate how the usage of only optical, only SAR, and their fusion affect the classification accuracy; (2) identify the combination of which time-steps and feature-sets lead to peak accuracy; (3) analyze misclassifications based on the parcel size, optical data availability, and crops' temporal profiles. Two fusion approaches were considered and compared in this study: feature stacking and decision fusion. To distinguish the most relevant feature subsets time- and variable-wise, grouped forward feature selection (gFFS) was used. gFFS allows focusing analysis and interpretation on feature sets of interest like spectral bands, vegetation indices (VIs), or data sensing time rather than on single features. This feature selection strategy leads to better interpretability of results while substantially reducing computational expenses. The results showed that, in contrast to most other studies, SAR datasets outperform optical datasets. Similar to most other studies, the optical-SAR combination outperformed single sensor predictions. No significant difference was recorded between feature stacking and decision fusion. Random Forest (RF) appears to be robust to high feature space dimensionality. The feature selection did not improve the accuracies even for the optical-SAR feature stack with 320 features. Nevertheless, the combination of RF feature importance and time- and variable-wise gFFS rankings in one visualization enhances interpretability and understanding of the features' relevance for specific classification tasks. For example, by enabling the identification of features that have high RF feature importance values but are, in their information content, correlated with other features. This study contributes to the growing domain of interpretable machine learning. ©","Crop mapping; Decision fusion; Feature stacking; Group-wise forward feature selection; Interpretable machine learning; Optical-SAR synergy","Crops; Decision trees; Sensor data fusion; Space-based radar; Synthetic aperture radar; Classification accuracy; Computational expense; Crop type classification; Earth observation data; Forward feature selections; High-dimensional feature space; Information contents; Structural information; Feature extraction"
"O'Sullivan C.M., Ghahramani A., Deo R.C., Pembleton K.G.","Pattern recognition describing spatio-temporal drivers of catchment classification for water quality","10.1016/j.scitotenv.2022.160240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143865924&doi=10.1016%2fj.scitotenv.2022.160240&partnerID=40&md5=c5153f3a261038e1b5d7809fc9924a4f","Classification using spatial data is foundational for hydrological modelling, particularly for ungauged areas. However, models developed from classified land use drivers deliver inconsistent water quality results for the same land uses and hinder decision-making guided by those models. This paper explores whether the temporal variation of water quality drivers, such as season and flow, influence inconsistency in the classification, and whether variability is captured in spatial datasets that include original vegetation to represent the variability of biotic responses in areas mapped with the same land use. An Artificial Neural Network Pattern Recognition (ANN-PR) method is used to match catchments by Dissolved Inorganic Nitrogen (DIN) patterns in water quality datasets partitioned into Wet vs Dry Seasons and Increasing vs Retreating flows. Explainable artificial intelligence approaches are then used to classify catchments via spatial feature datasets for each catchment. Catchments matched for sharing patterns in both spatial data and DIN datasets were corroborated and the benefit of partitioning the observed DIN dataset evaluated using Kruskal Wallis method. The highest corroboration rates for spatial data classification with DIN classification were achieved with seasonal partitioning of water quality datasets and significant independence (p < 0.001 to 0.026) from non-partitioned datasets was achieved. This study demonstrated that DIN patterns fall into three categories suited to classification under differing temporal scales with corresponding vegetation types as the indicators. Categories 1 and 3 included dominance of woodlands in their datasets and catchments suited to classify together change depending on temporal scale of the data. Category 2 catchments were dominated by vineforest and classified catchments did not change under different temporal scales. This demonstrates that including original vegetation as a proxy for differences in DIN patterns will help guide future classification where only spatially mapped data is available for ungauged catchments and will better inform data needs for water modelling. © 2022","ANN; Classification; Data; Pattern recognition; Spatial; Temporal; Water quality; XAI (eXplainable Artificial Intelligence)","Classification (of information); Decision making; Land use; Neural networks; Pattern recognition; Runoff; Vegetation; Water quality; ANN; Classifieds; Data; Dissolved inorganic nitrogens; Spatial; Spatial data; Spatio-temporal; Temporal; Temporal scale; XAI (explainable artificial intelligence); Catchments; dissolved inorganic nitrogen; nitrogen; unclassified drug; artificial intelligence; artificial neural network; catchment; classification; pattern recognition; spatial data; temporal variation; water quality; Article; artificial intelligence; artificial neural network; artificial neural network pattern recognition; catchment area (hydrology); controlled study; data classification; flow; forest; land use; mesophyll; nitrogen partitioning; notophyll; organismal interaction; plant tissue; seasonal variation; vegetation; vineforest; water quality; artificial intelligence; environmental monitoring; season; Artificial Intelligence; Environmental Monitoring; Seasons; Water Quality"
"Ozbilge E., Ulukok M.K., Toygar O., Ozbilge E.","Tomato Disease Recognition Using a Compact Convolutional Neural Network","10.1109/ACCESS.2022.3192428","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135242443&doi=10.1109%2fACCESS.2022.3192428&partnerID=40&md5=3c3148688019df28a9666bea81cac800","The detection of diseases in tomatoes in advance and early intervention and treatment increase the production amount, efficiency, and quality, which will satisfy the consumer with a more affordable shelf price. Thus, the efforts of farmers waiting for harvests throughout the season are not wasted. In this study, a compact convolutional neural network (CNN) is proposed for a disease identification task in which the network comprises only six layers, which is why it is computationally inexpensive in terms of the parameters employed in the network. This network was trained using PlantVillage's tomato crop dataset, which consisted of 10 classes (nine diseases and one healthy). The proposed network was first compared with the well-known pre-trained ImageNet deep networks using a transfer learning approach. The results show that the proposed network performs better than pre-trained knowledge transferred deep network models, and that there is no need to constitute very large, complicated network architectures to achieve superior tomato disease identification performance. Furthermore, data augmentation techniques are employed during network training to improve the performance of the proposed network. The proposed network achieved an accuracy of the F1 score, Matthews correlation coefficient, true positive rate, and true negative rate of 99.70%, 98.49%, 98.31%, 98.49%, and 99.81%, respectively, using 9,077 unseen test images. Our results are better than or similar to those of state-of-the-art deep neural network approaches that use the PlantVillage database and the proposed method employs the cheapest architecture. © 2013 IEEE.","computer vision; data augmentation; deep learning; Tomato disease classification; transfer learning","Computer architecture; Convolution; Deep neural networks; Fruits; Network architecture; Convolutional neural network; Data augmentation; Deep learning; Disease classification; Image color analysis; Performance; Tomato disease; Tomato disease classification; Transfer learning; Computer vision"
"Ozmen Garibay O., Winslow B., Andolina S., Antona M., Bodenschatz A., Coursaris C., Falco G., Fiore S.M., Garibay I., Grieman K., Havens J.C., Jirotka M., Kacorri H., Karwowski W., Kider J., Konstan J., Koon S., Lopez-Gonzalez M., Maifeld-Carucci I., McGregor S., Salvendy G., Shneiderman B., Stephanidis C., Strobel C., Ten Holter C., Xu W.","Six Human-Centered Artificial Intelligence Grand Challenges","10.1080/10447318.2022.2153320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145502740&doi=10.1080%2f10447318.2022.2153320&partnerID=40&md5=45db35763d44bdea21307a3c338efb34","Widespread adoption of artificial intelligence (AI) technologies is substantially affecting the human condition in ways that are not yet well understood. Negative unintended consequences abound including the perpetuation and exacerbation of societal inequalities and divisions via algorithmic decision making. We present six grand challenges for the scientific community to create AI technologies that are human-centered, that is, ethical, fair, and enhance the human condition. These grand challenges are the result of an international collaboration across academia, industry and government and represent the consensus views of a group of 26 experts in the field of human-centered artificial intelligence (HCAI). In essence, these challenges advocate for a human-centered approach to AI that (1) is centered in human well-being, (2) is designed responsibly, (3) respects privacy, (4) follows human-centered design principles, (5) is subject to appropriate governance and oversight, and (6) interacts with individuals while respecting human’s cognitive capacities. We hope that these challenges and their associated research directions serve as a call for action to conduct research and development in AI that serves as a force multiplier towards more fair, equitable and sustainable societies. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.",,"Decision making; International cooperation; Algorithmics; Artificial intelligence technologies; Decisions makings; Grand Challenge; Human conditions; Human-centred designs; International collaborations; Scientific community; Unintended consequences; Well being; Artificial intelligence"
"Padarian J., McBratney A.B., Minasny B.","Game theory interpretation of digital soil mapping convolutional neural networks","10.5194/soil-6-389-2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089908220&doi=10.5194%2fsoil-6-389-2020&partnerID=40&md5=8144c7ed5824a8eb1b8ee9b3b2d00a77","The use of complex models such as deep neural networks has yielded large improvements in predictive tasks in many fields including digital soil mapping. One of the concerns about using these models is that they are perceived as black boxes with low interpretability. In this paper we introduce the use of game theory, specifically Shapley additive explanations (SHAP) values, in order to interpret a digital soil mapping model. SHAP values represent the contribution of a covariate to the final model predictions. We applied this method to a multi-task convolutional neural network trained to predict soil organic carbon in Chile. The results show the contribution of each covariate to the model predictions in three different contexts: (a) at a local level, showing the contribution of the various covariates for a single prediction; (b) a global understanding of the covariate contribution; and (c) a spatial interpretation of their contributions. The latter constitutes a novel application of SHAP values and also the first detailed analysis of a model in a spatial context. The analysis of a SOC (soil organic carbon) model in Chile corroborated that the model is capturing sensible relationships between SOC and rainfall, temperature, elevation, slope, and topographic wetness index. The results agree with commonly reported relationships, highlighting environmental thresholds that coincide with significant areas within the study area. This contribution addresses the limitations of the current interpretation of models in digital soil mapping, especially in a spatial context. We believe that SHAP values are a valuable tool that should be included within the DSM (digital soil mapping) framework, since they address the important concerns regarding the interpretability of more complex models. The model interpretation is a crucial step that could lead to generating new knowledge to improve our understanding of soils. © Author(s) 2020.",,"artificial neural network; data interpretation; digital mapping; game theory; mapping method; soil analysis"
"Palansooriya K.N., Li J., Dissanayake P.D., Suvarna M., Li L., Yuan X., Sarkar B., Tsang D.C.W., Rinklebe J., Wang X., Ok Y.S.","Prediction of Soil Heavy Metal Immobilization by Biochar Using Machine Learning","10.1021/acs.est.1c08302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128159790&doi=10.1021%2facs.est.1c08302&partnerID=40&md5=00e2ee2e6edd8bac0a30d2c56d30a9bc","Biochar application is a promising strategy for the remediation of contaminated soil, while ensuring sustainable waste management. Biochar remediation of heavy metal (HM)-contaminated soil primarily depends on the properties of the soil, biochar, and HM. The optimum conditions for HM immobilization in biochar-amended soils are site-specific and vary among studies. Therefore, a generalized approach to predict HM immobilization efficiency in biochar-amended soils is required. This study employs machine learning (ML) approaches to predict the HM immobilization efficiency of biochar in biochar-amended soils. The nitrogen content in the biochar (0.3-25.9%) and biochar application rate (0.5-10%) were the two most significant features affecting HM immobilization. Causal analysis showed that the empirical categories for HM immobilization efficiency, in the order of importance, were biochar properties > experimental conditions > soil properties > HM properties. Therefore, this study presents new insights into the effects of biochar properties and soil properties on HM immobilization. This approach can help determine the optimum conditions for enhanced HM immobilization in biochar-amended soils. © 2022 American Chemical Society. All rights reserved.","biochar; graphical user interface; heavy metal; machine learning models; soil remediation","Efficiency; Forecasting; Graphical user interfaces; Heavy metals; Machine learning; Remediation; Soil conservation; Soils; Waste management; Amended soil; Biochar; Heavy metal immobilization; Immobilization efficiency; Machine learning models; Optimum conditions; Property; Soil heavy metals; Soil property; Soils remediation; Soil pollution; carbon; charcoal; heavy metal; nitrogen; charcoal; biochar; heavy metal; immobilization; machine learning; nitrogen; soil remediation; Article; controlled study; cross validation; immobilization; machine learning; physical chemistry; prediction; prediction error; pyrolysis; soil; soil acidity; soil property; ecosystem restoration; machine learning; soil; soil pollutant; Charcoal; Environmental Restoration and Remediation; Machine Learning; Metals, Heavy; Soil; Soil Pollutants"
"Palomares I., Martínez-Cámara E., Montes R., García-Moral P., Chiachio M., Chiachio J., Alonso S., Melero F.J., Molina D., Fernández B., Moral C., Marchena R., de Vargas J.P., Herrera F.","A panoramic view and swot analysis of artificial intelligence for achieving the sustainable development goals by 2030: progress and prospects","10.1007/s10489-021-02264-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107518477&doi=10.1007%2fs10489-021-02264-y&partnerID=40&md5=c1adae3895d194ba38cc3a8d311231cd","The17 Sustainable Development Goals (SDGs) established by the United Nations Agenda 2030 constitute a global blueprint agenda and instrument for peace and prosperity worldwide. Artificial intelligence and other digital technologies that have emerged in the last years, are being currently applied in virtually every area of society, economy and the environment. Hence, it is unsurprising that their current role in the pursuance or hampering of the SDGs has become critical. This study aims at providing a snapshot and comprehensive view of the progress made and prospects in the relationship between artificial intelligence technologies and the SDGs. A comprehensive review of existing literature has been firstly conducted, after which a series SWOT (Strengths, Weaknesses, Opportunities and Threats) analyses have been undertaken to identify the strengths, weaknesses, opportunities and threats inherent to artificial intelligence-driven technologies as facilitators or barriers to each of the SDGs. Based on the results of these analyses, a subsequent broader analysis is provided, from a position vantage, to (i) identify the efforts made in applying AI technologies in SDGs, (ii) pinpoint opportunities for further progress along the current decade, and (iii) distill ongoing challenges and target areas for important advances. The analysis is organized into six categories or perspectives of human needs: life, economic and technological development, social development, equality, resources and natural environment. Finally, a closing discussion is provided about the prospects, key guidelines and lessons learnt that should be adopted for guaranteeing a positive shift of artificial intelligence developments and applications towards fully supporting the SDGs attainment by 2030. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Artificial intelligence; Emerging digital technologies; Sustainable development goals","Economic and social effects; Planning; Sustainable development; AI Technologies; Artificial intelligence technologies; Digital technologies; Natural environments; Panoramic views; Social development; SWOT (strengths , weaknesses , opportunities and threats) analysis; Technological development; Artificial intelligence"
"Pan J., Shangguan W., Li L., Yuan H., Zhang S., Lu X., Wei N., Dai Y.","Using data-driven methods to explore the predictability of surface soil moisture with FLUXNET site data","10.1002/hyp.13540","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070780680&doi=10.1002%2fhyp.13540&partnerID=40&md5=1f6cca722a27f099990be20dedda4202","Soil moisture (SM) is a key variable of land surface-atmosphere interactions. Data-driven methods have been used to predict SM, but the predictability of SM has not been well evaluated. This study investigated what variables and methods can be used to better predict SM for leading times of 7 days or longer with a global coverage of FLUXNET site data for the first time. Three machine-learning models, that is, Bayesian linear regression, random forest, and gradient boosting regression tree, are used for the prediction. Variables including atmospheric forcing, surface soil temperature, time variables (year, day of year, and hour), the Fourier transformation of time variables, and lagged SM (7- to 14-day lagged) were sequentially added into models. A framework with five experiments is designed for factorial exploration of SM predictability. A stepwise method was used to build the best models for each site. The performance of regression models became better when adding more explaining variables in most cases. The results showed that from 50 to 95% of variation of the best models can be explained. The important explaining variables are lagged surface SM, followed by day of year, year, soil temperature, and atmospheric forcing. The predictability of SM depends highly on SM memory characteristics and the persistence of seasonality. The effect of SM memory characteristics on SM prediction as an initial condition question has been widely discussed in this paper. Our results also provide an insight that mechanisms of seasonality effects on SM should be also paid more attention to. © 2019 The Authors Hydrological Processes Published by John Wiley & Sons Ltd","data-driven; machine learning; predictability; soil moisture","Adaptive boosting; Decision trees; Forecasting; Fourier transforms; Learning systems; Machine learning; Regression analysis; Soil moisture; Temperature; Atmospheric forcing; Data driven; Data-driven methods; Fourier transformations; Machine learning models; predictability; Surface soil moisture; Surface soil temperatures; Soil surveys; atmosphere-biosphere interaction; atmospheric forcing; Fourier transform; machine learning; regression analysis; seasonality; soil moisture"
"Panayides A.S., Amini A., Filipovic N.D., Sharma A., Tsaftaris S.A., Young A., Foran D., Do N., Golemati S., Kurc T., Huang K., Nikita K.S., Veasey B.P., Zervakis M., Saltz J.H., Pattichis C.S.","AI in Medical Imaging Informatics: Current Challenges and Future Directions","10.1109/JBHI.2020.2991043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087474079&doi=10.1109%2fJBHI.2020.2991043&partnerID=40&md5=88f75a062b3e2d9749d9bad4f56b6592","This paper reviews state-of-the-art research solutions across the spectrum of medical imaging informatics, discusses clinical translation, and provides future directions for advancing clinical practice. More specifically, it summarizes advances in medical imaging acquisition technologies for different modalities, highlighting the necessity for efficient medical data management strategies in the context of AI in big healthcare data analytics. It then provides a synopsis of contemporary and emerging algorithmic methods for disease classification and organ/ tissue segmentation, focusing on AI and deep learning architectures that have already become the de facto approach. The clinical benefits of in-silico modelling advances linked with evolving 3D reconstruction and visualization applications are further documented. Concluding, integrative analytics approaches driven by associate research branches highlighted in this study promise to revolutionize imaging informatics as known today across the healthcare continuum for both radiology and digital pathology applications. The latter, is projected to enable informed, more accurate diagnosis, timely prognosis, and effective treatment planning, underpinning precision medicine. © 2013 IEEE.","Big Data; Deep Learning; Image Analysis; Image Classification; Image Processing; Image Segmentation; Image Visualization; Integrative Analytics; Machine Learning; Medical Imaging","Clinical research; Data Analytics; Deep learning; Diagnosis; Health care; Information management; Medical imaging; Three dimensional computer graphics; Algorithmic methods; Clinical translation; Digital pathologies; Disease classification; Imaging informatics; Learning architectures; Medical data management; Visualization application; Medical informatics; fluorodeoxyglucose; breast cancer; cancer growth; cancer prognosis; cancer staging; cancer therapy; clinical data repository; data interoperability; deep learning; diabetic retinopathy; diagnostic imaging; disease classification; echography; electronic health record; fluorescence imaging; fluorescence microscopy; functional connectivity; gamma radiation; glioblastoma; glioma; high frequency ultrasound; human; image analysis; image retrieval; image segmentation; learning algorithm; lung cancer; magnetic resonance elastography; mammography; melanoma; microscopy; nuclear magnetic resonance imaging; nuclear medicine; optical coherence tomography; overall survival; positron emission tomography-computed tomography; progression free survival; radiation dose; Review; single photon emission computed tomography; tissue microarray; treatment planning; tumor microenvironment; ultrasound; World Health Organization; X ray; x-ray computed tomography; artificial intelligence; computer assisted diagnosis; image processing; medical informatics; personalized medicine; Artificial Intelligence; Big Data; Diagnostic Imaging; Humans; Image Interpretation, Computer-Assisted; Image Processing, Computer-Assisted; Medical Informatics; Precision Medicine"
"Pandian J A., Kanchanadevi K., Rajalakshmi N.R., G.arulkumaran","An Improved Deep Residual Convolutional Neural Network for Plant Leaf Disease Detection","10.1155/2022/5102290","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138660547&doi=10.1155%2f2022%2f5102290&partnerID=40&md5=d7063faabc80c5606bab5a1057d8c2d5","In this research, we proposed a novel deep residual convolutional neural network with 197 layers (ResNet197) for the detection of various plant leaf diseases. Six blocks of layers were used to develop ResNet197. ResNet197 was trained and tested using a combined plant leaf disease image dataset. Scaling, cropping, flipping, padding, rotation, affine transformation, saturation, and hue transformation techniques were used to create the augmentation data of the plant leaf disease image dataset. The dataset consisted of 103 diseased and healthy image classes of 22 plants and 154,500 images of healthy and diseased plant leaves. The evolutionary search technique was used to optimise the layers and hyperparameter values of ResNet197. ResNet197 was trained on the combined plant leaf disease image dataset using a graphics processing unit (GPU) environment for 1000 epochs. It produced a 99.58 percentage average classification accuracy on the test dataset. The experimental results were superior to existing ResNet architectures and recent transfer learning techniques. © 2022 Arun Pandian J. et al.",,"Classification (of information); Computer graphics; Computer graphics equipment; Convolution; Convolutional neural networks; Deep neural networks; Evolutionary algorithms; Metadata; Multilayer neural networks; Network layers; Plants (botany); Program processors; Statistical tests; Affine transformations; Convolutional neural network; Evolutionary search; Image datasets; Leaf disease; Leaf disease detections; Plant leaves; Scalings; Search technique; Transformation techniques; Graphics processing unit"
"Pata U.K., Erdogan S., Ozkan O.","Is reducing fossil fuel intensity important for environmental management and ensuring ecological efficiency in China?","10.1016/j.jenvman.2022.117080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145588877&doi=10.1016%2fj.jenvman.2022.117080&partnerID=40&md5=6c8541674741d64aab7bcd05f53a141c","Since China is a country with high environmental pollution, researchers have intensively studied China's environmental problems using various environmental indicators such as carbon emissions and ecological footprint. Unlike previous literature, this study analyzes the effects of economic growth, globalization, foreign direct investment, and fossil energy intensity on ecological efficiency in China. As an innovation to the literature, the study examines the Chinese ecosystem simultaneously with its economic and environmental aspects by focusing on ecological efficiency. To this end, the study applies dynamic autoregressive distributed lag (DARDL) simulations and kernel-based regularized least squares (KRLS) methods for the period from 1990 to 2018. The results of the DARDL simulations show that globalization, and economic growth enhance ecological efficiency in China. The findings also demonstrate that both foreign direct investment and fossil fuel intensity have a negative impact on environmental quality in China. Based on these results, the study suggests that the Chinese government should adopt policies to channel foreign direct investment into environmentally friendly production, reduce fossil fuel intensity, and improve ecological efficiency by making use of environmentally friendly technologies provided by globalization and economic development. © 2022 Elsevier Ltd","China; Dynamic ARDL simulations; Ecological efficiency; Fossil energy intensity; Globalization","fossil fuel; carbon dioxide; economic growth; environmental management; environmental quality; foreign direct investment; fossil fuel; globalization; government; innovation; Article; carbon dioxide emission; communication technology; ecological footprint; economic development; environmental indicator; environmental management; environmental sustainability; foreign direct investment; fossil energy; gross national product; pollution; China; ecosystem; environmental protection; investment; China; Carbon Dioxide; China; Conservation of Natural Resources; Economic Development; Ecosystem; Fossil Fuels; Investments"
"Pathan R.K., Alam F.I., Yasmin S., Hamd Z.Y., Aljuaid H., Khandaker M.U., Lau S.L.","Breast Cancer Classification by Using Multi-Headed Convolutional Neural Network Modeling","10.3390/healthcare10122367","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144683448&doi=10.3390%2fhealthcare10122367&partnerID=40&md5=dcf0e5c48506502908abac71737fcb0d","Breast cancer is one of the most widely recognized diseases after skin cancer. Though it can occur in all kinds of people, it is undeniably more common in women. Several analytical techniques, such as Breast MRI, X-ray, Thermography, Mammograms, Ultrasound, etc., are utilized to identify it. In this study, artificial intelligence was used to rapidly detect breast cancer by analyzing ultrasound images from the Breast Ultrasound Images Dataset (BUSI), which consists of three categories: Benign, Malignant, and Normal. The relevant dataset comprises grayscale and masked ultrasound images of diagnosed patients. Validation tests were accomplished for quantitative outcomes utilizing the exhibition measures for each procedure. The proposed framework is discovered to be effective, substantiating outcomes with only raw image evaluation giving a 78.97% test accuracy and masked image evaluation giving 81.02% test precision, which could decrease human errors in the determination cycle. Additionally, our described framework accomplishes higher accuracy after using multi-headed CNN with two processed datasets based on masked and original images, where the accuracy hopped up to 92.31% (±2) with a Mean Squared Error (MSE) loss of 0.05. This work primarily contributes to identifying the usefulness of multi-headed CNN when working with two different types of data inputs. Finally, a web interface has been made to make this model usable for non-technical personals. © 2022 by the authors.","breast cancer classification; medical image modeling; multi-headed CNN; ultrasound image processing",
"Patibandla R.S.M.L., Rao B.T., Narayana V.L., Srinivas V.S.","An overview of ontology-based artificial intelligence services in health care systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141647616&partnerID=40&md5=216b1b2059ffc50e5a4517b9e16d798f","Service Computing includes an interdisciplinary focal point that coordinates science and age to connect the space between big business administrations and mastery Technology (IT) contributions. The inescapable idea of contributions figuring control is shown in the greatest venture settings. In way of life, new business administration developments will create an eminent, insights economy to least difficult eat up steam as every purchaser and business utilization of the Internet of Things (IoT) innovations are progressed. Inside and out, we are drawing nearer to a period of Artificially Intelligent (AI) contributions, which are conveyed in multi-scale, complex assigned models. These AI administrations are routinely designed from significant level computational knowledge that uses rising investigative strategies identified with Big Data, Web analysis, information and text mining, Artificial Intelligence, semantic web, and a lot of different advances. At a methodological and innovative difficulties. For the duration of this chapter, service computing, the necessity for service computing, capabilities and applications of carrier computing, security and privateness issues, and Trust associated problems in fitness care services are certainly represented. Equivalent time, it'll become progressively fundamental to compute specialized and reasonable difficulties and to recognize decent practices learned through understanding. The arranging, improvement, and arrangement of ML contributions blessing novel. © 2021 Nova Science Publishers, Inc.","AI; Computing; Healthcare; Ontology; Services",
"Patil A.B., Bachute M.R., Kotecha K.","Artificial Perception of the Beverages: An In-Depth Review of the Tea Sample","10.1109/ACCESS.2021.3086038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107385725&doi=10.1109%2fACCESS.2021.3086038&partnerID=40&md5=4e0dfcff19eb6650dd02dfd7e35ccddc","India is the second-largest tea producer and consumer in the world after China. In 2017, the Indian tea market size accounted for 130 billion Indian rupees. An estimated global tea market size was at USD 13.31 billion in 2019, and the expected compound annual growth rate is 5.5% up to the year 2025. India can grab worth tea market size globally by making market strategies with AI and ML-based demonstrations for the unique identity of tea flavor. Conventional instruments available are not handy, time-consuming and require a skilled person to operate. The tea attributes should be digitally recognizable before purchase from the consumer's perspective, significantly enlarging the tea market circle. In the paper, the comprehensive review about an artificial perception of tea has been discussed. Three major attributes of the tea sample, its taste, smell, and color, are under consideration. With the help of various sensors, the attributes of liquefied tea samples Had got converted into their digital signature. By analyzing the correlation of them with the pattern recognition, their classification had been done. The electronic feature fusion of tea liquor attributes may cause handling issues with the formation of redundant data. So this paper explains the method and guidelines of an application of specific filters which remove the redundant data. The constructive sample data can establish the decision matrix for correlation. With the established decision matrix, précised test prediction can be achieved for the tea sample based on correlation and regression. The limitations and glitches of the conventional instruments for an artificial perception have been discussed in-depth for possible improvement. The paper ends with a bibliometric analysis of the topic 'artificial taste perception of tea,' which had derived from the standard repository of Web of Science. The bibliometric analysis is very useful to showcase the current research trends in the artificial taste perception of tea. © 2013 IEEE.","Artificial intelligence (AI); artificial neural network (ANN); bibliometric analysis; e-nose; e-tongue; machine learning (ML); pattern recognition; peak signal to noise ratio (PSNR); principal component analysis (PCA)","Commerce; Flavor compounds; Matrix algebra; Pattern recognition; Artificial perception; Bibliometric analysis; Compound annual growth rates; Conventional instruments; Decision matrices; Market strategies; Research trends; Taste perceptions; Tea"
"Pattathal V. A., Sahoo M.M., Porwal A., Karnieli A.","Deep-learning-based latent space encoding for spectral unmixing of geological materials","10.1016/j.isprsjprs.2021.11.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120319577&doi=10.1016%2fj.isprsjprs.2021.11.008&partnerID=40&md5=24940e32b5ea8ddfea91bbd395d32d81","The relatively coarse spatial resolution of hyperspectral images causes the mixing of disparate materials’ spectral responses in the sensor's instantaneous field of view (IFOV), resulting in mixed pixels. The current study proposes a capsule-based generative encoding model, called a denoising unmixing encoder network (DUENet), to formulate an end-to-end trainable spectral unmixing model. The reconstruction and cross-entropy losses and input prior-based constraints achieve joint optimization of denoising, data imputation, and spectral unmixing. Unlike earlier approaches, interpolation-based convolution and dynamic time wrapping (DTW)-based convolutional units facilitate DUENet to even unmix noisy spectra. In addition to embedding label information to improve the physical significance of the latent space, DUENet dynamically learns the parameters of the interpolation kernels. Benchmark airborne hyperspectral datasets (the Nabesna and Cuprite datasets) and simulated datasets were employed to evaluate the performance of the proposed approach. It was observed that the proposed joint optimization of spectral unmixing and denoising significantly improves the results. The adopted feature characterization using capsules improves the generalizability and gives good results, even with a limited number of training samples. This study shows the need for interpretability-based evaluation measures to analyze the unmixing frameworks based on the concepts learned for each endmember. The experiments confirm that the proposed strategy significantly reduces the models’ sensitivity to network parameters. © 2021 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS)","Airborne hyperspectral remote sensing; Autoencoder; Convolutional neural network; Deep learning; Denoising; Feature learning; Geological application; Spectral unmixing","Benchmarking; Convolutional neural networks; Deep learning; Encoding (symbols); Geology; Interpolation; Network coding; Remote sensing; Space optics; Spectroscopy; Airborne hyperspectral remote sensing; Auto encoders; Convolutional neural network; De-noising; Deep learning; Feature learning; Geological applications; Joint optimization; Spectral unmixing; Unmixing; Convolution; field of view; geological phenomena; interpolation; optimization; reconstruction; spatial resolution; spectral analysis; Cuprite; Nevada; United States"
"Paudel D., de Wit A., Boogaard H., Marcos D., Osinga S., Athanasiadis I.N.","Interpretability of deep learning models for crop yield forecasting","10.1016/j.compag.2023.107663","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147255463&doi=10.1016%2fj.compag.2023.107663&partnerID=40&md5=9487a0f9c222385b9c510772f6be933d","Machine learning models for crop yield forecasting often rely on expert-designed features or predictors. The effectiveness and interpretability of these handcrafted features depends on the expertise of the people designing them. Neural networks have the ability to learn features directly from input data and train the feature learning and prediction steps simultaneously. In this paper, we evaluate the performance and interpretability of neural network models for crop yield forecasting using data from the MARS Crop Yield Forecasting System of the European Commission's Joint Research Centre. The selected neural networks can handle sequential or time series data and include long short-term memory (LSTM) recurrent neural network and 1-dimensional convolutional neural network (1DCNN). Performance was compared with a linear trend model and a Gradient-Boosted Decision Trees (GBDT) model, trained using hand-designed features. Feature importance scores of input variables were computed using feature attribution methods and were analyzed by crop yield modeling and agronomy experts. Results showed that LSTM models perform statistically better than GBDT models for soft wheat in Germany and similar to GBDT models for all other case studies. In addition, LSTM models captured the effect of yield trend, static features (e.g. elevation, soil water holding capacity) and biomass features on crop yield well, but struggled to capture the impact of extreme temperature and moisture conditions. Our work shows the potential of deep learning to automatically learn features and produce reliable crop yield forecasts, and highlights the importance and challenges of involving human stakeholders in assessing model interpretability. © 2023 The Author(s)","Crop yield; Deep learning; Human stakeholders; Interpretability; Neural networks","Convolutional neural networks; Crops; Decision trees; Deep neural networks; Forecasting; Learning systems; Soil moisture; Boosted decision trees; Crop yield; Crop yield forecasting; Decision-tree model; Deep learning; Human stakeholder; Interpretability; Learn+; Neural-networks; Performance; Long short-term memory"
"Pazira M., Baleghi Y., Akbari A.","Hardware Trojan Detection Using Thermal Imaging in FPGAs with Combined Features","10.1109/ICSPIS54653.2021.9729357","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127412477&doi=10.1109%2fICSPIS54653.2021.9729357&partnerID=40&md5=caf66f0b584e4eda074aa7f082ca7c7f","A Hardware Trojan (HT) is a malicious modification of the circuitry of an integrated circuit. The importance of Hardware Trojan detection increases with increase in the complexity of integrated circuits. The possible effects of the insertion of a Hardware Trojan involve a range of harms from leakage of sensitive information to the complete destruction of the integrated circuit itself. Non-invasive methods of Hardware Trojan detection are divided into two general categories: performance testing and side channel analysis. Hardware Trojan detection using thermal imagery is one of the side channel analysis methods which have recently been considered. In this paper, we propose a Hardware Trojan detection method on FPGA, based on thermal image processing of defected and authentic chips assuming that a golden chip is available. We also provide a dataset of thermal images captured from multiple experiments on a certain FPGA board. Each experiment contains 12 images taken in 55 seconds of working FPGA. The Hardware Trojan detection method relies on extracting two different features from images and detecting the presence of a Hardware Trojan using machine learning techniques. Results shows that if proposed method is combined with a basic method, hardware Trojan detection accuracy can be increased, significantly. © 2021 IEEE.","FPGA; Hardware Trojan detection; side channel analysis; thermal image analysis","Feature extraction; Hardware security; Image analysis; Infrared imaging; Integrated circuits; Learning systems; Malware; Noninvasive medical procedures; Combined features; Detection methods; Hardware Trojan detection; Noninvasive methods; Performance testing; Sensitive informations; Side-channel analysis; Thermal image analysis; Thermal imagery; Thermal-imaging; Field programmable gate arrays (FPGA)"
"Pazouki E.","Optimizing an irrigation treatment using an evolutionary algorithm and a knowledge discovery framework based on Deep models","10.1016/j.asoc.2022.109940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145648860&doi=10.1016%2fj.asoc.2022.109940&partnerID=40&md5=54b73c1bcc2b17e1e45b197808bc6d78","Nowadays, learning models have good accuracy and learn complex patterns which are hidden in the data. Occasionally, patterns which are discovered using these models cannot be discovered by a human. So representing the discovered patterns and knowledge as an explainable knowledge for human is important. In this paper, a framework is proposed for knowledge discovery from real agricultural datasets. In the proposed framework, Deep Learning (DL) models are used for learning the patterns and effective features from tabular datasets; The integrated gradient method is used as an indirect metric for representing the black-box models as an interpretable model; A fuzzy expert system is used for interpreting the discovered knowledge as an expert system; An especial evolutionary algorithm is used for extracting the knowledge as a fuzzy expert system. In order to evaluate the proposed framework, some experiments are performed on the real tabular dataset on the agricultural field for extracting knowledge about productivity. For validating the discovered knowledge, an optimization algorithm is proposed which uses the discovered expert system for designing optimal irrigation treatments on the selected dataset. DSSAT, which is a farm simulator, is used for validating discovered knowledge. The obtained results show that the discovered knowledge can improve the productivity by 30% and decrease the used water by 30%. In addition, yields of the designed treatment and discovered knowledge correlate more than 0.8. © 2022 Elsevier B.V.","Agricultural knowledge discovery; Deep learning; Fuzzy expert system; Genetic fuzzy system; Irrigation treatment","Data mining; Deep learning; Expert systems; Gradient methods; Irrigation; Learning algorithms; Learning systems; Agricultural knowledge discovery; Complex pattern; Deep learning; Fuzzy-expert systems; Genetic fuzzy systems; Genetic fuzzy-system; Irrigation treatments; Knowledge discovery framework; Learn+; Learning models; Evolutionary algorithms"
"Peeples J., Xu W., Gloaguen R., Rowland D., Zare A., Brym Z.","Spatial and Texture Analysis of Root System distribution with Earth mover’s Distance (STARSEED)","10.1186/s13007-022-00974-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145717184&doi=10.1186%2fs13007-022-00974-z&partnerID=40&md5=dfbfddded7687c2c7648a0d1905cc7e0","Purpose: Root system architectures are complex and challenging to characterize effectively for agronomic and ecological discovery. Methods: We propose a new method, Spatial and Texture Analysis of Root SystEm distribution with Earth mover’s Distance (STARSEED), for comparing root system distributions that incorporates spatial information through a novel application of the Earth Mover’s Distance (EMD). Results: We illustrate that the approach captures the response of sesame root systems for different genotypes and soil moisture levels. STARSEED provides quantitative and visual insights into changes that occur in root architectures across experimental treatments. Conclusion: STARSEED can be generalized to other plants and provides insight into root system architecture development and response to varying growth conditions not captured by existing root architecture metrics and models. The code and data for our experiments are publicly available: https://github.com/GatorSense/STARSEED. © 2023, The Author(s).","Artificial Intelligence; Earth Mover’s Distance; Image analysis; Root architecture; Sesamum indicum",
"Pei Z., Liu S., Jing Z., Zhang Y., Wang J., Liu J., Wang Y., Guo W., Li Y., Feng L., Zhou H., Li G., Han Y., Liu D., Pan J.","Understanding of the interrelationship between methane production and microorganisms in high-solid anaerobic co-digestion using microbial analysis and machine learning","10.1016/j.jclepro.2022.133848","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137178861&doi=10.1016%2fj.jclepro.2022.133848&partnerID=40&md5=00cd02bd155b046a3e5961794220dbc0","Co-digestion of lignocellulosic biomass and animal manure is a common approach to increase the efficiency of methane production, but the niche differentiation and microbial metabolism of the anaerobic digestion (AD) process remain to be determined. To further explore the effect of the interaction between species and their compositional niches, the methane yield and resulting microbial community were determined by machine learning (ML) and 16S rRNA gene sequencing in mixed high-solid anaerobic digestion (HS-AD) with spray-enhanced conditions to explore the internal relationship between physical and chemical parameters and microorganisms and to speculate on the enhancement mechanism of co-digestion. In this study, three ML models (extreme learning machine (ELM), artificial neural network (ANN), and random forest (RF)) were applied to analyse and model AD of dry fermentation. The results showed that the best prediction model, based on ELM, could best predict the material biogas production in this experiment with a mean absolute error (MAE/10) of 0.678 and a coefficient of determination (R2) of 0.9574, whereas the characteristic percentage analysis of the RF model showed that butyric acid, acetic acid, and pH had three important influences on the biogas production values. Meanwhile, the results of high-throughput 16S rRNA gene sequencing and PICRUSt showed that the addition of manure containing ammonia nitrogen improved the metabolism of amino acids, enriched species capable of Clostridiales and Methanosarcinales, promoted the electronic transfer of nutrient metabolism, and thus enhanced AD. Moreover, the co-occurrence network showed that seven niches were differentiated within the HS-AD system to reduce the shock of ammonia nitrogen for methanogens. Overall, microbial analysis and ML can help understand the dynamic processes of methanogenic microorganisms and predict biogas production for the efficient operation of AD. © 2022 Elsevier Ltd","Cattle manure; Corn straw; High-solid anaerobic digestion; Machine learning; Microbiological analysis","Ammonia; Biogas; Chemical analysis; Decision trees; Fertilizers; Forecasting; Genes; Learning systems; Machine learning; Manures; Metabolism; Methane; Neural networks; Nitrogen; RNA; 16S rRNA gene sequencing; Biogas production; Cattle manures; Codigestion; Corn straws; High-solids anaerobic digestion; Learning machines; Machine-learning; Microbial analysis; Microbiological analysis; Anaerobic digestion"
"Peichl M., Thober S., Samaniego L., Hansjürgens B., Marx A.","Machine-learning methods to assess the effects of a non-linear damage spectrum taking into account soil moisture on winter wheat yields in Germany","10.5194/hess-25-6523-2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122012712&doi=10.5194%2fhess-25-6523-2021&partnerID=40&md5=c1c54a39bec00889d8f8329b1884783b","Agricultural production is highly dependent on the weather. The mechanisms of action are complex and interwoven, making it difficult to identify relevant management and adaptation options. The present study uses random forests to investigate such highly non-linear systems for predicting yield anomalies in winter wheat at district levels in Germany. In order to take into account sub-seasonality, monthly features are used that explicitly take soil moisture into account in addition to extreme meteorological events. Clustering is used to show spatially different damage potentials, such as a higher susceptibility to drought damage from May to July in eastern Germany compared to the rest of the country. In addition, relevant heat effects are not detected if the clusters are not sufficiently defined. The variable with the highest importance is soil moisture in March, where higher soil moisture has a detrimental effect on crop yields. In general, soil moisture explains more yield variations than the meteorological variables. The approach has proven to be suitable for explaining historical extreme yield anomalies for years with exceptionally high losses (2003, 2018) and gains (2014) and the spatial distribution of these anomalies. The highest test R-squared (R2) is about 0.68. Furthermore, the sensitivity of yield variations to soil moisture and extreme meteorological conditions, as shown by the visualization of average marginal effects, contributes to the promotion of targeted decision support systems. © 2021 Michael Peichl et al.",,"Crops; Decision support systems; Decision trees; Linear systems; Machine learning; Sensitivity analysis; Agricultural productions; Clusterings; Machine learning methods; Mechanism of action; Non linear system; Non-linear damages; Seasonality; Spectra's; Winter wheat; Winter wheat yields; Soil moisture; assessment method; crop yield; machine learning; soil moisture; soil water; wheat; Germany"
"Peiró-Signes Á., Segarra-Oña M., Trull-Domínguez Ó., Sánchez-Planelles J.","Exposing the ideal combination of endogenous–exogenous drivers for companies’ ecoinnovative orientation: Results from machine-learning methods","10.1016/j.seps.2021.101145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115740198&doi=10.1016%2fj.seps.2021.101145&partnerID=40&md5=f75b85571ba877fa7d4174bd1d39d846","This study provides an XGBoost model to characterize the environmental orientation of innovative firms. This novel approach, using state-of-the-art machine learning methodologies and multiple recognized drivers of eco-innovation, provides solid empirical support for the understanding of the mechanisms that are crucial for firms' transition to a low-carbon economy. Although many drivers have been considered to affect firms’ eco-innovation, our feature selection process using the BorutaShap algorithm demonstrates that few aspects are truly relevant. Furthermore, analyzing a tree surrogate of the final model, our study explores the different paths or combinations of aspects that consistently lead to a specific eco-innovation orientation. The accuracy of the model and the large and complete spectrum of innovative companies in the sample contribute to the generalizability of the results. This study is particularly relevant because the main drivers of firms’ eco-innovative orientation depend on their innovative behavior, indicating that the managerial and policy work has to be directed to raising awareness of the different externalities derived from innovation. On one side, policy regulations should continue to pressure firms with environmental standards. On the other side, managers can stimulate the creation of a corporate innovative culture oriented toward improving operational efficiency (reducing unnecessary costs), improving the workplace environment, and focusing on new customer demands, which, in essence, will guide the organization to be more environmentally and socially responsible. © 2021 The Authors","Drivers; Eco-innovation; Innovative firms; Machine learning","accuracy assessment; algorithm; empirical analysis; firm size; innovation; machine learning"
"Pelosi M., Brown M., Ahmad K.","Improved hybrid opponent system for professional military training","10.25046/aj0203220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069190988&doi=10.25046%2faj0203220&partnerID=40&md5=af8cc29bee835508cb2b50b0745cef4f","Described herein is a general-purpose software engineering architecture for autonomous, computer controlled opponent implementation in modern maneuver warfare simulation and training. The implementation has been developed, refined, and tested in the user crucible for several years. The approach represents a hybrid application of various well-known AI techniques, including domain modeling, agent modeling, and object-oriented programming. Inspired by computer chess approaches, the methodology combines this theoretical foundation with a hybrid and scalable portfolio of additional techniques. The result remains simple enough to be maintainable, comprehensible for the code writers as well as the end-users, and robust enough to handle a wide spectrum of possible mission scenarios and circumstances without modification. © 2017 ASTES Publishers. All rights reserved.","Artificial intelligence; Expert system; Hybrid AI; Professional training; Software engineering",
"Peng S., Zhu J., Liu Z., Hu B., Wang M., Pu S.","Prediction of Ammonia Concentration in a Pig House Based on Machine Learning Models and Environmental Parameters","10.3390/ani13010165","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145851126&doi=10.3390%2fani13010165&partnerID=40&md5=1be43116b5b5634420b5fdefa06599bf","Accurately predicting the air quality in a piggery and taking control measures in advance are important issues for pig farm production and local environmental management. In this experiment, the NH3 concentration in a semi-automatic piggery was studied. First, the random forest algorithm (RF) and Pearson correlation analysis were combined to analyze the environmental parameters, and nine input schemes for the model feature parameters were identified. Three kinds of deep learning and three kinds of conventional machine learning algorithms were applied to the prediction of NH3 in the piggery. Through comparative experiments, appropriate environmental parameters (CO2, H2O, P, and outdoor temperature) and superior algorithms (LSTM and RNN) were selected. On this basis, the PSO algorithm was used to optimize the hyperparameters of the algorithms, and their prediction performance was also evaluated. The results showed that the R2 values of PSO-LSTM and PSO-RNN were 0.9487 and 0.9458, respectively. These models had good accuracy when predicting NH3 concentration in the piggery 0.5 h, 1 h, 1.5 h, and 2 h in advance. This study can provide a reference for the prediction of air concentrations in pig house environments. © 2022 by the authors.","ammonia concentration; machine learning; pig house; prediction models","ammonia; accuracy; animal experiment; Article; artificial neural network; cell activation; correlation analysis; decision tree; deep learning; environmental parameters; Fourier transform infrared photoacoustic spectroscopy; humidity; learning algorithm; long short term memory network; machine learning; memory cell; nonhuman; particle swarm optimization; pig; prediction; random forest; recurrent neural network; support vector machine; temperature"
"Peng Y., Wang Y.","Leaf disease image retrieval with object detection and deep metric learning","10.3389/fpls.2022.963302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138928757&doi=10.3389%2ffpls.2022.963302&partnerID=40&md5=cea2bf4a3611ef5f79bf95b78bd48235","Rapid identification of plant diseases is essential for effective mitigation and control of their influence on plants. For plant disease automatic identification, classification of plant leaf images based on deep learning algorithms is currently the most accurate and popular method. Existing methods rely on the collection of large amounts of image annotation data and cannot flexibly adjust recognition categories, whereas we develop a new image retrieval system for automated detection, localization, and identification of individual leaf disease in an open setting, namely, where newly added disease types can be identified without retraining. In this paper, we first optimize the YOLOv5 algorithm, enhancing recognition ability in small objects, which helps to extract leaf objects more accurately; secondly, integrating classification recognition with metric learning, jointly learning categorizing images and similarity measurements, thus, capitalizing on prediction ability of available image classification models; and finally, constructing an efficient and nimble image retrieval system to quickly determine leaf disease type. We demonstrate detailed experimental results on three publicly available leaf disease datasets and prove the effectiveness of our system. This work lays the groundwork for promoting disease surveillance of plants applicable to intelligent agriculture and to crop research such as nutrition diagnosis, health status surveillance, and more. Copyright © 2022 Peng and Wang.","convolutional neural networks; deep metric learning; image retrieval algorithm; leaf disease recognition; object detection",
"Persello C., Wegner J.D., Hansch R., Tuia D., Ghamisi P., Koeva M., Camps-Valls G.","Deep Learning and Earth Observation to Support the Sustainable Development Goals: Current approaches, open challenges, and future opportunities","10.1109/MGRS.2021.3136100","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123365246&doi=10.1109%2fMGRS.2021.3136100&partnerID=40&md5=9005f2f2001b676e878a4253d8c83a14","The synergistic combination of deep learning (DL) models and Earth observation (EO) promises significant advances to support the Sustainable Development Goals (SDGs). New developments and a plethora of applications are already changing the way humanity will face the challenges of our planet. This article reviews current DL approaches for EO data, along with their applications toward monitoring and achieving the SDGs most impacted by the rapid development of DL in EO. We systematically review case studies to achieve zero hunger, create sustainable cities, deliver tenure security, mitigate and adapt to climate change, and preserve biodiversity. Important societal, economic, and environmental implications are covered. Exciting times are coming when algorithms and Earth data can help in our endeavor to address the climate crisis and support more sustainable development. © 2013 IEEE.",,"Biodiversity; Climate change; Deep learning; Earth (planet); Observatories; Planning; 'current; Case-studies; Earth observation data; Earth observations; Economic implications; Learning approach; Learning models; Societal implications; Sustainable cities; Synergistic combinations; Sustainable development; algorithm; climate change; EOS; learning; Sustainable Development Goal"
"Pešek O., Segal-Rozenhaimer M., Karnieli A.","Using Convolutional Neural Networks for Cloud Detection on VENμS Images over Multiple Land-Cover Types","10.3390/rs14205210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140979465&doi=10.3390%2frs14205210&partnerID=40&md5=a2afc51b3ed09243776c29d8f340bafe","In most parts of the electromagnetic spectrum, solar radiation cannot penetrate clouds. Therefore, cloud detection and masking are essential in image preprocessing for observing the Earth and analyzing its properties. Because clouds vary in size, shape, and structure, an accurate algorithm is required for removing them from the area of interest. This task is usually more challenging over bright surfaces such as exposed sunny deserts or snow than over water bodies or vegetated surfaces. The overarching goal of the current study is to explore and compare the performance of three Convolutional Neural Network architectures (U-Net, SegNet, and DeepLab) for detecting clouds in the VEN (Formula presented.) S satellite images. To fulfil this goal, three VEN (Formula presented.) S tiles in Israel were selected. The tiles represent different land-use and cover categories, including vegetated, urban, agricultural, and arid areas, as well as water bodies, with a special focus on bright desert surfaces. Additionally, the study examines the effect of various channel inputs, exploring possibilities of broader usage of these architectures for different data sources. It was found that among the tested architectures, U-Net performs the best in most settings. Its results on a simple RGB-based dataset indicate its potential value for any satellite system screening, at least in the visible spectrum. It is concluded that all of the tested architectures outperform the current VEN (Formula presented.) S cloud-masking algorithm by lowering the false positive detection ratio by tens of percents, and should be considered an alternative by any user dealing with cloud-corrupted scenes. © 2022 by the authors.","artificial neural network; CNN; deep learning; remote sensing; semantic segmentation","Arid regions; Convolution; Deep neural networks; Land use; Network architecture; Remote sensing; Semantic Segmentation; Semantic Web; Semantics; 'current; Cloud detection; Cloud masking; Convolutional neural network; Deep learning; Electromagnetic spectra; Land-cover types; Remote-sensing; Semantic segmentation; Waterbodies; Convolutional neural networks"
"Pham T.D., Manapragada C., Rajan N., Aickelin U.","Pharmaceutical process optimisation: Decision support under high uncertainty","10.1016/j.compchemeng.2022.108100","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145269959&doi=10.1016%2fj.compchemeng.2022.108100&partnerID=40&md5=9600b25cd70085b8006bb08f296994fe","Optimisation of cell culture processes is an extremely challenging problem for the biomanufacturing industry. Limited data availability, coupled with biological complexity in modelling highly variable living cells, necessitates a decision support methodology that is performant under high levels of uncertainty. Raw materials, experimental & manufacturing facilities, and human expertise are all steeply expensive and availability is tightly constrained — planning their allocation is subject to the core uncertainties underlying the behaviour of living cells. This paper presents a novel decision support methodology for optimisation under high uncertainty. Optimisation techniques require an “objective function” that maps decision variables to the quantity being optimised, so that the decision space can be explored to find an optimum. By learning multiple types of objective function candidates with different levels of fidelity to real-world processes, our method mitigates the risk of picking a poor approximation of the objective function due to sampling effects and algorithmic randomness. Wet lab experimentation on a biomanufacturing feed optimisation problem verified that inferred candidates can successfully support domain experts in designing a new optimised feed strategy with significantly higher product yield than the current industrial control strategy. Our results indicate potential for extending our methodology to the optimisation of other complex industrial processes. © 2022 Elsevier Ltd","AI; Bioprocessing; mAb; Machine learning; Optimisation; Pharmaceuticals","Cell culture; Decision support systems; Drug products; Learning systems; Machine learning; Product design; Uncertainty analysis; Bio-manufacturing; Bioprocessing; Decision supports; Living cell; Mab; Machine-learning; Objective functions; Optimisations; Pharmaceuticals process; Uncertainty; Optimization"
"Phan T.C., Quach N.D.K., Nguyen T.T., Nguyen T.T., Jo J., Nguyen Q.V.H.","Real-time wildfire detection with semantic explanations","10.1016/j.eswa.2022.117007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129566143&doi=10.1016%2fj.eswa.2022.117007&partnerID=40&md5=64f03f051dbf8e8fae85540e83823dfb","Wildfire detection is an indispensable component of many resilient platforms, preventing environmental disasters from damaging life. Online detection, which refers to situations in which wildfire events need to be detected in real time, is an essential tool, as the consequences of wildfires might already be irreversible by the time they are detected. Recently, wildfire detection methods based on machine learning and deep learning have been proposed. However, most of these methods take raw data as the input and then aggregate it into predictive features, which requires all of the historical data or a large part of a stream and violates the timeliness requirement of online detection. Moreover, these methods scarcely discuss the explainability (e.g., how the model comes up with the final detection). The lack of explainability reduces human trust in the system and may hinder further applications of the system, especially in high-stakes situations where decisions can have significant consequences. Unlike existing works that treat the timeliness and explainability problems separately, we propose a real-time wildfire detection system that is built upon the streaming capability of complex event processing and the expressiveness of semantic annotation. The system continuously processes raw data streams, transforms them into semantic events, and learns CEP queries that are both predictive and interpretable for humans at the same time. Experiments on four real datasets and one synthetic dataset show that our approach outperforms the baselines in terms of efficiency, accuracy, explainability, and adaptivity. © 2022 Elsevier Ltd","Complex event processing; Explanation discovery; Real-time monitoring; Wildfire detection","Deep learning; Disaster prevention; Fires; Complex event processing; Complex events; Detection methods; Environmental disasters; Event Processing; Explanation discovery; On-line detection; Real time monitoring; Real- time; Wildfire detection; Semantics"
"Pi Y., Nath N.D., Sampathkumar S., Behzadan A.H.","Deep Learning for Visual Analytics of the Spread of COVID-19 Infection in Crowded Urban Environments","10.1061/(ASCE)NH.1527-6996.0000492","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105168217&doi=10.1061%2f%28ASCE%29NH.1527-6996.0000492&partnerID=40&md5=84454c5841622c2e26be3b38010f2bc0","The novel SARS-CoV-2 coronavirus caused a global pandemic in 2020 with millions of diagnosed cases and a staggering number of deaths. As a preventive measure, many governments issued social distancing and shelter-in-place mandates to limit human contact and slow the rate of infection. The large extent and duration of the crisis is poised to transform the health sector and alter current practices in retail, business, manufacturing, and construction. While medical researchers are working on antidote and vaccine solutions, contact tracing and self-isolation are deemed effective methods to control community spread. This paper presents a visual analysis approach that uses convolutional neural networks (CNNs) to generate quantifiable metrics of contact tracing. In particular, the YOLO-v3 architecture was trained on an annotated video dataset containing pedestrians. Network pruning and non-maximum suppression were applied to optimize model performance, resulting in 69.41% average precision. The fully trained model was then tested on sample crosswalk video data from Xiamen, China, recorded during the COVID-19 pandemic, followed by projecting detected pedestrians onto an orthogonal map for contact tracing by tracking movement trajectories and simulating the spread of droplets among the healthy population. Results demonstrate that the proposed technique is capable of tracing and documenting infection sources, times, and locations. © 2021 American Society of Civil Engineers.","Computer vision; Contact tracing; Convolutional neural networks; COVID-19; Deep learning; Social distancing","Convolutional neural networks; Population statistics; Current practices; Healthy population; Medical researchers; Movement trajectories; Non-maximum suppression; Preventive measures; Rate of infections; Urban environments; Deep learning; COVID-19; infectivity; urban agriculture; urban area; viral disease; visual analysis; Coronavirus; SARS coronavirus"
"Pierdicca R., Paolanti M.","GeoAI: a review of artificial intelligence approaches for the interpretation of complex geomatics data","10.5194/gi-11-195-2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132047224&doi=10.5194%2fgi-11-195-2022&partnerID=40&md5=e5e45ea0ce988778ef270abc9d8aafd7","Researchers have explored the benefits and applications of modern artificial intelligence (AI) algorithms in different scenarios. For the processing of geomatics data, AI offers overwhelming opportunities. Fundamental questions include how AI can be specifically applied to or must be specifically created for geomatics data. This change is also having a significant impact on geospatial data. The integration of AI approaches in geomatics has developed into the concept of geospatial artificial intelligence (GeoAI), which is a new paradigm for geographic knowledge discovery and beyond. However, little systematic work currently exists on how researchers have applied AI for geospatial domains. Hence, this contribution outlines AI-based techniques for analysing and interpreting complex geomatics data. Our analysis has covered several gaps, for instance defining relationships between AI-based approaches and geomatics data. First, technologies and tools used for data acquisition are outlined, with a particular focus on red-green-blue (RGB) images, thermal images, 3D point clouds, trajectories, and hyperspectral-multispectral images. Then, how AI approaches have been exploited for the interpretation of geomatic data is explained. Finally, a broad set of examples of applications is given, together with the specific method applied. Limitations point towards unexplored areas for future investigations, serving as useful guidelines for future research directions. © Copyright:",,"Data acquisition; Surveying; 3D point cloud; Artificial intelligence algorithms; Geo-spatial; Geo-spatial data; Geographic knowledge discoveries; Geomatic; HyperSpectral; Multispectral images; Red green blues; Thermal images; Artificial intelligence; artificial intelligence; data acquisition; detection method; image analysis"
"Pinciroli Vago N.O., Sacaj M., Sadeghi M., Kalwar S., Vogelsang A., Rossi M.","On the visualization of semantic-based mappings",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116081127&partnerID=40&md5=c6491ab9d3821916c2c048bbad130695","The popularity of the semantic web in many domains, such as transportation, has led to an ever-increasing development of standards, vocabularies, and ontologies, which generates problems of heterogeneity and lack of interoperability. To address this issue, a large body of research focused on providing various mapping tools and techniques to translate data from one standard to another to foster smooth communication among them. While valuable advancements in mapping techniques have been achieved so far, the explainability and usability of such tools have been overlooked. Since explainability of software is being recognized as a crucial non-functional requirement for complex systems, the development of self-explaining and user-friendly graphical interfaces is becoming a pressing need. In this paper we present S2SMaT, our contribution to the problem of visualization of mappings. The tool helps users easily navigate the structure of standards, understand the suggested mappings between their terms, and in general more easily interact with the system. © 2021 CEUR-WS. All rights reserved.","Automated mappings; Coordinated views; Semantic mappings; Visual explanation; Visualization; XML to ontology mapping","Ontology; Semantic Web; Visualization; Automated mapping; Coordinated views; Mapping techniques; Mapping tools; Ontology mapping; Ontology's; Semantic-Web; Semantics mappings; Visual explanation; XML to ontology mapping; Mapping"
"Podgorelec V., Pečnik Š., Vrbančič G.","Classification of similar sports images using convolutional neural network with hyper-parameter optimization","10.3390/app10238494","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096700528&doi=10.3390%2fapp10238494&partnerID=40&md5=8250f246728199b90eceaf9a5a1db6ef","With the exponential growth of the presence of sport in the media, the need for effective classification of sports images has become crucial. The traditional approaches require carefully hand-crafted features, which make them impractical for massive-scale data and less accurate in distinguishing images that are very similar in appearance. As the deep learning methods can automatically extract deep representation of training data and have achieved impressive performance in image classification, our goal was to apply them to automatic classification of very similar sports disciplines. For this purpose, we developed a CNN-TL-DE method for image classification using the fine-tuning of transfer learning for training a convolutional neural network model with the use of hyper-parameter optimization based on differential evolution. Through the automatic optimization of neural network topology and essential training parameters, we significantly improved the classification performance evaluated on a dataset composed from images of four similar sports—American football, rugby, soccer, and field hockey. The analysis of interpretable representation of the trained model additionally revealed interesting insights into how our model perceives images which contributed to a greater confidence in the model prediction. The performed experiments showed our proposed method to be a very competitive image classification method for distinguishing very similar sports and sport situations. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Classification; CNN; Machine learning; Optimization; Transfer learning",
"Poeplau C., Don A., Schneider F.","Roots are key to increasing the mean residence time of organic carbon entering temperate agricultural soils","10.1111/gcb.15787","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110300001&doi=10.1111%2fgcb.15787&partnerID=40&md5=94e055f2a5be89df954acc7abe48206f","The ratio of soil organic carbon stock (SOC) to annual carbon input gives an estimate of the mean residence time of organic carbon that enters the soil (MRTOC). It indicates how efficiently biomass can be transformed into SOC, which is of particular relevance for mitigating climate change by means of SOC storage. There have been few comprehensive studies of MRTOC and their drivers, and these have mainly been restricted to the global scale, on which climatic drivers dominate. This study used the unique combination of regional-scale cropland and grassland topsoil (0–30 cm) SOC stock data and average site-specific OC input data derived from the German Agricultural Soil Inventory to elucidate the main drivers of MRTOC. Explanatory variables related to OC input composition and other soil-forming factors were used to explain the variability in MRTOC by means of a machine-learning approach. On average, OC entering German agricultural topsoils had an MRT of 21.5 ± 11.6 years, with grasslands (29.0 ± 11.2 years, n = 465) having significantly higher MRTOC than croplands (19.4 ± 10.7, n = 1635). This was explained by the higher proportion of root-derived OC inputs in grassland soils, which was the most important variable for explaining MRTOC variability at a regional scale. Soil properties such as clay content, soil group, C:N ratio and groundwater level were also important, indicating that MRTOC is driven by a combination of site properties and OC input composition. However, the great importance of root-derived OC inputs indicated that MRTOC can be actively managed, with maximization of root biomass input to the soil being a straightforward means to extend the time that assimilated C remains in the soil and consequently also increase SOC stocks. © 2021 The Authors. Global Change Biology published by John Wiley & Sons Ltd.","carbon; carbon sequestration; clay content; root input; soil carbon; soil organic matter; turnover","agricultural soil; carbon sequestration; clay; organic carbon; residence time; root; soil carbon; soil organic matter; turnover; Matthiola; carbon; agriculture; carbon sequestration; soil; Agriculture; Carbon; Carbon Sequestration; Soil"
"Poggi B., Babatounde C., Vittori E., Antoine-Santoni T.","Efficient WSN Node Placement by Coupling KNN Machine Learning for Signal Estimations and I-HBIA Metaheuristic Algorithm for Node Position Optimization","10.3390/s22249927","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144547451&doi=10.3390%2fs22249927&partnerID=40&md5=a16d144ec7ac21ff90d6b8264f73f885","Wireless sensor network (WSN) deployment is an intensive field of research. In this paper, we propose a novel approach based on machine learning (ML) and metaheuristics (MH) for supporting decision-makers during the deployment process. We suggest optimizing node positions by introducing a new hybridized version of the “Hitchcock bird-inspired algorithm” (HBIA) metaheuristic algorithm that we named “Intensified-Hitchcock bird-inspired algorithm” (I-HBIA). During the optimization process, our fitness function focuses on received signal maximization between nodes and antennas. Signal estimations are provided by the machine learning “K Nearest Neighbors” (KNN) algorithm working with real measured data. To highlight our contribution, we compare the performances of the canonical HBIA algorithm and our I-HBIA algorithm on classical optimization benchmarks. We then evaluate the accuracy of signal predictions by the KNN algorithm on different maps. Finally, we couple KNN and I-HBIA to provide efficient deployment propositions according to actual measured signal on areas of interest. © 2022 by the authors.","deployment; HBIA; KNN; optimization; wireless sensor network","Decision making; Learning algorithms; Machine learning; Nearest neighbor search; Sensor nodes; Deployment; Hitchcock bird-inspired algorithm”; K near neighbor”; Machine-learning; Meta-heuristics algorithms; Nearest-neighbor algorithms; Nearest-neighbour; Nodes' positions; Optimisations; Signal estimation; Birds"
"Politikos D.V., Petasis G., Katselis G.","Interpretable machine learning to forecast hypoxia in a lagoon","10.1016/j.ecoinf.2021.101480","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118860080&doi=10.1016%2fj.ecoinf.2021.101480&partnerID=40&md5=ae72ee6e7bcbe5d91079213111be0c6f","Dissolved oxygen is a key indicator in aquatic ecosystems, reflecting changes in water quality. Low levels of dissolved oxygen may lead to oxygen depletion (called hypoxia), putting at high risk the survival of aquatic organisms. Identifying the environmental conditions inducing hypoxia is therefore a topic of high ecological importance. In this study, we used four machine learning algorithms (Extreme Gradient Boosting (XGBoost), Extremely Randomized Trees (EXT), Random Forest, and Logistic Regression) to forecast hypoxia in a lagoon, considering different time lags (2,5,10 and 20-days). To do so, we used data on dissolved oxygen and a total of nine physicochemical and meteorological variables from Papas lagoon, Greece during 2015–2018. Key drivers and synergies that increase the risk of hypoxia were identified using the Shapley Additive exPlanations (SHAP) methodology. EXT was slightly superior to the other algorithms in forecasting hypoxia, achieving a success between 89% and 94% with pH, water temperature, chlorophyll and salinity as top explanatory variables. SHAP showed that the synergistic effect of low pH and chlorophyll, and elevated water temperature and salinity tended to favor conditions leading to hypoxia. SHAP also illustrated that diverse synergies of the explanatory variables can induce hypoxia, indicating the complex and nonlinear relationships between environmental factors and hypoxia. Overall, the present approach may be proved useful for the development of a reliable forecasting tool for alarming hypoxia and, ultimately, the effective monitoring of the lagoon. © 2021 Elsevier B.V.","classification; Dissolved oxygen; Hypoxia; Interpretability; Machine learning; SHAP","detection method; dissolved oxygen; environmental conditions; lagoon; machine learning; physicochemical property; salinity; water temperature; Greece; Indicator indicator"
"Pradhan N., Sille R., Sagar S.","Artificial Intelligence Empowered Models for UAV Communications","10.1007/978-3-031-08395-2_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140309473&doi=10.1007%2f978-3-031-08395-2_5&partnerID=40&md5=97181a03a3e3b6a160b5de80d22839be","UAVs and AI are used for a variety of tasks, including object detection, segmentation, tracking, facial recognition, fire and smoke detection, and so on. Drones can collect data from sensors thanks to AI, resulting in a smart, agile model for businesses and consumers. AI technology aids UAVs in identifying things while in flight, resulting in data collection and analysis on the ground. UAVs can recognize and track objects using a neural network, which is considered the foundation model of AI. Drones also help in conducting risky work in construction sites and monitoring agricultural activities. UAVs use a variety of methods from machine learning, which is a subset of artificial intelligence. Deep learning, a subset of machine learning, is also included, which aids with object detection and image recognition. This chapter discusses the usage of artificial intelligence techniques in real-world scenarios. It also discusses usage of UAV in various fields. Better connectivity, a good prediction system, and increased UAV network performance are all made possible by combining AI, ML, and DL. Because they capture photographs via drones and large data is smoothly linked with multiple commercial applications, AI-based platforms offer a lot of potentials. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Artificial intelligence; Deep learning; Machine learning; UAV",
"Prag K., Woolway M., Celik T.","Toward Data-Driven Optimal Control: A Systematic Review of the Landscape","10.1109/ACCESS.2022.3160709","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127038477&doi=10.1109%2fACCESS.2022.3160709&partnerID=40&md5=a882cdf2d4257d18b6e28d50decb0d29","This literature review extends and contributes to research on the development of data-driven optimal control. Previous reviews have documented the development of model-based and data-driven control in isolation and have not critically reviewed reinforcement learning approaches for adaptive data-driven optimal control frameworks. The presented review discusses the development of model-based to model-free adaptive controllers, highlighting the use of data in control frameworks. In data-driven control frameworks, reinforcement learning methods may be used to derive the optimal policy for dynamical systems. Attractive characteristics of these methods include not requiring a mathematical model of complex systems, their inherent adaptive control capabilities, being an unsupervised learning technique and their decision-making abilities, which are both an advantage and motivation behind this approach. This review considers previous reviews on these topics, including recent work on data-driven control methods. In addition, this review shows the use of data to derive system dynamics, determine the control policy using feedback information, and tune fixed controllers. Furthermore, the review summarises various data-driven methods and their corresponding characteristics. Finally, the review provides a taxonomy, a timeline and a concise narrative of the development of model-based to model-free data-driven adaptive control and underlines the limitations of these techniques due to the lack of theoretical analysis. Areas of further work include theoretical analysis on stability and robustness for data-driven control systems, explainability of black-box policy learning techniques and an evaluation of the impact of the extension of system simulators to include digital twins. © 2013 IEEE.","adaptive control; Data-driven control; learning-based control; model predictive control; model-based; model-free; optimal control; systematic review","Controllers; Decision making; Dynamical systems; Information use; Learning algorithms; Model predictive control; Reinforcement learning; Robustness (control systems); Adaptation models; Adaptive Control; Data-driven control; Learning-based control; Model free; Model-based OPC; Model-predictive control; Optimal controls; Systematic Review; Tuning; Adaptive control systems"
"Praveen C.K., Srinivasan K.","Psychological Impact and Influence of Animation on Viewer's Visual Attention and Cognition: A Systematic Literature Review, Open Challenges, and Future Research Directions","10.1155/2022/8802542","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137666338&doi=10.1155%2f2022%2f8802542&partnerID=40&md5=34fc6f781c0780ee2e5a92d2909eb27b","Animation is an excellent method to associate with the audience in a fun and innovative manner. In recent span, animation has been employed in various fields to enhance knowledge, marketing, advertisement, and age groups from infants to adults. The present communication expounds the systematic review on the impact created by animation on the viewer's visual attention. For this review, a database such as Google Scholar, ScienceDirect, Taylor & Francis, and IEEE Xplore were pursued for publications on the impact of animation on viewer's visual attention from January 2015 to December 2021. The search results showcased 175 titles with 114 full articles, out of which 35 were related to viewers' visual attention towards animation. These reviewed studies comprised of physical outcome (n=9), psychological outcome (n=15), and cognitive outcome (n=11) from which the attention-related factors, physical effects, and cognitive effects of animation were assessed. The animation has influenced the viewer's visual attention through the integration of the different stimuli and the highly organized presentation. Furthermore, the animation has also aided the viewer in attaining greater conceptual understanding, thereby facilitating their cognitive response. As a result, the animation was found to be helpful in enhancing learning skills, food marketing, and teaching strategy. Furthermore, the drawbacks and future recommendations of the studies were elaborated. In addition, challenges and open issues faced during the studies were discussed. Finally, the priority areas in animation identified for promising future directions to visualize large pool data, provide smart communication, and design 3D modeling structures were highlighted. © 2022 C. K. Praveen and Kathiravan Srinivasan.",,"3D modeling; Behavioral research; Commerce; Marketing; Age groups; Future research directions; Google scholar; Marketing groups; Psychological outcomes; Related factors; Systematic literature review; Systematic Review; Visual Attention; Visual Cognition; Animation; attention; cognition; human; human experiment; learning; marketing; outcome assessment; review; ScienceDirect; search engine; skill; systematic review; teaching; visual attention; adult; learning; Adult; Cognition; Humans; Learning"
"Priyadarshini I., Alkhayyat A., Obaid A.J., Sharma R.","Water pollution reduction for sustainable urban development using machine learning techniques","10.1016/j.cities.2022.103970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137027087&doi=10.1016%2fj.cities.2022.103970&partnerID=40&md5=3f09bdd1098dbbbabac53d328a4264f6","Water quality is affected by increased urbanization as pollutants produced in the urban environment settle and contaminate water, and there is an increase in competition of water among cities, industries, agriculture, etc. The quality and quantity of water are affected by alterations in the microclimate, water dynamics, geomorphology, ecology, and biogeochemistry. As more pavements get created, it becomes increasingly difficult for water to soak into the ground and this causes a decrease in the water table. Impervious structures like streets and roofs when washed with rain deposit excessive pollutants in water bodies. The overall increase in water pollution is a potential health hazard for humans and aquatic life. Hence it is necessary to take adequate measures for addressing the water pollution issue that may potentially arise due to increased urbanization. In this study, we tackle the issue using two approaches. The first approach deals with analyzing the water quality to determine its potability using fifteen different types of machine learning techniques like random forests, decision trees, support vector machines, artificial neural networks, etc. The model has been evaluated using metrics such as precision, recall, accuracy, and F-1 score. The second approach deals with identifying marine litter from beaches in many parts of the world using machine learning algorithms. We also explore the different types of beach environments and the type of litter that is found in different locations using extensive exploratory analysis. Both approaches can be used for ensuring sustainable urban development by reducing water pollution. © 2022 Elsevier Ltd","Machine learning; Marine litter; Urban development; Water pollution; Water quality","machine learning; marine pollution; pollution control; sustainable development; urban development; urbanization; water pollution; water quality"
"Prodhan F.A., Zhang J., Hasan S.S., Pangali Sharma T.P., Mohana H.P.","A review of machine learning methods for drought hazard monitoring and forecasting: Current research trends, challenges, and future research directions","10.1016/j.envsoft.2022.105327","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123743395&doi=10.1016%2fj.envsoft.2022.105327&partnerID=40&md5=b1aa094a75f409b9f6dddd004c16af76","Machine learning is a dynamic field with wide-ranging applications, including drought modeling and forecasting. Drought is a complex, devastating natural disaster for which it is challenging to develop effective prediction models. Therefore, our review focuses on basic information about machine learning methods (MLMs) and their potential applications in developing efficient and effective drought forecasting models. We observed that MLMs have achieved significant advances in the robustness, effectiveness, and accuracy of the algorithms for drought modelling in recent years. The performance comparison of MLMs with other models provides a comprehensive conception of different model evaluation metrics. Further challenges of MLMs, such as inadequate training data sets, noise, outliers, and observation bias for spatial data sets, are explored. Finally, our review conveys in-depth understanding to researchers on machine learning applications in forecasting and modeling and provides drought mitigation strategy guidance for policymakers. © 2022 Elsevier Ltd","Big data; Deep learning; Drought; Forecasting; Machine learning","Big data; Deep learning; Disasters; Weather forecasting; 'current; Deep learning; Drought modeling; Dynamic fields; Future research directions; Hazard monitoring; Machine learning methods; Modeling and forecasting; Research trends; Wide-ranging applications; Drought; disaster management; drought; drought stress; forecasting method; hazard assessment; health monitoring; machine learning; monitoring; natural disaster; policy making; spatial data; strategic approach; trend analysis"
"Pugliese R., Regondi S., Marini R.","Machine learning-based approach: Global trends, research directions, and regulatory standpoints","10.1016/j.dsm.2021.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127621188&doi=10.1016%2fj.dsm.2021.12.002&partnerID=40&md5=0a4b4562173b5ae73beaa3b5ae4be275","The field of machine learning (ML) is sufficiently young that it is still expanding at an accelerating pace, lying at the crossroads of computer science and statistics, and at the core of artificial intelligence (AI) and data science. Recent progress in ML has been driven both by the development of new learning algorithms theory, and by the ongoing explosion in the availability of vast amount of data (often referred to as “big data”) and low-cost computation. The adoption of ML-based approaches can be found throughout science, technology and industry, leading to more evidence-based decision-making across many walks of life, including healthcare, biomedicine, manufacturing, education, financial modeling, data governance, policing, and marketing. Although the past decade has witnessed the increasing interest in these fields, we are just beginning to tap the potential of these ML algorithms for studying systems that improve with experience. In this paper, we present a comprehensive view on geo worldwide trends (taking into account China, the USA, Israel, Italy, the UK, and the Middle East) of ML-based approaches highlighting rapid growth in the last 5 years attributable to the introduction of related national policies. Furthermore, based on the literature review, we also discuss the potential research directions in this field, summarizing some popular application areas of machine learning technology, such as healthcare, cyber-security systems, sustainable agriculture, data governance, and nanotechnology, suggesting that the “dissemination of research” in the ML scientific community has undergone the exceptional growth in the time range of 2018–2020, reaching a value of 16,339 publications. Finally, we report the challenges and the regulatory standpoints for managing ML technology. Overall, we hope that this work will help to explain the geo trends of ML approaches and their applicability in various real-world domains, as well as serve as a reference point for both academia and industry professionals, particularly from a technical, ethical and regulatory point of view. © 2021 Xi'an Jiaotong University","Artificial intelligence; Cybersecurity; Data governance; Healthcare; Machine learning; Nanotechnology; Research trends",
"Pullagura L., Kumari N.V., Bhuyan H.K., Ghantasala G.S.P.","Biomedical data analysis and processing using explainable artificial intelligence and responsive artificial intelligence",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141409033&partnerID=40&md5=5e9ea877f8596b52247f3c1782c3e1ef","Medicine and biomedical sciences ensure developed data-intensive arenas, at the same time, allowing the application of data-driven methods and necessitating refined data processing and data analysis methods. Biomedical informatics affords an appropriate interdisciplinary circumstance to assimilate information and data when dispensation accessible information, with the intention of generous operative decision-making maintenance in translational and clinic research. Potential applications in the biomedical field comprise the instinctive identification of entrant biomarkers on behalf of a disease or analytic of a treatment reaction, and the edifice of prognostic or diagnostic rules manipulating these biomarkers. These procedures being generic, they could be pragmatic to numerous causes of data and biomedical/biological requests. Nowadays, in medical applications, the growth of procedures for explaining, visualizing, and interpreting deep learning replicas has freshly appealed to cumulative attention. Interpretable Machine Learning (IML) or Explainable Machine Learning (XAI) programs are intended to generate a complement of machine learning procedures that yield additional explainable models while upholding a high level of accurateness. It moreover empowers users to comprehend, applicably trust, and effectively achieve the evolving cohort of artificially intelligent associates. The XAI befits more and more decisive for deep learning-powered applications, exclusively for healthcare and medical studies. A pace elsewhere XAI is Responsive AI (RAI), which symbolizes a set of moralities to have happened when arranging AI-based classifications in practical circumstances: Fairmindedness, Human-Centric, Explainability Accountability, Privacy Awareness, Security and Safety. Owed to the flora of amenities and the liability of an enormous segment of patrons, the theme of accountable AI is necessary to convert the focus of prevalent learning and conversation. The main idea underlying the concept of Biomedical Data Analysis and Processing is extracting knowledge from the very large amount of medical data which is available in the form of signals and images, with a very large amount of variables. © 2022 Nova Science Publishers, Inc.","Artificial intelligence; Biomedical informatics, explainable machine learning (XAI); Data analysis; Interpretable machine learning (IML)",
"Pulugurtha S.S., Mathew S.","Spatial Interpolation-Based Localized Growth Factors Compared to Statewide, Regional-Level, and County-Level Growth Factors for Local Roads","10.1061/JTEPBS.0000733","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134429346&doi=10.1061%2fJTEPBS.0000733&partnerID=40&md5=87dafd98ea877a5c66dc5303ce04e724","The focus of this paper is on developing localized growth factors for estimating annual average daily traffic (AADT) of a local, functionally classified road (referred to herein as a local road). Statewide, regional-level, and county-level median and mean growth factors were computed and compared with localized growth factor estimates from spatial interpolation methods, such as Ordinary Kriging, inverse distance weighted (IDW), and natural neighbor (NN) interpolation. The use of Ordinary Kriging-based localized growth factor is recommended for a local road AADT estimation. If count-based local road AADT (c-AADT) figures for previous years are available, they, along with localized growth factors for those years, should be used to estimate the local road AADT (e-AADT) for the reporting year. The estimated AADT (e-AADT) for the base year and localized growth factors from the base year to the reporting year must be used for estimating e-AADT of a non-covered local road link for the reporting year. The c-AADT or e-AADT of the local road link can be used to compute vehicle miles traveled (VMT) for reporting purposes. The proposed methodology reduces the costs and other resources required for traffic data collection and for e-AADT accounting for spatial variations. © 2022 American Society of Civil Engineers.","Annual average daily traffic (AADT); Growth factor; Inverse distance weighting; Kriging; Local road; Natural neighbor (NN) interpolation","Inverse problems; Roads and streets; Annual average daily traffic; Annual average daily traffics; County level; Growth factor; Inverse distance weighting; Kriging; Local road; Localized growth; Natural Neighbour interpolation; Regional levels; Kriging; data set; estimation method; growth; interpolation; kriging; road; spatial variation; traffic management; travel time"
"Pulunggono H.B., Hanifah N., Nadalia D., Zulfajrin M., Nurazizah L.L., Mubarok H., Tambusai N., Anwar S., Sabiham S.","Declined peat heterotrophic respiration as consequences from zeolite amendment simulation: coupling descriptive and predictive modelling approaches","10.15243/jdmlm.2022.101.3889","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140966711&doi=10.15243%2fjdmlm.2022.101.3889&partnerID=40&md5=9633355e0fc9b3b0d01c5dcca9cec514","Nowadays, halting greenhouse gasses (GHG) emission is the world's major concern to mitigate global climate change. In oil palm cultivated tropical peatland, GHG emission is primarily constituted of CO2 flux emitted from aerobic heterotrophic respiration (Rh), the natural degradation process of organic material in an oxidative environment. By coupling descriptive and predictive statistical approaches, this study attempted to gain an in-depth understanding of the effects of zeolite rates and incubation time on CO2 emission that came from aerobic Rh in peat, as well as their decomposition process. This study found that zeolite amelioration up to 30% of the peat at field capacity and starting from the first month of observation (month-1) significantly restricted peat Rh, denoted by a reduced amount of observed CO2 flux (0.021 and 0.019-0.012 mg m-2 sec-1, respectively). Both factors and several soil variables exhibited some non-linear relationships with Rh at different magnitudes and importance, showing the limitation of the traditional linear-based approach to interpreting their complex interrelationships, as well as predicting CO2 flux. This study highlights the vital role of a polynomial (GAM) and artificial intelligence (Cubist and GBM) -based pedotransfer models in improving our understanding regarding the dynamic of the peat decomposition process as affected by zeolite amendment. © 2022 The authors.","artificial intelligence; CO2 emission; machine learning; multivariate analysis; pedotransfer modelling",
"Pulunggono H.B., Fitriana S., Nadalia D., Zulfajrin M., Nurazizah L.L., Mubarok H., Tambusai N., Anwar S., Sabiham S.","Simulating and modeling CO2 flux emitted from decomposed oil palm root cultivated at tropical peatland as affected by water content and residence time","10.15243/jdmlm.2022.094.3663","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135457494&doi=10.15243%2fjdmlm.2022.094.3663&partnerID=40&md5=ec90ea9f6e6fc53dceeee6a9f33e3166","Determining the oil palm dead roots contribution to total (Rt) and heterotrophic (Rh) respiration as a source of greenhouse gas/GHG emission in tropical peatland is urgently required, as well as predicting their magnitude to cope with difficulties of direct in-situ measurement. This study is designed to simulate the CO2 flux emitted from oil palm dead roots/Rdr in tropical peatland as affected by water content/WC and residence time/RT. The dead oil palm roots were cleaned, treated with control/15, 100, 150, 300, and 450% WC, and then incubated for three months. CO2 flux measurement, C, N, and CN ratio determination were conducted every month. This study demonstrated the importance Rdr among other CO2 emission sources, ranging from 0.05-2.3 Mg CO2 ha-1 year-1 with an average of 0.7 Mg CO2 ha-1 year-1. Rdr contribution for literature Rt and Rh were around 0.3 to 1.3 and 0.9 to 3.5%, respectively. As a product of microbial respiration, Rdr was affected by WC and RT, supported by analysis of variance, linear mixed effect model/REML, and multivariate analysis. 100-150%WC resulting in significant and highest Rdr, whereas the increase (300-450%WC) or decrease (15%WC) would generate lower emission. Rdr culminated in the first month after incubation; meanwhile, it declined in the following months. This study also emphasized non-linear relationships between CO2 flux and other root properties, which can be modeled conveniently using non-linear approach, particularly using polynomial and artificial intelligence-based models. The simulation presented in this study served as an initial attempt to separate Rdr from Rh, as well as to predict CO2 flux with reasonable accuracy and interpretable methods. © Brawijaya University.All right reserved.","artificial intelligence; dead root; greenhouse gas; incubation time; respiration",
"Purcell W., Neubauer T., Mallinger K.","Digital Twins in agriculture: challenges and opportunities for environmental sustainability","10.1016/j.cosust.2022.101252","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146922050&doi=10.1016%2fj.cosust.2022.101252&partnerID=40&md5=d429e946cac21927f020ef01ba3d3063","Food security, land degradation, climate change, and a growing population are interconnected challenges and key issues for sustainable agriculture. In this context, the Digital Twin (DT) is uniquely positioned to overcome these challenges and support the goals of sustainability. Through the use of state-of-the-art technologies, increased information availability can empower stakeholders to pursue sustainable objectives and production methods. However, if these benefits are to be fully leveraged, the potential negative technical and social–ecological effects of the technology must be assessed and mitigated. Therefore, an exploratory review is conducted, outlining the progress of current examples toward the aims of sustainable agriculture. Additionally, the social–ecological and technological dangers of the concept are investigated, culminating in a high-level roadmap that highlights necessary milestones required to support the open and sustainable development of DTs in agriculture. © 2023 The Author(s)",,"alternative agriculture; climate change; food security; sustainability; sustainable development"
"Qamar F., Siddiqui M.U.A., Hindia M.H.D.N., Hassan R., Nguyen Q.N.","Issues, challenges, and research trends in spectrum management: A comprehensive overview and new vision for designing 6g networks","10.3390/electronics9091416","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093816012&doi=10.3390%2felectronics9091416&partnerID=40&md5=eacfd60b499ba1eae08f0257255a4efc","With an extensive growth in user demand for high throughput, large capacity, and low latency, the ongoing deployment of Fifth-Generation (5G) systems is continuously exposing the inherent limitations of the system, as compared with its original premises. Such limitations are encouraging researchers worldwide to focus on next-generation 6G wireless systems, which are expected to address the constraints. To meet the above demands, future radio network architecture should be effectively designed to utilize its maximum radio spectrum capacity. It must simultaneously utilize various new techniques and technologies, such as Carrier Aggregation (CA), Cognitive Radio (CR), and small cell-based Heterogeneous Networks (HetNet), high-spectrum access (mmWave), and Massive Multiple-Input-Multiple-Output (M-MIMO), to achieve the desired results. However, the concurrent operations of these techniques in current 5G cellular networks create several spectrum management issues; thus, a comprehensive overview of these emerging technologies is presented in detail in this study. Then, the problems involved in the concurrent operations of various technologies for the spectrum management of the current 5G network are highlighted. The study aims to provide a detailed review of cooperative communication among all the techniques and potential problems associated with the spectrum management that has been addressed with the possible solutions proposed by the latest researches. Future research challenges are also discussed to highlight the necessary steps that can help achieve the desired objectives for designing 6G wireless networks. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","5G; 6G; Carrier Aggregation (CA); Cognitive Radio (CR); High-spectrum access; M-MIMO; MmWave; Small cell; Spectrum management",
"Qi C., Gao J., Chen K., Shu L., Pearson S.","Tea Chrysanthemum Detection by Leveraging Generative Adversarial Networks and Edge Computing","10.3389/fpls.2022.850606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128662095&doi=10.3389%2ffpls.2022.850606&partnerID=40&md5=c1125ed7b315789b9125bf1fed2edd49","A high resolution dataset is one of the prerequisites for tea chrysanthemum detection with deep learning algorithms. This is crucial for further developing a selective chrysanthemum harvesting robot. However, generating high resolution datasets of the tea chrysanthemum with complex unstructured environments is a challenge. In this context, we propose a novel tea chrysanthemum – generative adversarial network (TC-GAN) that attempts to deal with this challenge. First, we designed a non-linear mapping network for untangling the features of the underlying code. Then, a customized regularization method was used to provide fine-grained control over the image details. Finally, a gradient diversion design with multi-scale feature extraction capability was adopted to optimize the training process. The proposed TC-GAN was compared with 12 state-of-the-art generative adversarial networks, showing that an optimal average precision (AP) of 90.09% was achieved with the generated images (512 × 512) on the developed TC-YOLO object detection model under the NVIDIA Tesla P100 GPU environment. Moreover, the detection model was deployed into the embedded NVIDIA Jetson TX2 platform with 0.1 s inference time, and this edge computing device could be further developed into a perception system for selective chrysanthemum picking robots in the future. Copyright © 2022 Qi, Gao, Chen, Shu and Pearson.","deep learning; edge computing; generative adversarial network; NVIDIA Jetson TX2; tea chrysanthemum",
"Qian P., Unhelkar V.","Evaluating the Role of Interactivity on Improving Transparency in Autonomous Agents",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134321454&partnerID=40&md5=0663b43de829093145a69430de431914","Autonomous agents are increasingly being deployed amongst human end-users. Yet, human users often have little knowledge of how these agents work or what they will do next. This lack of transparency has already resulted in unintended consequences during AI use: a concerning trend which is projected to increase with the proliferation of autonomous agents. To curb this trend and ensure safe use of AI, assisting users in establishing an accurate understanding of agents that they work with is essential. In this work, we present AI Teacher, a user-centered Explainable AI framework to address this need for autonomous agents that follow a Markovian policy. Our framework first computes salient instructions of agent behavior by estimating a user's mental model and utilizing algorithms for sequential decision-making. Next, in contrast to existing solutions, these instructions are presented interactively to the end-users, thereby enabling a personalized approach to improving AI transparency. We evaluate our framework, with emphasis on its interactive features, through experiments with human participants. The experiment results suggest that, relative to non-interactive approaches, interactive teaching can both reduce the amount of time it takes for humans to create accurate mental models of these agents and is subjectively preferred by human users. © 2022 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved","Explainable AI; Human-AI Collaboration; Machine Teaching; Monte-Carlo Tree Search; Shared Mental Models","Autonomous agents; Behavioral research; Cognitive systems; Decision making; Multi agent systems; End-users; Explainable AI; Human users; Human-AI collaboration; Interactivity; Mental model; Monte-carlo tree search; Shared mental model; Tree-search; Unintended consequences; Transparency"
"Qian X., Zhang C., Chen L., Li K.","Deep Learning-Based Identification of Maize Leaf Diseases Is Improved by an Attention Mechanism: Self-Attention","10.3389/fpls.2022.864486","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130139441&doi=10.3389%2ffpls.2022.864486&partnerID=40&md5=3e9a7611edd393b26492d6537a3c0ed6","Maize leaf diseases significantly reduce maize yield; therefore, monitoring and identifying the diseases during the growing season are crucial. Some of the current studies are based on images with simple backgrounds, and the realistic field settings are full of background noise, making this task challenging. We collected low-cost red, green, and blue (RGB) images from our experimental fields and public dataset, and they contain a total of four categories, namely, southern corn leaf blight (SCLB), gray leaf spot (GLS), southern corn rust (SR), and healthy (H). This article proposes a model different from convolutional neural networks (CNNs) based on transformer and self-attention. It represents visual information of local regions of images by tokens, calculates the correlation (called attention) of information between local regions with an attention mechanism, and finally integrates global information to make the classification. The results show that our model achieves the best performance compared to five mainstream CNNs at a meager computational cost, and the attention mechanism plays an extremely important role. The disease lesions information was effectively emphasized, and the background noise was suppressed. The proposed model is more suitable for fine-grained maize leaf disease identification in a complex background, and we demonstrated this idea from three perspectives, namely, theoretical, experimental, and visualization. Copyright © 2022 Qian, Zhang, Chen and Li.","attention mechanism; crop disease; deep learning; machine learning; neural network",
"Qin X., Zhou S., Li H., Wang G., Chen C., Liu C., Wang X., Huo J., Lin Y., Chen J., Fu Q., Duan Y., Huang K., Deng C.","Enhanced natural releases of mercury in response to the reduction in anthropogenic emissions during the COVID-19 lockdown by explainable machine learning","10.5194/acp-22-15851-2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145566246&doi=10.5194%2facp-22-15851-2022&partnerID=40&md5=03a47b14bb42ed84c3a831bf2f0a9813","The wide spread of the coronavirus (COVID-19) has significantly impacted the global human activities. Compared to numerous studies on conventional air pollutants, atmospheric mercury that has matched sources from both anthropogenic and natural emissions is rarely investigated. At a regional site in eastern China, an intensive measurement was performed, showing obvious decreases in gaseous elemental mercury (GEM) during the COVID-19 lockdown, while it was not as significant as most of the other measured air pollutants. Before the lockdown, when anthropogenic emissions dominated, GEM showed no correlation with temperature and negative correlations with wind speed and the height of the boundary layer. In contrast, GEM showed significant correlation with temperature, while the relationship between GEM and the wind speed/boundary layer disappeared during the lockdown, suggesting the enhanced natural emissions of mercury. By applying a machine learning model and the SHAP (SHapley Additive exPlanations) approach, it was found that the mercury pollution episodes before the lockdown were driven by anthropogenic sources, while they were mainly driven by natural sources during and after the lockdown. Source apportionment results showed that the absolute contribution of natural surface emissions to GEM unexpectedly increased (44%) during the lockdown. Throughout the whole study period, a significant negative correlation was observed between the absolute contribution of natural and anthropogenic sources to GEM. We conclude that the natural release of mercury could be stimulated to compensate for the significantly reduced anthropogenic GEM via the surface-air exchange in the balance of mercury. © 2022 Copernicus GmbH. All rights reserved.",,"anthropogenic source; atmospheric pollution; COVID-19; emission control; machine learning; mercury (element); China"
"Qiu T., Underhill A., Sapkota S., Cadle-Davidson L., Jiang Y.","High throughput saliency-based quantification of grape powdery mildew at the microscopic level for disease resistance breeding","10.1093/hr/uhac187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145196000&doi=10.1093%2fhr%2fuhac187&partnerID=40&md5=02e6b7e5a12e40cfff55486a5c5026b1","Imaging-based high throughput phenotyping (HTP) systems have demonstrated promising solutions to enhance genetic understanding of grapevine powdery mildew (PM) resistance and have accelerated PM-resistant cultivar breeding. The accuracy and throughput of extracting phenotypic traits from images are still the bottleneck of modern HTP systems, especially at the microscopic level. The goal of this study was to develop a saliency-based processing pipeline for the quantification of PM infection in microscopic images and comprehensively evaluate its performance for genetic analyses. An input image was segregated into subimages that were classified as infected or healthy by a pretrained CNN classifier. Saliency maps from the classification were generated post-hoc and used for the quantification of PM infection in the input image at the pixel level without the use of mask annotations. A total of seven phenotypic traits were extracted from images collected for a biparental population. Experimental results showed that optimal combinations of convolutional neural network and saliency methods achieved strong measurement correlations (r = 0.74 to 0.75) with human assessments at the image patch level, and the traits calculated by the saliency-based processing pipeline were highly correlated (r = 0.87 to 0.88) with reference PM infection ratings at the leaf image level. The high quantification accuracy of the saliency-based pipeline led to the increased explanation of phenotypic variance and reliable identification of quantitative trait loci. Therefore, the saliency-based processing pipeline can be used as an effective and efficient analysis tool for PM disease research and breeding programs in the future, especially agricultural and life science studies requiring microscopic image analysis. © 2022 The Author(s). Published by Oxford University Press on behalf of Nanjing Agricultural University.",,
"Qiu T., Underhill A., Sapkota S., Cadle-Davidson L., Jiang Y.","Deep learning-based saliency maps for the quantification of grape powdery mildew at the microscopic level","10.13031/aim.202100496","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114199172&doi=10.13031%2faim.202100496&partnerID=40&md5=946d14ca9aa1f5fc5b955f48ea71b935","Powdery mildew (PM) is one of the most widespread plant diseases and can damage a wide range of crops, causing significant economic losses annually. This urges the breeding of PM resistant crop cultivars and the development of management practices. A major bottleneck is the accuracy and efficiency of image analysis at the microscopic level, which is essential to understand PM infection and accelerate crop breeding and management practice development. The overall goal of this study was to develop a deep learning-based saliency map approach that can quantify PM infection in images of high spatial resolution. A subset of a total of 2690 images of 1-cm leaf disks was randomly selected to extract a total of 21,162 image patches of 224×224 pixels. A custom thresholding method was used to mask out irrelevant background information from a leaf disk image. The remaining image part was cropped into image patches of 224×224 pixels to be classified by pretrained CNN classifiers. For the patches predicted as infected, patch saliency maps were generated using several saliency methods. All patch saliency maps were re-assembled to construct a leaf-level infection map for the quantification of PM infection in leaf disk images. Experimental results showed that with a well-trained CNN classifier (validation accuracy of 95.66%), our approach achieved remarkable accuracy of the localization and quantification of PM hyphae by using only patch-level class annotations, suggesting a great potential of reducing annotation cost for deep learning-based quantification. Compared with the manual assessment, our approach also improved the processing speed by 20 to 60 times. Therefore, the developed approach can be an effective and efficient analysis tool for PM disease research in the future. © ASABE 2021 Annual International Meeting","Disease quantification; Explainable AI; Grape powdery mildew; High-throughput phenotyping","Crops; Fungi; Image segmentation; Losses; Pixels; Background information; Disease research; Efficient analysis; Grape powdery mildew; High spatial resolution; Management practices; Microscopic levels; Thresholding methods; Deep learning"
"Qiu Y., Wu Y., Li L., Chen S., Zhao Y., Li C., Xiang H., Wang D., Wei Y., Wang Y.","Elucidating the mechanism underlying volatile and non-volatile compound development related to microbial amino acid metabolism during golden pomfret (Trachinotus ovatus) fermentation","10.1016/j.foodres.2022.112095","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141749997&doi=10.1016%2fj.foodres.2022.112095&partnerID=40&md5=01e842186d57c5afbda408de4f7eccb4","Golden pomfret (Trachinotus ovatus) is an important farmed fish in Asia, often consumed following salting and natural microbial fermentation. Flavor development in fermented foods depends on the metabolism of fermenting microbes, especially amino acid metabolism. However, the microbes involved in golden pomfret fermentation and the mechanism by which they regulate flavor development are largely unknown. Accordingly, in this study, we investigated the microbial community and volatile and non-volatile compounds during the traditional fermentation of golden pomfret, focusing on amino acid metabolism. Thirty-five volatile compounds were detected. Glutamate, alanine, and leucine were the main amino acids responsible for the development of the characteristic taste of fermented golden pomfret. Metagenomic analyses were performed, and microbial genes for amino acid metabolism were functionally annotated, revealing the underlying mechanisms of flavor development during fish fermentation. Halobacterium, Clostridium, Natrinema, Alkalibacillus, Natrialba, and Vibrio were the dominant microbial genera with a major contribution to amino acid metabolism during fermentation and were strongly correlated with the majority of volatile compounds. The study provides a theoretical reference for the mechanism of flavor formation and important information on the microbial sources of volatile compounds derived from amino acids. © 2022 Elsevier Ltd","Amino acid metabolism; Fermented fish; Flavor formation; Golden pomfret; Metagenomics; Microorganism; Taste","Amino acids; Bacteria; Fish; Flavor compounds; Metabolism; Volatile organic compounds; Amino acid metabolism; Amino-acids; Fermented fishes; Flavor development; Flavor formation; Golden pomfret; Metagenomics; Non-volatile compounds; Taste; Volatile compounds; Fermentation; amino acid; glutamic acid; animal; fermentation; fish; sea food; Amino Acids; Animals; Fermentation; Fishes; Glutamic Acid; Seafood"
"Ragu N., Teo J.","Object detection and classification using few-shot learning in smart agriculture: A scoping mini review","10.3389/fsufs.2022.1039299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147225201&doi=10.3389%2ffsufs.2022.1039299&partnerID=40&md5=655ab6d2978b346f4c6ab30c0415e20f","Smart agriculture is the application of modern information and communication technologies (ICT) to agriculture, leading to what we might call a third green revolution. These include object detection and classification such as plants, leaves, weeds, fruits as well as animals and pests in the agricultural domain. Object detection, one of the most fundamental and difficult issues in computer vision has attracted a lot of attention lately. Its evolution over the previous two decades can be seen as the pinnacle of computer vision advancement. The detection of objects can be done via digital image processing. Machine learning has achieved significant advances in the field of digital image processing in current years, significantly outperforming previous techniques. One of the techniques that is popular is Few-Shot Learning (FSL). FSL is a type of meta-learning in which a learner is given practice on several related tasks during the meta-training phase to be able to generalize successfully to new but related activities with a limited number of instances during the meta-testing phase. Here, the application of FSL in smart agriculture, with particular in the detection and classification is reported. The aim is to review the state of the art of currently available FSL models, networks, classifications, and offer some insights into possible future avenues of research. It is found that FSL shows a higher accuracy of 99.48% in vegetable disease recognition on a limited dataset. It is also shown that FSL is reliable to use with very few instances and less training time. Copyright © 2023 Ragu and Teo.","computer vision; digital image processing; few-shot learning; machine learning; object detection; smart agriculture",
"Rahmani A.M., Yousefpoor E., Yousefpoor M.S., Mehmood Z., Haider A., Hosseinzadeh M., Ali Naqvi R.","Machine learning (Ml) in medicine: Review, applications, and challenges","10.3390/math9222970","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119902780&doi=10.3390%2fmath9222970&partnerID=40&md5=9bf3faa87a0466bf02804dbc18f907e5","Today, artificial intelligence (AI) and machine learning (ML) have dramatically advanced in various industries, especially medicine. AI describes computational programs that mimic and simulate human intelligence, for example, a person’s behavior in solving problems or his ability for learning. Furthermore, ML is a subset of artificial intelligence. It extracts patterns from raw data automatically. The purpose of this paper is to help researchers gain a proper understanding of machine learning and its applications in healthcare. In this paper, we first present a classification of machine learning-based schemes in healthcare. According to our proposed taxonomy, machine learning-based schemes in healthcare are categorized based on data pre-processing methods (data cleaning methods, data reduction methods), learning methods (unsupervised learning, supervised learning, semi-supervised learning, and reinforcement learning), evaluation methods (simulation-based evaluation and practical implementation-based evaluation in real environment) and applications (diagnosis, treatment). According to our proposed classification, we review some studies presented in machine learning applications for healthcare. We believe that this review paper helps researchers to familiarize themselves with the newest research on ML applications in medicine, recognize their challenges and limitations in this area, and identify future research directions. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence (AI); Diagnosis; Machine learning (ML); Medicine; Treatment",
"Rajulapati L., Chinta S., Shyamala B., Rengaswamy R.","Integration of machine learning and first principles models","10.1002/aic.17715","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128741374&doi=10.1002%2faic.17715&partnerID=40&md5=60a332eff1ed675992eb81b15fb7be30","Model building and parameter estimation are traditional concepts widely used in chemical, biological, metallurgical, and manufacturing industries. Early modeling methodologies focused on mathematically capturing the process knowledge and domain expertise of the modeler. The models thus developed are termed first principles models (or white-box models). Over time, computational power became cheaper, and massive amounts of data became available for modeling. This led to the development of cutting edge machine learning models (black-box models) and artificial intelligence (AI) techniques. Hybrid models (gray-box models) are a combination of first principles and machine learning models. The development of hybrid models has captured the attention of researchers as this combines the best of both modeling paradigms. Recent attention to this field stems from the interest in explainable AI (XAI), a critical requirement as AI systems become more pervasive. This work aims at identifying and categorizing various hybrid models available in the literature that integrate machine-learning models with different forms of domain knowledge. Benefits such as enhanced predictive power, extrapolation capabilities, and other advantages of combining the two approaches are summarized. The goal of this article is to consolidate the published corpus in the area of hybrid modeling and develop a comprehensive framework to understand the various techniques presented. This framework can further be used as the foundation to explore rational associations between several models. © 2022 American Institute of Chemical Engineers.","data driven models; first principles models; hybrid models; physics inspired models","Machine learning; Data-driven model; First-principles modeling; Hybrid model; Machine learning models; Manufacturing industries; Metallurgical industry; Modeling methodology; Parameters estimation; Physic inspired model; Process knowledge; Domain Knowledge"
"Ramírez-Delgado J.P., Di Marco M., Watson J.E.M., Johnson C.J., Rondinini C., Corredor Llano X., Arias M., Venter O.","Matrix condition mediates the effects of habitat fragmentation on species extinction risk","10.1038/s41467-022-28270-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123973342&doi=10.1038%2fs41467-022-28270-3&partnerID=40&md5=2bbf0144877a046e08e286b0390426c5","Habitat loss is the leading cause of the global decline in biodiversity, but the influence of human pressure within the matrix surrounding habitat fragments remains poorly understood. Here, we measure the relationship between fragmentation (the degree of fragmentation and the degree of patch isolation), matrix condition (measured as the extent of high human footprint levels), and the change in extinction risk of 4,426 terrestrial mammals. We find that the degree of fragmentation is strongly associated with changes in extinction risk, with higher predictive importance than life-history traits and human pressure variables. Importantly, we discover that fragmentation and the matrix condition are stronger predictors of risk than habitat loss and habitat amount. Moreover, the importance of fragmentation increases with an increasing deterioration of the matrix condition. These findings suggest that restoration of the habitat matrix may be an important conservation action for mitigating the negative effects of fragmentation on biodiversity. © 2022, The Author(s).",,"anthropogenic effect; biodiversity; conservation status; extinction risk; habitat fragmentation; habitat loss; mammal; matrix; terrestrial ecosystem; article; biodiversity; deterioration; habitat fragmentation; human; life history trait; mammal; nonhuman; species extinction; animal; ecosystem; Animals; Biodiversity; Ecosystem; Extinction, Biological; Humans; Mammals"
"Ramírez-Mejía D., Levers C., Mas J.-F.","Spatial patterns and determinants of avocado frontier dynamics in Mexico","10.1007/s10113-022-01883-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125664846&doi=10.1007%2fs10113-022-01883-6&partnerID=40&md5=307c6434dfeb1cd466b798049496099d","The surging demand for commodity crops has led to rapid and severe agricultural frontier expansion globally and has put producing regions increasingly under pressure. However, knowledge about spatial patterns of agricultural frontier dynamics, their leading spatial determinants, and socio-ecological trade-offs is often lacking, hindering contextualized decision making towards more sustainable food systems. Here, we used inventory data to map frontier dynamics of avocado production, a cash crop of increasing importance in global diets, for Michoacán, Mexico, before and after the implementation of the North American Free Trade Agreement (NAFTA). We compiled a set of environmental, accessibility and social variables and identified the leading determinants of avocado frontier expansion and their interactions using extreme gradient boosting. We predicted potential expansion patterns and assessed their impacts on areas important for biodiversity conservation. Avocado frontiers expanded more than tenfold from 12,909 ha (1974) to 152,493 ha (2011), particularly after NAFTA. Annual precipitation, distance to settlements, and land tenure were key factors explaining avocado expansion. Under favorable climatic and accessibility conditions, most avocado expansion occurred on private lands. Contrary, under suboptimal conditions, most avocado expansion occurred on communal lands. Large areas suitable for further avocado expansion overlapped with priority sites for restoration, highlighting an imminent conflict between conservation and economic revenues. This is the first analysis of avocado frontier dynamics and their spatial determinants across a major production region and our results provide entry points to implement government-based strategies to support small-scale farmers, mostly those on communal lands, while trying to minimize the socio-environmental impacts of avocado production. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Agricultural expansion; Commodity frontiers; Extreme gradient boosting; Globalization; NAFTA",
"Ramuš Cvetkovič I., Drobnjak M.","As Above so Below: The Use of International Space Law as an Inspiration for Terrestrial AI Regulation to Maximize Harm Prevention","10.1007/978-3-031-19149-7_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147439927&doi=10.1007%2f978-3-031-19149-7_9&partnerID=40&md5=dfb68499ce0c6ba618c4c9ba26d1f73f","Artificial intelligence (AI) is becoming an integral part of technologies aimed at preventing harm, both on Earth and in outer space. However, there exists no comprehensive legal framework governing the use of AI, as international law is yet to regulate this emerging field. The majority of the currently existing standards for AI regulation were adopted as soft-law or ethical guidelines, adopted by various different subjects and therefore varying in content and format. This chapter will argue that in the process of transforming such non-binding guidelines into a binding coherent international legal framework for AI, certain space law provisions, in particular, those found in the fundamental Outer Space Treaty and the subsequent Liability Convention, could serve as an inspiration, in order to ensure that the international framework for AI will be aimed at preventing harm to the greatest extent possible. It will accomplish this by first illustrating the current uses of AI solutions in preventing harm on Earth and in outer space (which correspond to the term narrow AI), as well as some examples of technology under development, which is planned to reach greater or even complete autonomy (strong AI). Secondly, it will provide an extraction of some basic soft-law and ethical principles, that are most often found in the regulations governing the use of AI on Earth, before proceeding to relevant space law principles which are guiding the use of AI in outer space. Lastly, it will compare the two categories—the existing general guidelines and corresponding space law provisions, to examine how the latter could serve as a good example in the process of concretizing the existing general principles while translating them into a comprehensive binding legal framework on Earth aimed at preventing harm and maximizing social benefits, in line with what the authors named the “as above so below” approach. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Artificial intelligence; Environmental harm; Harm prevention; Outer space; Space law",
"Rana N.P., Chatterjee S., Dwivedi Y.K., Akter S.","Understanding dark side of artificial intelligence (AI) integrated business analytics: assessing firm’s operational inefficiency and competitiveness","10.1080/0960085X.2021.1955628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111903831&doi=10.1080%2f0960085X.2021.1955628&partnerID=40&md5=ff9548541ea4d6f9fb7da5f1d37f3957","The data-centric revolution generally celebrates the proliferation of business analytics and AI in exploiting firm’s potential and success. However, there is a lack of research on how the unintended consequences of AI integrated business analytics (AI-BA) influence a firm’s overall competitive advantage. In this backdrop, this study aims to identify how factors, such as AI-BA opacity, suboptimal business decisions and perceived risk are responsible for a firm’s operational inefficiency and competitive disadvantage. Drawing on the resource-based view, dynamic capability view, and contingency theory, the proposed research model captures the components and effects of an AI-BA opacity on a firm’s risk environment and negative performance. The data were gathered from 355 operational, mid-level and senior managers from various service sectors across all different size organisations in India. The results indicated that lack of governance, poor data quality, and inefficient training of key employees led to an AI-BA opacity. It then triggers suboptimal business decisions and higher perceived risk resulting in operational inefficiency. The findings show that operational inefficiency significantly contributes to negative sales growth and employees’ dissatisfaction, which result in a competitive disadvantage for a firm. The findings also highlight the significant moderating effect of contingency plan in the nomological chain. © Operational Research Society 2021.","Artificial intelligence; business analytics; firm dis-performance; firm’s competitiveness; operational inefficiency; Patrick Mikalef, Aleš Popovic, Jenny Eriksson Lundström and Kieran Conboy","Advanced Analytics; Competition; Opacity; Personnel training; Sales; Service industry; Business analytics; Business decisions; Competitive advantage; Contingency theory; Dynamic capabilities; Integrated business; Resource-based view; Unintended consequences; Artificial intelligence"
"Rana P., Varshney L.R.","Exploring limits to tree planting as a natural climate solution","10.1016/j.jclepro.2022.135566","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144055709&doi=10.1016%2fj.jclepro.2022.135566&partnerID=40&md5=b0e77b3421617d45df1c815413a095f9","Large-scale tree planting has been advocated for decades in many countries as a cost-effective strategy to mitigate carbon, rejuvenate degraded landscapes, and support local livelihoods. Recent studies, however, suggest limited ecological and livelihood impacts of tree planting programs, indicating possible limits to tree planting as a natural climate solution. In this paper, we explore these carrying capacity-like limits by evaluating the site suitability of forestry landscapes of the northern Indian state of Himachal Pradesh using theory/expert-based rules and machine learning algorithms. We find that the state can only achieve a maximum of 31.54% forest cover due to socio-ecological and biophysical constraints, much less than India's goal of bringing 66% of the total geographical area of Himalayan states into forest cover. The low availability of suitable lands for growing trees, together with poor plantation site selection by forest range officers limit the use of tree planting as a sole climate mitigation strategy. To approach theoretical planting limits, we propose an ePSA (e-Plantation Site Assistant) recommendation system based on our site-suitability results to assist forest rangers in selecting suitable sites for planting trees. An initial deployment of the recommender system suggests its potential utility in shaping the long-term success of tree plantations as an effective carbon strategy in northern India and beyond. Overall, we argue that there is a need to realign over-ambitious national and international tree planting targets with actual limits from site characteristics to avoid massive wastage of funds and to obtain feasible carbon mitigation outcomes. © 2022 Elsevier Ltd","Forestry science; Machine learning; Natural climate solutions; Plantation site recommendation; Tree planting","Cost effectiveness; Ecology; Learning algorithms; Machine learning; Recommender systems; Reforestation; Site selection; Timber; Cost effective strategies; Forest cover; Forestry science; Large-scales; Machine-learning; Natural climate solution; Plantation site recommendation; Plantings; Rule learning algorithms; Tree plantings; Carbon"
"Ranasinghe N., Ramanan A., Fernando S., Hameed P.N., Herath D., Malepathirana T., Suganthan P., Niranjan M., Halgamuge S.","Interpretability and accessibility of machine learning in selected food processing, agriculture and health applications","10.4038/jnsfsr.v50i0.11249","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142728547&doi=10.4038%2fjnsfsr.v50i0.11249&partnerID=40&md5=ec1eab76ad7c9ab8f6a518935776e096","Artificial Intelligence (Al) and its data-centric branch of machine learning (ML) have greatly evolved over the last few decades. However, as Al is used increasingly in real world use cases, the importance of the interpretability of and accessibility to Al systems have become major research areas. The lack of interpretability of ML based systems is a major hindrance to widespread adoption of these powerful algorithms. This is due to many reasons including ethical and regulatory concerns, which have resulted in poorer adoption of ML in some areas. The recent past has seen a surge in research on interpretable ML. Generally, designing a ML system requires good domain understanding combined with expert knowledge. New techniques are emerging to improve ML accessibility through automated model design. This paper provides a review of the work done to improve interpretability and accessibility of machine learning in the context of global problems while also being relevant to developing countries. We review work under multiple levels of interpretability including scientific and mathematical interpretation, statistical interpretation and partial semantic interpretation. This review includes applications in three areas, namely food processing, agriculture and health. © 2022, National Science Foundation. All rights reserved.","Disease detection in agriculture; drug repositioning; food processing; interpretation of neural networks; metagenomics",
"Rani S., Al-Zaqri N., Iqbal J., Akram S.J., Boshaala A., Mehmood R.F., Saeed M.U., Rashid E.U., Khera R.A.","Designing dibenzosilole core based, A2-π-A1-π-D-π-A1-π-A2 type donor molecules for promising photovoltaic parameters in organic photovoltaic cells","10.1039/d2ra05934g","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141899793&doi=10.1039%2fd2ra05934g&partnerID=40&md5=23836358d0c70e79ccdeab08633e5782","In this research work, four new molecules from the π-A-π-D-π-A-π type reference molecule “DBS-2PP”, were designed for their potential application in organic solar cells by adding peripheral A2 acceptors to the reference. Under density functional theory, a comprehensive theoretical investigation was conducted to examine the structural geometries, along with the optical and photovoltaic parameters; comprising frontier molecular orbitals, density of states, light-harvesting effectiveness, excitation, binding, and reorganizational energies, molar absorption coefficient, dipole moment, as well as transition density matrix of all the molecules under study. In addition, some photo-voltaic characteristics (open circuit photo-voltage and fill factor) were also studied for these molecules. Although all the developed compounds (D1-D4) surpassed the reference molecule in the attributes mentioned above, D4 proved to be the best. D4 possessed the narrowest band-gap, as well as the highest absorption maxima and dipole moment of all the molecules in both the evaluated phases. Moreover, with PC61BM as the acceptor, D4 showed the maximum VOC and FF values. Furthermore, while D3 had the greatest hole mobility owing to its lowest value of hole reorganization energy, D4 exhibited the maximum electron mobility due to its lowermost value of electron reorganization energy. Overall, all the chromophores proposed in this study showed outstanding structural, optical, and photovoltaic features. Considering this, organic solar cell fabrication can be improved by using these newly derived donors at the donor-acceptor interfaces. © 2022 The Royal Society of Chemistry.",,"Chromophores; Density functional theory; Dipole moment; Energy gap; Hole mobility; Molecular orbitals; Organic solar cells; Photoelectrochemical cells; Density-functional-theory; Donor molecules; Optical parameter; Organic photovoltaic cell (OPVs); Photovoltaic parameters; Photovoltaics; Reorganization energies; Structural geometry; Theoretical investigations; π-type; Molecules"
"Raouf I., Lee H., Noh Y.R., Youn B.D., Kim H.S.","Prognostic health management of the robotic strain wave gear reducer based on variable speed of operation: A data-driven via deep learning approach","10.1093/jcde/qwac091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144648871&doi=10.1093%2fjcde%2fqwac091&partnerID=40&md5=884ed374d0322a7005673d96ddabcdfc","The robotic reducer is prone to failure because of its unique characteristics. Data from vibration and acoustic emission sensors have been used for the prognostics of the reducer. However, various issues are associated with such traditional techniques. Hence, our research group proposes a novel approach to utilize the embedded setup of the electrical current to detect the mechanical fault of the robotic reducer in the actual industrial robot. Previously, a comprehensive approach of feature engineering was proposed to classify the mechanical fault for the robotic reducer. However, handcraft-based feature extraction is quite a tedious task, and computationally expensive. These features require a well-designed feature extractor, and the features need to be manually optimized before feeding into classifiers. In addition, the handcrafted features are problem-specific, and are complicated to generalize. To resolve these challenges, deep features are extracted to classify the fault and generalize for two different motion profiles under different working conditions. In the proposed research work, the fault characteristic is generalized for variable speed of operations considering various kinds of scenarios. In this research work, the generalization capability of the proposed approach is comprehensively evaluated. For that purpose, the data under different working conditions such as of lower speeds, higher speeds, and speed sequestration are used as unseen data to validate the model. The authenticity of the presented approach can be supported by the performance evaluation for fault classification of the different motion profiles and speed of operations. © 2022 The Author(s). Published by Oxford University Press on behalf of the Society for Computational Design and Engineering.","deep feature extraction; domain-based analysis; prognostic health management; strain wave gear reducer; variable speed-based fault detection","Acoustic emission testing; Classification (of information); Deep learning; Extraction; Fault detection; Industrial research; Robotics; Deep feature extraction; Domain-based analyse; Faults detection; Features extraction; Gear reducers; Prognostic health managements; Strain wave gear reducer; Strain waves; Variable speed; Variable speed-based fault detection; Feature extraction; computer simulation; design; detection method; robotics; sensor; vibration; working conditions"
"Rath A., Kannapiran E., Almahirah M.S., Bora A., Chowdhury S.","Artificial Intelligence Empowered Internet of Things for Smart City Management","10.1007/978-3-031-07012-9_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131939452&doi=10.1007%2f978-3-031-07012-9_18&partnerID=40&md5=dce3fd857f1df79577fcabf09a2223bc","The Research on the Internet of Things (IoT) has paved the way for a revolution in community services. It was found that the application of IoT in a smart city is mainly carried out without major human intervention. The different uses of IoT devices allow interfaces to available systems, improve communication and perform a variety of tasks. In addition, the availability of multiple IoT devices has been shown to be compatible to protect integrity, collect and analyze information, and improve functionality. The study is focused in understanding the critical role Artificial Intelligence empowered Internet of Things (IoT) for creating Smart city. The researchers have used extensive data analysis by collecting the data from the respondents to understand the importance of AI empowered IoT in creating better smart city. The analysis is focused in using regression tools and other key data analysis to test the hypothesis. Based on the overall analysis it is concluded that enhanced security and privacy; implementing smart sensors; implementation of Intelligent analytics and better collaboration and Networking has supported the organization and other stakeholders in creating better smart city. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Artificial Intelligence; Chi square test analysis; Internet of Things; Regression analysis; Smart city management","Artificial intelligence; Data handling; Information analysis; Regression analysis; Smart city; Statistical tests; Chi square test analyse; Chi-square tests; City management; Community services; Human intervention; Security and privacy; Smart city management; Test analysis; Internet of things"
"Rathi V.K., Rajput N.K., Mishra S., Grover B.A., Tiwari P., Jaiswal A.K., Hossain M.S.","An edge AI-enabled IoT healthcare monitoring system for smart cities","10.1016/j.compeleceng.2021.107524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116919952&doi=10.1016%2fj.compeleceng.2021.107524&partnerID=40&md5=c594cc09c8ed65cc74bb1542e7984de6","Healthcare systems have significantly benefited from Artificial Intelligence (AI) and the Internet of Things (IoT). The vital signs of patients can be continuously monitored using the technologies mentioned above, and timely treatment can be provided. To this end, this paper proposes a scalable, responsive, and reliable AI-enabled IoT and edge computing-based healthcare solution with low latency when serving patients. The system comprises the collection of health-related data, data processing and analysis at edge nodes, and permanent storage and sharing at edge data centers. The edge nodes and edge controller schedule patients and provide resources in real time. Simulations were conducted to test system performance. The results for end-to-end time, computing, optimization, and transmission latency prove to be very promising. To determine system performance in a real-world scenario, a neural network was used to model transmission latency. The system is extremely useful for those who are disabled or elderly, as well as in pandemic situations. © 2021 Elsevier Ltd","AI-enabled IoT; IoT edge; Multi-access edge computing; Smart city; Smart healthcare","Data handling; Digital storage; Edge computing; Internet of things; Patient treatment; Artificial intelligence-enabled internet of thing; Edge computing; Edge nodes; Healthcare monitoring; Internet of thing edge; Monitoring system; Multi-access edge computing; Multiaccess; Smart healthcare; Systems performance; Smart city"
"Ravi M., Negi A., Chitnis S.","A Comparative Review of Expert Systems, Recommender Systems, and Explainable AI","10.1109/I2CT54291.2022.9824265","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135624204&doi=10.1109%2fI2CT54291.2022.9824265&partnerID=40&md5=da1e1745214895766a45c9c2a6b8b92a","Previously Expert Systems (ES) dominated Artificial Intelligence (AI) applications and various ES were developed in multiple domains. However, due to knowledge acquisition bottlenecks, these systems fell out of use. With the rise in Machine Learning (ML) and Deep Learning (DL) approaches, another category of systems called Recommender Systems (RS) is now developed for various application domains. As ML/DL systems acted like black boxes, explainable AI (XAI) came into the picture to provide explanations for the recommendations or predictions made. In this paper, we review the architectural similarities and differences between these three approaches along with applications and future directions. It is important to study these to predict the future of RS and any possible resurgence of ES, developments in XAI and application domains. © 2022 IEEE.","and Explainable Artificial Intelligence (XAI); Artificial Intelligence (AI); Deep Learning (DL); Expert Systems (ES); Machine Learning (ML); Recommender Systems (RS); Rule Engine (RE); Search Engine (SE)","Deep learning; Expert systems; Learning systems; Search engines; And explainable artificial intelligence (XAI); Artificial intelligence; Deep learning; Expert system; Machine learning; Machine-learning; Recommende system; Rule engine; Search engine; Recommender systems"
"Ray A.","Machine learning in postgenomic biology and personalized medicine","10.1002/widm.1451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123476575&doi=10.1002%2fwidm.1451&partnerID=40&md5=c12434126e4130d45da9a777fe7a13bf","In recent years, machine learning (ML) has been revolutionizing biology, biomedical sciences, and gene-based agricultural technology capabilities. Massive data generated in biological sciences by rapid and deep gene sequencing and protein or other molecular structure determination, on the one hand, require data analysis capabilities using ML that are distinctly different from classical statistical methods; on the other, these large datasets are enabling the adoption of novel data-intensive ML algorithms for the solution of biological problems that until recently had relied on mechanistic model-based approaches that are computationally expensive. This review provides a bird's eye view of the applications of ML in postgenomic biology. Attempt is also made to indicate as far as possible the areas of research that are poised to make further impacts in these areas, including the importance of explainable artificial intelligence in human health. Further contributions of ML are expected to transform medicine, public health, agricultural technology, as well as to provide invaluable gene-based guidance for the management of complex environments in this age of global warming. This article is categorized under: Technologies > Machine Learning Technologies > Artificial Intelligence Technologies > Prediction. © 2022 Wiley Periodicals LLC.","genomics; healthcare; machine learning; personalized medicine; postgenomic","Agriculture; Bioinformatics; Engineering education; Genes; Global warming; Large dataset; Agricultural technologies; Biological science; Biomedical science; Data intensive; Gene sequencing; Large datasets; Massive data; Personalized medicines; Post-genomic biology; Structure determination; Machine learning"
"Raza A., Tran K.P., Koehl L., Li S.","Designing ECG monitoring healthcare system with federated transfer learning and explainable AI","10.1016/j.knosys.2021.107763","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120445086&doi=10.1016%2fj.knosys.2021.107763&partnerID=40&md5=bf9900e5139c5e01cee6e22bc255e8a8","Deep learning plays a vital role in classifying different arrhythmias using electrocardiography (ECG) data. Nevertheless, training deep learning models normally requires a large amount of data and can lead to privacy concerns. Unfortunately, a large amount of healthcare data cannot be easily collected from a single silo. Additionally, deep learning models are like black-box, with no explainability of the predicted results, which is often required in clinical healthcare. This limits the application of deep learning in real-world health systems. In this paper, to address the above-mentioned challenges, we design a novel end-to-end framework in a federated setting for ECG-based healthcare using explainable artificial intelligence (XAI) and deep convolutional neural networks (CNN). The federated setting is used to solve challenges such as data availability and privacy concerns. Furthermore, the proposed framework effectively classifies different arrhythmias using an autoencoder and a classifier, both based on a CNN. Additionally, we propose an XAI-based module on top of the proposed classifier for interpretability of the classification results, which helps clinical practitioners to interpret the predictions of the classifier and to make quick and reliable decisions. The proposed framework was trained and tested using the baseline Massachusetts Institute of Technology - Boston's Beth Israel Hospital (MIT-BIH) Arrhythmia database. The trained classifier outperformed existing work by achieving accuracy up to 94.5% and 98.9% for arrhythmia detection using noisy and clean data, respectively, with five-fold cross-validation. We also propose a new communication cost reduction method to reduce the communication costs and to enhance the privacy of users’ data in the federated setting. While the proposed framework was tested and validated for ECG classification, it is general enough to be extended to many other healthcare applications. © 2021 Elsevier B.V.","Deep learning; Electrocardiography (ECG); Explainable AI (XAI); Federated learning; Privacy; Security","Classification (of information); Convolutional neural networks; Cost reduction; Data privacy; Deep neural networks; Diseases; Health care; Deep learning; Electrocardiography; Explainable AI (XAI); Federated learning; Healthcare systems; Learning models; Privacy; Privacy concerns; Security; Transfer learning; Electrocardiography"
"Razavi S., Jakeman A., Saltelli A., Prieur C., Iooss B., Borgonovo E., Plischke E., Lo Piano S., Iwanaga T., Becker W., Tarantola S., Guillaume J.H.A., Jakeman J., Gupta H., Melillo N., Rabitti G., Chabridon V., Duan Q., Sun X., Smith S., Sheikholeslami R., Hosseini N., Asadzadeh M., Puy A., Kucherenko S., Maier H.R.","The Future of Sensitivity Analysis: An essential discipline for systems modeling and policy support","10.1016/j.envsoft.2020.104954","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099475423&doi=10.1016%2fj.envsoft.2020.104954&partnerID=40&md5=c5b1b7fe003debfae8849b9e2d6895fc","Sensitivity analysis (SA) is en route to becoming an integral part of mathematical modeling. The tremendous potential benefits of SA are, however, yet to be fully realized, both for advancing mechanistic and data-driven modeling of human and natural systems, and in support of decision making. In this perspective paper, a multidisciplinary group of researchers and practitioners revisit the current status of SA, and outline research challenges in regard to both theoretical frameworks and their applications to solve real-world problems. Six areas are discussed that warrant further attention, including (1) structuring and standardizing SA as a discipline, (2) realizing the untapped potential of SA for systems modeling, (3) addressing the computational burden of SA, (4) progressing SA in the context of machine learning, (5) clarifying the relationship and role of SA to uncertainty quantification, and (6) evolving the use of SA in support of decision making. An outlook for the future of SA is provided that underlines how SA must underpin a wide variety of activities to better serve science and society. © 2021 The Authors","Decision making; Machine learning; Mathematical modeling; Model robustness; Model validation and verification; Policy support; Sensitivity analysis; Uncertainty quantification","Decision making; Uncertainty analysis; Computational burden; Data-driven model; Multi-disciplinary groups; Potential benefits; Real-world problem; Research challenges; Theoretical framework; Uncertainty quantifications; Sensitivity analysis"
"Razzaq A., Kaur P., Akhter N., Wani S.H., Saleem F.","Next-Generation Breeding Strategies for Climate-Ready Crops","10.3389/fpls.2021.620420","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111911243&doi=10.3389%2ffpls.2021.620420&partnerID=40&md5=847db685a4eac1b0aee647963bf64927","Climate change is a threat to global food security due to the reduction of crop productivity around the globe. Food security is a matter of concern for stakeholders and policymakers as the global population is predicted to bypass 10 billion in the coming years. Crop improvement via modern breeding techniques along with efficient agronomic practices innovations in microbiome applications, and exploiting the natural variations in underutilized crops is an excellent way forward to fulfill future food requirements. In this review, we describe the next-generation breeding tools that can be used to increase crop production by developing climate-resilient superior genotypes to cope with the future challenges of global food security. Recent innovations in genomic-assisted breeding (GAB) strategies allow the construction of highly annotated crop pan-genomes to give a snapshot of the full landscape of genetic diversity (GD) and recapture the lost gene repertoire of a species. Pan-genomes provide new platforms to exploit these unique genes or genetic variation for optimizing breeding programs. The advent of next-generation clustered regularly interspaced short palindromic repeat/CRISPR-associated (CRISPR/Cas) systems, such as prime editing, base editing, and de nova domestication, has institutionalized the idea that genome editing is revamped for crop improvement. Also, the availability of versatile Cas orthologs, including Cas9, Cas12, Cas13, and Cas14, improved the editing efficiency. Now, the CRISPR/Cas systems have numerous applications in crop research and successfully edit the major crop to develop resistance against abiotic and biotic stress. By adopting high-throughput phenotyping approaches and big data analytics tools like artificial intelligence (AI) and machine learning (ML), agriculture is heading toward automation or digitalization. The integration of speed breeding with genomic and phenomic tools can allow rapid gene identifications and ultimately accelerate crop improvement programs. In addition, the integration of next-generation multidisciplinary breeding platforms can open exciting avenues to develop climate-ready crops toward global food security. © Copyright © 2021 Razzaq, Kaur, Akhter, Wani and Saleem.","abiotic stress; climate change; CRISPR/Cas; crop improvement; food security; genome editing; genomics; next-generation breeding",
"Reddy S.R.G., Varma G.P.S., Davuluri R.L.","Resnet-based modified red deer optimization with DLCNN classifier for plant disease identification and classification","10.1016/j.compeleceng.2022.108492","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143539722&doi=10.1016%2fj.compeleceng.2022.108492&partnerID=40&md5=24868e65e8a633fc8913da924417efaa","The manual inspections of plant diseases resulted in low accuracy with high time consumption and unable to predict the multiple diseases of plants. To address these difficulties, it is necessary to develop automated systems that are capable of effectively classifying. Therefore, this article presents a customized PDICNet model for plant leaf disease identification and classification. Initially, ResNet-50 is used to extract multiple features from plant leaf images with colour and texture properties. In addition, the modified Red Deer optimization algorithm (MRDOA) is implemented as an optimal feature selection algorithm to obtain optimized and salient features with a reduced size of the MRDOA. Further, a deep learning convolutional neural network (DLCNN) classifier model is utilized to achieve enhanced classification performance. Obtained simulation outcome discloses the superiority of proposed PDICNet model with an accuracy and F1-score of 99.73%, and 99.78%, respectively for PlantVillage dataset and 99.68%, and 99.71% for Rice Plant dataset. © 2022","Classification; Convolutional neural network; Deep learning; Plant Leaf disease identification; Red deer optimization algorithm","Automation; Convolution; Deep learning; Learning systems; Optimization; Textures; Convolutional neural network; Deep learning; Leaf disease; Modified reds; Neural networks classifiers; Optimization algorithms; Plant disease; Plant leaf disease identification; Plant leaves; Red deer optimization algorithm; Convolutional neural networks"
"Ren Y.-S., Ma C.-Q., Kong X.-L., Baltas K., Zureigat Q.","Past, present, and future of the application of machine learning in cryptocurrency research","10.1016/j.ribaf.2022.101799","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141522289&doi=10.1016%2fj.ribaf.2022.101799&partnerID=40&md5=a0d4ea4b7e22ac970e4720ab1900fe55","Cryptocurrency has captured the interest of financial scholars and become a major research topic in blockchain. In cryptocurrency research, the use of machine learning algorithms is enabled by the presence of many types of data and abundant resources. However, there is currently no comprehensive review on cryptocurrencies using machine learning. Therefore, we collect papers on cryptocurrency-related using machine learning in the web of science database, and summarize these papers according to the algorithm, and draw the following conclusions: (1) The application of machine learning for cryptocurrencies research is increasing year over year; (2) Predicting cryptocurrency price trends and income fluctuations is the most relevant research topic; (3) The machine learning algorithm utilized in cryptocurrency research is not unique, and the practise of combining multiple machine learning approaches has emerged; (4) Concerns such as overfitting and interpretability still persist with machine learning methods. Finally, we suggest future research directions. © 2022 Elsevier B.V.","Bibliometric analysis; Blockchain; Cryptocurrency; Machine learning",
"Reski R., Rybicki E., Foster G.","Editorial overview: Plant biotechnology","10.1016/j.copbio.2020.02.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081892604&doi=10.1016%2fj.copbio.2020.02.012&partnerID=40&md5=95bd60d18d39d1de68ff27e33419610e",[No abstract available],,"carbon; bioremediation; climate change; developing country; drought resistance; Editorial; food security; gene editing; genetic manipulation; middle income country; molecular farming; plant biotechnology; priority journal; soil pollution; synthetic biology; water pollution; biotechnology; plant; Biotechnology; Plants"
"Rhodes K., Sagan V.","Integrating Remote Sensing and Machine Learning for Regional-Scale Habitat Mapping: Advances and future challenges for desert locust monitoring","10.1109/MGRS.2021.3097280","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118602375&doi=10.1109%2fMGRS.2021.3097280&partnerID=40&md5=350ac0913ad165716194b6d445d9b8e5","Increased access to reliable data and computationally efficient systems has created more collaborative potential between remote sensing and machine learning for species habitat prediction. Exploiting the integrative opportunities will require a deeper understanding of methods remote sensing instruments use to capture biophysical variables and the extent that data science can model ecological relationships. In this article, we provide the first systemic review of the integration of remote sensing and machine learning to predict habitat for the highly destructive desert locust and explore deep learning as a new method for increased classification. We evaluated the performance of six machine learning algorithms in two study regions (Niger and Sudan), using locust observations, multiple pseudoabsence data sets, and remotely sensed habitat data. In both regions, the k-nearest neighbor (kNN) and a deep neural network (DNN) were the best-preforming models. In Niger, the kNN average accuracy score was 88%, and the F-1 score was 89% for the Present (1) class. The DNN average accuracy score was 88%, and the F-1 score was 89%. In Sudan, the kNN average accuracy score was 88%, and the F-1 score was 88% for the Present (1) class. The DNN average accuracy score was 88%, and the F-1 score was 89%. Additionally, we outline a process for robustly modeling habitat through remote sensing data and highlight important limitations. We propose that the DNN model has the best potential for constructing a transferable representation and discuss novel methods to meet future challenges in desert locust management in a sustainable way. © 2013 IEEE.",,"Deep neural networks; Landforms; Learning algorithms; Nearest neighbor search; Remote sensing; Bio-physical variables; Computationally efficient; Future challenges; Habitat mapping; Machine-learning; Niger; Regional scale; Remote machines; Remote sensing instruments; Remote-sensing; Ecosystems; locust; machine learning; mapping; monitoring; remote sensing; Niger; Sudan"
"Riekki J., Mammela A.","Research and Education towards Smart and Sustainable World","10.1109/ACCESS.2021.3069902","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103792200&doi=10.1109%2fACCESS.2021.3069902&partnerID=40&md5=264b59c3cd451e7ffd018c6feefd9623","We propose a vision for directing research and education in the field of information and communications technology (ICT). Our Smart and Sustainable World vision targets prosperity for the people and the planet through better awareness and control of both human-made and natural environments. The needs of society, individuals, and industries are fulfilled with intelligent systems that sense their environment, make proactive decisions on actions advancing their goals, and perform the actions on the environment. We emphasize artificial intelligence, feedback loops, human acceptance and control, intelligent use of basic resources, performance parameters, mission-oriented interdisciplinary research, and a holistic systems view complementing the conventional analytical reductive view as a research paradigm, especially for complex problems. To serve a broad audience, we explain these concepts and list the essential literature. We suggest planning research and education by specifying, in a step-wise manner, scenarios, performance criteria, system models, research problems, and education content, resulting in common goals and a coherent project portfolio as well as education curricula. Research and education produce feedback to support evolutionary development and encourage creativity in research. Finally, we propose concrete actions for realizing this approach. © 2013 IEEE.","artificial intelligence (AI); availability; basic resources; closed-loop feedback control; computational intelligence (CI); constraints; decision making; degree of centralization; dependability; distributed systems; education; emergence; energy efficiency; experimental-inductive method; functionality; hierarchy; history; hypothetico-deductive method; innovation; integrative learning; Internet of Things (IoT); open-loop control; optimization; performance; reductive view; reliability; research; safety; security; Smart world vision; sustainable development goals; systems view","Feedback; Intelligent systems; Evolutionary development; Information and communications technology; Interdisciplinary research; Natural environments; Performance criterion; Performance parameters; Project portfolio; Research problems; Sustainable development"
"Rigon R., Formetta G., Bancheri M., Tubini N., D'amato C., David O., Massari C.","HESS Opinions: Participatory Digital eARth Twin Hydrology systems (DARTHs) for everyone - a blueprint for hydrologists","10.5194/hess-26-4773-2022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140653709&doi=10.5194%2fhess-26-4773-2022&partnerID=40&md5=c9b37060cdb29da1d8250826a45dcb67","The ""Digital Earth""(DE) metaphor is very useful for both end users and hydrological modelers (i.e., the coders). In this opinion paper, we analyze different categories of models with the view of making them part of Digital eARth Twin Hydrology systems (DARTHs). We stress the idea that DARTHs are not models, rather they are an appropriate infrastructure that hosts (certain types of) models and provides some basic services for connecting to input data. We also argue that a modeling-by-component strategy is the right one for accomplishing the requirements of the DE. Five technological steps are envisioned to move from the current state of the art of modeling. In step 1, models are decomposed into interacting modules with, for instance, the agnostic parts dealing with inputs and outputs separated from the model-specific parts that contain the algorithms. In steps 2 to 4, the appropriate software layers are added to gain transparent model execution in the cloud, independently of the hardware and the operating system of computer, without human intervention. Finally, step 5 allows models to be selected as if they were interchangeable with others without giving deceptive answers. This step includes the use of hypothesis testing, the inclusion of error of estimates, the adoption of literate programming and guidelines to obtain informative clean code. The urgency for DARTHs to be open source is supported here in light of the open-science movement and its ideas. Therefore, it is argued that DARTHs must promote a new participatory way of performing hydrological science, in which researchers can contribute cooperatively to characterize and control model outcomes in various territories. Finally, three enabling technologies are also discussed in the context of DARTHs - Earth observations (EOs), high-performance computing (HPC) and machine learning (ML) - as well as how these technologies can be integrated in the overall system to both boost the research activity of scientists and generate knowledge. © Author(s) 2022.",,"Computer hardware; Computer operating systems; Engineering education; Open source software; Open systems; 'current; Digital Earth; End-users; Human intervention; Hydrological modellers; Hypothesis testing; Input and outputs; Input datas; Model executions; State of the art; Hydrology; algorithm; EOS; hydrological modeling; machine learning"
"Rios T.N., Rios R., Mello R.","eXplainable Ensemble Strategy using distinct and restrict learning biases: A case study on the Brazilian Forest[Formula presented]","10.1016/j.asoc.2022.109976","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145970833&doi=10.1016%2fj.asoc.2022.109976&partnerID=40&md5=45b6c658fcff80b8a27a8ba0b738ff78","Supervised learning algorithms consider different learning biases from the universe of all admissible functions to induce classifiers. When using ensembles, one takes advantage of different biases typically built from the same algorithm to combine complementary classifiers into a single model, such as Random Forest, that builds up several trees from different attributes and examples. This paper innovates ensemble strategies by explaining and exploring distinct, restrict, and complementary biases from different algorithms. Multi-bias classifiers are combined using Fuzzy rules to execute symbolic reasoning and explain how each learning bias contributes to the final classification results. The contributions of our work are twofold: first, the proposed approach looks for the most suitable learner by individually analyzing the attributes of each new instance, and second, the process used to perform such a search is based on inferences run on fuzzy rules, that uses IF–THEN structures, which are interpretable, thus allowing to explain the process used to select the best learner. Finally, it is worth emphasizing that our approach was applied to the Brazilian biodiversity dataset to corroborate that, even working on hundreds of examples, results are promising, thus stimulating studies on biodiversity and the design of sustainable economic solutions. © 2022 Elsevier B.V.","Ensemble method; Fuzzy Systems; Supervised learning","Biodiversity; Forestry; Fuzzy inference; Learning algorithms; Learning systems; Supervised learning; Admissible functions; Case-studies; Classification results; Ensemble methods; Ensemble strategies; Multi-bias; Random formulas; Single models; Sustainable economics; Symbolic reasoning; Fuzzy rules"
"Ritter N., Straub J.","Implementation of hardware-based expert systems and comparison of their performance to software-based expert systems","10.3390/machines9120361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121725723&doi=10.3390%2fmachines9120361&partnerID=40&md5=0bf7accb5fd4f28d623a020f2d218e46","Expert systems are a form of highly understandable artificial intelligence that allow humans to trace the decision-making processes that are used. While they are typically software implemented and use an iterative algorithm for rule-fact network processing, this is not the only possible implementation approach. This paper implements and evaluates the use of hardware-based expert systems. It shows that they work accurately and can be developed to parallel software implementations. It also compares the processing speed of software and hardware-based expert systems, showing that hardware-based systems typically operate two orders of magnitude faster than the software ones. The potential applications that hardware-based expert systems can be used for and the capabilities that they can provide are discussed. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Efficacy; Electronic; Expert systems; Performance; Rule-fact network",
"Rivera M.M., Escalante-Garcia N., Dena-Aguilar J.A., Olvera-Gonzalez E., Vacas-Jacques P.","Feature Selection to Predict LED Light Energy Consumption with Specific Light Recipes in Closed Plant Production Systems","10.3390/app12125901","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132273147&doi=10.3390%2fapp12125901&partnerID=40&md5=8c1ca03acfd87f23c783703ad5db2cbd","The use of closed growth environments, such as greenhouses, plant factories, and vertical farms, represents a sustainable alternative for fresh food production. Closed plant production systems (CPPSs) allow growing of any plant variety, no matter the year’s season. Artificial lighting plays an essential role in CPPSs as it promotes growth by providing optimal conditions for plant development. Nevertheless, it is a model with a high demand for electricity, which is required for artificial radiation systems to enhance the developing plants. A high percentage (40% to 50%) of the costs in CPPSs point to artificial lighting systems. Due to this, lighting strategies are essential to improve sustainability and profitability in closed plant production systems. However, no tools have been applied in the literature to contribute to energy savings in LED-type artificial radiation systems through the configuration of light recipes (wavelengths combination. For CPPS to be cost-effective and sustainable, a pre-evaluation of energy consumption for plant cultivation must consider. Artificial intelligence (AI) methods integrated into the prediction crucial variables such as each input-variable light color or specific wavelengths like red, green, blue, and white along with light intensity (quantity), frequency (pulsed light), and duty cycle. This paper focuses on the feature-selection stage, in which a regression model is trained to predict energy consumption in LED lights with specific light recipes in CPPSs. This stage is critical because it identifies the most representative features for training the model, and the other stages depend on it. These tools can enable further in-depth analysis of the energy savings that can be obtained with light recipes and pulsed and continuous operation light modes in artificial LED lighting systems. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","energy efficiency; features selection; light wavelength; machine learning",
"Robinet C., Van Den Dool R., Collot D., Douma J.C.","Modelling for risk and biosecurity related to forest health","10.1042/ETLS20200062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098532832&doi=10.1042%2fETLS20200062&partnerID=40&md5=f4d115510c8d5e17a5fe988fb731fee2","Modelling the invasion and emergence of forest pests and pathogens (PnPs) is necessary to quantify the risk levels for forest health and provide key information for policy makers. Here, we make a short review of the models used to quantify the invasion risk of exotic species and the emergence risk of native species. Regarding the invasion process, models tackle each invasion phase, e.g. pathway models to describe the risk of entry, species distribution models to describe potential establishment, and dispersal models to describe (human-assisted) spread. Concerning the emergence process, models tackle each process: spread or outbreak. Only a few spread models describe jointly dispersal, growth, and establishment capabilities of native species while some mechanistic models describe the population temporal dynamics and inference models describe the probability of outbreak. We also discuss the ways to quantify uncertainty and the role of machine learning. Overall, promising directions are to increase the models' genericity by parameterization based on meta-analysis techniques to combine the effect of species traits and various environmental drivers. Further perspectives consist in considering the models' interconnection, including the assessment of the economic impact and risk mitigation options, as well as the possibility of having multi-risks and the reduction in uncertainty by collecting larger fit-for-purpose datasets. © 2020 The Author(s).",,"agriculture; forest; human; introduced species; meta analysis; population dynamics; Agriculture; Forests; Humans; Introduced Species; Population Dynamics"
"Rogers J., Cagle L., Ball J.E., Kurum M., Gurbuz S.Z.","Application of deep learning to radar remote sensing","10.1049/SBRA529E_ch11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114564934&doi=10.1049%2fSBRA529E_ch11&partnerID=40&md5=8bf367144b776164e70fb184d00c68da","Although the origins of radar can be traced back to the military, since its inception, civilian applications have flourished, especially those related to remote sensing. Applications such as object (e.g., ship or vehicle) detection directly translate from their military counterparts of airborne and ground-based automatic target recognition (ATR). However, most applications involving the remote sensing of the environment fundamentally reverse the way radar backscattering is perceived. In detection and recognition, scattering from any surface other than the object is regarded as “clutter”- undesirable reflections that ought to be removed or suppressed in the data so that the true nature of the object of interest can be ascertained. However, in environmental remote sensing, it is the surface or volume scattering that we seek to understand and exploit. In many cases, remote sensing aims at extracting geophysical properties, which can be related back to the way materials interact with electromagnetic waves. Examples include soil moisture or water concentration, terrain elevation, biomass, mass movement rates, hydrometeor type, plant health, drought tolerance, crop yield, ice layers, and snow thickness. Because deep learning (DL) was originally developed in consideration of real-valued data and optical images, the potential performance, architectures, and optimization of deep neural networks (DNNs) operating on radar remote sensing data must be reassessed. The relationship between geophysical properties, electromagnetic scattering, and the RF data representations used to reveal these relationships creates vast, complex, multidimensional, and time-varying datasets over which DL can be leveraged. Thus, the rich and unique qualities of remote sensing data present new challenges for DL, which has driven much research in this area. Chapter Contents: • 11.1 Open questions in DL for radar remote sensing • 11.1.1 What is the best way to exploit multimodal sensing data? • 11.1.2 How to satisfy the large data needs for training a DL system? • 11.1.3 How can prior knowledge on sensor quality be incorporated into joint domain models? • 11.1.4 What is the best way to leverage data, models, and prior knowledge? • 11.1.5 How can DL aide in solving multi-temporal processing challenges? • 11.1.6 How can the big data challenge presented by remote sensing data be addressed? • 11.1.7 How can DL be used to leverage nontraditional data sources? • 11.1.8 How can DL be used in automotive autonomy? • 11.2 Selected applications • 11.2.1 Land use and land cover (LULC) classification • 11.2.1.1 Land cover classification • 11.2.1.2 Land use classification • 11.2.2 Change detection • 11.2.3 Ship detection • 11.2.4 Geophysical parameter estimation • 11.2.4.1 Drought monitoring • 11.2.4.2 Precipitation nowcasting • 11.2.4.3 Snow depth estimation • 11.2.4.4 Ice layer tracking • 11.2.5 Radar aeroecology • 11.2.5.1 Birds in ground radar data • 11.2.5.2 Birds and insects in meteorological radar data • 11.3 Additional resources • 11.4 Concluding remarks • References. © The Institution of Engineering and Technology 2021.","Airborne ground-based automatic target recognition; Civilian applications; Deep learning; Environmental remote sensing; Geophysical image processing; Geophysical properties; Image classification; Military counterparts; Neural nets; Radar imaging; Radar remote sensing data; Remote sensing by radar; Way radar backscattering",
"Rojo D., Htun N.N., Parra D., De Croon R., Verbert K.","AHMoSe: A knowledge-based visual support system for selecting regression machine learning models","10.1016/j.compag.2021.106183","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107960558&doi=10.1016%2fj.compag.2021.106183&partnerID=40&md5=8b86db7145e048b8b84236c8ef58ba58","Decision support systems have become increasingly popular in the domain of agriculture. With the development of automated machine learning, agricultural experts are now able to train, evaluate and make predictions using cutting edge machine learning (ML) models without the need for much ML knowledge. Although this automated approach has led to successful results in many scenarios, in certain cases (e.g., when few labeled datasets are available) choosing among different models with similar performance metrics is a difficult task. Furthermore, these systems do not commonly allow users to incorporate their domain knowledge that could facilitate the task of model selection, and to gain insight into the prediction system for eventual decision making. To address these issues, in this paper we present AHMoSe, a visual support system that allows domain experts to better understand, diagnose and compare different regression models, primarily by enriching model-agnostic explanations with domain knowledge. To validate AHMoSe, we describe a use case scenario in the viticulture domain, grape quality prediction, where the system enables users to diagnose and select prediction models that perform better. We also discuss feedback concerning the design of the tool from both ML and viticulture experts. © 2021 Elsevier B.V.","Automated Machine Learning; Decision Support System; Explainable AI; Visual Analytics","Agriculture; Automation; Decision making; Decision support systems; Forecasting; Knowledge based systems; Regression analysis; Automated machine learning; Automated machines; Decision supports; Domain knowledge; Explainable AI; Knowledge based; Machine learning models; Machine-learning; Support systems; Visual analytics; Machine learning; automation; decision making; decision support system; design; knowledge; machine learning; performance assessment; prediction; regression analysis"
"Romero E., Stewart C., Li A., Hale K., Morris N.","Bolt: Fast Inference for Random Forests","10.1145/3528535.3531519","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132298722&doi=10.1145%2f3528535.3531519&partnerID=40&md5=ece11ab172908f9c4d8b403605baaf4c","Random forests use ensembles of decision trees to boost accuracy for machine learning tasks. However, large ensembles slow down inference on platforms that process each tree in an ensemble individually. We present Bolt, a platform that restructures whole random forests, not just individual trees, to speed up inference. Conceptually, Bolt maps every path in each tree to a lookup table which, if cache were large enough, would allow inference with just one memory access. When the size of the lookup table exceeds cache capacity, Bolt employs a novel combination of lossless compression, parameter selection, and bloom filters to shrink the table while preserving fast inference. We compared inference speed in Bolt to three state-of-the-art platforms: Python Scikit-Learn, Ranger, and Forest Packing. We evaluated these platforms using datasets with vision, natural language processing and categorical applications. We observed that on ensembles of shallow decision trees Bolt can run 2 - 14X faster than competing platforms and that Bolt's speedups persist as the number of decision trees in an ensemble increases. © 2022 ACM.",,"Bolts; Forestry; Natural language processing systems; Random forests; Table lookup; Cache capacity; Fast inference; Forest use; Individual tree; Learning tasks; Lossless compression; Machine-learning; Memory access; Random forests; Speed up; Decision trees"
"Romero-Gainza E., Stewart C., Li A., Hale K., Morris N.","Memory mapping and parallelizing random forests for speed and cache efficiency","10.1145/3458744.3474052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115952974&doi=10.1145%2f3458744.3474052&partnerID=40&md5=496b23a7c562788dce61ce69778ca80e","Memory mapping enhances decision tree implementations by enabling constant-time statistical inference, and is particularly effective when memory mapped tables fit in processor cache. However, memory mapping is more challenging when applied to random forests - ensembles of many trees - as the table sizes can easily outstrip cache capacity. We argue that careful system design for parallel and cache efficiency can make memory mapping effective for random forests. Our preliminary results show memory-mapped forests can speed up inference latency by a factor of up to 30 × . © 2021 ACM.",,"Cache memory; Efficiency; Mapping; Cache capacity; Cache efficiency; Constant time; Memory mapping; Parallel efficiency; Parallelizing; Processor cache; Speed up; Statistical inference; Table size; Decision trees"
"Ronaghi M.H.","The influence of artificial intelligence adoption on circular economy practices in manufacturing industries","10.1007/s10668-022-02670-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138166014&doi=10.1007%2fs10668-022-02670-3&partnerID=40&md5=24b97bdc0ad51bfba0d20d1fe30dcdaf","Considering the increase in the stakeholders’ supervision and the change of production processes, sustainable development plays a crucial role in the survival of businesses. In order to achieve sustainable development, the circular economy (CE) seeks to manage the flow of materials and energy to closed-loop systems. Circular economy has led to the formation of sustainable business models. Artificial intelligence (AI) capabilities change work activities, data flows, and organizational processes. The purpose of this study is to identify the impact of adoption of AI on circular economy practices in the organization. The research questions include: What are the factors affecting the adoption of AI in manufacturing companies? What effect does the adoption of AI have on the CE practices in the organization? In the first phase, research constructs are identified and a conceptual model is developed based on previous studies. In the second phase, the research model is evaluated among 97 manufacturing companies in the Middle East. Structural equation model and Smart PLS software have been used for data analysis. The findings show that the technology characteristics, organizational capabilities and external task environment have an effect on adoption of AI, and adoption of AI has a positive effect on circular economy practices. Based on the results, AI technology can be a solution to change the production process and reduce the destructive effects of industry on the environment. Managers of manufacturing companies can use the capabilities of machine learning, intelligence and neural networks to manage resources and optimize product production. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.","Artificial intelligence; Circular economy; Environmental pollution; Manufacturing industries; Middle east; Sustainable development",
"Ross E.M., Hayes B.J.","Metagenomic Predictions: A Review 10 years on","10.3389/fgene.2022.865765","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135443620&doi=10.3389%2ffgene.2022.865765&partnerID=40&md5=cf4663b5deba1cd865504635f5a5931d","Metagenomic predictions use variation in the metagenome (microbiome profile) to predict the unknown phenotype of the associated host. Metagenomic predictions were first developed 10 years ago, where they were used to predict which cattle would produce high or low levels of enteric methane. Since then, the approach has been applied to several traits and species including residual feed intake in cattle, and carcass traits, body mass index and disease state in pigs. Additionally, the method has been extended to include predictions based on other multi-dimensional data such as the metabolome, as well to combine genomic and metagenomic information. While there is still substantial optimisation required, the use of metagenomic predictions is expanding as DNA sequencing costs continue to fall and shows great promise particularly for traits heavily influenced by the microbiome such as feed efficiency and methane emissions. Copyright © 2022 Ross and Hayes.","feed efficiency; metagenomics; methane; microbiome; prediction","accuracy; body mass; bovine; carcass; feed efficiency; metagenomics; methane emission; microbiome; nonhuman; operational taxonomic unit; prediction; residual feed intake; Review"
"Routis G., Paraskevopoulos M., Vetsikas I.A., Roussaki I., Stavrakoudis D., Katsantonis D.","Data-Driven and Interoperable Smart Agriculture: An IoT-based Use-Case for Arable Crops","10.1109/COINS54846.2022.9855001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137973765&doi=10.1109%2fCOINS54846.2022.9855001&partnerID=40&md5=630f93a403038c2d437472ef0e6fa7d8","The sustainability of the agricultural sector relies on exploiting all technologies available today (and further advancing them), in order to decrease the costs and the environmental impact, maintaining yields at the same time. DEMETER is a Horizon 2020 project that aspires to empower farmers to better exploit their existing operational context and create new business models through smart data sharing in the agricultural sector, in an interoperable, reusable, and safe manner. This paper presents a specific use-case that uses the facilities developed in order to optimize rice and maize irrigation and fertilization management processes. It provides an overview of the project's objectives and concepts and then describes the various modules of the specific use-case and how they cooperate to establish suitable decision support mechanisms. Finally, it elaborates on how the development of other similar services reusing the individual building blocks, in an interoperable and vendor-neutral manner, is facilitated. © 2022 IEEE.","arable crops; data-driven; Internet of Things; interoperability; smart agriculture","Agricultural technology; Crops; Decision support systems; Environmental impact; Environmental technology; Internet of things; Sustainable development; Agricultural sector; Arable crops; Data driven; Data interoperability; Data Sharing; Fertilisation; Horizon 2020; New business models; Smart agricultures; SMART datum; Interoperability"
"Rovito L., Bonin L., Manzoni L., De Lorenzo A.","An Evolutionary Computation Approach for Twitter Bot Detection","10.3390/app12125915","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132158937&doi=10.3390%2fapp12125915&partnerID=40&md5=fcb8eb67b2489730b4bd029f758c3d01","Bot accounts are automated software programs that act as legitimate human profiles on social networks. Identifying these kinds of accounts is a challenging problem due to the high variety and heterogeneity that bot accounts exhibit. In this work, we use genetic algorithms and genetic programming to discover interpretable classification models for Twitter bot detection with competitive qualitative performance, high scalability, and good generalization capabilities. Specifically, we use a genetic programming method with a set of primitives that involves simple mathematical operators. This enables us to discover a human-readable detection algorithm that exhibits a detection accuracy close to the top state-of-the-art methods on the TwiBot-20 dataset while providing predictions that can be interpreted, and whose uncertainty can be easily measured. To the best of our knowledge, this work is the first attempt at adopting evolutionary computation techniques for detecting bot profiles on social media platforms. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","binary classification; bot detection; cybersecurity; evolutionary computation; explainable AI; genetic algorithms; genetic programming; machine learning; supervised learning; Twitter",
"Rowbottom R., Carver S., Barmuta L.A., Weinstein P., Allen G.R.","How do local differences in saltmarsh ecology influence disease vector mosquito populations?","10.1111/mve.12433","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088853560&doi=10.1111%2fmve.12433&partnerID=40&md5=de9cc3ad6b075e84048ba63f865f8080","Saltmarsh breeding mosquitoes are an important source of vectors for arboviral transmission. In southern Australia, the most prominent vector borne disease, Ross River virus (Togaviridae: Alphavirus) (RRV), is transmitted by the saltmarsh mosquito (Diptera: Culicidae) Aedes camptorhynchus (Thomson). However, the factors driving the abundance of this mosquito within and among saltmarshes are poorly understood. To predict the abundance of this mosquito within saltmarshes, the environmental conditions and aquatic invertebrate ecology of three temperate saltmarshes habitats were monitored over two seasons. Up to 44% of first-instar mosquito numbers and 21% of pupal numbers were accounted for by environmental variables. Samphire vegetation cover was a common predictor of first-instar numbers across sites although, between saltmarshes, aquatic factors such as high salinity, temperatures less than 22 °C and water body volume were important predictors. The identified predictors of pupal numbers were more variable and included high tides, waterbody volume and alkalinity. The composition of invertebrate functional feeding groups differed between saltmarshes and showed that an increased diversity led to fewer mosquitoes. It was evident that apparently similar saltmarshes can vary markedly in invertebrate assemblages, water availability and conditions through tidal inundations, rainfall or waterbody permanency. The present study advances insight into predictors of vector mosquito numbers that drive the risk of RRV outbreaks. © 2020 The Royal Entomological Society","Aedes camptorhynchus; functional feeding groups; habitat comparison; RRV; seasonal variability; Tasmania","rain; abundance; arboreal species; disease transmission; disease vector; environmental conditions; invertebrate; mosquito; saltmarsh; temperate environment; vegetation cover; Article; coastal waters; Diptera; environmental factor; environmental parameters; filter feeder; hatching; infection risk; limit of quantitation; mosquito vector; nonhuman; pH; predictor variable; pupa; Ross River virus; salinity; temperature; tide; vegetation; virus infection; Aedes; Alphavirus infection; animal; cold; mosquito vector; physiology; population dynamics; Ross River virus; salinity; Tasmania; wetland; Australia; Aedes camptorhynchus; Alphavirus; Crithmum maritimum; Culicidae; Diptera; Invertebrata; Ross River virus; Togaviridae; Aedes; Alphavirus Infections; Animals; Cold Temperature; Mosquito Vectors; Population Dynamics; Ross River virus; Salinity; Tasmania; Wetlands"
"Roy R., Babakerkhell M.D., Mukherjee S., Pal D., Funilkul S.","Evaluating the Intention for the Adoption of Artificial Intelligence-Based Robots in the University to Educate the Students","10.1109/ACCESS.2022.3225555","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144086285&doi=10.1109%2fACCESS.2022.3225555&partnerID=40&md5=e189c1baa432749e10c6c05d9ea0c8ff","Technology adoption is accepting, integrating, and using the latest innovative technologies in society. Artificial intelligence (AI) and robotics are changing the face of the industrial and service sectors. There is a need to change the traditional way of teaching by introducing the latest innovative methods. This study aims to measure the intention of adopting AI-based robots in the educational system of Indian universities. This study uses three theories technology acceptance model, the theory of planned behaviour, and the technology readiness index. Thirteen hypotheses are proposed for this study. The teachers and students survey Indian universities. This study also measures the users' attitudes and the impact on their intention. Nine hypotheses got accepted, and four hypotheses got rejected. This study will benefit the university administration as they will understand the importance of AI-based robots and their applications. These will also be helpful in a way that the students and teachers both are in favours of the adoption process. © 2013 IEEE.","Artificial intelligence; attitude; intention; robots; universities","Intelligent robots; Teaching; Attitude; Industrial sector; Innovative method; Innovative technology; Intention; Service sectors; Teachers'; Technology adoption; Technology in society; University; Students"
"Roy S., Meena T., Lim S.-J.","Demystifying Supervised Learning in Healthcare 4.0: A New Reality of Transforming Diagnostic Medicine","10.3390/diagnostics12102549","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140635489&doi=10.3390%2fdiagnostics12102549&partnerID=40&md5=5465f01681023c2b25d41b7144b19fb4","The global healthcare sector continues to grow rapidly and is reflected as one of the fastest-growing sectors in the fourth industrial revolution (4.0). The majority of the healthcare industry still uses labor-intensive, time-consuming, and error-prone traditional, manual, and manpower-based methods. This review addresses the current paradigm, the potential for new scientific discoveries, the technological state of preparation, the potential for supervised machine learning (SML) prospects in various healthcare sectors, and ethical issues. The effectiveness and potential for innovation of disease diagnosis, personalized medicine, clinical trials, non-invasive image analysis, drug discovery, patient care services, remote patient monitoring, hospital data, and nanotechnology in various learning-based automation in healthcare along with the requirement for explainable artificial intelligence (AI) in healthcare are evaluated. In order to understand the potential architecture of non-invasive treatment, a thorough study of medical imaging analysis from a technical point of view is presented. This study also represents new thinking and developments that will push the boundaries and increase the opportunity for healthcare through AI and SML in the near future. Nowadays, SML-based applications require a lot of data quality awareness as healthcare is data-heavy, and knowledge management is paramount. Nowadays, SML in biomedical and healthcare developments needs skills, quality data consciousness for data-intensive study, and a knowledge-centric health management system. As a result, the merits, demerits, and precautions need to take ethics and the other effects of AI and SML into consideration. The overall insight in this paper will help researchers in academia and industry to understand and address the future research that needs to be discussed on SML in the healthcare and biomedical sectors. © 2022 by the authors.","artificial intelligence; computer vision; deep learning; healthcare; medical imaging; precision medicine; supervised learning; XAI","algorithm; artificial intelligence; biomedicine; cancer diagnosis; clinical practice; clinical trial (topic); comparative study; computer vision; data quality; diabetic retinopathy; diagnosis; diagnostic accuracy; diagnostic imaging; drug design; health care; health care management; heart disease; hospital; human; image analysis; immunomics; internet of things; knowledge management; malignant neoplasm; medical ethics; nanotechnology; neurologic disease; non invasive procedure; pandemic; patient care; patient monitoring; personalized medicine; prediction; radiomics; reproducibility; Review; robot assisted surgery; skin disease; supervised machine learning; synthetic biology; team building; teleconsultation; telemonitoring"
"Rozman J., Hagras H., Perez J.A., Clarke D., Muller B., Data S.F.","Privacy-preserving gesture recognition with explainable type-2 fuzzy logic based systems","10.1109/FUZZ48607.2020.9177768","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090499338&doi=10.1109%2fFUZZ48607.2020.9177768&partnerID=40&md5=f8f1af8fada243622ae952cf2e266de8","Smart homes are a growing market in need of privacy preserving sensors paired with explainable, interpretable and reliable control systems. The recent boom in Artificial Intelligence (AI) has seen an ever-growing persistence to incorporate it in all spheres of human life including the household. This growth in AI has been met with reciprocal concern for the privacy impacts and reluctance to introduce sensors, such as cameras, into homes. This concern has led to research of sensors not traditionally found in households, mainly short range radar. There has been also increasing awareness of AI transparency and explainability. Traditional AI black box models are not trusted, despite boasting high accuracy scores, due to the inability to understand what the decisions were based on. Interval Type-2 Fuzzy Logic offers a powerful alternative, achieving close to black box levels of performance while remaining completely interpretable. This paper presents a privacy preserving short range radar sensor coupled with an Explainable AI system employing a Big Bang Big Crunch (BB-BC) Interval Type-2 Fuzzy Logic System (FLS) to classify gestures performed in an indoor environment. © 2020 IEEE.","Big Bang - Big Crunch; Explainable Artificial Intelligence (XAI); Privacy Preserving Sensing; Type-2 Fuzzy Logic","Artificial intelligence; Automation; Computer circuits; Fuzzy systems; Gesture recognition; Intelligent buildings; Man machine systems; Radar; Growing markets; Indoor environment; Interval type-2 fuzzy logic; Interval type-2 fuzzy logic systems; Privacy preserving; Reliable control; Short range radar; Type-2 fuzzy logic; Fuzzy logic"
"Ruett M., Junker-Frohn L.V., Siegmann B., Ellenberger J., Jaenicke H., Whitney C., Luedeling E., Tiede-Arlt P., Rascher U.","Hyperspectral imaging for high-throughput vitality monitoring in ornamental plant production","10.1016/j.scienta.2021.110546","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114451163&doi=10.1016%2fj.scienta.2021.110546&partnerID=40&md5=1d00123993d043fc6982eb6044a640e3","Ornamental heather (Calluna vulgaris) production is characterized by high risks such as occurrence of fungal diseases and plant losses. Given the general absence of formal research on this economically important production system, farmers depend on their own approaches to assess plant vitality. We provide a reproducible, affordable and transparent workflow for assessing ornamental plant vitality with spectroscopy data. We use hyperspectral imaging as a non-invasive alternative for monitoring plant performance by combining the long-term experience of experts with hyperspectral images taken with a portable hyperspectral camera. We tested a custom-made setup deployed in a horticultural production facility and screened thousands of heather plants over a period of 14 weeks during their development from cuttings to young plants under production conditions. The vitality of shoots and roots was classified by experts for comparison with spectral signatures of shoot tips of healthy and stressed plants. To identify wavelengths that allow distinguishing between healthy and stressed heather plants, we evaluated the datasets using Partial Least Squares regression. Reflectance in the green (519–575 nm) and red-edge (712–718 nm) region of the spectrum was identified as most important for classifying plants as healthy or stressed. We transferred the trained Partial Least Squares regression model to independent test data obtained on a different date, correctly classifying 98.1% of the heather plants. The setup we describe here is adjustable and can be used to measure different plant species. We identify challenges in data evaluation, point out promising evaluation approaches, and make our dataset available to facilitate further studies on plant vitality in horticultural production systems. © 2021","Cutting vitality; Expert knowledge; Heather (Calluna vulgaris); Hyperspectral image processing; Imaging spectroscopy; Partial least squares regression (PLSR)","detection method; dicotyledon; equipment; fungal disease; imaging method; ornamental species; Calluna; Calluna vulgaris"
"Russo A., Lax G.","Using Artificial Intelligence for Space Challenges: A Survey","10.3390/app12105106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131051761&doi=10.3390%2fapp12105106&partnerID=40&md5=ff386fca5b4d90b93f48d40db9e23795","Artificial intelligence is applied to many fields and contributes to many important applications and research areas, such as intelligent data processing, natural language processing, autonomous vehicles, and robots. The adoption of artificial intelligence in several fields has been the subject of many research papers. Still, recently, the space sector is a field where artificial intelligence is receiving significant attention. This paper aims to survey the most relevant problems in the field of space applications solved by artificial intelligence techniques. We focus on applications related to mission design, space exploration, and Earth observation, and we provide a taxonomy of the current chal-lenges. Moreover, we present and discuss current solutions proposed for each challenge to allow researchers to identify and compare the state of the art in this context. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","deep learning; Earth observation; machine learning; mission design; reinforcement learning; space exploration",
"Ryo M.","Explainable artificial intelligence and interpretable machine learning for agricultural data analysis","10.1016/j.aiia.2022.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142455007&doi=10.1016%2fj.aiia.2022.11.003&partnerID=40&md5=57b5d3de92fc75e2bdc63e895fcdc60f","Artificial intelligence and machine learning have been increasingly applied for prediction in agricultural science. However, many models are typically black boxes, meaning we cannot explain what the models learned from the data and the reasons behind predictions. To address this issue, I introduce an emerging subdomain of artificial intelligence, explainable artificial intelligence (XAI), and associated toolkits, interpretable machine learning. This study demonstrates the usefulness of several methods by applying them to an openly available dataset. The dataset includes the no-tillage effect on crop yield relative to conventional tillage and soil, climate, and management variables. Data analysis discovered that no-tillage management can increase maize crop yield where yield in conventional tillage is <5000 kg/ha and the maximum temperature is higher than 32°. These methods are useful to answer (i) which variables are important for prediction in regression/classification, (ii) which variable interactions are important for prediction, (iii) how important variables and their interactions are associated with the response variable, (iv) what are the reasons underlying a predicted value for a certain instance, and (v) whether different machine learning algorithms offer the same answer to these questions. I argue that the goodness of model fit is overly evaluated with model performance measures in the current practice, while these questions are unanswered. XAI and interpretable machine learning can enhance trust and explainability in AI. © 2022","Agriculture; Crop yield; Explainable artificial intelligence; Interpretable machine learning; No-tillage; XAI",
"Saba T., Haseeb K., Rehman A., Damaševičius R., Bahaj S.A.","Smart Random Walk Distributed Secured Edge Algorithm Using Multi-Regression for Green Network","10.3390/electronics11244141","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144883311&doi=10.3390%2felectronics11244141&partnerID=40&md5=e7645a946553400cd2c13a028f84ccf4","Smart communication has significantly advanced with the integration of the Internet of Things (IoT). Many devices and online services are utilized in the network system to cope with data gathering and forwarding. Recently, many traffic-aware solutions have explored autonomous systems to attain the intelligent routing and flowing of internet traffic with the support of artificial intelligence. However, the inefficient usage of nodes’ batteries and long-range communication degrades the connectivity time for the deployed sensors with the end devices. Moreover, trustworthy route identification is another significant research challenge for formulating a smart system. Therefore, this paper presents a smart Random walk Distributed Secured Edge algorithm (RDSE), using a multi-regression model for IoT networks, which aims to enhance the stability of the chosen IoT network with the support of an optimal system. In addition, by using secured computing, the proposed architecture increases the trustworthiness of smart devices with the least node complexity. The proposed algorithm differs from other works in terms of the following factors. Firstly, it uses the random walk to form the initial routes with certain probabilities, and later, by exploring a multi-variant function, it attains long-lasting communication with a high degree of network stability. This helps to improve the optimization criteria for the nodes’ communication, and efficiently utilizes energy with the combination of mobile edges. Secondly, the trusted factors successfully identify the normal nodes even when the system is compromised. Therefore, the proposed algorithm reduces data risks and offers a more reliable and private system. In addition, the simulations-based testing reveals the significant performance of the proposed algorithm in comparison to the existing work. © 2022 by the authors.","edge computing; green computing; internet of things; multi-sensors; optimal system; smart development",
"Sabrina F., Sohail S., Farid F., Jahan S., Ahamed F., Gordon S.","An Interpretable Artificial Intelligence Based Smart Agriculture System","10.32604/cmc.2022.026363","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127341562&doi=10.32604%2fcmc.2022.026363&partnerID=40&md5=e108fa83bf09e2ec1ea42205cb1001d8","With increasing world population the demand of food production has increased exponentially. Internet of Things (IoT) based smart agriculture system can play a vital role in optimising crop yield by managing crop requirements in real-Time. Interpretability can be an important factor to make such systems trusted and easily adopted by farmers. In this paper, we propose a novel artificial intelligence-based agriculture system that uses IoT data to monitor the environment and alerts farmers to take the required actions for maintaining ideal conditions for crop production. The strength of the proposed system is in its interpretability which makes it easy for farmers to understand, trust and use it. The use of fuzzy logic makes the system customisable in terms of types/number of sensors, type of crop, and adaptable for any soil types and weather conditions. The proposed system can identify anomalous data due to security breaches or hardware malfunction using machine learning algorithms. To ensure the viability of the system we have conducted thorough research related to agricultural factors such as soil type, soil moisture, soil temperature, plant life cycle, irrigation requirement and water application timing for Maize as our target crop. The experimental results show that our proposed system is interpretable, can detect anomalous data, and triggers actions accurately based on crop requirements. © 2022 Tech Science Press. All rights reserved.","Explainable artificial intelligence; fuzzy logic; internet of things; machine learning; sensors; smart agriculture","Computer circuits; Crops; Cultivation; Fuzzy logic; Learning algorithms; Life cycle; Machine learning; Monitoring; Soil moisture; Agriculture systems; Crop yield; Explainable artificial intelligence; Food production; Fuzzy-Logic; Interpretability; Sensor; Smart agricultures; Soil types; World population; Internet of things"
"Sachit M.S., Shafri H.Z.M., Abdullah A.F., Rafie A.S.M., Gibril M.B.A.","Global Spatial Suitability Mapping of Wind and Solar Systems Using an Explainable AI-Based Approach","10.3390/ijgi11080422","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137368755&doi=10.3390%2fijgi11080422&partnerID=40&md5=c1d95af4bcb059ea45220801df03a741","An assessment of site suitability for wind and solar plants is a strategic step toward ensuring a low-cost, high-performing, and sustainable project. However, these issues are often handled on a local scale using traditional decision-making approaches that involve biased and non-generalizable weightings. This study presents a global wind and solar mapping approach based on eXplainable Artificial Intelligence (XAI). To the best of the author’s knowledge, the current study is the first attempt to create global maps for siting onshore wind and solar power systems and formulate novel weights for decision criteria. A total of 13 conditioning factors (independent variables) defined through a comprehensive literature review and multicollinearity analysis were assessed. Real-world renewable energy experiences (more than 55,000 on-site wind and solar plants worldwide) are exploited to train three machine learning (ML) algorithms, namely Random Forest (RF), Support Vector Machine (SVM), and Multi-layer Perceptron (MLP). Then, the output of ML models was explained using SHapley Additive exPlanations (SHAP). RF outperformed SVM and MLP in both wind and solar modeling with an overall accuracy of 90% and 89%, kappa coefficient of 0.79 and 0.78, and area under the curve of 0.96 and 0.95, respectively. The high and very high suitability categories accounted for 23.2% (~26.84 million km2) of the site suitability map for wind power plants. In addition, they covered more encouraging areas (24.0% and 19.4%, respectively, equivalent to ~50.31 million km2) on the global map for hosting solar energy farms. SHAP interpretations were consistent with the Gini index indicating the dominance of the weights of technical and economic factors over the spatial assessment under consideration. This study provides support to decision-makers toward sustainable power planning worldwide. © 2022 by the authors.","GIS; site suitability; solar plants; wind plants; XAI",
"Sadayappan K., Kerins D., Shen C., Li L.","Nitrate concentrations predominantly driven by human, climate, and soil properties in US rivers","10.1016/j.watres.2022.119295","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140911167&doi=10.1016%2fj.watres.2022.119295&partnerID=40&md5=3b363e0da7fed74128ad20b75b68cb9a","Nitrate is one of the most widespread and persistent pollutants in our time. Our understanding of nitrate dynamics has advanced substantially in the past decades, although its predominant drivers across gradients of climate, land use, and geology have remained elusive. Here we collated nitrate data from 2061 rivers along with 32 watershed characteristic indexes and developed machine learning models to reconstruct long-term mean (multi-year average) nitrate concentrations in the contiguous United States (CONUS). The trained models show similarly satisfactory model performance and can predict nitrate concentrations in chemically-ungauged places with about 70% accuracy. Further analysis revealed that five (out of 32) indexes (drivers) can explain about 70% of spatial variations in mean nitrate concentrations. The five influential drivers are nitrogen application rates Nrate and urban area Aurban% (human drivers), mean annual precipitation and temperature (climate drivers), and sand percent Sand% (soil property driver). Nitrate concentrations in undeveloped sites are primarily modulated by climate and soil property; they decrease with increasing mean discharge and Sand%. Nitrate concentrations in agriculture and urban sites increase with Nrate and Aurban% until reaching their apparent maxima around 10,000 kg/km2/yr and around 25%, respectively. Results indicate that nitrate concentrations may remain similar or increase with growing human population. In addition, nitrate concentrations can increase even without human input, as warming escalates water demand and reduces mean discharge in many places. These results allude to a conceptual model that highlights the impacts of distinct drivers: while human drivers predominate nitrogen input to land and rivers, climate drivers and soil properties modulate its transport and transformation, the balance of which determine long-term mean concentrations. Such mechanism-based insights and forecasting capabilities are essential for water management as we expect changing climate and growing agriculture and urbanization. © 2022 Elsevier Ltd","Agriculture; Biogeochemical cycles; Climate change; Land use; Machine learning; Nutrient contamination; Urbanization; Water Quality","Agricultural pollution; Biogeochemistry; Climate change; Climate models; Land use; Machine learning; Nitrates; Nitrogen; River pollution; Soils; Urban growth; Water management; Water quality; Biogeochemical cycle; Climate properties; Human drivers; Machine-learning; Nitrate concentration; Nitrate dynamics; Nutrient contamination; Soil property; Urbanization; Watershed characteristics; Rivers; nitrate; nitric acid derivative; nitrogen; climate effect; human activity; machine learning; nitrate; pollutant transport; river pollution; soil property; Article; climate; environmental temperature; geology; human; land use; machine learning; population growth; precipitation; river; sand; soil property; United States; urban area; water management; agriculture; environmental monitoring; procedures; soil; United States; Agriculture; Environmental Monitoring; Humans; Nitrates; Nitrogen; Rivers; Sand; Soil"
"Safeer S., Pandey R.P., Rehman B., Safdar T., Ahmad I., Hasan S.W., Ullah A.","A review of artificial intelligence in water purification and wastewater treatment: Recent advancements","10.1016/j.jwpe.2022.102974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139302856&doi=10.1016%2fj.jwpe.2022.102974&partnerID=40&md5=d7fd1c92e22658506a2e339879090e5a","Artificial intelligence (AI) is an emerging powerful novel technology that can model real-time problems involving numerous intricacies. The modeling capabilities of AI techniques are quite advantageous in water purification and wastewater treatment processes because the automation of such facilities resulted in easy and low cost operations; in addition to the significant reduction in the occurrence of human errors. AI technologies involve multi-linear or non-linear relationships and process dynamics that are usually impractical to model by conventional methodologies. This review presents a compendious synopsis of recent advancements and discoveries in various AI technologies applied to source water quality determination, coagulation/flocculation, disinfection, membrane filtration, desalination, modeling wastewater treatment plants, prediction of membrane fouling, removal of heavy metals, and monitoring of biological oxygen demand (BOD) and chemical oxygen demand (COD) levels. The analysis of the performance of various AI technologies in this review proves the successful implementation of these technologies in water treatment related applications. It also highlights the limitations that hinder their implementations in real-world water treatment systems. © 2022","Artificial intelligence; Machine learning; Wastewater treatment; Water purification",
"Saghiri A.M.","Cognitive Internet of Things: Challenges and Solutions","10.1007/978-3-030-87059-1_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122777996&doi=10.1007%2f978-3-030-87059-1_13&partnerID=40&md5=122bd1f1a9eb4072813162000fdd901c","Internet of Things (IoT) technology will be used in a wide range of applications such as healthcare and transportation. Because of distributed and dynamic nature of IoT-based systems, designing management algorithms for them results in challenging problems. On the other hand, cognitive computing refers to systems that emulate cognitive processes inspired by human thinking processes for solving problems. The Cognitive Internet of Things (CIoT) technology refers to a combination of cognitive systems and IoT. A benefit of this technology is that the management problems of the IoT will be solved by solutions that come from cognitive systems domain. In recent years, CIoT has received much attention. This is because the management algorithms of the IoT are very complex and therefore human thinking processes as computerized cognitive processes are required for fast and accurate decision-making. Existing algorithms reported as management mechanisms for CIoT only focus on utilizing artificial intelligence without considering fundamental issues of cognitive systems such as predictability, controllability, responsibility, safety, security, and energy consumption. Ignoring these issues may result in designing inappropriate cognitive systems that may be faced with a wide range of problems such as hacking and failure. CIoT inherited numerous challenges from artificial intelligence, IoT, and cognitive systems. Therefore, the challenges of these fields should be studied to extract the challenges in designing CIoT. In the literature, there is no study on extracting the challenges considering associated technologies to CIoT. In this paper, the challenges of the associated technologies are summarized. Then, some important challenges in designing CIoT are obtained. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Artificial intelligence; Cognitive Internet of Things; Cognitive systems; Internet of Things; Management mechanisms","Artificial intelligence; Cognitive systems; Decision making; Energy utilization; Personal computing; Cognitive Computing; Cognitive internet of thing; Cognitive internets; Cognitive process; Dynamic nature; Human thinking; Internet of things technologies; Management mechanisms; System designing; Thinking process; Internet of things"
"Sagi O., Rokach L.","Explainable decision forest: Transforming a decision forest into an interpretable tree","10.1016/j.inffus.2020.03.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083315261&doi=10.1016%2fj.inffus.2020.03.013&partnerID=40&md5=8fdcb4bbeaffca7565028650c74d85b9","Decision forests are considered the best practice in many machine learning challenges, mainly due to their superior predictive performance. However, simple models like decision trees may be preferred over decision forests in cases in which the generated predictions must be efficient or interpretable (e.g. in insurance or health-related use cases). This paper presents a novel method for transforming a decision forest into an interpretable decision tree, which aims at preserving the predictive performance of decision forests while enabling efficient classifications that can be understood by humans. This is done by creating a set of rule conjunctions that represent the original decision forest; the conjunctions are then hierarchically organized to form a new decision tree. We evaluate the proposed method on 33 UCI datasets and show that the resulting model usually approximates the ROC AUC gained by random forest while providing an interpretable decision path for each classification. © 2020 Elsevier B.V.","Classification Trees; Decision forest; Ensemble learning","Classification (of information); Decision trees; Best practices; Decision forest; Decision paths; Predictive performance; Set of rules; Uci datasets; Learning algorithms"
"Sahal R., Alsamhi S.H., Brown K.N.","Conceptual Framework of Contact-Less Consumer Products Industry During and Post-pandemic Era","10.1007/978-3-031-20936-9_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147853537&doi=10.1007%2f978-3-031-20936-9_13&partnerID=40&md5=6247982d3aa7d0198372554183f1dfba","The COVID-19 era has reshaped the world regarding the contact-less economy, healthcare systems, remote work environment, people’s lifestyle and their daily routines, etc. The consumer products (CP) industry is being impacted due to the behaviours of consumers during self-quarantine. This accelerates adopting digital transformation and upgrading the business models for the contact-less CP industry. Accordingly, this study provides a step toward the contact-less CP industry during and post-pandemic. First, we have proposed a conceptual framework for the contact-less CP industry that aims to bring together the key advanced technologies (e.g., Digital Twin (DT), blockchain, AI, cloud computing, 5G, and robots). The combination of the advanced technologies provides data monitoring, transparency, traceability, automation, and data sharing among consumers and CP partners. The proposed framework will enable a more contact-less personalized interaction that will work towards higher levels of consumer satisfaction while maintaining contact-less economy growth. Then, we have described how the proposed framework can be applied for contact-less delivery services for the CP industry during and post-pandemic. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Blockchain; Consumer products industry; Contact-less; COVID-19; Digital twin; Post pandemic","Blockchain; Consumer products; Industry 4.0; Advanced technology; Block-chain; Conceptual frameworks; Consumer product industries; Contact less; Daily routines; Digital transformation; Healthcare systems; Post pandemic; Work environments; COVID-19"
"Saheb T., Dehghani M., Saheb T.","Artificial intelligence for sustainable energy: A contextual topic modeling and content analysis","10.1016/j.suscom.2022.100699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124482291&doi=10.1016%2fj.suscom.2022.100699&partnerID=40&md5=7246d131ba857b4c616485bac1a7a251","Parallel to the rising debates over sustainable energy and artificial intelligence solutions, the world is currently discussing the ethics of artificial intelligence and its possible negative effects on society and the environment. In these arguments, sustainable AI is proposed, which aims at advancing the pathway toward sustainability, such as sustainable energy. In this paper, we offered a novel contextual topic modeling combining LDA, BERT and Clustering. We then combined these computational analyses with content analysis of related scientific publications to identify the main scholarly topics, sub-themes and cross-topic themes within scientific research on sustainable AI in energy. Our research identified eight dominant topics including sustainable buildings, AI-based DSSs for urban water management, climate artificial intelligence, Agriculture 4, convergence of AI with IoT, AI-based evaluation of renewable technologies, smart campus and engineering education and AI-based optimization. We then recommended 14 potential future research strands based on the observed theoretical gaps. In addition to its theoretical contribution to scientific research on sustainable artificial intelligence in energy management, the research utilizes a novel topic modeling method in exploring scientific texts and identifying challenges and possible solutions. A variety of solutions was incorporated, including huggingface tool or elbow method, to address these challenges. © 2022 Elsevier Inc.","Artificial intelligence; Content analysis; Energy; Sustainability; Sustainable energy; Topic modeling","Artificial intelligence; Energy conservation; Energy management; Engineering education; Intelligent buildings; Water management; Clusterings; Computational analysis; Content analysis; Energy; Modeling analyzes; Scientific publications; Scientific researches; Sustainable building; Topic Modeling; Urban water management; Sustainable development"
"Sahli H., Sayadi M.","Application of Random Forest Method for Estimating Rejected Product in Industrial Conveyor Belt","10.1109/IC_ASET53395.2022.9765883","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130611024&doi=10.1109%2fIC_ASET53395.2022.9765883&partnerID=40&md5=fa1db23ec882a89e8134790975db3983","In most companies, the unloading system still poses a major problem which constitutes repetitive stops of the chain because of cracking at the level of the carriage and the intensive loss of the large quantities of the raw material. This problem can cause a time waste, a high cost and even stopping the production line. This paper presents an enhanced procedure able to achieve relevant classification of weight product in conveyor belt in order to supply quantitative estimation of rejected or not rejected (R/nR) cases. The studied database contains the different weight of both rejected and not-rejected product. The results show that the use of a random forest classifier is an effective way to improve estimation and classification for fast and truthful industrial diagnostic. Compared to other machine learning methods, the proposed method provided a significant performance reaching more than 90% of accuracy. © 2022 IEEE.","Classification; Industrial conveyor belt; Random forest method; Rejected product; Unloading system","Belt conveyors; Learning systems; Unloading; Conveyor belts; High costs; Industrial conveyor belt; Industrial conveyors; Production line; Quantitative estimation; Random forest classifier; Random forest methods; Rejected product; Unloading systems; Decision trees"
"Sahoo A.K., Chakraverty S.","Machine intelligence in dynamical systems: \A state-of-art review","10.1002/widm.1461","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132635989&doi=10.1002%2fwidm.1461&partnerID=40&md5=431ec4302272a6a75fc96b310d34cc2e","This article is dedicated to study the impact of machine intelligence (MI) methods viz. various types of Neural models for investigating dynamical systems arising in interdisciplinary areas. Different types of artificial neural network (ANN) methods, viz., recurrent neural network, functional-link neural network, convolutional neural network, symplectic artificial neural network, genetic algorithm neural network, and so on, are addressed by different researchers to investigate these problems. Although various traditional methods have been developed by researchers to solve these dynamical problems but the existing traditional methods may sometimes be problem dependent, require repetitions of the simulations, and fail to solve nonlinearity behavior. In this regard, neural network model based methods are more general and solutions are continuous over the given domain of integration, self-adaptive and can be used as a black box. As such, in this article, we have reviewed and analyzed different MI methods, which are applied to investigate these problems. This article is categorized under: Technologies > Computational Intelligence Technologies > Machine Learning Application Areas > Science and Technology. © 2022 Wiley Periodicals LLC.","ANN; astrophysics; COVID-19; damage detection; dynamical problems; earthquake; machine intelligence; share market","Computer aided instruction; Dynamical systems; Genetic algorithms; Recurrent neural networks; Artificial neural network methods; Convolutional neural network; COVID-19; Dynamical problems; Earthquake; Functional link neural network; Machine intelligence; Neural modelling; Share market; Symplectic; Astrophysics"
"Saini P., Kaur J., Lamba S.","A Review on Pattern Recognition Using Machine Learning","10.1007/978-981-16-0942-8_58","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112623471&doi=10.1007%2f978-981-16-0942-8_58&partnerID=40&md5=5fa842fe47c2c2fbbe9651a2ef97825a","Machine learning (ML) techniques have gained remarkable attention in past two decades including many fields like computer vision, information retrieval, and pattern recognition. This paper presents a literature review on pattern recognition of various applications like signal processing, agriculture sector, healthcare sector, signature recognition, and different model analysis using ML techniques. The focus of our survey is at the ML techniques, classification techniques and deep learning model, and improves the accuracy rate for the automatic decision making algorithms. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Classification techniques; Decision making; Deep learning; Machine learning; Pattern recognition","Deep learning; Pattern recognition; Signal processing; Agriculture sectors; Classification technique; Decisions makings; Deep learning; Information patterns; Literature reviews; Machine learning techniques; Machine-learning; Signal-processing; Vision information; Decision making"
"Sajid S.S., Shahhosseini M., Huber I., Hu G., Archontoulis S.V.","County-scale crop yield prediction by integrating crop simulation with machine learning models","10.3389/fpls.2022.1000224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143907057&doi=10.3389%2ffpls.2022.1000224&partnerID=40&md5=a35d48d7e870c02e695367e997014223","Crop yield prediction is of great importance for decision making, yet it remains an ongoing scientific challenge. Interactions among different genetic, environmental, and management factors and uncertainty in input values are making crop yield prediction complex. Building upon a previous work in which we coupled crop modeling with machine learning (ML) models to predict maize yields for three US Corn Belt states, here, we expand the concept to the entire US Corn Belt (12 states). More specifically, we built five new ML models and their ensemble models, considering the scenarios with and without crop modeling variables. Additional input values in our models are soil, weather, management, and historical yield data. A unique aspect of our work is the spatial analysis to investigate causes for low or high model prediction errors. Our results indicated that the prediction accuracy increases by coupling crop modeling with machine learning. The ensemble model overperformed the individual ML models, having a relative root mean square error (RRMSE) of about 9% for the test years (2018, 2019, and 2020), which is comparable to previous studies. In addition, analysis of the sources of error revealed that counties and crop reporting districts with low cropland ratios have high RRMSE. Furthermore, we found that soil input data and extreme weather events were responsible for high errors in some regions. The proposed models can be deployed for large-scale prediction at the county level and, contingent upon data availability, can be utilized for field level prediction. Copyright © 2022 Sajid, Shahhosseini, Huber, Hu and Archontoulis.","APSIM; data integration; ensemble model; model transparency; spatial analysis",
"Sajid S.S., Huber I., Archontoulis S., Hu G.","Integrating Crop Simulation and Machine Learning Models to Improve Crop Yield Prediction","10.1109/SOSE55472.2022.9812678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135120002&doi=10.1109%2fSOSE55472.2022.9812678&partnerID=40&md5=80fee16c6e44030c48127a87805ed0bf","Accurate crop yield prediction can contribute to the decision-making in farm management. In this paper, we propose a crop yield prediction model which integrates the outputs from a crop simulation model (APSIM). These outputs are included as features in the machine learning (ML) models to improve the transparency and an ensemble model then is designed for prediction. The proposed model is applied to predict the corn yield of 12 US Corn Belt States. RRMSE of 9.34%, 8.99%, and 9.52% was achieved after evaluating the model at the county level for the years 2018, 2019, and 2020 respectively. The proposed model has similar accuracy as the top-performing state-of-art prediction models while providing interpretability. Additional analyses have been conducted to understand the source of model errors. In this analysis, it has been identified that counties and crop reporting districts (CRD) with high cropland ratio have a lower error due to the high data availability in those regions. © 2022 IEEE.","APSIM; Optimized Ensemble Model; yield Prediction","Decision making; Forecasting; Machine learning; A crop simulation model; Crop simulation modeling; Crop simulations; Crop yield; Decisions makings; Ensemble models; Farm management; Machine learning models; Optimized ensemble model; Yield prediction; Crops"
"Salah K., Rehman M.H.U., Nizamuddin N., Al-Fuqaha A.","Blockchain for AI: Review and open research challenges","10.1109/ACCESS.2018.2890507","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061080545&doi=10.1109%2fACCESS.2018.2890507&partnerID=40&md5=2760d0f4fa04a691632be3e9223d1bf8","Recently, artificial intelligence (AI) and blockchain have become two of the most trending and disruptive technologies. Blockchain technology has the ability to automate payment in cryptocurrency and to provide access to a shared ledger of data, transactions, and logs in a decentralized, secure, and trusted manner. Also with smart contracts, blockchain has the ability to govern interactions among participants with no intermediary or a trusted third party. AI, on the other hand, offers intelligence and decision-making capabilities for machines similar to humans. In this paper, we present a detailed survey on blockchain applications for AI. We review the literature, tabulate, and summarize the emerging blockchain applications, platforms, and protocols specifically targeting AI area. We also identify and discuss open research challenges of utilizing blockchain technologies for AI. © 2013 IEEE.","Artificial intelligence; blockchain; consensus protocols; cybersecurity; machine learning; smart contracts","Artificial intelligence; Decision making; Learning systems; Consensus protocols; Cyber security; Disruptive technology; Research challenges; Trusted third parties; Blockchain"
"Salinero-Delgado M., Estévez J., Pipia L., Belda S., Berger K., Gómez V.P., Verrelst J.","Monitoring cropland phenology on google earth engine using gaussian process regression","10.3390/rs14010146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121999890&doi=10.3390%2frs14010146&partnerID=40&md5=f7f17e3582fd082183cc871224d3d76a","Monitoring cropland phenology from optical satellite data remains a challenging task due to the influence of clouds and atmospheric artifacts. Therefore, measures need to be taken to overcome these challenges and gain better knowledge of crop dynamics. The arrival of cloud computing platforms such as Google Earth Engine (GEE) has enabled us to propose a Sentinel-2 (S2) phenology end-to-end processing chain. To achieve this, the following pipeline was implemented: (1) the building of hybrid Gaussian Process Regression (GPR) retrieval models of crop traits optimized with active learning, (2) implementation of these models on GEE (3) generation of spatiotemporally continuous maps and time series of these crop traits with the use of gap-filling through GPR fitting, and finally, (4) calculation of land surface phenology (LSP) metrics such as the start of season (SOS) or end of season (EOS). Overall, from good to high performance was achieved, in particular for the estimation of canopy-level traits such as leaf area index (LAI) and canopy chlorophyll content, with normalized root mean square errors (NRMSE) of 9% and 10%, respectively. By means of the GPR gap-filling time series of S2, entire tiles were reconstructed, and resulting maps were demonstrated over an agricultural area in Castile and Leon, Spain, where crop calendar data were available to assess the validity of LSP metrics derived from crop traits. In addition, phenology derived from the normalized difference vegetation index (NDVI) was used as reference. NDVI not only proved to be a robust indicator for the calculation of LSP metrics, but also served to demonstrate the good phenology quality of the quantitative trait products. Thanks to the GEE framework, the proposed workflow can be realized anywhere in the world and for any time window, thus representing a shift in the satellite data processing paradigm. We anticipate that the produced LSP metrics can provide meaningful insights into crop seasonal patterns in a changing environment that demands adaptive agricultural production. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Crop traits; Gap-filling; Gaussian process regression (GPR); Google Earth Engine (GEE); Hybrid models; Land surface phenology (LSP); Sentinel-2","Biology; Data handling; Engines; Filling; Gaussian distribution; Gaussian noise (electronic); Mean square error; Regression analysis; Surface measurement; Time series; Crop traits; Gap filling; Gaussian process regression; Google earth engine; Google earths; Hybrid model; Land surface phenology; Sentinel-2; Crops"
"Sallustio L., Harfouche A.L., Salvati L., Marchetti M., Corona P.","Evaluating the potential of marginal lands available for sustainable cellulosic biofuel production in Italy","10.1016/j.seps.2022.101309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128670343&doi=10.1016%2fj.seps.2022.101309&partnerID=40&md5=c1b53d210d6685ca54bd6c7029f215ae","The European Union aims to provide as much as one quarter of its transportation fuels via biofuels derived from renewable sources by 2030. To put this into perspective, the Italian government has recently established an ambitious goal to support the wider uptake of advanced second-generation biofuels, including cellulosic biofuels for the transportation sector. A sustainable way forward is to grow perennial biomass crops on marginal lands, however the nationwide availability of those lands for lignocellulosic feedstock production remains uncertain. We identify and evaluate the potential of marginal lands in Italy to produce sizeable amounts of biomass for sustainable cellulosic biofuel production while limiting land use conflicts and negative ecological impacts. We applied spatial multi-criteria decision analysis techniques in geographic information systems to ultimately generate spatially-explicit national land suitability and availability maps at a fine resolution (250-m). We selected a broad range of leading cellulosic biomass crops that includes poplar (Populus × canadensis Moench), willow (Salix alba Linnaeus), black locust (Robinia pseudoacacia Linnaeus), giant reed (Arundo donax Linnaeus), and vetiver grass (Chrysopogon zizanioides Linnaeus). Based on marginality criteria, our results suggest that such biomass plantations of perennial grasses and short rotation trees may produce 3.1–27.4 billion liters of cellulosic ethanol per year from 462,265 to 2,811,064 million hectares of available marginal lands. This estimated production may fulfill 7.8–69.1% of Italy's current liquid transportation fuel consumption, constrained by the requirement that each modelled location be within 70 km of a potential cellulosic biorefinery. Collectively, this study provides the cornerstone of efforts to rationally meet Italy's need for renewable fuels in a sustainable low-carbon economy future. © 2022 Elsevier Ltd","Cellulosic feedstocks; Environmental sustainability; Land availability; Perennial grasses; Renewable bioenergy; Short rotation trees","biofuel; cellulose; decision analysis; multicriteria analysis; renewable resource; sustainability; Italy"
"Sanaeifar A., Yang C., de la Guardia M., Zhang W., Li X., He Y.","Proximal hyperspectral sensing of abiotic stresses in plants","10.1016/j.scitotenv.2022.160652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143850967&doi=10.1016%2fj.scitotenv.2022.160652&partnerID=40&md5=bca41d3ffd0f76d65a5ede3b5fc5d885","Recent attempts, advances and challenges, as well as future perspectives regarding the application of proximal hyperspectral sensing (where sensors are placed within 10 m above plants, either on land-based platforms or in controlled environments) to assess plant abiotic stresses have been critically reviewed. Abiotic stresses, caused by either physical or chemical reasons such as nutrient deficiency, drought, salinity, heavy metals, herbicides, extreme temperatures, and so on, may be more damaging than biotic stresses (affected by infectious agents such as bacteria, fungi, insects, etc.) on crop yields. The proximal hyperspectral sensing provides images at a sub-millimeter spatial resolution for doing an in-depth study of plant physiology and thus offers a global view of the plant's status and allows for monitoring spatio-temporal variations from large geographical areas reliably and economically. The literature update has been based on 362 research papers in this field, published from 2010, most of which are from four years ago and, in our knowledge, it is the first paper that provides a comprehensive review of the applications of the technique for the detection of various types of abiotic stresses in plants. © 2022 Elsevier B.V.","Abiotic plant stressors; Hyperspectral sensing; Proximal sensing; Remote sensing","Heavy metals; Abiotic plant stressor; Abiotic stress; Controlled environment; Extreme temperatures; Future perspectives; Hyperspectral sensing; Nutrient deficiency; Plant stressors; Proximal sensing; Remote-sensing; Remote sensing; heavy metal; herbicide; abiotic factor; angiosperm; critical analysis; multispectral image; remote sensing; spatial resolution; abiotic stress; bacterium; canopy; canopy scale; data processing; drought; environmental stress; flooding; fungus; geographic distribution; harvest; high temperature; hyperspectral imaging; hyperspectral sensing; insect; leaf scale; low temperature; mesophyll; nonhuman; nutrient; nutritional deficiency; plant; plant leaf; plant parameters; plant physiology; proximal sensing; remote sensing; Review; salinity; spatial analysis; spatiotemporal analysis; water content; microbiology; physiological stress; Droughts; Fungi; Plants; Salinity; Stress, Physiological"
"Sanches-Neto F.O., Dias-Silva J.R., Keng Queiroz Junior L.H., Carvalho-Silva V.H.","“pySiRC”: Machine Learning Combined with Molecular Fingerprints to Predict the Reaction Rate Constant of the Radical-Based Oxidation Processes of Aqueous Organic Contaminants","10.1021/acs.est.1c04326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115028563&doi=10.1021%2facs.est.1c04326&partnerID=40&md5=0647b90aaa988d3eab20c0062f0d073b","We developed a web application structured in a machine learning and molecular fingerprint algorithm for the automatic calculation of the reaction rate constant of the oxidative processes of organic pollutants by•OH and SO4•-radicals in the aqueous phase—thepySiRC platform. The model development followed the OECD principles: internal and external validation, applicability domain, and mechanistic interpretation. Three machine learning algorithms combined with molecular fingerprints were evaluated, and all the models resulted in high goodness-of-fit for the training set withR2&gt; 0.931 for the•OH radical andR2&gt; 0.916 for the SO4•-radical and good predictive capacity for the test set withRext2=Qext2values in the range of 0.639-0.823 and 0.767-0.824 for the•OH and SO4•-radicals. The model was interpreted using the SHAP (SHapley Additive exPlanations) method: the results showed that the model developed made the prediction based on a reasonable understanding of how electron-withdrawing and -donating groups interfere with the reactivity of the•OH and SO4•-radicals. We hope that our models and web interface can stimulate and expand the application and interpretation of kinetic research on contaminants in water treatment units based on advanced oxidative technologies. © 2021 American Chemical Society","apps and web applications; artificial intelligence; emerging contaminant degradation; kinetic parameters","Free radicals; Machine learning; Organic pollutants; Rate constants; Turing machines; Water treatment; Automatic calculations; Electronwithdrawing; Mechanistic interpretations; Molecular fingerprint; Organic contaminant; Oxidation process; Predictive capacity; Water treatment unit; Learning algorithms; hydroxyl radical; radical; sulfate; sulfate anion radical; unclassified drug; hydroxyl radical; water; algorithm; machine learning; molecular analysis; organic pollutant; prediction; reaction rate; Article; artificial neural network; calculation; controlled study; cross validation; decision tree; degradation kinetics; electron transport; kinetic parameters; learning algorithm; machine learning; molecular fingerprinting; organic pollution; Organisation for Economic Co-operation and Development; oxidation; prediction; quantitative structure activity relation; random forest; rate constant; reaction rate constant; waste water management; water pollutant; water pollution; water treatment; kinetics; machine learning; oxidation reduction reaction; water management; water pollutant; Hydroxyl Radical; Kinetics; Machine Learning; Oxidation-Reduction; Water; Water Pollutants, Chemical; Water Purification"
"Sapienza S.","Current Trends, Machine Learning, and Food Safety Data Governance","10.1007/978-3-031-09367-8_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140714138&doi=10.1007%2f978-3-031-09367-8_4&partnerID=40&md5=7a1be37b17fa0f4319a8989ff9cf2c0b","This Chapter shifts from the normative perspective adopted in the previous sections to a broader and inclusive approach encompassing governance issues. In particular, emerging concerns are related to the increasingly growing use of artificial intelligence algorithms in the context of food safety risk assessment, and revolve around topics such as algorithmic transparency, fairness, and explainability. Following an introduction to these topics, the discussion is contextualised to the domain at stake by examining the consequences of the use of machine learning and artificial intelligence algorithms in food safety risk assessment from an ethical and legal point of view. A closer look to the forthcoming EU Data Governance Act provides insights on the use of such computational approaches in the public decison-making and, in particular, in matters related to food safety. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.",,
"Saranti A., Hudec M., Mináriková E., Takáč Z., Großschedl U., Koch C., Pfeifer B., Angerschmid A., Holzinger A.","Actionable Explainable AI (AxAI): A Practical Example with Aggregation Functions for Adaptive Classification and Textual Explanations for Interpretable Machine Learning","10.3390/make4040047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144729975&doi=10.3390%2fmake4040047&partnerID=40&md5=fa969a4713666675ab9e8c756de97854","In many domains of our daily life (e.g., agriculture, forestry, health, etc.), both laymen and experts need to classify entities into two binary classes (yes/no, good/bad, sufficient/insufficient, benign/malign, etc.). For many entities, this decision is difficult and we need another class called “maybe”, which contains a corresponding quantifiable tendency toward one of these two opposites. Human domain experts are often able to mark any entity, place it in a different class and adjust the position of the slope in the class. Moreover, they can often explain the classification space linguistically—depending on their individual domain experience and previous knowledge. We consider this human-in-the-loop extremely important and call our approach actionable explainable AI. Consequently, the parameters of the functions are adapted to these requirements and the solution is explained to the domain experts accordingly. Specifically, this paper contains three novelties going beyond the state-of-the-art: (1) A novel method for detecting the appropriate parameter range for the averaging function to treat the slope in the “maybe” class, along with a proposal for a better generalisation than the existing solution. (2) the insight that for a given problem, the family of t-norms and t-conorms covering the whole range of nilpotency is suitable because we need a clear “no” or “yes” not only for the borderline cases. Consequently, we adopted the Schweizer–Sklar family of t-norms or t-conorms in ordinal sums. (3) A new fuzzy quasi-dissimilarity function for classification into three classes: Main difference, irrelevant difference and partial difference. We conducted all of our experiments with real-world datasets. © 2022 by the authors.","actionable explainable AI; aggregation functions; classification; continuous XOR-problem; interpretable machine learning; ordinal sums",
"Sartas M., Cummings S., Garbero A., Akramkhanov A.","A human machine hybrid approach for systematic reviews and maps in international development and social impact sectors","10.3390/f12081027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112264988&doi=10.3390%2ff12081027&partnerID=40&md5=888bd002ee42130eeeffd5a3f2c8c302","The international development and social impact evidence community is divided about the use of machine-centered approaches in carrying out systematic reviews and maps. While some researchers argue that machine-centered approaches such as machine learning, artificial intelligence, text mining, automated semantic analysis, and translation bots are superior to human-centered ones, others claim the opposite. We argue that a hybrid approach combining machine and human-centered elements can have higher effectiveness, efficiency, and societal relevance than either approach can achieve alone. We present how combining lexical databases with dictionaries from crowdsourced literature, using full texts instead of titles, abstracts, and keywords. Using metadata sets can significantly improve the current practices of systematic reviews and maps. Since the use of machine-centered approaches in forestry and forestry-related reviews and maps are rare, the gains in effectiveness, efficiency, and relevance can be very high for the evidence base in forestry. We also argue that the benefits from our hybrid approach will increase in time as digital literacy and better ontologies improve globally. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; Crowdsourcing; Effectiveness; Efficiency; Metadata; Societal relevance; Text mining","Artificial intelligence; Efficiency; Forestry; Natural language processing systems; Semantics; Text mining; Timber; Current practices; Digital literacies; Human-machine; Hybrid approach; International development; Lexical database; Semantic analysis; Systematic Review; Economic and social effects; artificial intelligence; crowdsourcing; data mining; efficiency measurement; forestry; literacy; literature review; mapping method; metadata; social impact; Artificial Intelligence; Development; Efficiency; Forestry; Impact; International; Machinery; Maps"
"Saunders A., Drew D.M., Brink W.","Machine learning models perform better than traditional empirical models for stomatal conductance when applied to multiple tree species across different forest biomes","10.1016/j.tfp.2021.100139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116487355&doi=10.1016%2fj.tfp.2021.100139&partnerID=40&md5=a56ebfe09bc3f0bafc325de6be8749a3","Stomatal closure decreases water loss and is one of the main mechanisms that trees can use to mitigate drought-induced physiological stress. The adaptability of trees to drought is likely to be of increasing importance as climate changes occur around the world. Modelling stomatal regulation can help improve our understanding of how forests respond to their environment. Traditionally, empirical models have been used to model stomatal responses, however these models cannot always capture nonlinear responses and their parameters are often difficult to measure. In this study various machine learning (ML) models were able to capture stomatal responses of multiple tree species. We showed that ML can be a useful tool for predicting stomatal response based on climate variables and species traits. A random forest model performed the best with an R2 of 75 %, compared to the empirical Ball-Berry stomatal conductance model (BWB) (R2 = 41 %). In this study, the use of a combined dataset consisting out of data from multiple studies were successfully used, showcasing the use of data across studies. This also allowed for an ML model to be trained on 36 tree species from 5 forest biomes, from measurements taken across 6 continents, instead of being limited to one species, increasing the versatility of the model. The importance of species-specific stomatal responses was highlighted, with the drought strategies used by plants significantly influencing stomatal responses and predictions. ML models were able to capture these trends parsimoniously without prior knowledge of the underlying physiology of the tree species. The quality of combined datasets are however still not desirable, and long-term data collection using standardized measuring protocols are required to increase the strength of ML models. Data taken across different climatic regions and vegetation types can also help improve the adaptability of ML models. Regardless of limitations on data accessibility, ML shows promise in modelling plant responses to changes in climate. Focus on the use of ML together with traditional models can help give further insight into various ecological mechanisms. © 2021 The Author(s)","Climate data; Machine learning; Stomatal conductance","climate change; drought; drought resistance; drought stress; environmental factor; forest management; machine learning; numerical model; physiological response; regional climate; stomatal conductance"
"Saunders A., Duncan J., Hurley J., Amati M., Caccetta P., Chia J., Boruff B.","Leaf my neighbourhood alone! predicting the influence of densification on residential tree canopy cover in Perth","10.1016/j.landurbplan.2020.103804","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082687665&doi=10.1016%2fj.landurbplan.2020.103804&partnerID=40&md5=8ab6ae38ed237c1eeb20396e1583b6ba","Trees provide myriad ecosystem services of benefit to urban populations; however, urban development is pressuring existing urban tree coverage. Thus, a pertinent challenge for planners is identifying development scenarios that find synergies between urban growth and the preservation or enhancement of tree canopy coverage. This paper presents the training and validation of a model that predicts changes in neighbourhood-level urban tree canopy cover associated with different socio-economic and physical urban form variables. Neighbourhoods across Perth, the capital city of Western Australia, were used as a case study. A Random Forests model was trained using a suite of socio-economic and urban form variables and neighbourhood percentage tree canopy cover derived from very high resolution multispectral remote sensing images and digital surface models. This model was validated using independent test data with a mean absolute error of 1.78% and a root mean square error of 2.42%. An application of this model was demonstrated using the City of Nedlands, Perth, where a new planning scheme allowing denser urban development has been approved by the State Government. The magnitude and spatial variation in the change of neighbourhood tree canopy cover in the City of Nedlands in 2050 associated with three urban development scenarios was predicted using the model. © 2020 Elsevier B.V.","Random Forests; Remote sensing; Urban forests; Urban landscapes","canopy architecture; capital city; landscape change; numerical model; prediction; remote sensing; satellite imagery; socioeconomic conditions; urban area; urban development; urban forestry; Australia; Perth [Western Australia]; Western Australia"
"Savargiv M., Masoumi B., Keyvanpour M.R.","A new random forest algorithm based on learning automata","10.1155/2021/5572781","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104385792&doi=10.1155%2f2021%2f5572781&partnerID=40&md5=03691ea21e3966ca3eb80e2653b3fe0f","The goal of aggregating the base classifiers is to achieve an aggregated classifier that has a higher resolution than individual classifiers. Random forest is one of the types of ensemble learning methods that have been considered more than other ensemble learning methods due to its simple structure, ease of understanding, as well as higher efficiency than similar methods. The ability and efficiency of classical methods are always influenced by the data. The capabilities of independence from the data domain, and the ability to adapt to problem space conditions, are the most challenging issues about the different types of classifiers. In this paper, a method based on learning automata is presented, through which the adaptive capabilities of the problem space, as well as the independence of the data domain, are added to the random forest to increase its efficiency. Using the idea of reinforcement learning in the random forest has made it possible to address issues with data that have a dynamic behaviour. Dynamic behaviour refers to the variability in the behaviour of a data sample in different domains. Therefore, to evaluate the proposed method, and to create an environment with dynamic behaviour, different domains of data have been considered. In the proposed method, the idea is added to the random forest using learning automata. The reason for this choice is the simple structure of the learning automata and the compatibility of the learning automata with the problem space. The evaluation results confirm the improvement of random forest efficiency. Copyright © 2021 Mohammad Savargiv et al.",,"Automata theory; Decision trees; Efficiency; Learning systems; Reinforcement learning; Robots; Adaptive capabilities; Classical methods; Different domains; Dynamic behaviours; Evaluation results; Higher efficiency; Individual classifiers; Random forest algorithm; Random forests; algorithm; learning; Algorithms; Learning"
"Savelonas M.A., Veinidis C.N., Bartsokas T.K.","Computer Vision and Pattern Recognition for the Analysis of 2D/3D Remote Sensing Data in Geoscience: A Survey","10.3390/rs14236017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143799914&doi=10.3390%2frs14236017&partnerID=40&md5=33db2fde84fad2ef48b0a7f086feb698","Historically, geoscience has been a prominent domain for applications of computer vision and pattern recognition. The numerous challenges associated with geoscience-related imaging data, which include poor imaging quality, noise, missing values, lack of precise boundaries defining various geoscience objects and processes, as well as non-stationarity in space and/or time, provide an ideal test bed for advanced computer vision techniques. On the other hand, the developments in pattern recognition, especially with the rapid evolution of powerful graphical processing units (GPUs) and the subsequent deep learning breakthrough, enable valuable computational tools, which can aid geoscientists in important problems, such as land cover mapping, target detection, pattern mining in imaging data, boundary extraction and change detection. In this landscape, classical computer vision approaches, such as active contours, superpixels, or descriptor-guided classification, provide alternatives that remain relevant when domain expert labelling of large sample collections is often not feasible. This issue persists, despite efforts for the standardization of geoscience datasets, such as Microsoft’s effort for AI on Earth, or Google Earth. This work covers developments in applications of computer vision and pattern recognition on geoscience-related imaging data, following both pre-deep learning and post-deep learning paradigms. Various imaging modalities are addressed, including: multispectral images, hyperspectral images (HSIs), synthetic aperture radar (SAR) images, point clouds obtained from light detection and ranging (LiDAR) sensors or digital elevation models (DEMs). © 2022 by the authors.","change detection; computer vision; deep learning; geoscience; hyperspectral imaging; land cover mapping; LiDAR; multispectral imaging; pattern recognition; SAR imaging; target detection","Change detection; Computer vision; Deep learning; Geology; Graphics processing unit; Image segmentation; Mapping; Optical radar; Pixels; Program processors; Radar imaging; Radar target recognition; Remote sensing; Space optics; Space-based radar; Synthetic aperture radar; 3D remote sensing; Change detection; Deep learning; Geosciences; Imaging data; Land cover mapping; Light detection and ranging; Multispectral imaging; Synthetic aperture radar imaging; Targets detection; Hyperspectral imaging"
"Savla D., Dhaka V.S., Rani G., Oza M.","Apple Leaf Disease Detection and Classification Using CNN Models","10.1007/978-981-19-2719-5_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130894758&doi=10.1007%2f978-981-19-2719-5_26&partnerID=40&md5=fc7b3c3d92102ec7a5e0f5d5c8f03ddd","Diseases such as apple scab, cedar rust, and black rot in apple plants are the primary cause of degradation in product quality and reduction in yield. Thus, it is a concern for the agriculture industry to detect these diseases early and minimize product loss. Manual detection of these diseases is time-consuming and requires human expertise. Computer vision and deep learning techniques have gained popularity in the recent era due to the higher potential for accurate object detection and pattern matching. Thus, these techniques can resolve the challenges of disease detection and classification in apple leaves. The machine learning algorithms viz. Support Vector Machine and random forest employed so fardo not focus on criteria for selectingthe model to detect and classify diseases in apple leaves. This paper presents a comparative analysis of different Convolutional Neural Network Models, viz. ResNet50, Alexnet, Inception, VGG16, and InceptionResNetV2 were employed to classify apple scab, cedar rust, black rot, and healthy leaves. The training and testing on 8,800 images of apple leaves show that VGG16 reports the highest accuracy of 92.50% in multiclass classification. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.","Apple leaf; Classification; CNN; Deep learning; Disease; Neural networks","Convolutional neural networks; Decision trees; Deep learning; Learning algorithms; Object detection; Plants (botany); Support vector machines; Apple leaf; Apple scab; Black rot; CNN; CNN models; Deep learning; Disease classification; Leaf disease detections; Neural-networks; Products quality; Fruits"
"Sayed G.I., Hassanien A.E.","Explainable AI and Slime Mould Algorithm for Classification of Pistachio Species","10.1007/978-3-031-13702-0_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141680820&doi=10.1007%2f978-3-031-13702-0_3&partnerID=40&md5=72d1415e9023e033faea877db389cf17","The safety and quality of the food are considered an essential issue in the entire world. This is due to food being the basis of human health. Nowadays, machine learning algorithms have embodied the recent technology in all stages of food processing such as food grading, food quality determination, and food classification. Pistachio nuts have an important role in the agricultural economy. To increase the efficiency of post-harvest industrial processes, there is a need to introduce technologies for classifying different species of pistachio. This study considers an automated model to separate pistachio species. The proposed pistachio species classification consists of three main phases; features selection based on slime mould algorithm phase, feature interpretation based on explainable artificial intelligence phase, and finally classification of pistachio species using logistic regression phase. The proposed pistachio species classification model obtained overall 90% classification accuracy, 90% precision, and 91% f1-score. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Explainable artificial intelligence; Feature selection; Food Industry; Pistachio species; Swarm intelligence",
"Scanlon B.R., Fakhreddine S., Reedy R.C., Yang Q., Malito J.G.","Drivers of Spatiotemporal Variability in Drinking Water Quality in the United States","10.1021/acs.est.1c08697","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137916847&doi=10.1021%2facs.est.1c08697&partnerID=40&md5=755120a786c95ed93722bf2542b80068","Approximately 10% of community water systems in the United States experience a health-based violation of drinking water quality; however, recently allocated funds for improving United States water infrastructure ($50 billion) provide an opportunity to address these issues. The objective of this study was to examine environmental, operational, and sociodemographic drivers of spatiotemporal variability in drinking water quality violations using geospatial analysis and data analytics. Random forest modeling was used to evaluate drivers of these violations, including environmental (e.g., landcover, climate, geology), operational (e.g., water source, system size), and sociodemographic (social vulnerability, rurality) drivers. Results of random forest modeling show that drivers of violations vary by violation type. For example, arsenic and radionuclide violations are found mostly in the Southwest and Southcentral United States related to semiarid climate, whereas disinfection byproduct rule violations are found primarily in Southcentral United States related to system operations. Health-based violations are found primarily in small systems in rural and suburban settings. Understanding the drivers of water quality violations can help develop optimal approaches for addressing these issues to increase compliance in community water systems, particularly small systems in rural areas across the United States. © 2022 American Chemical Society.","drinking water; random forest modeling; regulatory compliance; Safe Drinking Water Act; violations; water quality","Data Analytics; Decision trees; Quality control; Regulatory compliance; Rural areas; Water quality; Community water systems; Drinking-water qualities; Geo-spatial analysis; Random forest modeling; Safe Drinking Water Act; Smallest systems; Sociodemographics; Spatiotemporal variability; Violation; Water infrastructure; Potable water; arsenic; drinking water; radioisotope; arsenic; drinking water; forest management; regulatory approach; spatiotemporal analysis; water quality; Article; controlled study; geology; human; irrigation (agriculture); land use; population density; random forest; rural area; semiarid climate; social vulnerability; soil; spatiotemporal analysis; suburban area; United States; water disinfection; water quality; water supply; rural population; United States; water quality; United States; Arsenic; Drinking Water; Humans; Rural Population; United States; Water Quality"
"Schellens M.K., Belyazid S.","Revisiting the contested role of natural resources in violent conflict risk through machine learning","10.3390/su12166574","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089845648&doi=10.3390%2fsu12166574&partnerID=40&md5=358a4df3e241755bda6e3b8946821fcd","The integrated character of the sustainable development goals in Agenda 2030, as well as research in environmental security, flag that sustainable peace requires sustainable and conflict-sensitive natural resource use. The precise relationship between the risk for violent conflict and natural resources remains contested because of the interplay with socio-economic variables. This paper aims to improve the understanding of natural resources' role in the risk of violent conflicts by accounting for complex interactions with socio-economic conditions. Conflict data was analysed with machine learning techniques, which can account for complex patterns, such as variable interactions. More commonly used logistic regression models are compared with neural network models and random forest models. The results indicate that a country's natural resource features are important predictors of its risk for violent conflict and that they interact with socio-economic conditions. Based on these empirical results and the existing literature, we interpret that natural resources can be root causes of violent intrastate conflict, and that signals from natural resources leading to conflict risk are reflected in and influenced by interacting socio-economic conditions. More specifically, the results show that variables such as access to water and food security are important predictors of conflict, while resource rents and oil and ore exports are relatively less important than other natural resource variables, contrasting what prior research has suggested. Given the potential of natural resource features to act as an early warning for violent conflict, we argue that natural resources should be included in conflict risk models for conflict prevention. © 2020 by the authors.","Conflict prediction; Environmental conflict; Logistic regression; Machine learning; Natural resource conflict; Natural resources; Neural network; Random forest; Sustainable peace","conflict management; food security; machine learning; risk assessment; socioeconomic status; sustainable development; violence"
"Schmitt I.","QLC: A Quantum-Logic-inspired Classifier","10.1145/3548785.3548790","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139005131&doi=10.1145%2f3548785.3548790&partnerID=40&md5=2ac4ef7c0604c997cb0a29589325d29f","Besides a good prediction a classifier is to give an explanation how the input data is related to the classification result. There is a general agreement that logic expressions provide a better explanation than other methods like SVM, logistic regression, and neural networks. However, a classifier based on Boolean logic needs to map continuous data to Boolean values which can cause a loss of information. In contrast, we design a quantum-logic-inspired classifier where continuous data are directly processed and the laws of the Boolean algebra are maintained. As a result from our approach we obtain a CQQL condition which provides good insights into the relation of input features to the class decision. Furthermore, our experiment shows a good prediction accuracy. © 2022 ACM.","Classifier; Interpretable AI; Quantum logic","Boolean algebra; Classification (of information); Quantum theory; Support vector machines; Boolean logic; Boolean values; Classification results; Continuous data; Input datas; Interpretable AI; Logic expressions; Neural-networks; Quantum logic; SVM-Logistic regression; Computer circuits"
"Schneider F., Poeplau C., Don A.","Predicting ecosystem responses by data-driven reciprocal modelling","10.1111/gcb.15817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112368501&doi=10.1111%2fgcb.15817&partnerID=40&md5=45f3e1755b00b67ff112aa655d267796","Treatment effects are traditionally quantified in controlled experiments. However, experimental control is often achieved at the expense of representativeness. Here, we present a data-driven reciprocal modelling framework to quantify the individual effects of environmental treatments under field conditions. The framework requires a representative survey data set describing the treatment (A or B), its responding target variable and other environmental properties that cause variability of the target within the region or population studied. A machine learning model is trained to predict the target only based on observations in group A. This model is then applied to group B, with predictions restricted to the model's space of applicability. The resulting residuals represent case-specific effect size estimates and thus provide a quantification of treatment effects. This paper illustrates the new concept of such data-driven reciprocal modelling to estimate spatially explicit effects of land-use change on organic carbon stocks in European agricultural soils. For many environmental treatments, the proposed concept can provide accurate effect size estimates that are more representative than could feasibly ever be achieved with controlled experiments. © 2021 The Authors. Global Change Biology published by John Wiley & Sons Ltd.","association; causal inference; causation; correlation; land-use change; machine learning; soil organic carbon; statistical modelling","agricultural soil; correlation; ecosystem response; land use change; machine learning; prediction; soil carbon; Europe; Matthiola; carbon; agriculture; carbon sequestration; ecosystem; soil; Agriculture; Carbon; Carbon Sequestration; Ecosystem; Soil"
"Schneider F., Amelung W., Don A.","Origin of carbon in agricultural soil profiles deduced from depth gradients of C:N ratios, carbon fractions, δ13C and δ15N values","10.1007/s11104-020-04769-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097152383&doi=10.1007%2fs11104-020-04769-w&partnerID=40&md5=825f1cef285a1f31962831fd517f2b7b","Aims: Agricultural soils in Germany store 2.54 Pg of organic carbon (C). However, information about how and when this C entered the soils is limited. This study illustrates how depth profiles of organic matter can shed light on different entry paths of organic C. Methods: Machine learning was used to explain total organic C (TOC), C:N, particulate organic C (POC), δ13C and δ15N values down to 100 cm depth based on pedology, geology, climate and management-related variables from the German Agricultural Soil Inventory. We estimated TOC turnover rates based on the relationship between the proportion of maize (only C4 plant) in crop rotations and soil δ13C values. Results: In the upper 30 cm of cropland, fresh photosynthates added on average 0.2 to 0.8 Mg C ha− 1 year− 1. Organic fertiliser was another source of topsoil C, especially in grassland. Sandy sites in north-west Germany contained historic C from past heathland and peatland. One third of German agricultural land was found to be on colluvial and alluvial deposits, in which allochthonous C from upstream and upslope areas evidently increased the TOC content of subsoils. In and below hardpans, TOC content and C:N and POC:TOC ratios were low, indicating restricted root-derived C input. Conclusions: Our data indicate that ongoing management in German agricultural soils mainly affects topsoil C, while C storage in subsoils reveals significant legacies from allochthonous, buried or translocated C inputs. Specific attention should be focused on the sustainable loosening of hardpans that could result in a slow, but significant increase in subsoil C stocks. © 2020, The Author(s).",,"agricultural soil; carbon isotope; crop rotation; heathland; isotopic fractionation; machine learning; maize; nitrogen isotope; soil depth; soil organic matter; soil profile; subsoil; topsoil; Germany; Matthiola"
"Schoenke J., Aschenbruck N., Interdonato R., Kanawati R., Meisener A.-C., Thierart F., Vial G., Atzmueller M.","Gaia-AgStream: An Explainable AI Platform for Mining Complex Data Streams in Agriculture","10.1007/978-3-030-88259-4_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119875445&doi=10.1007%2f978-3-030-88259-4_6&partnerID=40&md5=3ee852e65c1f129b82bc022ceead0f53","We present a position paper about our concept for an artificial intelligence (AI) and data streaming platform for the agricultural sector. The goal of our project is to support agroecology in terms of carbon farming and biodiversity protection by providing an AI and data streaming platform called Gaia-AgStream that accelerates the adoption of AI in agriculture and is directly usable by farmers as well as agricultural companies in general. The technical innovations we propose focus on smart sensor networks, unified uncertainty management, explainable AI, root cause analysis and hybrid AI approaches. Our AI and data streaming platform concept contributes to the European open data infrastructure project Gaia-X in terms of interoperability for data and AI models as well as data sovereignty and AI infrastructure. Our envisioned platform and the developed AI components for carbon farming and biodiversity will enable farmers to adopt sustainable and resilient production methods while establishing new and diverse revenue streams by monetizing carbon sequestration and AI ready data streams. The open and federated platform concept allows to bring together research, industry, agricultural start-ups and farmers in order to form sustainable innovation networks. We describe core concepts and architecture of our proposed approach in these contexts, outline practical use cases for our platform and finally outline challenges and future prospects. © 2021, Springer Nature Switzerland AG.","Agroecology; Anomaly detection; Biodiversity; Carbon farming; Complex networks; Data fusion; Data quality; Distributed systems; Explainable AI; Knowledge graph; Machine learning; Root cause analysis; Sensor networks; Uncertainty management","Agriculture; Anomaly detection; Biodiversity; Complex networks; Data integration; Data reduction; Information management; Knowledge graph; Open Data; Quality control; Semantic Web; Sensor data fusion; Sensor networks; Uncertainty analysis; Agro ecologies; Anomaly detection; Carbon farming; Data quality; Data streaming; Explainable artificial intelligence; Knowledge graphs; Root cause analysis; Sensors network; Uncertainty management; Machine learning"
"Schratz P., Muenchow J., Iturritxa E., Cortés J., Bischl B., Brenning A.","Monitoring forest health using hyperspectral imagery: Does feature selection improve the performance of machine-learning techniques?","10.3390/rs13234832","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120182456&doi=10.3390%2frs13234832&partnerID=40&md5=742b5270d99376ac4a154b14c0c020c6","This study analyzed highly correlated, feature-rich datasets from hyperspectral remote sensing data using multiple statistical and machine-learning methods. The effect of filter-based feature selection methods on predictive performance was compared. In addition, the effect of multiple expert-based and data-driven feature sets, derived from the reflectance data, was investigated. Defoliation of trees (%), derived from in situ measurements from fall 2016, was modeled as a function of reflectance. Variable importance was assessed using permutation-based feature importance. Overall, the support vector machine (SVM) outperformed other algorithms, such as random forest (RF), extreme gradient boosting (XGBoost), and lasso (L1) and ridge (L2) regressions by at least three percentage points. The combination of certain feature sets showed small increases in predictive performance, while no substantial differences between individual feature sets were observed. For some combinations of learners and feature sets, filter methods achieved better predictive performances than using no feature selection. Ensemble filters did not have a substantial impact on performance. The most important features were located around the red edge. Additional features in the near-infrared region (800 nm–1000 nm) were also essential to achieve the overall best performances. Filter methods have the potential to be helpful in high-dimensional situations and are able to improve the interpretation of feature effects in fitted models, which is an essential constraint in environmental modeling studies. Nevertheless, more training data and replication in similar benchmarking studies are needed to be able to generalize the results. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Feature selection; Forest health monitoring; Hyperspectral imagery; Machine learning; Model comparison","Adaptive boosting; Decision trees; Image enhancement; Infrared devices; Random forests; Reflection; Regression analysis; Remote sensing; Spectroscopy; Support vector machines; Features selection; Features sets; Filter method; Forest health; Forest health monitoring; Highly-correlated; Machine learning techniques; Models comparisons; Performance; Predictive performance; Feature extraction"
"Schubert M., Panzarasa G., Burgert I.","Sustainability in Wood Products: A New Perspective for Handling Natural Diversity","10.1021/acs.chemrev.2c00360","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144378759&doi=10.1021%2facs.chemrev.2c00360&partnerID=40&md5=6a7df81c9017f8bab9bae1a8bff7bb25","Wood is a renewable resource with excellent qualities and the potential to become a key element of a future bioeconomy. The increasing environmental awareness and drive to achieve sustainability is leading to a resurgence of research on wood materials. Nevertheless, the global climate changes and associated consequences will soon challenge the wood-value chains in several regions (e.g., central Europe). To cope with these challenges, it is necessary to rethink the current practice of wood sourcing and transformation. The goal of this review is to address the intrinsic natural diversity of wood, from its origin to its technological consequences for the present and future manufacturing of wood products. So far, industrial processes have been optimized to repress the variability of wood properties, enabling more efficient processing and production of reliable products. However, the need to preserve biodiversity and the impact of climate change on forests call for new wood processing techniques and green chemistry protocols for wood modification as enabling factors necessary for managing a more diverse wood provision in the future. This article discusses the past developments that have resulted in the current wood value chains and provides a perspective about how natural variability could be turned into an asset for making truly sustainable wood products. After briefly introducing the chemical and structural complexity of wood, the methods conventionally adopted for industrial homogenization and modification of wood are discussed in relation to their evolution toward increased sustainability. Finally, a perspective is given on technological potentials of machine learning techniques and of novel functional wood materials. Here the main message is that through a combination of sustainable forestry, adherence to green chemistry principles and adapted processes based on machine learning, the wood industry could not only overcome current challenges but also thrive in the near future despite the awaiting challenges. © 2022 American Chemical Society.",,"Biodiversity; Chemical modification; Climate change; Forestry; Homogenization method; Machine learning; Wood products; 'current; Central Europe; Current practices; Environmental awareness; Global climate changes; Green-chemistry; Key elements; Renewable resource; Value chains; Wood materials; Sustainable development"
"Schuwirth N., Borgwardt F., Domisch S., Friedrichs M., Kattwinkel M., Kneis D., Kuemmerlen M., Langhans S.D., Martínez-López J., Vermeiren P.","How to make ecological models useful for environmental management","10.1016/j.ecolmodel.2019.108784","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071568617&doi=10.1016%2fj.ecolmodel.2019.108784&partnerID=40&md5=4ad0ce20bb730a331182c9d0c2cce3c0","Understanding and predicting the ecological consequences of different management alternatives is becoming increasingly important to support environmental management decisions. Ecological models could contribute to such predictions, but in the past this was often not the case. Ecological models are often developed within research projects but are rarely used for practical applications. In this synthesis paper, we discuss how to strengthen the role of ecological modeling in supporting environmental management decisions with a focus on methodological aspects. We address mainly ecological modellers but also potential users of modeling results. Various modeling approaches can be used to predict the response of ecosystems to anthropogenic interventions, including mechanistic models, statistical models, and machine learning approaches. Regardless of the chosen approach, we outline how to better align the modeling to the decision making process, and identify six requirements that we believe are important to increase the usefulness of ecological models for management support, especially if management decisions need to be justified to the public. These cover: (i) a mechanistic understanding regarding causality, (ii) alignment of model input and output with the management decision, (iii) appropriate spatial and temporal resolutions, (iv) uncertainty quantification, (v) sufficient predictive performance, and (vi) transparent communication. We discuss challenges and synthesize suggestions for addressing these points. © 2019 The Author(s)","Calibration; Machine learning; Mechanistic models; Stakeholder; Theory based data science; Uncertainty; Variable selection","Calibration; Ecology; Environmental management; Forecasting; Learning systems; Machine learning; Ecological consequences; Machine learning approaches; Mechanistic models; Spatial and temporal resolutions; Stakeholder; Uncertainty; Uncertainty quantifications; Variable selection; Decision making; calibration; decision making; ecological modeling; ecological theory; environmental management; machine learning; management practice; stakeholder; uncertainty analysis"
"Scoville C., Chapman M., Amironesei R., Boettiger C.","Algorithmic conservation in a changing climate","10.1016/j.cosust.2021.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101994628&doi=10.1016%2fj.cosust.2021.01.009&partnerID=40&md5=5738df7ae9e77e6373efc431febe76ef","Climate change and the adoption of artificial intelligence (AI) technologies are simultaneously reshaping environmental conservation. This article reviews the intersection of these two trends. First, we review how AI has become integrated into existing climate knowledge infrastructures and decision-making systems. Second, we review how AI is reshaping decision-making processes in the face of climate change, focusing on the governance of changing biological systems. AI is transforming data collection and classification, conservation decision-making, and rule enforcement. A crucial theme is the changing temporality of environmental governance. We emphasize automated data collection and classification, dynamic optimization and predictive enforcement. Third, we turn to emergent problems in the ethics and politics of algorithmic conservation. AI's increasingly prevalent role in conservation has the potential to introduce ethical dilemmas, redistribute power among stakeholders, and enable the emergence of new objects of knowledge and political struggles. © 2021 Elsevier B.V.",,"artificial intelligence; climate change; conservation status; decision making; governance approach; indigenous knowledge; knowledge; optimization"
"Scuri S., Ferreira M., Jardim Nunes N., Nisi V., Mulligan C.","Hiting the Triple Botom Line: Widening the HCI Approach to Sustainability","10.1145/3491102.3517518","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130567099&doi=10.1145%2f3491102.3517518&partnerID=40&md5=bb25586011dbbb47a5c092e51b6fc0bf","Sustainable Development (SD) in its dimensions - environment, economy, and society - is a growing area of concern within the HCI community. This paper advances a systematic literature review on sustainability across the Sustainable Human-Computer Interaction (SHCI) body of work. The papers were classified according to the Triple Bottom Line (TBL) framework to understand how the pillars of SD play into the HCI discourse on sustainability. The economic angle was identified as a gap in SHCI literature. To meet the TBL of SD, however, a balance needs to be sought across all 'lines'. In this paper, we propose that HCI can advance the discussion and the understanding of the economic concepts around sustainability through taking a sociology perspective on the economic angle of the TBL. We sustain this claim by discussing economic concepts and the role that digital can play in redefining the established foundations of our economic system. © 2022 Owner/Author.","Sustainable Development; Sustainable HCI; Systematic Literature Review; Triple Bottom Line","Botnet; Planning; Sustainable development; Areas of concerns; Classifieds; Economic system; Economy and society; Sustainable development; Sustainable HCI; Systematic literature review; Triple Bottom Line; Human computer interaction"
"Sepúlveda M., Arauna D., García F., Albala C., Palomo I., Fuentes E.","Frailty in Aging and the Search for the Optimal Biomarker: A Review","10.3390/biomedicines10061426","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132694913&doi=10.3390%2fbiomedicines10061426&partnerID=40&md5=cbb7a1d49fb2788f286d4037ec053db9","In the context of accelerated aging of the population worldwide, frailty has emerged as one of the main risk factors that can lead to loss of self-sufficiency in older people. This syndrome is defined as a reduced state of physiological reserve and functional capacity. The main diagnostic tools for frailty are based on scales that show deficits compared to their clinical application, such as the Fried frailty phenotype, among others. In this context, it is important to have one or more biomarkers with clinical applicability that can objectively and precisely determine the degree or risk of frailty in older people. The objective of this review was to analyze the biomarkers associated with frailty, classified according to the pathophysiological components of this syndrome (inflammation, coagula-tion, antioxidants, and liver function, among others). The evidence demonstrates that biomarkers associated with inflammation, oxidative stress, skeletal/cardiac muscle function, and platelet function represent the most promising markers of frailty due to their pathophysiological association with this syndrome. To a lesser extent but with the possibility of greater innovation, biomarkers associated with growth factors, vitamins, amino acids, and miRNAs represent alternatives as markers of this geriatric syndrome. Likewise, the incorporation of artificial intelligence represents an interesting approach to strengthening the diagnosis of frailty by biomarkers. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","aging; biomarkers; diagnosis; frailty; older people",
"Serrano E., Bajo J.","Discovering hidden mental states in open multi-agent systems by leveraging multi-protocol regularities with machine learning","10.3390/s20185198","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090561459&doi=10.3390%2fs20185198&partnerID=40&md5=8cb71bc7a471b0305e8194294d415f7a","The agent paradigm and multi-agent systems are a perfect match for the design of smart cities because of some of their essential features such as decentralization, openness, and heterogeneity. However, these major advantages also come at a great cost. Since agents’ mental states are hidden when the implementation is not known and available, intelligent services of smart cities cannot leverage information from them. We contribute with a proposal for the analysis and prediction of hidden agents’ mental states in a multi-agent system using machine learning methods that learn from past agents’ interactions. The approach employs agent communication languages, which is a core property of these multi-agent systems, to infer theories and models about agents’ mental states that are not accessible in an open system. These mental state models can be used on their own or combined to build protocol models, allowing agents (and their developers) to predict future agents’ behavior for various tasks such as testing and debugging them or making communications more efficient, which is essential in an ambient intelligence environment. This paper’s main contribution is to explore the problem of building these agents’ mental state models not from one, but from several interaction protocols, even when the protocols could have different purposes and provide distinct ambient intelligence services. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Agent communication languages; Agent-oriented software engineering; Open multi-agent system; Smart city","Ambient intelligence; Intelligent agents; Machine learning; Smart city; Agent Communication Languages; Essential features; Intelligence services; Intelligent Services; Inter-action protocols; Machine learning methods; Open multi-agent system; Testing and debugging; Multi agent systems; ambient intelligence; article; human; human experiment; language; machine learning; mental health; prediction; software"
"Serre L., Amyot-Bourgeois M.","An Application of Automated Machine Learning Within a Data Farming Process","10.1109/WSC57314.2022.10015513","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147417458&doi=10.1109%2fWSC57314.2022.10015513&partnerID=40&md5=d2c3ea428c4d3ce823b5354a4a98fe89","Data farming is a simulation-based methodology used within the defense community to analyze complex systems and provide insights to decision makers. It can produce very large, multi-dimensional data sets that require sophisticated analysis tools, such as metamodeling. Advances in explainable artificial intelligence have expanded the types of metamodels that can be considered; however, constructing a well-fitting machine learning metamodel involves many tasks that can become time consuming for an analyst. Automated machine learning (autoML) can save an analyst time by automating metamodel training, tuning and testing. Using outputs of an agent-based simulation of a military ground-based air defense scenario, we compared the performance of metamodels trained using autoML and different experimental designs. We found that autoML can reasonably automate the construction of metamodels and adds robustness to the analysis by considering multiple types of metamodels; however, the type and size of experimental design can significantly impact metamodel performance. © 2022 IEEE.",,"Decision making; Design of experiments; Network security; Statistics; Analysis tools; Automated machines; Data farming; Data set; Decision makers; Machine-learning; Meta model; Metamodeling; Multidimensional data; Performance; Machine learning"
"Serre L., Amyot-Bourgeois M., Astles B.","Use of Shapley Additive Explanations in Interpreting Agent-Based Simulations of Military Operational Scenarios","10.23919/ANNSIM52504.2021.9552151","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117383633&doi=10.23919%2fANNSIM52504.2021.9552151&partnerID=40&md5=b1dec8ec693efd15c0e3429a18dcd7f5","Military defense modernization initiatives often involve complex systems that must be understood to inform design, planning, implementation and acquisition decisions. To gain a basic understanding of the system and identify key initial parameters, simulation experiments can be used to generate-or farm-data efficiently and effectively over a large parametric space. While machine learning models can be used for post-simulation analysis to identify key parameters, interpretability and their black-box nature can present challenges when the intent is to provide support to decision makers. In this paper, we apply a model-agnostic method for interpreting machine learning predictions, known as SHapley Additive exPlanations (SHAP), to data farmed from an agent-based simulation that models a military operational scenario. The scenario is motivated by a Canadian Army initiative to modernize its intelligence, surveillance, and reconnaissance assets and abstracted to minimize the complexity of the modeled system and validate the findings of SHAP. © 2021 SCS.","agent-based simulation; data farming; explainable machine learning","Decision making; Machine learning; Acquisition decision; Agent based simulation; Data farming; Defense modernization; Design decisions; Design planning; Explainable machine learning; Military defense; Operational scenario; Shapley; Additives"
"Serré L., Amyot-Bourgeois M., Astles B.","Use of shapley additive explanations in interpreting agent-based simulations of military operational scenarios",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118532203&partnerID=40&md5=9ae7cde7798a7ec1b267e6b77795e71d","Military defensemodernization initiatives often involve complex systems that must be understood to inform design, planning, implementation and acquisition decisions. To gain a basic understanding of the system and identify key initial parameters, simulation experiments can be used to generate - or farm - data efficiently and effectively over a large parametric space. While machine learning models can be used for post-simulation analysis to identify key parameters, interpretability and their black-box nature can present challenges when the intent is to provide support to decision makers. In this paper, we apply a modelagnostic method for interpreting machine learning predictions, known as SHapley Additive exPlanations (SHAP), to data farmed from an agent-based simulation that models a military operational scenario. The scenario is motivated by a Canadian Army initiative to modernize its intelligence, surveillance, and reconnaissance assets and abstracted to minimize the complexity of the modeled system and validate the findings of SHAP. © 2021 Society for Modeling & Simulation International (SCS).","Agent-based simulation; Data farming; Explainable machine learning","Decision making; Machine learning; Acquisition decision; Agent based simulation; Data farming; Design decisions; Design planning; Explainable machine learning; Initial parameter; Operational scenario; Parameter simulations; Shapley; Additives"
"Severinsen A., Myrland Ø.","Statistical learning to estimate energy savings from retrofitting in the Norwegian food retail market","10.1016/j.rser.2022.112691","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132228564&doi=10.1016%2fj.rser.2022.112691&partnerID=40&md5=4dce03eef9ad5188bb8dbab692790ac7","Buildings worldwide consume about 40% of all produced energy and are major contributors to GHG emissions. Hence, to reach the 2030 European energy efficiency target it is vital to reduce the energy consumption in buildings. An important barrier that hinders renovation projects is uncertainty regarding the expected savings. The main objective of this paper is to present two different statistical methods to estimate energy savings. The two methods are easy to implement for practitioners within the energy retrofitting industry, and at the same time has acceptable precision and reliability. The two methods are applied at 5 different food retail stores that undertook renovation in 2019. The models are trained on data from 2018 (one whole year before any of the retrofitting's took place) and are further applied to estimate the energy savings in 2021. The first method is the Tao Vanilla benchmarking method (TVB). The TVB model predict energy consumption in buildings on an hourly level. The model has received a lot of attention within the load forecasting literature and has previously proved its performance in machine learning competitions. The TVB has a straightforward specification, and the model parameters are easily understood. This is the first study that apply the TVB to estimate energy savings in a large retrofitting project within the energy and building sector. The second method relies on a more common industrial approach, which is to use weekly data and energy temperature curves to document energy savings. In addition, we demonstrate a novel approach of using broken line (BL) models to estimate energy savings. The suggested BL approach can simultaneously estimate all the model parameters and yield a full covariance matrix within a standard linear regression framework. The results from the retrofitting projects demonstrates considerable energy savings between 25% and 55%. Furthermore, both the TVB and the BL models deliver reliable precision. The estimated energy savings from both models are coinciding. This indicates that they could jointly be used to gain insight that may lead to more informed decisions for energy saving projects. The TVB model proves to be a proficient benchmarking model that can give detailed hourly information about the savings. The BL model is used to gain intrinsic details about the buildings varying cooling and heating needs depending on the outside temperature during the year. © 2022 Elsevier Ltd","Broken line models; Building energy retrofitting; Data driven models; Energy savings evaluation; Measurement and verification; Tao Vanilla Benchmark model","Benchmarking; Buildings; Covariance matrix; Energy efficiency; Greenhouse gases; Learning systems; Retail stores; Retrofitting; Benchmark models; Broken line model; Building energy; Building energy retrofitting; Data-driven model; Energy saving evaluation; Energy-savings; Line models; Measurement and verification; Tao vanillum benchmark model; Energy utilization"
"Seymoens T., Ongenae F., Jacobs A., Verstichel S., Ackaert A.","A methodology to involve domain experts and machine learning techniques in the design of human-centered algorithms","10.1007/978-3-030-05297-3_14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059895613&doi=10.1007%2f978-3-030-05297-3_14&partnerID=40&md5=1f093cfe2685ec929a7c04f0c9ebe161","Machine learning techniques are increasingly applied in Decision Support Systems. The selection processes underlying a conclusion often become black-boxed. Thus, the decision flow is not always comprehensible by developers or end users. It is unclear what the priorities are and whether all of the relevant information is used. In order to achieve human interpretability of the created algorithms, it is recommended to include domain experts in the modelling phase. Their knowledge is elicited through a combination of machine learning and social science techniques. The idea is not new, but it remains a challenge to extract and apply the experts’ experience without overburdening them. The current paper describes a methodology set to unravel, define and categorize the implicit and explicit domain knowledge in a less intense way by making use of co-creation to design human-centered algorithms, when little data is available. The methodology is applied to a case in the health domain, targeting a rheumatology triage problem. The domain knowledge is obtained through dialogue, by alternating workshops and data science exercises. © IFIP International Federation for Information Processing 2019.","Decision support systems; Human-centered algorithms; Knowledge elicitation methods; Knowledge engineering","Artificial intelligence; Decision support systems; Knowledge engineering; Learning algorithms; Co-creation; Domain experts; Domain knowledge; End users; Interpretability; Machine learning techniques; Learning systems"
"Sghaireen M.G., Al-Smadi Y., Al-Qerem A., Srivastava K.C., Ganji K.K., Alam M.K., Nashwan S., Khader Y.","Machine Learning Approach for Metabolic Syndrome Diagnosis Using Explainable Data-Augmentation-Based Classification","10.3390/diagnostics12123117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144904616&doi=10.3390%2fdiagnostics12123117&partnerID=40&md5=d95f6ed083c3d2f9abeffd03ddb15535","Metabolic syndrome (MetS) is a cluster of risk factors including hypertension, hyperglycemia, dyslipidemia, and abdominal obesity. Metabolism-related risk factors include diabetes and heart disease. MetS is also linked to numerous cancers and chronic kidney disease. All of these variables raise medical costs. Developing a prediction model that can quickly identify persons at high risk of MetS and offer them a treatment plan is crucial. Early prediction of metabolic syndrome will highly impact the quality of life of patients as it gives them a chance for making a change to the bad habit and preventing a serious illness in the future. In this paper, we aimed to assess the performance of various algorithms of machine learning in order to decrease the cost of predictive diagnoses of metabolic syndrome. We employed ten machine learning algorithms along with different metaheuristics for feature selection. Moreover, we examined the effects of data augmentation in the prediction accuracy. The statistics show that the augmentation of data after applying feature selection on the data highly improves the performance of the classifiers. © 2022 by the authors.","data augmentation; diagnostic algorithms; disease diagnosis; feature selection; metabolic syndrome",
"Shah D.A., Butts T.R., Mourtzinis S., Rattalino Edreira J.I., Grassini P., Conley S.P., Esker P.D.","A machine learning interpretation of the contribution of foliar fungicides to soybean yield in the north‐central United States","10.1038/s41598-021-98230-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115371772&doi=10.1038%2fs41598-021-98230-2&partnerID=40&md5=b3dd4062ce9ed25646fa309abd9cb779","Foliar fungicide usage in soybeans in the north-central United States increased steadily over the past two decades. An agronomically-interpretable machine learning framework was used to understand the importance of foliar fungicides relative to other factors associated with realized soybean yields, as reported by growers surveyed from 2014 to 2016. A database of 2738 spatially referenced fields (of which 30% had been sprayed with foliar fungicides) was fit to a random forest model explaining soybean yield. Latitude (a proxy for unmeasured agronomic factors) and sowing date were the two most important factors associated with yield. Foliar fungicides ranked 7th out of 20 factors in terms of relative importance. Pairwise interactions between latitude, sowing date and foliar fungicide use indicated more yield benefit to using foliar fungicides in late-planted fields and in lower latitudes. There was a greater yield response to foliar fungicides in higher-yield environments, but less than a 100 kg/ha yield penalty for not using foliar fungicides in such environments. Except in a few production environments, yield gains due to foliar fungicides sufficiently offset the associated costs of the intervention when soybean prices are near-to-above average but do not negate the importance of disease scouting and fungicide resistance management. © 2021, The Author(s).",,
"Shah S.F.A., Chen B., Zahid M., Ahmad M.R.","Compressive strength prediction of one-part alkali activated material enabled by interpretable machine learning","10.1016/j.conbuildmat.2022.129534","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141267350&doi=10.1016%2fj.conbuildmat.2022.129534&partnerID=40&md5=91b1fb1a1efb05fd5f74a0c8fa6c8c81","In recent years, alkali activated material (AAM) or geopolymer has emerged as a sustainable and eco-friendly alternative to cement. It is owing to its low power consumption and greenhouse gas emissions, as well as good mechanical and durability features. However, due to the nature and diversity of available source materials, developing an AAM mix to attain desirable fresh properties, sufficient strength characteristics, and touted environmental benefits is quite challenging. It demands a precise selection of input material and mix proportions based on several trials, which requires a large quantity of material, time, and effort. Therefore, employing machine learning techniques could facilitate and accelerate the development of one-part AAM binder with the desired properties. This study evaluates the performance of various machine learning models (Ridge regression, RF, LightGBM, and XGBoost) for accurate compressive strength prediction of one-part AAM binder. Extreme Gradient Boost (XGBoost) outperformed all other algorithms in terms of prediction efficacy and accuracy. In addition, SHapley Additive exPlanations (SHAP) is also used to interpret the predicted compressive strength through XGBoost and the effect of various parameters, independently and in relation with other parameters, is evaluated and discussed in detail. The interpretable ML strategy used in this study will aid in the production and performance tuning of durable and sustainable one-part AAMs for widespread applications. © 2022 Elsevier Ltd","Compressive strength; Machine learning; One-part AAM; SHAP; XGBoost","Forecasting; Gas emissions; Greenhouse gases; Machine learning; Regression analysis; Sustainable development; Activated materials; Alkali-activated; Geopolymer; Machine-learning; One parts; One-part alkali activated material; Shapley; Shapley additive explanation; Strength prediction; Xgboost; Compressive strength"
"Shah S.F.A., Iqbal M., Aziz Z., Rana T.A., Khalid A., Cheah Y.-N., Arif M.","The Role of Machine Learning and the Internet of Things in Smart Buildings for Energy Efficiency","10.3390/app12157882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136984837&doi=10.3390%2fapp12157882&partnerID=40&md5=873c3b4b4c081f3490c016c495848785","Machine learning can be used to automate a wide range of tasks. Smart buildings, which use the Internet of Things (IoT) to connect building operations, enable activities, such as monitoring temperature, safety, and maintenance, for easier controlling via mobile devices and computers. Smart buildings are becoming core aspects in larger system integrations as the IoT is becoming increasingly widespread. The IoT plays an important role in smart buildings and provides facilities that improve human security by using effective technology-based life-saving strategies. This review highlights the role of IoT devices in smart buildings. The IoT devices platform and its components are highlighted in this review. Furthermore, this review provides security challenges regarding IoT and smart buildings. The main factors pertaining to smart buildings are described and the different methods of machine learning in combination with IoT technologies are also described to improve the effectiveness of smart buildings to make them energy efficient. © 2022 by the authors.","challenges in smart buildings; Internet of Things; IoT applications; machine learning; smart buildings",
"Shaharum N.S.N., Shafri H.Z.M., Ghani W.A.W.A.K., Samsatli S., Al-Habshi M.M.A., Yusuf B.","Oil palm mapping over Peninsular Malaysia using Google Earth Engine and machine learning algorithms","10.1016/j.rsase.2020.100287","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078101296&doi=10.1016%2fj.rsase.2020.100287&partnerID=40&md5=0f2cbd69ee8dccde76c778f2f802d28e","Oil palm plays a pivotal role in the ecosystem, environment, economy and without proper monitoring, uncontrolled oil palm activities could contribute to deforestation that can cause high negative impacts on the environment and therefore, proper management and monitoring of the oil palm industry are necessary. Mapping the distribution of oil palm is crucial in order to manage and plan the sustainable operations of oil palm plantations. Remote sensing provides a means to detect and map oil palm from space effectively. Recent advances in cloud computing and big data allow rapid mapping to be performed over large a geographical scale. In this study, 30 m Landsat 8 data were processed using a cloud computing platform of Google Earth Engine (GEE) in order to classify oil palm land cover using non-parametric machine learning algorithms such as Support Vector Machine (SVM), Classification and Regression Tree (CART) and Random Forest (RF) for the first time over Peninsular Malaysia. The hyperparameters were tuned, and the overall accuracy produced by the SVM, CART and RF were 93.16%, 80.08% and 86.50% respectively. Overall, the SVM classified the 7 classes (water, built-up, bare soil, forest, oil palm, other vegetation and paddy) the best. However, RF extracted oil palm information better than the SVM. The algorithms were compared and the McNemar's test showed significant values for comparisons between SVM and CART and RF and CART. On the other hand, the performance of SVM and RF are considered equally effective. Despite the challenges in implementing machine learning optimisation using GEE over a large area, this paper shows the efficiency of GEE as a cloud-based free platform to perform bioresource distributions mapping such as oil palm over a large area in Peninsular Malaysia. © 2020 Elsevier B.V.","Cloud computing; Image classification; Landsat; Machine learning; Oil palm",
"Shahhosseini M., Hu G., Archontoulis S.V.","Forecasting Corn Yield With Machine Learning Ensembles","10.3389/fpls.2020.01120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089431053&doi=10.3389%2ffpls.2020.01120&partnerID=40&md5=e568e86f03e53d7d4f332fa1754c1b28","The emergence of new technologies to synthesize and analyze big data with high-performance computing has increased our capacity to more accurately predict crop yields. Recent research has shown that machine learning (ML) can provide reasonable predictions faster and with higher flexibility compared to simulation crop modeling. However, a single machine learning model can be outperformed by a “committee” of models (machine learning ensembles) that can reduce prediction bias, variance, or both and is able to better capture the underlying distribution of the data. Yet, there are many aspects to be investigated with regard to prediction accuracy, time of the prediction, and scale. The earlier the prediction during the growing season the better, but this has not been thoroughly investigated as previous studies considered all data available to predict yields. This paper provides a machine leaning based framework to forecast corn yields in three US Corn Belt states (Illinois, Indiana, and Iowa) considering complete and partial in-season weather knowledge. Several ensemble models are designed using blocked sequential procedure to generate out-of-bag predictions. The forecasts are made in county-level scale and aggregated for agricultural district and state level scales. Results show that the proposed optimized weighted ensemble and the average ensemble are the most precise models with RRMSE of 9.5%. Stacked LASSO makes the least biased predictions (MBE of 53 kg/ha), while other ensemble models also outperformed the base learners in terms of bias. On the contrary, although random k-fold cross-validation is replaced by blocked sequential procedure, it is shown that stacked ensembles perform not as good as weighted ensemble models for time series data sets as they require the data to be non-IID to perform favorably. Comparing our proposed model forecasts with the literature demonstrates the acceptable performance of forecasts made by our proposed ensemble model. Results from the scenario of having partial in-season weather knowledge reveals that decent yield forecasts with RRMSE of 9.2% can be made as early as June 1st. Moreover, it was shown that the proposed model performed better than individual models and benchmark ensembles at agricultural district and state-level scales as well as county-level scale. To find the marginal effect of each input feature on the forecasts made by the proposed ensemble model, a methodology is suggested that is the basis for finding feature importance for the ensemble model. The findings suggest that weather features corresponding to weather in weeks 18–24 (May 1st to June 1st) are the most important input features. © Copyright © 2020 Shahhosseini, Hu and Archontoulis.","corn yields; ensemble; forecasting; machine learning; US Corn Belt",
"Shaikh N.P., Mahar M.H.","Deep learning framework for classification of emoji based sentiments","10.32604/cmc.2022.024843","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127352364&doi=10.32604%2fcmc.2022.024843&partnerID=40&md5=e1ee6f1888a01a7ea9f2bc82a27b3f84","Recent patterns of human sentiments are highly influenced by emoji based sentiments (EBS). Social media users are widely using emoji based sentiments (EBS) in between text messages, tweets and posts. Although tiny pictures of emoji contains sufficient information to be considered for construction of classification model; but due to the wide range of dissimilar, heterogynous and complex patterns of emoji with similarmeanings (SM) have become one of the significant research areas of machine vision. This paper proposes an approach to provide meticulous assistance to social media application (SMA) users to classify the EBS sentiments. Proposed methodology consists upon three layerswhere first layer deals with data cleaning and feature selection techniques to detect dissimilar emoji patterns (DEP) with similar meanings (SM). In first sub step we input set of emoji, in second sub step every emoji has to qualify user defined threshold, in third sub step algorithm detects every emoji by considering as objects and in fourth step emoji images are cropped, after data cleaning these tiny images are saved as emoji images. In second step we build classification model by using convolutional neural networks (CNN) to explore hidden knowledge of emoji datasets. In third step we present results visualization by using confusion matrix and other estimations. This paper contributes (1) data cleaning method to detect EBS; (2) highest classification accuracy for emoji classification measured as 97.63%. © 2022 Tech Science Press. All rights reserved.","Convolutional neural networkscsocial media; Deep learning; Emoji based sentiments; Machine vision","Classification (of information); Cleaning; Computer vision; Convolutional neural networks; Deep learning; Object detection; Social networking (online); Classification models; Complex pattern; Convolutional neural networkscsocial medium; Data cleaning; Deep learning; Emoji based sentiment; Learning frameworks; Machine-vision; Research areas; Social media; Convolution"
"Shao F.","New energy industry financial technology based on machine learning to help rural revitalization","10.1016/j.egyr.2022.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140902726&doi=10.1016%2fj.egyr.2022.10.001&partnerID=40&md5=cf58a1ee94073f7621743c8271747441","Rural economic development plays an important role in China's economic development, which can not only directly drive the development of the primary industry, but also indirectly drive the development of China's secondary and tertiary industries. With the development of the times and the advancement of science and technology, the application of intelligent technology in rural areas has become increasingly difficult in the context of social digital transformation, and the digital divide in large rural areas has widened, the energy industry financial technology is not satisfactory. In this context, in order to fully implement the rural revitalization strategy, bridge the digital divide between urban and rural areas, accelerate the pace of urban and rural financial technology, revitalize rural industries as soon as possible, and revitalize rural talents, this paper used machine learning algorithms to apply new energy industry fintech technology to rural revitalization. It can not only reduce the problem of rural information asymmetry, but also improve the rural economic level by 13.7%, which laid the foundation for the implementation of the strategy of technology-assisted financial services for rural revitalization. © 2022 The Author","Financial technology; Machine learning; New energy industry; Rural revitalization","Economic and social effects; Engineering education; Finance; Learning algorithms; Machine learning; Digital divide; Economic development; Financial technology; Machine-learning; New energy industries; On-machines; Rural revitalization; Science and Technology; Technology-based; Tertiary industries; Rural areas"
"Sharma A., Sharma V., Jaiswal M., Wang H.-C., Jayakody D.N.K., Basnayaka C.M.W., Muthanna A.","Recent Trends in AI-Based Intelligent Sensing","10.3390/electronics11101661","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130820769&doi=10.3390%2felectronics11101661&partnerID=40&md5=e94c3fcac3f9b62e3ff8046bb8902dba","In recent years, intelligent sensing has gained significant attention because of its autonomous decision-making ability to solve complex problems. Today, smart sensors complement and enhance the capabilities of human beings and have been widely embraced in numerous application areas. Artificial intelligence (AI) has made astounding growth in domains of natural language processing, machine learning (ML), and computer vision. The methods based on AI enable a computer to learn and monitor activities by sensing the source of information in a real-time environment. The combination of these two technologies provides a promising solution in intelligent sensing. This survey provides a comprehensive summary of recent research on AI-based algorithms for intelligent sensing. This work also presents a comparative analysis of algorithms, models, influential parameters, available datasets, applications and projects in the area of intelligent sensing. Furthermore, we present a taxonomy of AI models along with the cutting edge approaches. Finally, we highlight challenges and open issues, followed by the future research directions pertaining to this exciting and fast-moving field. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","artificial intelligence; datasets; intelligent sensing; IoT; learning algorithms; machine learning; neural networks",
"Sharma M., Nath K., Sharma R.K., Kumar C.J., Chaudhary A.","Ensemble Averaging of Transfer Learning Models for Identification of Nutritional Deficiency in Rice Plant","10.3390/electronics11010148","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122138985&doi=10.3390%2felectronics11010148&partnerID=40&md5=d3f9468a0c448530d7bceb220e9275ee","Computer vision-based automation has become popular in detecting and monitoring plants’ nutrient deficiencies in recent times. The predictive model developed by various researchers were so designed that it can be used in an embedded system, keeping in mind the availability of computational resources. Nevertheless, the enormous popularity of smart phone technology has opened the door of opportunity to common farmers to have access to high computing resources. To facilitate smart phone users, this study proposes a framework of hosting high end systems in the cloud where processing can be done, and farmers can interact with the cloud-based system. With the availability of high computational power, many studies have been focused on applying convolutional Neural Networks-based Deep Learning (CNN-based DL) architectures, including Transfer learning (TL) models on agricultural research. Ensembling of various TL architectures has the potential to improve the performance of predictive models by a great extent. In this work, six TL architectures viz. InceptionV3, ResNet152V2, Xception, DenseNet201, InceptionResNetV2, and VGG19 are considered, and their various ensemble models are used to carry out the task of deficiency diagnosis in rice plants. Two publicly available datasets from Mendeley and Kaggle are used in this study. The ensemble-based architecture enhanced the highest classification accuracy to 100% from 99.17% in the Mendeley dataset, while for the Kaggle dataset; it was enhanced to 92% from 90%. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Ensemble learning; ML/DL methods; Nutrient deficiency; Rice deficiency identification; Transfer learning",
"Sharma R., Shishodia A., Gunasekaran A., Min H., Munim Z.H.","The role of artificial intelligence in supply chain management: mapping the territory","10.1080/00207543.2022.2029611","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125088338&doi=10.1080%2f00207543.2022.2029611&partnerID=40&md5=ae1c78458e132d8a32520b22c2719e9f","The study aims to identify the current trends, gaps, and research opportunities in research pertaining to the disruptive field of artificial intelligence (AI) applications in supply chain management (SCM). Since SCM represents managerial innovation due to its new way of integrated system thinking, SCM has emerged as one of the most fruitful business disciplines for AI applications. The study utilises bibliometric review in tracing the evolution of AI research in SCM and further synthesises decades of past AI research efforts to develop viable solutions for various supply chain problems and then proposes promising future research themes that would enrich supply chain decision-aid tools. The study identified five main research clusters through scholarly network and content analysis. The identified themes were: (a) supply chain network design (SCND), (b) supplier selection, (c) inventory planning, (d) demand planning, and (e) green supply chain management. As the role of AI in SCM continues to grow, there is a growing need for exploiting AI as a way to add value to supply chain process. The study proposes a research framework which will help academicians and practitioners in identifying current research patterns of AI in SCM. © 2022 Informa UK Limited, trading as Taylor & Francis Group.","Artificial intelligence; bibliometric analysis; citation analysis; supply chain management; trend analysis","Artificial intelligence; Decision support systems; Systems thinking; 'current; Artificial intelligence research; Bibliometric; Bibliometrics analysis; Citation analysis; Integrated systems; Research efforts; Research opportunities; System thinkings; Trend analysis; Supply chain management"
"Sheikholeslami R., Hall J.W.","Global patterns and key drivers of stream nitrogen concentration: A machine learning approach","10.1016/j.scitotenv.2023.161623","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146539054&doi=10.1016%2fj.scitotenv.2023.161623&partnerID=40&md5=7feba7ec77d41bfb79f28ba4ffbc0e2c","Anthropogenic loading of nitrogen to river systems can pose serious health hazards and create critical environmental threats. Quantification of the magnitude and impact of freshwater nitrogen requires identifying key controls of nitrogen dynamics and analyzing both the past and present patterns of nitrogen flows. To tackle this challenge, we adopted a machine learning (ML) approach and built an ML-driven representation that captures spatiotemporal variability in nitrogen concentrations at global scale. Our model uses random forests to regress a large sample of monthly measured stream nitrogen concentrations onto a set of 17 predictors with a spatial resolution of 0.5-degree over the 1990–2013, including observations within the pixel and upstream drivers. The model was validated with data from rivers outside the training dataset and was used to predict nitrogen concentrations in 520 major river basins of the world, including many with scarce or no observations. We predicted that the regions with highest median nitrogen concentrations in their rivers (in 2013) were: United States (Mississippi), Pakistan, Bangladesh, India (Indus, Ganges), China (Yellow, Yangtze, Yongding, Huai), and most of Europe (Rhine, Danube, Vistula, Thames, Trent, Severn). Other major hotspots were the river basins of the Sebou (Morroco), Nakdong (South Korea), Kitakami (Japan), and Egypt's Nile Delta. Our analysis showed that the rate of increase in nitrogen concentration between 1990s and 2000s was greatest in rivers located in eastern China, eastern and central parts of Canada, Baltic states, Pakistan, mainland southeast Asia, and south-eastern Australia. Using a new grouped variable importance measure, we also found that temporality (month of the year and cumulative month count) is the most influential predictor, followed by factors representing hydroclimatic conditions, diffuse nutrient emissions from agriculture, and topographic features. Our model can be further applied to assess strategies designed to reduce nitrogen pollution in freshwater bodies at large spatial scales. © 2023 The Authors","Global water quality; Hotspot analysis; Nitrogen pollution; Random forests; Variable importance","Forestry; Health hazards; Health risks; Machine learning; Nitrogen; Quality control; River pollution; Rivers; Watersheds; Global water quality; Hotspot analyse; Hotspots; Machine learning approaches; Nitrogen concentrations; Nitrogen pollution; Pakistan; Random forests; River basins; Variable importances; Water quality; algorithm; concentration (composition); machine learning; nitrogen; river pollution; stream; water quality; Bangladesh; China; Danube River; Egypt; England; Ganges River; Honshu; Huai River; India; Indus River; Japan; Kitakami River; Mississippi River; Morocco; Nakdong River; Nile Delta; Pakistan; Poland [Central Europe]; Rhine River; Sebou River; Severn River [United Kingdom]; South Korea; Thames River [England]; Tohoku; Trent River [England]; United Kingdom; United States; Vistula River; Yangtze River; Yellow River; Yongding River [China]"
"Shen Y., Zhao E., Zhang W., Baccarelli A.A., Gao F.","Predicting pesticide dissipation half-life intervals in plants with machine learning models","10.1016/j.jhazmat.2022.129177","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131139880&doi=10.1016%2fj.jhazmat.2022.129177&partnerID=40&md5=7f50ce0b39ba2ca22c3eec9d4fbd4414","Pesticide dissipation half-life in plants is an important factor to assessing environmental fate of pesticides and establishing pre-harvest intervals critical to good agriculture practices. However, empirically measured pesticide dissipation half-lives are highly variable and the accurate prediction with models is challenging. This study utilized a dataset of pesticide dissipation half-lives containing 1363 datapoints, 311 pesticides, 10 plant types, and 4 plant component classes. Novel dissipation half-life intervals were proposed and predicted to account for high variations in empirical data. Four machine learning models (i.e., gradient boosting regression tree [GBRT], random forest [RF], supporting vector classifier [SVC], and logistic regression [LR]) were developed to predict dissipation half-life intervals using extended connectivity fingerprints (ECFP), temperature, plant type, and plant component class as model inputs. GBRT-ECFP had the best model performance with F1-microbinary score of 0.698 ± 0.010 for the binary classification compared with other machine learning models (e.g., LR-ECFP, F1-microbinary= 0.662 ± 0.009). Feature importance analysis of molecular structures in the binary classification identified aromatic rings, carbonyl group, organophosphate, =C-H, and N-containing heterocyclic groups as important substructures related to pesticide dissipation half-lives. This study suggests the utility of machine learning models in assessing the environmental fate of pesticides in agricultural crops. © 2022 Elsevier B.V.","Dissipation half-life; Extended connectivity fingerprints; Gradient boosting regression tree; Machine Learning; Molecular structure; Pesticide","Adaptive boosting; Decision trees; Forecasting; Forestry; Logistic regression; Machine learning; Molecular structure; Pesticides; Random forests; Boosting regression trees; Dissipation half-life; Environmental fate; Extended connectivity fingerprint; Gradient boosting; Gradient boosting regression tree; Half lives; Machine learning models; Machine-learning; Pesticide dissipations; Crops; acaricide; antinematodal agent; bactericide; fungicide; heterocyclic compound; insecticide; molluscacide; organophosphate; pesticide; pesticide; connectivity; data set; environmental fate; machine learning; molecular analysis; pesticide; prediction; regression analysis; Article; chemical structure; controlled study; crop; decision tree; environmental impact; k means clustering; logistic regression analysis; machine learning; molecular fingerprinting; prediction error; random forest; agriculture; half life time; machine learning; plant; Agriculture; Half-Life; Machine Learning; Pesticides; Plants"
"Shen Y., Hamm J.A., Gao F., Ryser E.T., Zhang W.","Assessing consumer buy and pay preferences for labeled food products with statistical and machine learning methods","10.4315/JFP-20-486","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113335223&doi=10.4315%2fJFP-20-486&partnerID=40&md5=b0e3da36aa4262188cff036c792ba320","Food labeling is one approach to encourage safe, healthy, and sustainable dietary practices. Consumer buy and pay preferences for specially labeled food products (e.g., U.S. Department of Agriculture organic, raised without antibiotics, and locally raised) may promote the adoption of associated production practices by food producers. Thus, it is important to understand how consumer buy and pay preferences for specially labeled products vary with their demographics, food-relevant habits, and foodborne disease perceptions. Using both conventional statistical and novel machine learning models, this study analyzed Michigan State University Environmental Science and Policy Program annual survey data (2019) to characterize consumer buy and pay preferences regarding eight labels related to food production practices. Older consumer age was significantly associated with lower consumer willingness to pay more for labeled products. Participants who prefer to shop in nonconventional grocery stores were more willing to buy and pay more for labeled products. Our machine learning models provide a new approach for analyzing food safety and labeling survey data and produced adequate average prediction accuracy scores for all eight labels. The label ""raised without antibiotics""had the highest average prediction accuracy for consumer willingness to buy. Thus, the machine learning models may be used to analyze food survey data and help develop strategies for promoting healthy food production practices. Copyright © International Association for Food Protection.","Consumer preference; Food; Food labeling; Machine learning","agriculture; consumer attitude; food packaging; food preference; human; machine learning; questionnaire; Agriculture; Consumer Behavior; Food Labeling; Food Preferences; Humans; Machine Learning; Surveys and Questionnaires"
"Shendryk Y.","Fusing GEDI with earth observation data for large area aboveground biomass mapping","10.1016/j.jag.2022.103108","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141958507&doi=10.1016%2fj.jag.2022.103108&partnerID=40&md5=90e4245c7dfc70a870b8bb0ade80cd06","An accurate and spatially explicit estimation of biomass is required for sustainable forest management, prevention of biodiversity loss, and carbon accounting for climate change mitigation. This study offers a methodology to generate wall-to-wall aboveground biomass density (AGBD) maps that exclusively relies on open access earth observation (EO) data. Specifically, spaceborne Global Ecosystem Dynamics Investigation (GEDI) LiDAR data were fused with Sentinel-1 synthetic-aperture radar, Sentinel-2 multispectral, elevation, and land cover data to produce biomass maps of Australia and the United States for 2020. The gradient boosting machine learning framework was applied to predict AGBD and its uncertainty at the resolutions of 100 m and 200 m. The performance of models based on (1) Sentinel-2 imagery and land cover and (2) a combination of Sentinel-2 and Sentinel-1 imagery with elevation and land cover data were compared. The most accurate gradient boosting model was identified using a Bayesian hyperparameter optimization with a 5-fold cross-validation. The Sentinel-2 imagery and land cover data analysis resulted in AGBD estimated with the coefficient of determination (R2) of 0.61 – 0.71, root-mean-square error (RMSE) of 59 – 86 Mg/ha, and relative root-mean-square error (RMSE%) of 45 – 80%. The accuracy of the models improved with the addition of Sentinel-1 and elevation data: AGBD estimation with R2 of 0.66 – 0.74, RMSE of 55 – 81 Mg/ha, and RMSE% of 41 – 77%. It was found that Sentinel-2 and land cover-derived predictors were the most important in estimating annual AGBD. The proposed method also reduced the saturation effect, which is common in high biomass areas when predicting AGBD using satellite imagery. Prediction maps produced in this study could serve as a baseline for current AGB stocks of forested lands equal to 9.8 Pg and 37.1 Pg in Australia and the United States, respectively. Overall, this research highlights methodological opportunities for combining open access EO data to yield more accurate and globally applicable AGB maps through data fusion. © 2022","Biomass; Data fusion; GEDI; LiDAR; Machine learning; Remote sensing; Satellite imagery","aboveground biomass; computer simulation; digital mapping; GIS; land cover; lidar; machine learning; satellite data; satellite imagery"
"Shendryk Y., Gorrod E.","Leveraging Airborne LiDAR Data and Gradient Boosting for Mapping the Density of Different Sized Trees","10.1109/JSTARS.2020.3046303","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098790605&doi=10.1109%2fJSTARS.2020.3046303&partnerID=40&md5=b69df993d85458ecd3cbb5ad57e80c03","Information on the distribution of trees with different diameters at breast height (DBH) is needed to inform management programs aimed at achieving conservation objectives in high stem density forest stands. This article explored the feasibility of mapping the density of trees with different DBHs using airborne LiDAR data. Experiments were conducted in the largest river red gum forest in the world, located in the southeast of Australia. Field measured data on trees with different DBHs were used for the supervised learning of airborne LiDAR scans with a pulse density of 5.92 pulses/m2. Specifically, the hyperparameters of gradient boosting and random forest regressors were tuned to produce a viable solution for mapping the density of different sized trees at the plot level. Our results indicate that the total tree density (DBH > 0 cm; height > 1.37 m) can be mapped using airborne LiDAR data with the coefficient of determination R2 of up to 0.67, with gradient boosting outperforming random forest. However, the accuracy of mapping the density of saplings (DBH ≤ 10 cm), small trees (10 cm < DBH ≤ 50 cm), and large trees (DBH > 50 cm) differed with R2 of 0.65, 0.60, and 0.42, respectively. These results show that the airborne LiDAR data can provide a viable solution for mapping the density of small trees (DBH ≤ 50 cm) over large areas and has the potential for mapping the density of large trees (DBH > 50 cm). © 2008-2012 IEEE.","Density; diameter at breast height (DBH); forest; gradient boosting; light detection and ranging (LiDAR); machine learning; random forest","Decision trees; Mapping; Optical radar; Random forests; Airborne lidar data; Coefficient of determination; Diameters at breast heights; Field-measured data; Gradient boosting; Hyper-parameter; Management programs; Viable solutions; Forestry; airborne sensing; algorithm; height determination; lidar; machine learning; population density; satellite data; vegetation mapping; Australia"
"Shendryk Y., Davy R., Thorburn P.","Integrating satellite imagery and environmental data to predict field-level cane and sugar yields in Australia using machine learning","10.1016/j.fcr.2020.107984","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094617083&doi=10.1016%2fj.fcr.2020.107984&partnerID=40&md5=a068b487dbdd9b376c47ed14c27153be","An accurate model for predicting sugarcane yield will benefit many aspects of managing growth and harvest of sugarcane crops. In this study, Sentinel-1 and Sentinel-2 satellite imagery were used in combination with climate, soil and elevation data to predict field-level sugarcane yield across the multiple sugar mill areas in the Wet Tropics of Australia at different time steps over four consecutive growing seasons (2016–2019). A total of ≈1400 field-level measurements were used to train predictive machine learning models of cane yield (t/ha), commercial cane sugar (CCS, %), sugar yield (t/ha), crop varieties and ratoon numbers. We compared the predictive performance of models based on both satellite imagery only and a fusion of satellite imagery with climate, soil and topographical information. Randomized search on hyperparameters was the method used to optimize and identify the most accurate decision tree-based machine model. Overall, gradient boosting was the most accurate method for predicting sugarcane attributes. The analysis resulted in cane yield, CCS and sugar yield predicted at the field level with R2 of up to 0.51 (RMSE = 16 t/ha), 0.63 (RMSE = 1 %) and 0.62 (RMSE = 2 t/ha) as soon as four months before the harvest season. It was also found that sugarcane varieties could be mapped with an accuracy of up to 73.4 %, while the differentiation of planted and ratoon crops exhibited the lowest accuracy of 45.4 %. Using a novel SHapley Additive exPlanations (SHAP) approach to explain the output of our machine learning models we found that Sentinel-2 derived spectral indices were the most important in predicting cane yield as well as differentiating sugarcane varieties and ratoon numbers. In contrast, climate and elevation derived predictors were the most important in predicting CCS and sugar yield. At the whole sugar mill area level, spatially averaged field-level results predicted mill area cane yield, CCS and sugar yield with R2 of 0.75 (RMSE = 4.6 t/ha), 0.80 (RMSE = 0.6 %) and 0.77 (RMSE = 1 t/ha). Early season prediction of sugarcane yields at both field- and mill-area level could be valuable for informing fertilizer application, harvest scheduling and marketing decisions. © 2020","Climate; Fusion; Machine learning; Remote sensing; Satellite; SHAP; Sugarcane; Yield","crop yield; environmental assessment; growing season; machine learning; prediction; satellite data; satellite imagery; Sentinel; sugar; sugar cane; Australia"
"Sheth P., Liu T., Doner D., Deng Q., Wei Y., Muenich R., Sabo J., Candan K.S., Liu H.","Causal Discovery for Feature Selection in Physical Process-Based Hydrological Systems","10.1109/BigData55660.2022.10020794","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147913038&doi=10.1109%2fBigData55660.2022.10020794&partnerID=40&md5=5acd142b44f56e8c46a4921b30fcb567","Physical process-based hydrological models are widely adopted to simulate the water quantity or quality. One of the most commonly used hydrological models is Soil and Water Assessment Tool (SWAT). SWAT models for a large watershed can have over tens of thousands of Hydrological Resource Units (HRUs) which necessitates considerable computational resources. One way to speed up applications of the SWAT model could be to leverage machine learning techniques to identify the crucial features for the prediction task - feature selection. However, majority of the feature selection techniques rely on correlations or some form of a score metric (e.g. mutual information). Furthermore, since correlation does not imply causation, it is important to identify the causal features to improve the prediction accuracy while enhancing the interpretability of machine learning models. However, the SWAT model uses multiple data inputs and features that typically vary by space/HRUs, but may or may not vary over time. This makes it difficult to directly utilize causal discovery models to infer the causal relations. Furthermore, due to the lack of the ground truth causal graph for the SWAT model it is difficult to comment on the validity of the learned causal relations. To overcome these problems, we propose a novel framework that first infers the causal relations for the daily scale of the SWAT data using causal discovery algorithms. Then, it utilizes a community detection module to group similar features together for better interpretability. Finally, it identifies the stable causal relations that appear most often across all the timesteps and leverage them for the prediction of the water quantity. By utilizing only the causal features for the prediction of the target variable can lead to high accuracy as it removes the reliance on spurious correlations. Furthermore, we conduct extensive experiments to validate the effectiveness of the proposed framework along with a real-world case study to evaluate whether the selected features are interpretable or not. © 2022 IEEE.","causal discovery; feature selection; hydrological systems; neural networks; SWAT models","Feature Selection; Forecasting; Runoff; Causal discovery; Causal relations; Features selection; Hydrological system; Neural-networks; Physical process; Process-based; Soil and water assessment tool model; Soil and Water assessment tools; Tool models; SWAT"
"Shi H., Xian G., Auch R., Gallo K., Zhou Q.","Urban heat island and its regional impacts using remotely sensed thermal data—a review of recent developments and methodology","10.3390/land10080867","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113581987&doi=10.3390%2fland10080867&partnerID=40&md5=be32d5cf3a32c1d569c38ad568d95d31","Many novel research algorithms have been developed to analyze urban heat island (UHI) and UHI regional impacts (UHIRIP) with remotely sensed thermal data tables. We present a comprehensive review of some important aspects of UHI and UHIRIP studies that use remotely sensed thermal data, including concepts, datasets, methodologies, and applications. We focus on reviewing progress on multi-sensor image selection, preprocessing, computing, gap filling, image fusion, deep learning, and developing new metrics. This literature review shows that new satellite sensors and valuable methods have been developed for calculating land surface temperature (LST) and UHI intensity, and for assessing UHIRIP. Additionally, some of the limitations of using remotely sensed data to analyze the LST, UHI, and UHI intensity are discussed. Finally, we review a variety of applications in UHI and UHIRIP analyses. The assimilation of time-series remotely sensed data with the application of data fusion, gap filling models, and deep learning using the Google Cloud platform and Google Earth Engine platform also has the potential to improve the estimation accuracy of change patterns of UHI and UHIRIP over long time periods. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Non-urban areas; Remote sensing; Thermal band; UHI intensity; UHI regional impacts; Urban heat island",
"Shi J., Chen C., Wang D., Wang Z., Liu Y.","The antimicrobial peptide LI14 combats multidrug-resistant bacterial infections","10.1038/s42003-022-03899-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137523883&doi=10.1038%2fs42003-022-03899-4&partnerID=40&md5=b893baef0fedd917706e6d2c330bc9d6","The prevalence of multidrug-resistant (MDR) pathogens raises public fears of untreatable infections and represents a huge health risk. There is an urgent need to exploit novel antimicrobial agents. Due to the unique mechanisms, antimicrobial peptides (AMPs) with a low probability to achieve resistance are regarded as potential antibiotic alternatives to address this issue. Herein, we develop a panel of synthetic peptide compounds with novel structures based on the database filters technology (DFT), and the lead peptide LI14 shows potent antibacterial activity against all tested drug-resistant bacteria. LI14 exhibits rapid bactericidal activity and excellent anti-biofilm and -persisters activity, simultaneously showing a low propensity to induce resistance. Moreover, LI14 shows tolerance against pH, temperatures, and pepsin treatment, and no detectable toxicity both in vitro and in vivo. Mechanistic studies revealed that LI14 induces membrane damage by targeting bacterial-specific membrane components and dissipates the proton motive force (PMF), thereby resulting in metabolic perturbations and the accumulation of toxic metabolic products. Furthermore, LI14 sensitizes clinically relevant antibiotics against MDR bacteria. In animal models of infection, LI14 or combined with antibiotics are effective against drug-resistant pathogens. These findings suggest that LI14 is a promising antibiotic candidate to tackle MDR bacterial infections. © 2022, The Author(s).",,"antiinfective agent; peptide; polypeptide antibiotic agent; animal; bacterial infection; bacterium; chemistry; microbial sensitivity test; Animals; Anti-Bacterial Agents; Antimicrobial Peptides; Bacteria; Bacterial Infections; Microbial Sensitivity Tests; Peptides"
"Shi W., Zhang M., Zhang R., Chen S., Zhan Z.","Change detection based on artificial intelligence: State-of-the-art and challenges","10.3390/rs12101688","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085560679&doi=10.3390%2frs12101688&partnerID=40&md5=3b4b5eff3f9085ff27a6dc471b9e1fbf","Change detection based on remote sensing (RS) data is an important method of detecting changes on the Earth's surface and has a wide range of applications in urban planning, environmental monitoring, agriculture investigation, disaster assessment, and map revision. In recent years, integrated artificial intelligence (AI) technology has become a research focus in developing new change detection methods. Although some researchers claim that AI-based change detection approaches outperform traditional change detection approaches, it is not immediately obvious how and to what extent AI can improve the performance of change detection. This review focuses on the state-of-the-art methods, applications, and challenges of AI for change detection. Specifically, the implementation process of AI-based change detection is first introduced. Then, the data from different sensors used for change detection, including optical RS data, synthetic aperture radar (SAR) data, street view images, and combined heterogeneous data, are presented, and the available open datasets are also listed. The general frameworks of AI-based change detection methods are reviewed and analyzed systematically, and the unsupervised schemes used in AI-based change detection are further analyzed. Subsequently, the commonly used networks in AI for change detection are described. From a practical point of view, the application domains of AI-based change detection methods are classified based on their applicability. Finally, the major challenges and prospects of AI for change detection are discussed and delineated, including (a) heterogeneous big data processing, (b) unsupervised AI, and (c) the reliability of AI. This review will be beneficial for researchers in understanding this field. © 2020 by the authors.","Artificial intelligence; Change detection; Deep learning; Hyperspectral; Multispectral; Neural network; Remote sensing; SAR; Street view; Unsupervised learning","Agricultural robots; Artificial intelligence; Remote sensing; Synthetic aperture radar; Artificial intelligence technologies; Change detection; Environmental Monitoring; Heterogeneous data; Implementation process; Remote sensing data; State of the art; State-of-the-art methods; Data handling"
"Shi Y., Han L., Huang W., Chang S., Dong Y., Dancey D., Han L.","A Biologically Interpretable Two-Stage Deep Neural Network (BIT-DNN) for Vegetation Recognition from Hyperspectral Imagery","10.1109/TGRS.2021.3058782","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101744087&doi=10.1109%2fTGRS.2021.3058782&partnerID=40&md5=0d52a4967aaf3ceb9b45f98320a3196e","Spectral-spatial-based deep learning models have recently proven to be effective in hyper-spectral image (HSI) classification for various earth monitoring applications such as land cover classification and agricultural monitoring. However, due to the nature of 'black-box' model representation, how to explain and interpret the learning process and the model decision, especially for vegetation classification, remains an open challenge. This study proposes a novel interpretable deep learning model - a biologically interpretable two-stage deep neural network (BIT-DNN), by incorporating the prior-knowledge (i.e., biophysical and biochemical attributes and their hierarchical structures of target entities)-based spectral-spatial feature transformation into the proposed framework, capable of achieving both high accuracy and interpretability on HSI-based classification tasks. The proposed model introduces a two-stage feature learning process: in the first stage, an enhanced interpretable feature block extracts the low-level spectral features associated with the biophysical and biochemical attributes of target entities; and in the second stage, an interpretable capsule block extracts and encapsulates the high-level joint spectral-spatial features representing the hierarchical structure of biophysical and biochemical attributes of these target entities, which provides the model an improved performance on classification and intrinsic interpretability with reduced computational complexity. We have tested and evaluated the model using four real HSI data sets for four separate tasks (i.e., plant species classification, land cover classification, urban scene recognition, and crop disease recognition tasks). The proposed model has been compared with five state-of-the-art deep learning models. The results demonstrate that the proposed model has competitive advantages in terms of both classification accuracy and model interpretability, especially for vegetation classification. © 1980-2012 IEEE.","Classification; deep learning; hyper-spectral images (HSIs); interpretability","Agricultural robots; Biophysics; Classification (of information); Competition; Deep neural networks; Learning systems; Neural networks; Spectroscopy; Vegetation; Agricultural monitoring; Classification accuracy; Hierarchical structures; Hyper-spectral imageries; Hyper-spectral images; Land cover classification; Monitoring applications; Vegetation classification; Deep learning; artificial neural network; data set; image classification; vegetation classification"
"Shilo S., Godneva A., Rachmiel M., Korem T., Kolobkov D., Karady T., Bar N., Wolf B.C., Glantz-Gashai Y., Cohen M., Levin N.Z., Shehadeh N., Gruber N., Levran N., Koren S., Weinberger A., Pinhas-Hamiel O., Segal E.","Prediction of Personal Glycemic Responses to Food for Individuals With Type 1 Diabetes Through Integration of Clinical and Microbial Data","10.2337/dc21-1048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125882146&doi=10.2337%2fdc21-1048&partnerID=40&md5=56a89f56e6977d73ca29f9efc80d14b2","OBJECTIVE Despite technological advances, results from various clinical trials have repeat-edly shown that many individuals with type 1 diabetes (T1D) do not achieve their glycemic goals. One of the major challenges in disease management is the administration of an accurate amount of insulin for each meal that will match the expected postprandial glycemic response (PPGR). The objective of this study was to develop a prediction model for PPGR in individuals with T1D. RESEARCH DESIGN AND METHODS We recruited individuals with T1D who were using continuous glucose monitoring and continuous subcutaneous insulin infusion devices simultaneously to a prospective cohort and profiled them for 2 weeks. Participants were asked to report real-time dietary intake using a designated mobile app. We measured their PPGRs and devised machine learning algorithms for PPGR prediction, which integrate glucose measurements, insulin dosages, dietary habits, blood parame-ters, anthropometrics, exercise, and gut microbiota. Data of the PPGR of 900 healthy individuals to 41,371 meals were also integrated into the model. The per-formance of the models was evaluated with 10-fold cross validation. RESULTS A total of 121 individuals with T1D, 75 adults and 46 children, were included in the study. PPGR to 6,377 meals was measured. Our PPGR prediction model sub-stantially outperforms a baseline model with emulation of standard of care (cor-relation of R 5 0.59 compared with R 5 0.40 for predicted and observed PPGR respectively; P &lt; 10210 ). The model was robust across different subpopulations. Feature attribution analysis revealed that glucose levels at meal initiation, glucose trend 30 min prior to meal, meal carbohydrate content, and meal’s carbohy-drate-to-fat ratio were the most influential features for the model. CONCLUSIONS Our model enables a more accurate prediction of PPGR and therefore may allow a better adjustment of the required insulin dosage for meals. It can be further implemented in closed loop systems and may lead to rationally designed nutri-tional interventions personally tailored for individuals with T1D on the basis of meals with expected low glycemic response. © 2022 by the American Diabetes Association.",,"insulin; insulin; adolescent; adult; anthropometry; Article; carbohydrate analysis; carbohydrate to fat ratio; clinical evaluation; clinical study; cohort analysis; continuous infusion; controlled study; data integration; dietary intake; DNA extraction; eating habit; exercise; feces analysis; female; food processing; glucose level; health care quality; human; insulin dependent diabetes mellitus; intestine flora; machine learning; major clinical study; male; nutrient profiling; nutritional parameters; observational study; patient participation; population structure; postprandial glycemic response; postprandial state; prediction; prospective study; treatment duration; validation study; blood glucose monitoring; child; crossover procedure; glucose blood level; insulin dependent diabetes mellitus; meal; physiology; postprandial state; Adult; Blood Glucose; Blood Glucose Self-Monitoring; Child; Cross-Over Studies; Diabetes Mellitus, Type 1; Humans; Insulin; Meals; Postprandial Period; Prospective Studies"
"Shin D., Kee K.F., Shin E.Y.","Algorithm awareness: Why user awareness is critical for personal privacy in the adoption of algorithmic platforms?","10.1016/j.ijinfomgt.2022.102494","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124874130&doi=10.1016%2fj.ijinfomgt.2022.102494&partnerID=40&md5=7ada24891494ff492da0118211e509e2","Understanding how algorithms shape users’ online experiences is a prerequisite to developing an effective algorithm design. Due to the rapid algorithmification of platforms, it is timely to examine users’ awareness of algorithms on online platforms because these algorithms can shape everyday decisions and interactions through mediating, gatekeeping, and structuring user interactions. Focusing on the role of algorithm awareness (AA) in the privacy calculus process, we investigate users’ intention to disclose personal information when using a platform with personalized algorithms. By conceptualizing AA with a range of theoretical and behavioral variables, we examine how users’ self-efficacy affects their privacy concerns when they adopt, consume, and interact with such platforms. The findings show that AA leads users to envisage, understand, and interact with algorithms depending on their understanding of the control of the information flow embedded within them. The awareness that users have regarding algorithms influences the trust of algorithmic processes and the way users evaluate privacy concerns and self-disclosures. The cognitive user processes of AA provide conceptual frameworks for algorithm design and a practical guideline for the design of personalized algorithms. © 2022 Elsevier Ltd","Algorithm awareness; Personal privacy; Personalized algorithms; Privacy calculus; Self-disclosure; Self-efficacy","Algorithm awareness; Algorithm design; Algorithmics; Effective algorithms; Personal privacy; Personalized algorithm; Privacy calculus; Privacy concerns; Self efficacy; Self-disclosure; Calculations"
"Shin J., Choi J.-G., Kim S.-H., Khim B.-K., Jo Y.-H.","Environmental variables affecting Sargassum distribution in the East China Sea and the Yellow Sea","10.3389/fmars.2022.1055339","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144494258&doi=10.3389%2ffmars.2022.1055339&partnerID=40&md5=7ddd221e2581e27aa889a75522813841","Floating Sargassum horneri has flowed into Jeju Island and the coast of the Korean Peninsula every year between February and May since 2015, causing considerable damage to aqua-farming sites and navigation. This study aimed to address the relationship between Sargassum distribution in the Yellow Sea (YS) and the East China Sea (ECS) and environmental variables for determining Sargassum distribution toward the Korean Peninsula. From feature importance ranking, we found that sea surface temperature (SST) is the most influential environmental variable in Sargassum distribution. From variables such as sea surface height (SSH), eastward seawater velocity (uo), and northward seawater velocity (vo), it was observed that Sargassum patches were not distributed in the southeast below 29 °N. Subsequently, we employed bagged tress models to evaluate the specific sensitivity of each environmental variable to Sargassum distribution. This model showed the best quantitative and qualitative performance when trained with physical and geographical variables. When estimating expanded areas of Sargassum distribution over time with the change in SST, a sider distribution range of Sargassum patches than usual and an early inflow into the Korean Peninsula were observed when the SST increased from the original. In addition, we found that the tolerable and favorable SST for Sargassum was 12–20 and 18°C, respectively. These results will enhance the understanding of the relationship between environmental variables and Sargassum distribution and provide valuable data for establishing a pre-disaster system for Sargassum blooms flowing toward the Korean Peninsula. Copyright © 2022 Shin, Choi, Kim, Khim and Jo.","feature importance ranking; GOCI; machine learning; particle-tracking experiment; Sargassum horneri",
"Shivaprakash K.N., Swami N., Mysorekar S., Arora R., Gangadharan A., Vohra K., Jadeyegowda M., Kiesecker J.M.","Potential for Artificial Intelligence (AI) and Machine Learning (ML) Applications in Biodiversity Conservation, Managing Forests, and Related Services in India","10.3390/su14127154","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132148138&doi=10.3390%2fsu14127154&partnerID=40&md5=6294bfa1687df649d2c38224471e2e3b","The recent advancement in data science coupled with the revolution in digital and satellite technology has improved the potential for artificial intelligence (AI) applications in the forestry and wildlife sectors. India shares 7% of global forest cover and is the 8th most biodiverse region in the world. However, rapid expansion of developmental projects, agriculture, and urban areas threaten the country’s rich biodiversity. Therefore, the adoption of new technologies like AI in Indian forests and biodiversity sectors can help in effective monitoring, management, and conservation of biodiversity and forest resources. We conducted a systematic search of literature related to the application of artificial intelligence (AI) and machine learning algorithms (ML) in the forestry sector and biodiversity conservation across globe and in India (using ISI Web of Science and Google Scholar). Additionally, we also collected data on AI-based startups and non-profits in forest and wildlife sectors to understand the growth and adoption of AI technology in biodiversity conservation, forest management, and related services. Here, we first provide a global overview of AI research and application in forestry and biodiversity conservation. Next, we discuss adoption challenges of AI technologies in the Indian forestry and biodiversity sectors. Overall, we find that adoption of AI technology in Indian forestry and biodiversity sectors has been slow compared to developed, and to other developing countries. However, improving access to big data related to forest and biodiversity, cloud computing, and digital and satellite technology can help improve adoption of AI technology in India. We hope that this synthesis will motivate forest officials, scientists, and conservationists in India to explore AI technology for biodiversity conservation and forest management. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","artificial intelligence; biodiversity conservation; forest; forest resource management; machine learning","artificial intelligence; biodiversity; conservation management; forest cover; forest management; forest resource; machine learning; satellite data; India"
"Shofadekan A.S., Azeta A.A., Akinwumi H.","Design and evaluation of quality assurance-based interactive machine learning model",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120859552&partnerID=40&md5=739e3cf9ffb7cc42d58aa31611b89294","Some complex task can be difficult to fully understand or represent or there may even be few data available about them thereby making it difficult to solve with classical machine learning approaches. Hence, Interactive Machine Learning (iML), an approach where humans are used to complement machines. However, existing interactive machine learning approaches have not sufficiently considered quality assurance of the human feedback in the interaction cycle to guaranty improved performance of the model. Interactive machine learning systems take on data for updates without checking the quality of the update data. This is capable of misleading a machine learning model if wrong, noisy or malicious data are used to update the model. Therefore, this paper proposes a quality assurance-based interactive machine learning model that is able to evaluate the quality of the feedback obtained from the human in the iterative feedback loop before passing such feedback to the learning model to update its knowledge about the problem. Existing literatures and concepts on interactive machine learning were reviewed. Also explored are areas where interactive machine learning approach has resulted in faster, less expensive model training process than the classical Machine Learning, especially when applied on rare and complex problems. Questionnaire method was used to conduct a survey that evaluates the usability and understandability of the proposed quality assurance-based interactive machine learning model using the Cognitive Walkthrough Strategy. The result gave a rating of 4.2 out of 5 for the usability of proposed model. This approach will increase the acceptability of the interactive machine learning model and the credibility of its predictions. © 2021 Little Lion Scientific.","Evaluation; Human-in-the-loop; Interactive Machine Learning; Machine Learning",
"Shojaiee F., Baleghi Y.","EFASPP U-Net for semantic segmentation of night traffic scenes using fusion of visible and thermal images","10.1016/j.engappai.2022.105627","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142511920&doi=10.1016%2fj.engappai.2022.105627&partnerID=40&md5=397ffd5fd913e4d9c23871e91a47b98f","The development of self-driving cars increases driving safety and accelerates urban transportation. These systems must have robust and real-time understanding of traffic conditions and surroundings, both at day and night. Many semantic image segmentation techniques have been proposed based on deep neural networks to partition the traffic scene images as a substantial step. However, the proposed algorithms and public datasets are mostly based on visible images during the daytime. Also, most of these algorithms are computationally intensive. However, little research has been done to date to address the application of the fusion of thermal and visible images and the high-performance low-volume deep convolutional networks. In this paper, a multispectral Encoder Fused Atrous Spatial Pyramid Pooling (EFASPP) U-Net deep network is proposed to merge the features of the visible and thermal images recorded at night traffic scenes. The proposed network is designed based on the structure of the U-Net, due to its high accuracy and speed of processing, as well as no need for large training datasets. The fusion of visible and thermal features in the encoders of EFASPP U-Net network is performed using standard and atrous convolution layers. Also, a new multispectral dataset is developed in this work for night-time traffic scenes due to the lack of sufficient public dataset in this field. The major contributions of this work include a low-volume high-performance multispectral semantic segmentation network for smart vehicles and a new dataset for this application. The experimental results show the high accuracy and speed of the proposed method. © 2022 Elsevier Ltd","Atrous convolution layers; Semantic segmentation; U-Net network; Visible and thermal images","Deep neural networks; Image fusion; Large dataset; Real time systems; Semantic Segmentation; Semantic Web; Semantics; Signal encoding; Urban transportation; Atrous convolution layer; Net networks; Performance; Public dataset; Semantic segmentation; Spatial pyramids; Thermal images; Traffic scene; U-net network; Visible image; Convolution"
"Silva J.L., Bordalo R., Pissarra J., de Palacios P.","Computer Vision-Based Wood Identification: A Review","10.3390/f13122041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144633159&doi=10.3390%2ff13122041&partnerID=40&md5=a83c69201bd4c725d1d5547dfaf210a5","Wood identification is an important tool in many areas, from biology to cultural heritage. In the fight against illegal logging, it has a more necessary and impactful application. Identifying a wood sample to genus or species level is difficult, expensive and time-consuming, even when using the most recent methods, resulting in a growing need for a readily accessible and field-applicable method for scientific wood identification. Providing fast results and ease of use, computer vision-based technology is an economically accessible option currently applied to meet the demand for automated wood identification. However, despite the promising characteristics and accurate results of this method, it remains a niche research area in wood sciences and is little known in other fields of application such as cultural heritage. To share the results and applicability of computer vision-based wood identification, this paper reviews the most frequently cited and relevant published research based on computer vision and machine learning techniques, aiming to facilitate and promote the use of this technology in research and encourage its application among end-users who need quick and reliable results. © 2022 by the authors.","computer vision; convolutional neural networks; deep learning; illegal logging; image recognition; machine learning; wood anatomy; wood identification","Convolutional neural networks; Crime; Deep learning; Image recognition; Learning systems; Wood; Convolutional neural network; Cultural heritages; Deep learning; Ease-of-use; Illegal logging; Machine-learning; Vision based; Wood anatomy; Wood identification; Wood samples; Computer vision; artificial neural network; computer vision; cultural heritage; learning; machine learning; wood; Application; Computers; Identification; Research; Technology; Vision; Wood Structure"
"Simkute A., Surana A., Luger E., Evans M., Jones R.","XAI for learning: Narrowing down the digital divide between ""new"" and ""old"" experts","10.1145/3547522.3547678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139863759&doi=10.1145%2f3547522.3547678&partnerID=40&md5=93422cc0839f8a74d84736adf79d8801","Regular eXplainable AI (XAI) approaches are often ineffective in supporting decision-makers across domains. In some instances, it can even lead to automation bias or algorithmic aversion or would simply be ignored as a redundant feature. Based on cognitive psychology literature we outline a strategy for how XAI interface design could be tailored to have a long-lasting educational value. We suggest the features that could support domain-related and technical skills development this way narrowing the digital divide between ""new""and ""old""experts. Lastly, we suggest an intermitted explainability approach that could help to find a balance between seamless and cognitively engaging explanations. © 2022 Owner/Author.","Decision Support Systems; Digital Divide; Expertise Development; Explainability; Machine Learning; Tailored Explanations","Decision making; Decision support systems; E-learning; Algorithmics; Automation bias; Cognitive psychology; Decision makers; Digital divide; Expertise development; Explainability; Machine-learning; Redundant features; Tailored explanation; Machine learning"
"Simon C.G.K., Jhanjhi N.Z., Goh W.W., Sukumaran S.","Applications of Machine Learning in Knowledge Management System: A Comprehensive Review","10.1142/S0219649222500174","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131044980&doi=10.1142%2fS0219649222500174&partnerID=40&md5=f9ab1d1b7559517bd15ae4cb900c12f3","As new generations of technology appear, legacy knowledge management solutions and applications become increasingly out of date, necessitating a paradigm shift. Machine learning presents an opportunity by foregoing rule-based knowledge intensive systems inundating the marketplace. An extensive review was made on the literature pertaining to machine learning which common machine learning algorithms were identified. This study has analysed more than 200 papers extracted from Scopus and IEEE databases. Searches ranged with the bulk of the articles from 2018 to 2021, while some articles ranged from 1959 to 2017. The research gap focusses on implementing machine learning algorithm to knowledge management systems, specifically knowledge management attributes. By investigating and reviewing each algorithm extensively, the usability of each algorithm is identified, with its advantages and disadvantages. From there onwards, these algorithms were mapped for what area of knowledge management it may be beneficial. Based on the findings, it is evidently seen how these algorithms are applicable in knowledge management and how it can enhance knowledge management system further. Based on the findings, the paper aims to bridge the gap between the literature in knowledge management and machine learning. A knowledge management-machine learning framework is conceived based on the review done on each algorithm earlier and to bridge the gap between the two literatures. The framework highlights how machine learning algorithm can play a part in different areas of knowledge management. From the framework, it provides practitioners how and where to implement machine learning in knowledge management. © 2022 World Scientific Publishing Co.","association rule; classification; clustering; Knowledge management; machine learning; machine learning algorithm; regression; supervised learning; unsupervised learning","Clustering algorithms; Knowledge acquisition; Learning algorithms; Machine learning; Clusterings; Generations of technology; Knowledge management system; Machine learning algorithms; Machine-learning; Paradigm shifts; Research gaps; Rule-based knowledge; Knowledge management"
"Singh A., Dwivedi A., Agrawal D., Singh D.","Identifying issues in adoption of AI practices in construction supply chains: towards managing sustainability","10.1007/s12063-022-00344-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146244584&doi=10.1007%2fs12063-022-00344-x&partnerID=40&md5=7864dee2da12b8670e798cf5a7018412","The fragmented nature of construction industry coupled with its complex and dynamic nature demands for innovative technologies to record better performance in project execution. In this respect, Artificial Intelligence (AI) based techniques posit a viable means to attain requisite efficiency in performance and alleviate the productivity of construction organizations. The adoption of sustainable practices in Construction Supply Chains (CSCs) lowers the environmental impact, lowers the risk of failure, and boosts competitiveness. The present study attempts to unearth potential issues in the adoption of AI practices in CSCs. Initially, the study identifies potential issues in the implementation of AI-based frameworks in CSCs by performing an extensive literature review and brainstorming sessions with industry experts. The exercise results in identifying 17 critical issues confronting the adoption of AI in CSCs which were subsequently subjected to fuzzy Decision Making Trial and Evaluation Laboratory (DEMATEL) approach. The findings from the study reveal that “Lack of trust in AI outcomes”, “Exploitation by hackers, cybercrimes and privacy intrusion”, “Risk and cost associated with construction projects”, “Uncertain processing and functions of AI algorithms”, and “Unclear profits and advantages” were the top five influential causal issues that affect the adoption of AI in CSCs. This study is a novel attempt in the direction to identify and prioritize the potential issues in the adoption of AI-based frameworks in the Indian CSCs. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Artificial intelligence; Construction supply chains; Issues; Sustainability",
"Singh A., Gaurav K., Rai A.K., Beg Z.","Machine learning to estimate surface roughness from satellite images","10.3390/rs13193794","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115794704&doi=10.3390%2frs13193794&partnerID=40&md5=81d0f51c6b63ada6911475eec78e240c","We apply the Support Vector Regression (SVR) machine learning model to estimate surface roughness on a large alluvial fan of the Kosi River in the Himalayan Foreland from satellite images. To train the model, we used input features such as radar backscatter values in Vertical–Vertical (VV) and Vertical–Horizontal (VH) polarisation, incidence angle from Sentinel-1, Normalised Difference Vegetation Index (NDVI) from Sentinel-2, and surface elevation from Shuttle Radar Topographic Mission (SRTM). We generated additional features (VH/VV and VH–VV) through a linear data fusion of the existing features. For the training and validation of our model, we conducted a field campaign during 11–20 December 2019. We measured surface roughness at 78 different locations over the entire fan surface using an in-house-developed mechanical pin-profiler. We used the regression tree ensemble approach to assess the relative importance of individual input feature to predict the surface soil roughness from SVR model. We eliminated the irrelevant input features using an iterative backward elimination approach. We then performed feature sensitivity to evaluate the riskiness of the selected features. Finally, we applied the dimension reduction and scaling to minimise the data redundancy and bring them to a similar level. Based on these, we proposed five SVR methods (PCA-NS-SVR, PCA-CM-SVR, PCA-ZM-SVR, PCA-MM-SVR, and PCA-S-SVR). We trained and evaluated the performance of all variants of SVR with a 60:40 ratio using the input features and the in-situ surface roughness. We compared the performance of SVR models with six different benchmark machine learning models (i.e., Gaussian Process Regression (GPR), Generalised Regression Neural Network (GRNN), Binary Decision Tree (BDT), Bragging Ensemble Learning, Boosting Ensemble Learning, and Automated Machine Learning (AutoML)). We observed that the PCA-MM-SVR perform better with a coefficient of correlation (R = 0.74), Root Mean Square Error (RMSE = 0.16 cm), and Mean Square Error (MSE = 0.025 cm2 ). To ensure a fair selection of the machine learning model, we evaluated the Akaike’s Information Criterion (AIC), corrected AIC (AICc), and Bayesian Information Criterion (BIC). We observed that SVR exhibits the lowest values of AIC, corrected AIC, and BIC of all the other methods; this indicates the best goodness-of-fit. Eventually, we also compared the result of PCA-MM-SVR with the surface roughness estimated from different empirical and semi-empirical radar backscatter models. The accuracy of the PCA-MM-SVR model is better than the backscatter models. This study provides a robust approach to measure surface roughness at high spatial and temporal resolutions solely from the satellite data. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","AutoML; Backscatter models; Machine learning models; Sentinel-1; Sentinel-2; Surface roughness","Adaptive boosting; Backscattering; Benchmarking; Binary trees; Data fusion; Decision trees; Iterative methods; Mean square error; Regression analysis; Surface roughness; Synthetic aperture radar; Automated machine learning; Automated machines; Backscatter model; Information criterion; Input features; Machine learning models; Machine-learning; Sentinel-1; Sentinel-2; Support vector regressions; Machine learning"
"Singh H., Roy A., Setia R.K., Pateriya B.","Estimation of nitrogen content in wheat from proximal hyperspectral data using machine learning and explainable artificial intelligence (XAI) approach","10.1007/s40808-021-01243-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111095976&doi=10.1007%2fs40808-021-01243-z&partnerID=40&md5=013ce58e392995ecbf59b7f822a8945b","Nitrogen (N) is a primary macronutrient essential for plant structures and metabolic processes, and the deficiency of N leads to critical plant disorders. The spectral reflectance can be used to predict the N status of plants using hyperspectral data. Therefore, the N status of wheat was predicted from hyperspectral data using machine learning techniques. Different derivative pre-processing treatments have been shown to have an impact on the spectral model performance. Therefore, we used different spectral pre-processing techniques (first derivative, deresolve and deresolve plus first derivative) coupled with six machine learning regression models (Support Vector Regression, Random Forest, k-nearest neighbours, Multilayer Perceptron, Gradient Boosting Regression and Partial Least Square Regression) to predict the N status of wheat. The deresolve plus first derivative spectral pre-processing technique along with Random Forest and Gradient Boosting Regression (R2 &gt; 0.85) were better than the other combination of spectral pre-processing and machine learning models to predict the N status of wheat. The eXplainable Artificial Intelligence (XAI) tool was used to provide the local and global explanations of the model decisions using SHapley Additive explanations (SHAP) values. The important wavelengths predicting N status were between 790 and 862 nm (global model) for Random Forest model. However, these wavelengths varied with the growth stages of wheat. The most important wavelength were 672, 794, 804, 806, 816 and 820 nm during the first six days of wheat growth (local model), 716, 794, 804 and 806 nm after 45 days of wheat growth, 724, 806, 820, 1556 and 1582 after 63–72 days of wheat growth and 718, 720, 724 and 1272 nm after 91–97 days of wheat growth. These results suggest that XAI tools are useful to explain the complex machine learning models related to hyperspectral data for remote monitoring of N status of wheat. © 2021, The Author(s), under exclusive licence to Springer Nature Switzerland AG.","Machine learning; Nitrogen; Random forest; Wheat; XAI","artificial intelligence; data set; estimation method; machine learning; nitrogen; spectral analysis; wheat"
"Singh H., Roy A., Setia R., Pateriya B.","Estimation of chlorophyll, macronutrients and water content in maize from hyperspectral data using machine learning and explainable artificial intelligence techniques","10.1080/2150704X.2022.2114108","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136478148&doi=10.1080%2f2150704X.2022.2114108&partnerID=40&md5=74e4d45db5ef5e85aa0b41e4d1151d94","We used the secondary hyperspectral data set (leaf reflectance of maize) taken in the spectral range from 350 to 2500 nm in a field (under low and high nitrogen conditions) and glasshouse experiment. Water, chlorophyll, nitrogen (N), phosphorus (P) and potassium (K) contents of maize leaves taken from these experiments were measured using the standard methods. Six machine learning regression algorithms (Random Forest, Support Vector Regression, k-Nearest Neighbours, Multilayer Perceptron, Gradient Boosting Regression and Partial Least Square Regression) were used for development of the models to predict these parameters from leaf reflectance data. Each plant parameter was estimated with a different machine learning algorithm. Explainable artificial intelligence methods were used to identify the optimum wavelengths for each parameter. The wavelengths in the short-wave infrared (SWIR) region were found optimum for estimating the water content across the three N regimes, and the red-edge band for chlorophyll. The optimum wavelengths for estimating N content in leaves were in the green spectral region under low N status, near-infrared (NIR) and SWIR regions under greenhouse and SWIR region under high N status. The important wavelengths for estimating P in maize leaves were 1088, 1262 and 1263 nm under low N status and the SWIR range under high N status and greenhouse conditions. The SWIR band was useful for estimating the K content in leaves. © 2022 Informa UK Limited, trading as Taylor & Francis Group.",,"Adaptive boosting; Decision trees; Infrared devices; Infrared radiation; Learning systems; Least squares approximations; Machine learning; Nearest neighbor search; Nitrogen; Parameter estimation; Plants (botany); Reflection; Regression analysis; Artificial intelligence techniques; Condition; Data set; Glasshouse experiment; High-nitrogen; Hyperspectral Data; Machine-learning; Optimum wavelength; Short wave infrared regions; Spectral range; Chlorophyll; machine learning"
"Singh S.K., Rathore S., Park J.H.","BlockIoTIntelligence: A Blockchain-enabled Intelligent IoT Architecture with Artificial Intelligence","10.1016/j.future.2019.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073017415&doi=10.1016%2fj.future.2019.09.002&partnerID=40&md5=8a548c7676930c7cc39c84ef9c3620a4","In the recent year, Internet of Things (IoT) is industrializing in several real-world applications such as smart transportation, smart city to make human life reliable. With the increasing industrialization in IoT, an excessive amount of sensing data is producing from various sensors devices in the Industrial IoT. To analyzes of big data, Artificial Intelligence (AI) plays a significant role as a strong analytic tool and delivers a scalable and accurate analysis of data in real-time. However, the design and development of a useful big data analysis tool using AI have some challenges, such as centralized architecture, security, and privacy, resource constraints, lack of enough training data. Conversely, as an emerging technology, Blockchain supports a decentralized architecture. It provides a secure sharing of data and resources to the various nodes of the IoT network is encouraged to remove centralized control and can overcome the existing challenges in AI. The main goal of our research is to design and develop an IoT architecture with blockchain and AI to support an effective big data analysis. In this paper, we propose a Blockchain-enabled Intelligent IoT Architecture with Artificial Intelligence that provides an efficient way of converging blockchain and AI for IoT with current state-of-the-art techniques and applications. We evaluate the proposed architecture and categorized into two parts: qualitative analysis and quantitative analysis. In qualitative evaluation, we describe how to use AI and Blockchain in IoT applications with “AI-driven Blockchain” and “Blockchain-driven AI.” In quantitative analysis, we present a performance evaluation of the BlockIoTIntelligence architecture to compare existing researches on device, fog, edge and cloud intelligence according to some parameters such as accuracy, latency, security and privacy, computational complexity and energy cost in IoT applications. The evaluation results show that the proposed architecture performance over the existing IoT architectures and mitigate the current challenges. © 2019","Artificial intelligence; Big data analysis; Blockchain; Internet of things; Security and privacy","Artificial intelligence; Big data; Blockchain; Data privacy; Information analysis; Network architecture; Centralized architecture; Decentralized architecture; Design and Development; Internet of Things (IOT); Proposed architectures; Qualitative evaluations; Security and privacy; State-of-the-art techniques; Internet of things"
"Singh T., Uppaluri R.V.S.","Machine learning tool-based prediction and forecasting of municipal solid waste generation rate: a case study in Guwahati, Assam, India","10.1007/s13762-022-04644-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141819377&doi=10.1007%2fs13762-022-04644-4&partnerID=40&md5=f7788e80d835145fe8ba680b85ea6c6c","Integrated large-scale solid waste management (SWM) policies are the need of the hour to design, develop and sustain SWM models. An accurate prediction and forecasting of municipal solid waste generation (MSWG) rate are essential for such advanced strategies. The primary objective of this study is to examine the criticality of demographic and socio-economic parameters for the fair prediction and forecasting of the MSWG rate. Machine learning (ML) models were formulated by mapping solid waste quantities at the municipal level with socio-economic and demographic variables of Guwahati city. Tree-based ML algorithms, namely decision tree (DT), random forest (RF) and gradient boosting (GB), were applied to build the models with 1936 data size. The moving average (MA) approaches were adapted for the forecasting of the MSWG rate. Model validation resulted in a root mean square error, RMSE (3.01), mean absolute error, MAE (2.86) and coefficient of determination, R2 (0.99) for the GB model and correlation coefficient (r) of 0.82 between observed and predicted values and thereby resulted in best performance in conjunction with DT and RF. With the exponential MA, the forecasted RMSE and R2 for GB, RF and DT were 2.12, 3.63 and 4.22; and 0.981, 0.972 and 0.967, respectively. However, with a model accuracy of 97%, the computation time for GB model (19.18 min) exhibited maximum due to its high complexity. The overall methodology involved developing effective tools to aid in regional SWM and planning through the integration of data sources in the public domain, pre-processing and modelling from diverse sources. © 2022, The Author(s) under exclusive licence to Iranian Society of Environmentalists (IRSEN) and Science and Research Branch, Islamic Azad University.","Forecasting; Machine learning algorithms; Modelling; Municipal solid waste; Prediction","Forecasting; Machine learning; Mean square error; Municipal solid waste; Population statistics; Random forests; Waste management; Gradient boosting; Machine learning algorithms; Machine-learning; Modeling; Municipal solid waste generation; Prediction and forecasting; Random forests; Socio-economics; Solid waste generation rates; Solid waste management; Decision trees"
"Singhal S., Ahuja L., Pathak N.","Impact of Artificial Intelligence and IOT in Agriculture","10.1109/ICAC3N53548.2021.9725655","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126929644&doi=10.1109%2fICAC3N53548.2021.9725655&partnerID=40&md5=c41d4cec540a56c9374c5d11c223fd40","It's a fact that Artificial Intelligence is something which is on peak nowadays, in any field whether it was manufacturing, marketing, Industry or even in gaming it is taking its chores at utmost levels. But what about one of the major concerns which is Agriculture. If we see the rate of dependencies of farming that what a percentage of whole worlds sharing in fact that how much a agriculture is getting in terms of new machines to farming their crops and make a plenty full of investments to buy the seeds and equipment's. This paper will be consisting of such like facts and study and getting know more about how the leading areas are working with these technologies to provide the best solutions to a farmer which is cos effective and very proper to ploughing their fields. © 2021 IEEE.","Artificial Intelligence; Big Data; Data Organization; Data Redundancy; IOT; Manufacturing Operations Management","Artificial intelligence; Internet of things; Manufacture; Seed; Data organization; Data-redundancy; IOT; Manufacturing operation management; Manufacturing operations; Operation management; Big data"
"Sinha A., Kundu T., Sinha K.","Comparative Study of Principle and Independent Component Analysis of CNN for Embryo Stage and Fertility Classification","10.4018/IJFSA.296594","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128211648&doi=10.4018%2fIJFSA.296594&partnerID=40&md5=d4d84a72eee24a7e6b452033f749e63f","Applications of deep learning for societal issues are one of the debatable concerns where the community medicine and implication of artificial intelligence for the societal issues are a big concern. This article shows the applications of neural networks in clinical practice for reproduction procedure enhancement. And thisis a well-known issue where image analysis has exact applications. In embryology, fetal abnormality early-stage detection and diagnosis is one of the challenging tasks and thus needs automation in the process of tomography and ultrasonic imaging. Also, interpretation and accuracy in the Medical Image Processing are very important for accurate results. © 2022, IGI Global.","CNN; Embryo Classification; ICA; Neural Network; Optimization; PCA","Cell proliferation; Deep learning; Diagnosis; Medical imaging; Principal component analysis; Ultrasonic imaging; Clinical practices; CNN; Comparatives studies; Embryo classification; Independent components analysis; Neural-networks; Optimisations; PCA; Principle components analysis; Societal issues; Independent component analysis"
"Sinha B.B., Dhanalakshmi R.","Recent advancements and challenges of Internet of Things in smart agriculture: A survey","10.1016/j.future.2021.08.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113348010&doi=10.1016%2fj.future.2021.08.006&partnerID=40&md5=8732e327dd7d616e70729c0dc7fb22ff","The Internet of Things (IoT) is an evolving paradigm that seeks to connect different smart physical components for multi-domain modernization. To automatically manage and track agricultural lands with minimal human intervention, numerous IoT-based frameworks have been introduced. This paper presents a rigorous discussion on the major components, new technologies, security issues, challenges and future trends involved in the agriculture domain. An in-depth report on recent advancements has been covered in this paper. The goal of this survey is to help potential researchers detect relevant IoT problems and, based on the application requirements, adopt suitable technologies. Furthermore, the significance of IoT and Data Analytics for smart agriculture has been highlighted. © 2021 Elsevier B.V.","Automated irrigation; Data analytics; IoT; IoT challenges; IoT smart farming","Agriculture; Data Analytics; Surveys; Agricultural land; Automated irrigation; Data analytics; Human intervention; Internet of thing challenge; Internet of thing smart farming; Multi-domains; Physical components; Security challenges; Smart agricultures; Internet of things"
"Sirsat M.S., Cernadas E., Fernández-Delgado M., Barro S.","Automatic prediction of village-wise soil fertility for several nutrients in India using a wide range of regression methods","10.1016/j.compag.2018.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053026277&doi=10.1016%2fj.compag.2018.08.003&partnerID=40&md5=ac260051c515d250a5aec287d36022dd","In low quality soils, as in the Indian state of Maharashtra, a sustainable land management practice is very important to enhance the soil quality and to maintain proper values for several nutrients that are relevant for an optimal crop yield. The evaluation of a soil fertility index for these nutrients and for each geographical place allows to create maps of village-wise fertility indices which are very useful for fertility management. An automatic prediction of such fertility indices would be very important to reduce the amount of chemical measurements of nutrients to be performed in different cultivation lands. The current study develops the prediction of fertility indices for soil organic carbon and four important soil nutrients (phosphorus pentoxide, iron, manganese and zinc) using almost all the available regression methods, specifically a collection of 76 regressors which belong to 20 families, including neural networks, deep learning, support vector regression, random forests, bagging and boosting, lasso and ridge regression, Bayesian models and more. The best results are achieved by the extremely randomized regression trees (extraTrees), with which achieve an acceptable prediction accuracy (average squared correlations between 0.57 and 0.70), being also relatively fast. Other regressors with high performance are random forests and regularized random forest, generalized boosting regression model and epsilon-support vector regression. © 2018 Elsevier B.V.","Extremely randomized regression trees; Indian agriculture; Machine learning; Regression; Soil fertility index","Bayesian networks; Cultivation; Decision trees; Deep learning; Forecasting; Forestry; Learning systems; Nutrients; Organic carbon; Rural areas; Soils; Automatic prediction; Chemical measurements; Regression; Regression trees; Regularized random forests; Soil fertility; Support vector regression (SVR); Sustainable land managements; Regression analysis; agricultural land; agricultural soil; agriculture; land management; machine learning; management practice; prediction; regression analysis; soil fertility; soil nutrient; soil organic matter; soil quality; India; Maharashtra"
"Sohns J.-T., Schmitt M., Jirasek F., Hasse H., Leitte H.","Attribute-based Explanation of Non-Linear Embeddings of High-Dimensional Data","10.1109/TVCG.2021.3114870","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118613758&doi=10.1109%2fTVCG.2021.3114870&partnerID=40&md5=4605fec5a5e12c42b910e47ee9b29014","Embeddings of high-dimensional data are widely used to explore data, to verify analysis results, and to communicate information. Their explanation, in particular with respect to the input attributes, is often difficult. With linear projects like PCA the axes can still be annotated meaningfully. With non-linear projections this is no longer possible and alternative strategies such as attribute-based color coding are required. In this paper, we review existing augmentation techniques and discuss their limitations. We present the Non-Linear Embeddings Surveyor (NoLiES) that combines a novel augmentation strategy for projected data (rangesets) with interactive analysis in a small multiples setting. Rangesets use a set-based visualization approach for binned attribute values that enable the user to quickly observe structure and detect outliers. We detail the link between algebraic topology and rangesets and demonstrate the utility of NoLiES in case studies with various challenges (complex attribute value distribution, many attributes, many data points) and a real-world application to understand latent features of matrix completion in thermodynamics. © 1995-2012 IEEE.","augmented projections; Dimensionality reduction; embedding; explainable artificial intelligence; point set contours","Clustering algorithms; Data visualization; Job analysis; Thermodynamics; Topology; Augmented projection; Dimensionality reduction; Embeddings; Explainable artificial intelligence; Image color analysis; Non linear; Point set; Point set contour; Task analysis; Visualization; article; embedding; thermodynamics"
"Son S., Kim D., Choul Choi M., Lee J., Kim B., Min Choi C., Kim S.","Weight interpretation of artificial neural network model for analysis of rice (Oryza sativa L.) with near-infrared spectroscopy","10.1016/j.fochx.2022.100430","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136738437&doi=10.1016%2fj.fochx.2022.100430&partnerID=40&md5=9367c784f8029f2ab45707094509b0e3","Prediction models for major nutrients of rice were built using near-infrared (NIR) spectral data based on the artificial neural network (ANN). Scientific interpretation of the weight values was proposed and performed to understand the wavenumbers contributing to the prediction of nutrients. NIR spectra were acquired from 110 rice samples. Carbohydrate and moisture contents were predicted with values for the determination coefficient, relative root mean square error, range error ratio, and residual prediction deviation of 0.98, 0.11 %, 44, and 7.3, and 0.97, 0.80 %, 27, and 5.8, respectively. The results agreed well with ones reported in the previous studies and acquired by the conventional partial least squares (PLS)-variable importance in projection method. This study demonstrates that the combination of NIR and ANN is a powerful and accurate tool to monitor nutrients of rice and scientific interpretation of weights can be performed to overcome black box nature of the ANN. © 2022","Artificial neural network; Near-infrared spectroscopy; Nutrients; Partial least squares; Prediction model; Rice","Forecasting; Infrared devices; Least squares approximations; Mean square error; Near infrared spectroscopy; Neural networks; Artificial neural network modeling; Near infrared spectra; Near infrared spectral; Partial least-squares; Prediction modelling; Rice; Rice (Oryza sativa L.); Spectral data; Wave numbers; Weight values; Nutrients; carbohydrate; Article; artificial neural network; carbohydrate analysis; fat content; feed forward neural network; moisture; near infrared spectroscopy; nutrient; partial least squares regression; predictive model; protein content; rice; root mean squared error; weight"
"Song C., Becagli S., Beddows D.C.S., Brean J., Browse J., Dai Q., Dall'Osto M., Ferracci V., Harrison R.M., Harris N., Li W., Jones A.E., Kirchgäßner A., Kramawijaya A.G., Kurganskiy A., Lupi A., Mazzola M., Severi M., Traversi R., Shi Z.","Understanding Sources and Drivers of Size-Resolved Aerosol in the High Arctic Islands of Svalbard Using a Receptor Model Coupled with Machine Learning","10.1021/acs.est.1c07796","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135923849&doi=10.1021%2facs.est.1c07796&partnerID=40&md5=5f5f06a86bdae95d622e2be2b1a24224","Atmospheric aerosols are important drivers of Arctic climate change through aerosol-cloud-climate interactions. However, large uncertainties remain on the sources and processes controlling particle numbers in both fine and coarse modes. Here, we applied a receptor model and an explainable machine learning technique to understand the sources and drivers of particle numbers from 10 nm to 20 μm in Svalbard. Nucleation, biogenic, secondary, anthropogenic, mineral dust, sea salt and blowing snow aerosols and their major environmental drivers were identified. Our results show that the monthly variations in particles are highly size/source dependent and regulated by meteorology. Secondary and nucleation aerosols are the largest contributors to potential cloud condensation nuclei (CCN, particle number with a diameter larger than 40 nm as a proxy) in the Arctic. Nonlinear responses to temperature were found for biogenic, local dust particles and potential CCN, highlighting the importance of melting sea ice and snow. These results indicate that the aerosol factors will respond to rapid Arctic warming differently and in a nonlinear fashion. © 2022 American Chemical Society. All rights reserved.","Arctic; machine learning; meteorology; particle number concentration; positive matrix factorization; source apportionment","Atmospheric aerosols; Climate change; Dust; Factorization; Nucleation; Sea ice; Snow; Arctic; Biogenics; High arctic; Machine-learning; Particle number concentration; Particle numbers; Positive Matrix Factorization; Receptor modeling; Source apportionment; Svalbard; Machine learning; snow; sodium chloride; climate change; aerosol; Arctic; Article; concentration (parameter); controlled study; environmental temperature; inductively coupled plasma mass spectrometry; machine learning; marine environment; meteorology; sea ice; solar radiation; summer; surface property; Svalbard and Jan Mayen; aerosol; air pollutant; dust; particle size; Arctic; Svalbard; Svalbard and Jan Mayen; Aerosols; Air Pollutants; Dust; Machine Learning; Particle Size; Svalbard"
"Song I., Kim D.","Three Common Machine Learning Algorithms Neither Enhance Prediction Accuracy Nor Reduce Spatial Autocorrelation in Residuals: An Analysis of Twenty-five Socioeconomic Data Sets","10.1111/gean.12351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139721299&doi=10.1111%2fgean.12351&partnerID=40&md5=019ab576cbadf46331584aef7d327293","Machine learning (ML) is being applied in an increasing volume of geographical research. However, the aspects of spatial autocorrelation (SAC) in the residuals produced by ML models have been understudied compared to the benefit of ML, namely, reduction of prediction errors. In this study, we examined the relationship between predictive accuracy and the reduction in the residual SAC for 597 variables from 25 geographical socio-economic data sets using spatial and nonspatial cross-validation of three ML algorithms such as random forests, support vector machine, and artificial neural network (ANN) to provide an extensive empirical diagnosis—but not a definitive theory—of the relationship between SAC and ML. Our results highlighted that the ML algorithms with tuned hyperparameters yielded marginal predictive accuracy gains and the minimal decreases in residual SAC. ANN revealed lower accuracy and higher reduction in the residual SAC than others. This implies ML algorithms in geographical research in socio-economic domains would not always result in higher prediction accuracy. We suggest that ML in geographical research should be cautiously employed when the main objective is related to the residual SAC. We also showed that spatial cross-validation neither improves predictive accuracy substantially nor reduce the residual SAC effectively. © 2022 The Ohio State University.",,
"Song J., Gao J., Zhang Y., Li F., Man W., Liu M., Wang J., Li M., Zheng H., Yang X., Li C.","Estimation of Soil Organic Carbon Content in Coastal Wetlands with Measured VIS-NIR Spectroscopy Using Optimized Support Vector Machines and Random Forests","10.3390/rs14174372","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137896869&doi=10.3390%2frs14174372&partnerID=40&md5=29806ff0018dec0a1485daeeb968d84d","Coastal wetland soil organic carbon (CW-SOC) is crucial for both “blue carbon” and carbon sequestration. It is of great significance to understand the content of soil organic carbon (SOC) in soil resource management. A total of 133 soil samples were evaluated using an indoor spectral curve and were categorized into silty soil and sandy soil. The prediction model of CW-SOC was established using optimized support vector machine regression (OSVR) and optimized random forest regression (ORFR). The Leave-One-Out Cross-Validation (LOO-CV) method was used to verify the model, and the performance of the two prediction models, as well as the models’ stability and uncertainty, was examined. The results show that (1) The SOC content of different coastal wetlands is significantly different, and the SOC content of silty soils is about 1.8 times that of sandy soils. Moreover, the characteristic wavelengths associated with SOC in silty soils are mainly concentrated in the spectral range of 500–1000 nm and 1900–2400 nm, while the spectral range of sandy soils is concentrated in the spectral range of 600–1400 nm and 1700–2400 nm. (2) The organic carbon prediction model of silty soil based on the OSVR method under the first-order differential of reflectance (R′) is the best, with the Adjusted-R2 value as high as 0.78, the RPD value is much greater than 2.0 and 5.07, and the RMSE value as low as 0.07. (3) The performance of the OSVR model is about 15~30% higher than that of the support vector machine regression (SVR) model, and the performance of the ORFR model is about 3~5% higher than that of the random forest regression (RFR) model. OSVR and ORFR are better methods of accurately predicting the CW-SOC content and provide data support for the carbon cycle, soil conservation, plant growth, and environmental protection of coastal wetlands. © 2022 by the authors.","coastal wetland soil organic carbon; optimized random forest regression; optimized support vector machine regression; prediction model; spectrum","Forecasting; Organic carbon; Random forests; Regression analysis; Sand; Soil conservation; Soils; Spectrum analysis; Support vector machines; Vectors; Coastal wetland soil organic carbon; Coastal wetlands; Optimized random forest regression; Optimized support vector machine regression; Prediction modelling; Random forests; Soil organic carbon; Spectra's; Support vector machine regressions; Wetland soils; Decision trees"
"Song M., Liu Y., Li T., Liu X., Hao Z., Ding S., Panichayupakaranant P., Zhu K., Shen J.","Plant Natural Flavonoids Against Multidrug Resistant Pathogens","10.1002/advs.202100749","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106465707&doi=10.1002%2fadvs.202100749&partnerID=40&md5=fa617d021b8246222d64e76ccabd3dc4","The increasing emergence and dissemination of multidrug resistant (MDR) bacterial pathogens accelerate the desires for new antibiotics. Natural products dominate the preferred chemical scaffolds for the discovery of antibacterial agents. Here, the potential of natural flavonoids from plants against MDR bacteria, is demonstrated. Structure–activity relationship analysis shows the prenylation modulates the activity of flavonoids and obtains two compounds, α-mangostin (AMG) and isobavachalcone (IBC). AMG and IBC not only display rapid bactericidal activity against Gram-positive bacteria, but also restore the susceptibility of colistin against Gram-negative pathogens. Mechanistic studies generally show such compounds bind to the phospholipids of bacterial membrane, and result in the dissipation of proton motive force and metabolic perturbations, through distinctive modes of action. The efficacy of AMG and IBC in four models associated with infection or contamination, is demonstrated. These results suggest that natural products of plants may be a promising and underappreciated reservoir to circumvent the existing antibiotic resistance. © 2021 The Authors. Advanced Science published by Wiley-VCH GmbH","bacterial membrane; drug discovery; flavonoids; isopentenyl; multidrug-resistant bacteria","Antibiotics; Bacteria; Phospholipids; Activity relationship analysis; Antibiotic resistance; Bacterial pathogens; Bactericidal activity; Gram-negative pathogens; Gram-positive bacterium; Multidrug resistants; Proton-motive forces; Flavonoids; antiinfective agent; colistin; flavonoid; plant extract; animal; bacterium; Bagg albino mouse; disease model; drug effect; female; microbial sensitivity test; mouse; multidrug resistance; Animals; Anti-Bacterial Agents; Bacteria; Colistin; Disease Models, Animal; Drug Resistance, Multiple, Bacterial; Female; Flavonoids; Mice; Mice, Inbred BALB C; Microbial Sensitivity Tests; Plant Extracts"
"Sottocornola G., Baric S., Stella F., Zanker M.","Development of a Knowledge-Based Expert System for Diagnosing Post-Harvest Diseases of Apple","10.3390/agriculture13010177","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146704460&doi=10.3390%2fagriculture13010177&partnerID=40&md5=5f3a50acc1ab4df36fc59ec468d4cee8","Post-harvest diseases are one of the main causes of economical losses in the apple fruit production sector. Therefore, this paper presents an application of a knowledge-based expert system to diagnose post-harvest diseases of apple. Specifically, we detail the process of domain knowledge elicitation for constructing a Bayesian network reasoning system. We describe the developed expert system, dubbed BN-DSSApple, and the diagnostic mechanism given the evidence provided by the user, as well as a likelihood evidence method, learned from the estimated consensus of users’ and expert’s interactions, to effectively transfer the performance of the model to different cohorts of users. Finally, we detail a novel technique for explaining the provided diagnosis, thus increasing the trust in the system. We evaluate BN-DSSApple with three different types of user studies, involving real diseased apples, where the ground truth of the target instances was established by microbiological and DNA analysis. The experiments demonstrate the performance differences in the knowledge-based reasoning mechanism due to heterogeneous users interacting with the system under various conditions and the capability of the likelihood-based method to improve the diagnostic performance in different environments. © 2023 by the authors.","Bayesian network; expert system in agriculture; explanation; knowledge elicitation; likelihood evidence; post-harvest diseases of apple",
"Sousa D., Davis F.W.","Scalable mapping and monitoring of Mediterranean-climate oak landscapes with temporal mixture models","10.1016/j.rse.2020.111937","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088018079&doi=10.1016%2fj.rse.2020.111937&partnerID=40&md5=b21e1343f5ef7e78b69c2ed2854cca92","Mediterranean-climate oak woodlands are prized for their biodiversity, aesthetics, and ecosystem services. Conservation and maintenance of these landscapes requires accurate observations of both present and historic conditions capable of spanning millions of hectares. Decameter optical satellite image time series have the observational coverage to meet this need, with almost 40 years of intercalibrated global observations from the Landsat program alone. However, the optimal approach to leverage these observations for oak ecosystem monitoring remains elusive. Temporal mixture models (TMMs) may offer a solution. TMMs use a linear inverse model based on temporal endmembers (tEMs) chosen to optimize both parsimony and information content by 1) possessing clear biophysical meaning, and 2) accurately representing the variance structure of the observations in the temporal feature space (TFS) composed of low-order Principal Components. We apply this approach to oak woodlands of the California Sierra Nevada foothills. Low-order TFS structure across the ≈1200 km2 study area is consistently bounded by 4 tEM phenologies: annual grasses, evergreen perennials, deciduous perennials + shadow, and unvegetated areas. Satellite-based tEM phenologies correspond to ground-based PhenoCam time series (correlations 0.8 to 0.9). Systematic temporal decimation is conducted to simulate years with varying numbers of cloud free measurements. Fractional cover of temporal endmembers is observed to scale linearly using as few as 6 images per year and coarse feature space topology is retained with as few as 4 well-timed images per year. In comparing 10 m versus 30 m pixel resolution, linear scaling is observed with correlations of 0.78–0.95. Comparison of 10 m Sentinel-2 and LiDAR-derived tree cover estimates at San Joaquin Experimental Range shows a correlation of 0.74. Visual orthophoto validation shows accuracies of annual, deciduous, and evergreen cover fractions of 74–88% (n = 102). Multi-year analysis of August imagery at Sequoia National Park to investigate dynamics associated with the 2012–2016 drought reveals 5 tEMs corresponding to: steady growth, steady decline, early decline then regrowth, persistent vegetation, and no vegetation. Validation images are sparse, but where available show accuracies in the 88 to 91% range for decrease, growth, and persistently vegetated multiyear endmembers (n = 102). Decreases are observed in areas with oak mortality documented in a recent field-based study. Overall, our results suggest the TMM approach has promise as an accurate, explainable, and linearly scalable method for retrospective analysis and prospective monitoring of Mediterranean-climate oak landscapes. © 2020 Elsevier Inc.","California; Landsat; Mediterranean ecosystems; Oak woodland; Phenology; Savanna; Sentinel","Biodiversity; Climatology; Ecosystems; Inverse problems; Mixtures; Optical radar; Scalability; Time series; Vegetation; Conservation and maintenance; Ecosystem monitoring; Information contents; Linear inverse models; Mediterranean climates; Optical satellite images; Principal Components; Retrospective analysis; Climate models; deciduous tree; Landsat; landscape; mapping method; Mediterranean environment; perennial plant; phenology; satellite imagery; Sentinel; spatiotemporal analysis; woodland; California; Sequoia National Park; Sierra Nevada [California]; United States; Poaceae"
"Sravanthi G., Sai Kiran P.","EMPIRICAL STUDY ON FUNGAL DISEASES IN VARIOUS PLANTS USING DIFFERENT DEEP LEARNING APPROACHES",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142400095&partnerID=40&md5=9b499c4a8db23066ae6a45b18bb7a518","The productivity of the agriculture decreasing day by day due to various factors. The quality of the agriculture is impacted by the pests and diseases infected on the plants. Many researches proposed traditional image processing techniques to identify the diseases and design a recommendation system but all these are expensive and inaccurate systems, which are not affordable by farmers. When a new era known as “Machine Learning” as evolved, researchers extracted necessary features from the plant images and converted them into csv files to classify the diseases in plants using these approaches. Even these approaches are time consuming, so researchers are moved to deep learning approaches in which the intermediate steps takes places automatically in between input and output like pre-processing feature extraction. In this paper, the model studied about different deep learning approaches available on the disease detection system in various plants. Among the deep learning models, the researchers who have implemented transfer learning approaches have obtained high accuracy and few have achieved good kappa cohen values also. In traditional models the system needs to assume random weights for the neurons to produce the dot vectors of every layers. These assumed values some times may give more error rate which results in back propagation. Transfer learning helps the model to get the optimal weights without assumptions of each neuron from the pre-trained model it implements. The major advantage of any pre-trained model lies in faster training of network with millions of different categories images. One of the popular dataset used by most of the researchers for this study is “ImageNet”. Using the concept of transfer using the ImageNet irrespective of any pre-trained model implemented the accuracy lies in between 92% to 96%. © 2022 Little Lion Scientific.","Annotation; Augmented Data; Image Enhancement; Segmentation; Transfer Learning",
"Srikrishnan V., Lafferty D.C., Wong T.E., Lamontagne J.R., Quinn J.D., Sharma S., Molla N.J., Herman J.D., Sriver R.L., Morris J.F., Lee B.S.","Uncertainty Analysis in Multi-Sector Systems: Considerations for Risk Analysis, Projection, and Planning for Complex Systems","10.1029/2021EF002644","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138008154&doi=10.1029%2f2021EF002644&partnerID=40&md5=6957081a3d3d27f84aff64b41f0d2632","Simulation models of multi-sector systems are increasingly used to understand societal resilience to climate and economic shocks and change. However, multi-sector systems are also subject to numerous uncertainties that prevent the direct application of simulation models for prediction and planning, particularly when extrapolating past behavior to a nonstationary future. Recent studies have developed a combination of methods to characterize, attribute, and quantify these uncertainties for both single- and multi-sector systems. Here, we review challenges and complications to the idealized goal of fully quantifying all uncertainties in a multi-sector model and their interactions with policy design as they emerge at different stages of analysis: (a) inference and model calibration; (b) projecting future outcomes; and (c) scenario discovery and identification of risk regimes. We also identify potential methods and research opportunities to help navigate the tradeoffs inherent in uncertainty analyses for complex systems. During this discussion, we provide a classification of uncertainty types and discuss model coupling frameworks to support interdisciplinary collaboration on multi-sector dynamics (MSD) research. Finally, we conclude with recommendations for best practices to ensure that MSD research can be properly contextualized with respect to the underlying uncertainties. © 2022 The Authors.","calibration; multi-sector dynamics; projections; scenario discovery; uncertainty","calibration; interdisciplinary approach; planning practice; prediction; risk assessment; scenario analysis; uncertainty analysis"
"Stein A.L.","Artificial intelligence and climate change",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096210380&partnerID=40&md5=0ea772a2c834e5b023895ce61977134d","As artificial intelligence (AI) continues to embed itself in our daily lives, many focus on the threats it poses to privacy, security, due process, and democracy itself. But beyond these legitimate concerns, AI promises to optimize activities, increase efficiency, and enhance the accuracy and efficacy of the many aspects of society relying on predictions and likelihoods. In short, its most promising applications may come, not from uses affecting civil liberties and the social fabric of our society, but from those particularly complex technical problems lying beyond our ready human capacity. Climate change is one such complex problem, requiring fundamental changes to our transportation, agricultural, building, and energy sectors. This Article argues for the enhanced use of AI to address climate change, using the energy sector to exemplify its potential promise and pitfalls. The Article then analyzes critical policy tradeoffs that may be associated with an increased use of AI and argues for its disciplined use in a way that minimizes its limitations while harnessing its benefits to reduce greenhouse-gas emissions. © 2020 Yale Journal on Regulation. All rights reserved.",,
"Stein L., Clark M.P., Knoben W.J.M., Pianosi F., Woods R.A.","How Do Climate and Catchment Attributes Influence Flood Generating Processes? A Large-Sample Study for 671 Catchments Across the Contiguous USA","10.1029/2020WR028300","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104861878&doi=10.1029%2f2020WR028300&partnerID=40&md5=5964dfb3975a11784aac815bde9cc4dd","Hydrometeorological flood generating processes (excess rain, short rain, long rain, snowmelt, and rain-on-snow) underpin our understanding of flood behavior. Knowledge about flood generating processes improves hydrological models, flood frequency analysis, estimation of climate change impact on floods, etc. Yet, not much is known about how climate and catchment attributes influence the spatial distribution of flood generating processes. This study aims to offer a comprehensive and structured approach to close this knowledge gap. We employ a large sample approach (671 catchments across the contiguous United States) and evaluate how catchment attributes and climate attributes influence the distribution of flood processes. We use two complementary approaches: A statistics-based approach which compares attribute frequency distributions of different flood processes; and a random forest model in combination with an interpretable machine learning approach (accumulated local effects [ALE]). The ALE method has not been used often in hydrology, and it overcomes a significant obstacle in many statistical methods, the confounding effect of correlated catchment attributes. As expected, we find climate attributes (fraction of snow, aridity, precipitation seasonality, and mean precipitation) to be most influential on flood process distribution. However, the influence of catchment attributes varies both with flood generating process and climate type. We also find flood processes can be predicted for ungauged catchments with relatively high accuracy (R2 between 0.45 and 0.9). The implication of these findings is flood processes should be considered for future climate change impact studies, as the effect of changes in climate on flood characteristics varies between flood processes. © 2020. The Authors.","accumulated local effects; catchment attributes; climate; flood generating process; interpretable machine learning; large sample","Catchments; Climate models; Decision trees; Flood control; Floods; Frequency estimation; Object oriented programming; Rain; Runoff; Snow; Attribute frequency; Climate change impact; Flood characteristics; Flood frequency analysis; Hydrological models; Machine learning approaches; Process distribution; Random forest modeling; Climate change; agricultural catchment; algorithm; catchment; climate change; climate effect; flood; flood frequency; machine learning; United States"
"Stetter C., Mennig P., Sauer J.","Using Machine Learning to Identify Heterogeneous Impacts of Agri-Environment Schemes in the EU: A Case Study","10.1093/erae/jbab057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135020553&doi=10.1093%2ferae%2fjbab057&partnerID=40&md5=e7b479742aae426cbd49b59746a2ca01","Legislators in the European Union have long been concerned with the environmental impact of farming activities and introduced so-called agri-environment schemes (AES) to mitigate adverse environmental effects and foster desirable ecosystem services in agriculture. This study combines economic theory with a novel machine learning method to identify the environmental effectiveness of AES at the farm level. We develop a set of more than 130 contextual predictors to assess the individual impact of participating in AES. Results from our empirical application for Southeast Germany suggest the existence of heterogeneous, but limited effects of agri-environment measures in several environmental dimensions such as climate change mitigation, clean water and soil health. By making use of Shapley values, we demonstrate the importance of considering the individual farming context in agricultural policy evaluation and provide important insights into the improved targeting of AES along several domains. © 2022 The Author(s). Published by Oxford University Press on behalf of the Foundation for the European Review of Agricultural Economics. All rights reserved.","Agri-environment schemes; causal machine learning; EU common agricultural policy (CAP); heterogeneous treatment effects; impact evaluation; random forests (RFs)","agricultural policy; climate change; ecosystem service; heterogeneous medium; machine learning; mitigation"
"Stocker M.D., Pachepsky Y.A., Hill R.L.","Prediction of E. coli Concentrations in Agricultural Pond Waters: Application and Comparison of Machine Learning Algorithms","10.3389/frai.2021.768650","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123403384&doi=10.3389%2ffrai.2021.768650&partnerID=40&md5=a0abfd2034f8e8b60f1cc756f4832289","The microbial quality of irrigation water is an important issue as the use of contaminated waters has been linked to several foodborne outbreaks. To expedite microbial water quality determinations, many researchers estimate concentrations of the microbial contamination indicator Escherichia coli (E. coli) from the concentrations of physiochemical water quality parameters. However, these relationships are often non-linear and exhibit changes above or below certain threshold values. Machine learning (ML) algorithms have been shown to make accurate predictions in datasets with complex relationships. The purpose of this work was to evaluate several ML models for the prediction of E. coli in agricultural pond waters. Two ponds in Maryland were monitored from 2016 to 2018 during the irrigation season. E. coli concentrations along with 12 other water quality parameters were measured in water samples. The resulting datasets were used to predict E. coli using stochastic gradient boosting (SGB) machines, random forest (RF), support vector machines (SVM), and k-nearest neighbor (kNN) algorithms. The RF model provided the lowest RMSE value for predicted E. coli concentrations in both ponds in individual years and over consecutive years in almost all cases. For individual years, the RMSE of the predicted E. coli concentrations (log10 CFU 100 ml−1) ranged from 0.244 to 0.346 and 0.304 to 0.418 for Pond 1 and 2, respectively. For the 3-year datasets, these values were 0.334 and 0.381 for Pond 1 and 2, respectively. In most cases there was no significant difference (P &gt; 0.05) between the RMSE of RF and other ML models when these RMSE were treated as statistics derived from 10-fold cross-validation performed with five repeats. Important E. coli predictors were turbidity, dissolved organic matter content, specific conductance, chlorophyll concentration, and temperature. Model predictive performance did not significantly differ when 5 predictors were used vs. 8 or 12, indicating that more tedious and costly measurements provide no substantial improvement in the predictive accuracy of the evaluated algorithms. Copyright © 2022 Stocker, Pachepsky and Hill.","E. coli; food safety; irrigation water; machine learning; microbial water quality",
"Storm H., Baylis K., Heckelei T.","Machine learning in agricultural and applied economics","10.1093/erae/jbz033","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087314535&doi=10.1093%2ferae%2fjbz033&partnerID=40&md5=e21fbc8812c555008f458fd09ba0642c","This review presents machine learning (ML) approaches from an applied economist's perspective. We first introduce the key ML methods drawing connections to econometric practice. We then identify current limitations of the econometric and simulation model toolbox in applied economics and explore potential solutions afforded by ML. We dive into cases such as inflexible functional forms, unstructured data sources and large numbers of explanatory variables in both prediction and causal analysis, and highlight the challenges of complex simulation models. Finally, we argue that economists have a vital role in addressing the shortcomings of ML when used for quantitative economic analysis. © 2019 Oxford University Press and Foundation for the European Review of Agricultural Economics 2019.","agri-environmental policy analysis; econometrics; machine learning; quantitative economic analysis; simulation models","agricultural economics; econometrics; economic analysis; machine learning; simulation"
"Straub J.","Automating the design and development of gradient descent trained expert system networks","10.1016/j.knosys.2022.109465","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136470838&doi=10.1016%2fj.knosys.2022.109465&partnerID=40&md5=3eff4787eb32afb580783bb1b89a2dfb","Prior work introduced a gradient descent trained expert system that conceptually combines the learning capabilities of neural networks with the understandability and defensible logic of an expert system. This system was shown to be able to learn patterns from data and to perform decision-making at levels rivaling those reported by neural network systems. The principal limitation of the approach, though, was the necessity for the manual development of a rule-fact network (which is then trained using backpropagation). This paper proposes a technique for overcoming this significant limitation, as compared to neural networks. Specifically, this paper proposes the use of larger and denser-than-application need rule-fact networks which are trained, pruned, manually reviewed and then re-trained for use. Multiple types of networks are evaluated under multiple operating conditions and these results are presented and assessed. Based on these individual experimental condition assessments, the proposed technique is evaluated. The data presented shows that error rates as low as 3.9% (mean, 1.2% median) can be obtained, demonstrating the efficacy of this technique for many applications. © 2022 Elsevier B.V.","Automation; Defensible artificial intelligence; Expert systems; Gradient descent; Machine learning; Network design; Training","Decision making; Gradient methods; Learning systems; Machine learning; Defensible artificial intelligence; Design and Development; Gradient-descent; Learn+; Learning capabilities; Machine-learning; Network design; Neural-networks; Systems networks; Understandability; Expert systems"
"Straub J.","Impact of techniques to reduce error in high error rule-based expert system gradient descent networks","10.1007/s10844-021-00672-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115672891&doi=10.1007%2fs10844-021-00672-7&partnerID=40&md5=323b5be4be72dc2297d45b0c55817c5f","Machine learning systems offer the key capability to learn about their operating environment from the data that they are supplied. They can learn via supervised and unsupervised training, from system results during operations, or both. However, while machine learning systems can identify solutions to problems and questions, in many cases they cannot explain how they arrived at them. Moreover, they cannot guarantee that they have not relied upon confounding variables and other non-causal relationships. In some circumstances, learned behaviors may violate legal or ethical principles such as rules regarding non-discrimination. In these and other cases, learned associations that are true in many – but not all – cases may result in critical system failures when processing exceptions to the learned behaviors. A machine learning system, which applies gradient descent to expert system networks, has been proposed as a solution to this. The expert system foundation means that the system can only learn across valid pathways, while the machine learning capabilities facilitate optimization via training and operational learning. While the initial results of this approach are promising, cases where networks were optimized into high error states (and for which continued optimization continued to increase the error level) were noted. This paper proposes and evaluates multiple techniques to handle these high error networks and improve system performance, in these cases. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Backpropagation; Error reduction; Expert system; Gradient descent; Machine learning; Training","Errors; Expert systems; Machine learning; Optimization; Systems engineering; Error reduction; Error rules; Gradient-descent; Learn+; Machine learning systems; Operating environment; Optimisations; Rule-based expert system; Supervised trainings; Unsupervised training; Gradient methods"
"Straub J.","Expert system gradient descent style training: Development of a defensible artificial intelligence technique","10.1016/j.knosys.2021.107275","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109218375&doi=10.1016%2fj.knosys.2021.107275&partnerID=40&md5=d70c3360647ad493bf9de0d00b8cd1cf","Artificial intelligence systems, which are designed with a capability to learn from the data presented to them, are used throughout society. These systems are used to screen loan applicants, make sentencing recommendations for criminal defendants, scan social media posts for disallowed content and more. Because these systems do not assign meaning to their complex learned correlation network, they can learn associations that do not equate to causality, resulting in non-optimal and indefensible decisions being made. In addition to making decisions that are sub-optimal, these systems may create legal liability for their designers and operators by learning correlations that violate anti-discrimination and other laws regarding what factors can be used in different types of decision making. This paper presents the use of a machine learning expert system, which is developed with meaning-assigned nodes (facts) and correlations (rules). Multiple potential implementations are considered and evaluated under different conditions, including different network error and augmentation levels and different training levels. The performance of these systems is compared to random and fully connected networks. © 2021 Elsevier B.V.","Defensible artificial intelligence; Expert systems; Gradient descent; Machine learning; Training","Decision making; Gradient methods; Machine learning; Optimization; Personnel training; Artificial intelligence systems; Artificial intelligence techniques; Correlation network; Defensible artificial intelligence; Gradient-descent; Learn+; Machine-learning; Making decision; Social media; Training development; Expert systems"
"Straub J.","Assessment of gradient descent trained rule-fact network expert system multi-path training technique performance","10.3390/computers10080103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113774552&doi=10.3390%2fcomputers10080103&partnerID=40&md5=876b2ee51efa1c75041807e5f5d31566","The use of gradient descent training to optimize the performance of a rule-fact network expert system via updating the network’s rule weightings was previously demonstrated. Along with this, four training techniques were proposed: two used a single path for optimization and two use multiple paths. The performance of the single path techniques was previously evaluated under a variety of experimental conditions. The multiple path techniques, when compared, outperformed the single path ones; however, these techniques were not evaluated with different network types, training velocities or training levels. This paper considers the multi-path techniques under a similar variety of experimental conditions to the prior assessment of the single-path techniques and demonstrates their effectiveness under multiple operating conditions. © 2021 by the author. Licensee MDPI, Basel, Switzerland.","Artificial intelligence; Expert system; Gradient descent; Machine learning; Multi-path; Single-path; Training",
"Streich J., Romero J., Gazolla J.G.F.M., Kainer D., Cliff A., Prates E.T., Brown J.B., Khoury S., Tuskan G.A., Garvin M., Jacobson D., Harfouche A.L.","Can exascale computing and explainable artificial intelligence applied to plant biology deliver on the United Nations sustainable development goals?","10.1016/j.copbio.2020.01.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079546842&doi=10.1016%2fj.copbio.2020.01.010&partnerID=40&md5=006c224ddebcd01a3660ed324db007dd","Human population growth and accelerated climate change necessitate agricultural improvements using designer crop ideotypes (idealized plants that can grow in niche environments). Diverse and highly skilled research groups must integrate efforts to bridge the gaps needed to achieve international goals toward sustainable agriculture. Given the scale of global agricultural needs and the breadth of multiple types of omics data needed to optimize these efforts, explainable artificial intelligence (AI with a decipherable decision making process that provides a meaningful explanation to humans) and exascale computing (computers that can perform 1018 floating-point operations per second, or exaflops) are crucial. Accurate phenotyping and daily-resolution climatype associations are equally important for refining ideotype production to specific environments at various levels of granularity. We review advances toward tackling technological hurdles to solve multiple United Nations Sustainable Development Goals and discuss a vision to overcome gaps between research and policy. © 2020 Elsevier Ltd",,"Agriculture; Artificial intelligence; Climate change; Decision making; Digital arithmetic; Planning; Population statistics; Sustainable development; Decision making process; Exascale computing; Floating point operations per seconds; Human population growth; Plant biology; Research groups; Sustainable agriculture; United Nations; Plants (botany); artificial intelligence; bioenergy; botany; climate change; computer analysis; crop; ecological niche; environmental mutagenesis; epigenetics; exascale computing; food security; genetic association; genomics; genotype; greenhouse gas; harvest; human; mathematical computing; metabolomics; multiomics; nonhuman; phenomics; phenotype; priority journal; proteomics; Review; sustainable development; time series analysis; transcriptomics; agriculture; motivation; United Nations; Agriculture; Artificial Intelligence; Goals; Humans; Sustainable Development; United Nations"
"Stupariu M.-S., Cushman S.A., Pleşoianu A.-I., Pătru-Stupariu I., Fürst C.","Machine learning in landscape ecological analysis: a review of recent approaches","10.1007/s10980-021-01366-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120385003&doi=10.1007%2fs10980-021-01366-9&partnerID=40&md5=77b040df42220f0416243e48bec63076","Context: Artificial Intelligence (AI) has rapidly developed over the past several decades. Several related AI approaches, such as Machine Learning (ML), have been applied to research on landscape patterns and ecological processes. Objectives: Our goal was to review the methods of AI, particularly ML, used in studies related to landscape ecology and the main topics addressed. We aimed to assess the trend in the number of ML papers and the methods used therein, and provide a synopsis and prospectus of current use and future applications of ML in landscape ecology. Methods: We conducted a systematic literature search and selected 125 papers for review. These were examined and scored according to multiple criteria regarding methods and topic. We applied quantitative statistical methods, including cluster analysis based on titles, abstracts, and keywords and a non-metric multidimensional scaling based on attributes assigned during the review. We used Random Forests machine learning to describe the differences between identified clusters in terms of the topics and methods they included. Results: The most frequent method found was Random Forests, but it is noteworthy to mention the increasing popularity of tools related to Deep Learning. The topics cover both ecologically oriented issues and the landscape-human interface. There has been a rapid increase in ML and AI methods in landscape ecology research, with Deep Learning and complex multi-step pipeline AI methods emerging in the last several years. Conclusions: The rapid increase in the number of ML papers in landscape ecology research, and the range of methods employed in them, suggest explosive growth in application of these methods in landscape ecology. The increase of Deep Learning approaches in the most recent years suggest a major change in analytical paradigms and methodologies that we feel may transform the field and enable analyses of more complex pattern process relationships across vaster data sets than has been possible previously. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.","Artificial intelligence; Classification; Clustering; Data analysis; Landscape ecology; Machine learning; Modelling; Prediction","artificial intelligence; cluster analysis; landscape ecology; literature review; machine learning; prediction"
"Sun B., Bai J., Chu X., Sun S., Li Y., Li H.","Interval prediction approach to crude oil price based on three-way clustering and decomposition ensemble learning","10.1016/j.asoc.2022.108933","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130366871&doi=10.1016%2fj.asoc.2022.108933&partnerID=40&md5=46c5fdcb93238d33b7e18805cd1ea289","Prediction methods have become a hot topic in intelligent decision making. Most of the existing prediction methods focus on the prediction accuracy and stability. As a second choice, accurate interval prediction can provide a relatively reliable reference in the sense of probability and provide help for assisting decision management. Therefore, we propose a novel interval prediction approach. Firstly, the decomposition method based on ensemble empirical mode decomposition (EEMD) is utilized to alleviate the complexity of the original time series, thereby generating a series of relatively smooth subseries. Secondly, a three-way clustering (TWC) algorithm is established by integrating sample entropy into probabilistic rough set, enriching the three-way clustering theory from the perspective of entropy. Thirdly, aiming at determining the optimal input dimensions of different neural networks, the feature selection technique based on phase space reconstruction (PSR) is constructed. Furthermore, an interval prediction system based on TWC is proposed to provide a new data-driven prediction method. Finally, the proposed approach is applied to predict the interval price of crude oil. On the one hand, the practicability of the constructed prediction approach is verified; on the other hand, it provides a new theoretical method for interval prediction of crude oil price. The experiment results show the proposed prediction approach can assist the decision-makers to make scientific and reasonable decisions. © 2022","Crude oil price forecasting; Ensemble empirical mode decomposition; Phase space reconstruction; Probability rough set","Clustering algorithms; Crude oil; Decision making; Entropy; Forecasting; Rough set theory; Clusterings; Crude oil price forecasting; Empirical Mode Decomposition; Ensemble empirical mode decomposition; Interval prediction; Phase space reconstruction; Phase spaces; Prediction methods; Probability rough set; Space reconstruction; Phase space methods"
"Sun H., Wang B., Xue J.","YOLO-P: An efficient method for pear fast detection in complex orchard picking environment","10.3389/fpls.2022.1089454","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146305057&doi=10.3389%2ffpls.2022.1089454&partnerID=40&md5=00279f650db7f576fbec6cb4d200664b","Introduction: Fruit detection is one of the key functions of an automatic picking robot, but fruit detection accuracy is seriously decreased when fruits are against a disordered background and in the shade of other objects, as is commmon in a complex orchard environment. Methods: Here, an effective mode based on YOLOv5, namely YOLO-P, was proposed to detect pears quickly and accurately. Shuffle block was used to replace the Conv, Batch Norm, SiLU (CBS) structure of the second and third stages in the YOLOv5 backbone, while the inverted shuffle block was designed to replace the fourth stage’s CBS structure. The new backbone could extract features of pears from a long distance more efficiently. A convolutional block attention module (CBAM) was inserted into the reconstructed backbone to improve the robot’s ability to capture pears’ key features. Hard-Swish was used to replace the activation functions in other CBS structures in the whole YOLOv5 network. A weighted confidence loss function was designed to enhance the detection effect of small targets. Result: At last, model comparison experiments, ablation experiments, and daytime and nighttime pear detection experiments were carried out. In the model comparison experiments, the detection effect of YOLO-P was better than other lightweight networks. The results showed that the module’s average precision (AP) was 97.6%, which was 1.8% higher than the precision of the original YOLOv5s. The model volume had been compressed by 39.4%, from 13.7MB to only 8.3MB. Ablation experiments verified the effectiveness of the proposed method. In the daytime and nighttime pear detection experiments, an embedded industrial computer was used to test the performance of YOLO-P against backgrounds of different complexities and when fruits are in different degrees of shade. Discussion: The results showed that YOLO-P achieved the highest F1 score (96.1%) and frames per second (FPS) (32 FPS). It was sufficient for the picking robot to quickly and accurately detect pears in orchards. The proposed method can quickly and accurately detect pears in unstructured environments. YOLO-P provides support for automated pear picking and can be a reference for other types of fruit detection in similar environments. Copyright © 2023 Sun, Wang and Xue.","convolutional neural network; deep learning; fruit detection; pear; YOLOv5",
"Sun T., Wu H.","Reconciling the actual and nominal exposure concentrations of microplastics in aqueous phase: Implications for risk assessment and deviation control","10.1016/j.jhazmat.2022.130246","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140806575&doi=10.1016%2fj.jhazmat.2022.130246&partnerID=40&md5=9b0387e5fbea8c807c71f1ff48f41c06","The deviation between actual and nominal concentrations of microplastics (MPs), as a long-standing issue, has been critically commented. However, there is still a lack of quantitative assessment and reconciling practice on the deviation. In this study, a total of 210 deviations were recompiled to thoroughly examine this issue. It was shown that up to 81 (39%) deviations exceeded the recommended ± 20% variation specification, highlighting that the deviation of MPs should not be neglected. This study attempted to reconcile the deviation based on the most prominent driving factors. Specifically, the game theory-based SHapley Additive exPlanations (SHAP) algorithm identified that the particle size was the most important factor affecting the deviation. Subsequently, at each size magnitude, a significant linear correlation between the logarithmic actual and nominal concentrations was determined, which provided a sound basis for estimating the actual concentration from the nominal one. Furthermore, deviations of different size classes were simulated through 10, 000 points, suggesting that the ± 20% deviation variation could be well maintained within a specific concentration range. Moreover, the potential interaction effects between factors were quantified by SHAP interaction values, with more detailed conversion bases proposed. Additionally, several control measures were recommended to reduce the deviation of MPs. © 2022 Elsevier B.V.","Actual concentration; Aqueous solution; Deviation control; Microplastics; Nominal concentration","Game theory; Microplastic; Risk assessment; Actual concentration; Aqueous phasis; Deviation control; Driving factors; Exposure concentration; Microplastics; Nominal concentration; Quantitative assessments; Risks assessments; Shapley; Particle size; dissolved organic matter; dissolved oxygen; fresh water; microplastic; polyester; polyethylene; polyethylene terephthalate; polymer; polypropylene; polystyrene; rubber; sea water; plastic; aqueous solution; concentration (composition); control system; particle size; plastic; risk assessment; acidification; algorithm; aqueous solution; Article; chemical composition; conductance; deviation control; environmental exposure; hydrodynamics; machine learning; microplastic pollution; morphology; motor vehicle tire; particle size; protonation; quality control; risk assessment; sedimentation; shapley additive explanation algorithm; simulation; stereospecificity; toxicity; water pollutant; Microplastics; Plastics; Risk Assessment; Water Pollutants, Chemical"
"Sun W., Bocchini P., Davison B.D.","Applications of artificial intelligence for disaster management","10.1007/s11069-020-04124-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087516664&doi=10.1007%2fs11069-020-04124-3&partnerID=40&md5=2e88504baab7c30f5f974b696d9ee737","Natural hazards have the potential to cause catastrophic damage and significant socioeconomic loss. The actual damage and loss observed in the recent decades has shown an increasing trend. As a result, disaster managers need to take a growing responsibility to proactively protect their communities by developing efficient management strategies. A number of research studies apply artificial intelligence (AI) techniques to process disaster-related data for supporting informed disaster management. This study provides an overview of current applications of AI in disaster management during its four phases: mitigation, preparedness, response, and recovery. It presents example applications of different AI techniques and their benefits for supporting disaster management at different phases, as well as some practical AI-based decision support tools. We find that the majority of AI applications focus on the disaster response phase. This study also identifies challenges to inspire the professional community to advance AI techniques for addressing them in future research. © 2020, Springer Nature B.V.","Artificial intelligence; Disaster management; Disaster resilience","artificial intelligence; disaster management; management practice; natural hazard"
"Sun Y., Zhao Y., Wu J., Liu N., Kang X., Wang S., Zhou D.","An explainable machine learning model for identifying geographical origins of sea cucumber Apostichopus japonicus based on multi-element profile","10.1016/j.foodcont.2021.108753","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120673973&doi=10.1016%2fj.foodcont.2021.108753&partnerID=40&md5=1fdd3ddf0a88eefc48256c9ee1bbcc9d","The geographical origin of sea cucumber Apostichopus japonicas plays an important role in determining its market value. This study investigated the feasibility of using multi-element profile combined with explainable machine learning to trace the origin of sea cucumber in China. Multi-element profile (23 elements) of 167 sea cucumber samples was determined with ICP-OES and ICP-MS, and used for construction and evaluation of 4 ensemble learning models. Extreme gradient boosting (XGBoost) model achieved superior performance with an overall accuracy, precision, recall, F1 score and AUC as 0.95, 0.93, 0.91 and 1, respectively. The Shapley Additive Explanations (SHAP) algorithm was subsequently applied to interpret the XGBoost model output for desirable geographical information. Se was identified as the most important elemental marker for discriminating sea cucumber origins. Therefore, with clarified scientific support, multi-element profile combined with machine learning model could serve as a powerful tool for identifying the provenance of sea cucumber. © 2021","Explainable machine learning; Geographical origins; Multi-element profile; Sea cucumber; SHAP; XGBoost",
"Sun Y., Zhu H., Qin C., Zhuang F., He Q., Xiong H.","Discerning Decision-Making Process of Deep Neural Networks with Hierarchical Voting Transformation",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131880546&partnerID=40&md5=45cadacad036f391d94364c7119717f4","Neural network based deep learning techniques have shown great success for numerous applications. While it is expected to understand their intrinsic decision-making processes, these deep neural networks often work in a black-box way. To this end, in this paper, we aim to discern the decision-making processes of neural networks through a hierarchical voting strategy by developing an explainable deep learning model, namely Voting Transformation-based Explainable Neural Network (VOTEN). Specifically, instead of relying on massive feature combinations, VOTEN creatively models expressive single-valued voting functions between explicitly modeled latent concepts to achieve high fitting ability. Along this line, we first theoretically analyze the major components of VOTEN and prove the relationship and advantages of VOTEN compared with Multi-Layer Perceptron (MLP), the basic structure of deep neural networks. Moreover, we design efficient algorithms to improve the model usability by explicitly showing the decision processes of VOTEN. Finally, extensive experiments on multiple real-world datasets clearly validate the performances and explainability of VOTEN. © 2021 Neural information processing systems foundation. All rights reserved.",,"Decision making; Multilayer neural networks; Black boxes; Decision-making process; Feature combination; Learning models; Learning techniques; Multilayers perceptrons; Network-based; Neural-networks; Transformation based; Voting strategies; Deep neural networks"
"Sun Z., Sandoval L., Crystal-Ornelas R., Mousavi S.M., Wang J., Lin C., Cristea N., Tong D., Carande W.H., Ma X., Rao Y., Bednar J.A., Tan A., Wang J., Purushotham S., Gill T.E., Chastang J., Howard D., Holt B., Gangodagamage C., Zhao P., Rivas P., Chester Z., Orduz J., John A.","A review of Earth Artificial Intelligence","10.1016/j.cageo.2022.105034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122572031&doi=10.1016%2fj.cageo.2022.105034&partnerID=40&md5=7369335e45f0676d2f5500c891d5b8d2","In recent years, Earth system sciences are urgently calling for innovation on improving accuracy, enhancing model intelligence level, scaling up operation, and reducing costs in many subdomains amid the exponentially accumulated datasets and the promising artificial intelligence (AI) revolution in computer science. This paper presents work led by the NASA Earth Science Data Systems Working Groups and ESIP machine learning cluster to give a comprehensive overview of AI in Earth sciences. It holistically introduces the current status, technology, use cases, challenges, and opportunities, and provides all the levels of AI practitioners in geosciences with an overall big picture and to “blow away the fog to get a clearer vision” about the future development of Earth AI. The paper covers all the majorspheres in the Earth system and investigates representative AI research in each domain. Widely used AI algorithms and computing cyberinfrastructure are briefly introduced. The mandatory steps in a typical workflow of specializing AI to solve Earth scientific problems are decomposed and analyzed. Eventually, it concludes with the grand challenges and reveals the opportunities to give some guidance and pre-warnings on allocating resources wisely to achieve the ambitious Earth AI goals in the future. © 2022","Artificial intelligence/machine learning; Atmosphere; Big data; Cyberinfrastructure; Geosphere; Hydrology","Artificial intelligence; Earth atmosphere; Earth system science; NASA; Artificial intelligence/machine learning; Cyberinfrastructure; Earth science data systems; Earth system science; Geospheres; NASA Earth Science; Operations cost; Reducing costs; Scaling-up; Subdomain; Big data; artificial intelligence; computer simulation; machine learning; NSCAT; numerical model"
"Suo J., Zhan J., Zhou G., Chen A., Hu Y., Huang W., Cai W., Hu Y., Li L.","CASM-AMFMNet: A Network Based on Coordinate Attention Shuffle Mechanism and Asymmetric Multi-Scale Fusion Module for Classification of Grape Leaf Diseases","10.3389/fpls.2022.846767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131861802&doi=10.3389%2ffpls.2022.846767&partnerID=40&md5=966f95ac3ea6ab41fac6912a22428cf8","Grape disease is a significant contributory factor to the decline in grape yield, typically affecting the leaves first. Efficient identification of grape leaf diseases remains a critical unmet need. To mitigate background interference in grape leaf feature extraction and improve the ability to extract small disease spots, by combining the characteristic features of grape leaf diseases, we developed a novel method for disease recognition and classification in this study. First, Gaussian filters Sobel smooth de-noising Laplace operator (GSSL) was employed to reduce image noise and enhance the texture of grape leaves. A novel network designated coordinated attention shuffle mechanism-asymmetric multi-scale fusion module net (CASM-AMFMNet) was subsequently applied for grape leaf disease identification. CoAtNet was employed as the network backbone to improve model learning and generalization capabilities, which alleviated the problem of gradient explosion to a certain extent. The CASM-AMFMNet was further utilized to capture and target grape leaf disease areas, therefore reducing background interference. Finally, Asymmetric multi-scale fusion module (AMFM) was employed to extract multi-scale features from small disease spots on grape leaves for accurate identification of small target diseases. The experimental results based on our self-made grape leaf image dataset showed that, compared to existing methods, CASM-AMFMNet achieved an accuracy of 95.95%, F1 score of 95.78%, and mAP of 90.27%. Overall, the model and methods proposed in this report could successfully identify different diseases of grape leaves and provide a feasible scheme for deep learning to correctly recognize grape diseases during agricultural production that may be used as a reference for other crops diseases. Copyright © 2022 Suo, Zhan, Zhou, Chen, Hu, Huang, Cai, Hu and Li.","CASM-AMFMNet; coordinate attention shuffle mechanism asymmetric; grape leaf diseases; GSSL; image enhancement; multi-scale fusion module",
"Suraci C., De Angelis V., Lofaro G., Giudice M.L., Marrara G., Rinaldi F., Russo A., Bevacqua M.T., Lax G., Mammone N., Laboccetta A.M., Morabito F.C., Araniti G.","The Next Generation of eHealth: A Multidisciplinary Survey","10.1109/ACCESS.2022.3231446","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146221846&doi=10.1109%2fACCESS.2022.3231446&partnerID=40&md5=981ec017fac63e1d3acca6f559ec3588","Over the past two years, the spread of COVID-19 has spurred the use of information and communication technologies (ICT) in aid of healthcare. The need to guarantee continuity to care has promoted research and industry activities aimed at developing solutions for the digitalization of the procedures to be performed to provide health services, even in emergency scenarios. Digital collection, transmission, and processing of health data represent the starting point for fulfilling this innovation process but also bring heterogeneous challenges. These motivations led to the elaboration of this work, which analyzes innovative and technological tools for the development of digital health (eHealth) through the collection of multisectoral literature, produced thanks to the cooperation of varied research groups, thus providing a multidisciplinary survey. Since digital health is expected to be one of the leading applications of the sixth-generation (6G) wireless cellular networks, this paper covers the related telecommunications aspects. Furthermore, the exploitation of artificial intelligence paradigms to elaborate massive amounts of biological data is examined. Given the extreme sensitivity of health data, this paper also investigates security and privacy issues. In particular, the main techniques and approaches to guarantee security properties (i.e., anonymity, responsibility, authentication, confidentiality, integrity, non-repudiation, and revocability) are studied. Applications involving innovative electromagnetic systems for healthcare and assisted living services are described to provide an example of an eHealth scenario leveraging ICT. Finally, the telemedicine-related regulations of the European Commission are analyzed, with particular reference to the General Data Protection Regulation (GDPR). © 2013 IEEE.","6G; artificial intelligence; data; eHealth; electromagnetism; GDPR; neural network; security; telemedicine","Artificial intelligence; Assisted living; eHealth; Industrial research; Information use; Network security; 6g; Data; Developing solutions; Ehealth; General data protection regulations; Health data; Health services; Information and Communication Technologies; Neural-networks; Security; Telemedicine"
"Surov I.","Opening the black box: Extracting Osgood semantic factors from the word2vec language model [Открытие чёрного ящика: Извлечение семантических факторов Осгуда из языковой модели word2vec]","10.15622/ia.21.5.3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141259363&doi=10.15622%2fia.21.5.3&partnerID=40&md5=9369e219bf7a5df44160a6d6339d3419","State-of-the-art models of artificial intelligence are developed in the black-box paradigm, in which meaningful information is limited to input-output interfaces, while internal representations are not interpretable. The resulting algorithms lack explainability and transparency, requested for responsible application. This paper addresses the problem by a method for finding Osgood's dimensions of affective meaning in multidimensional space of a pre-trained word2vec model of natural language. Three affective dimensions are found based on eight semantic prototypes, composed of individual words. Evaluation axis is found in 300-dimensional word2vec space as a difference between positive and negative prototypes. Potency and activity axes are defined from six process-semantic prototypes (perception, analysis, planning, action, progress, and evaluation), representing phases of a generalized circular process in that plane. All dimensions are found in simple analytical form, not requiring additional training. Dimensions are nearly orthogonal, as expected for independent semantic factors. Osgood's semantics of any word2vec object is then retrieved by a simple projection of the corresponding vector to the identified dimensions. The developed approach opens the possibility for interpreting the inside of black box-type algorithms in natural affective-semantic categories, and provides insights into foundational principles of distributive vector models of natural language. In the reverse direction, the established mapping opens machine-learning models as rich sources of data for cognitive-behavioral research and technology. © 2022 China Surfactant Detergent and Cosmetics.","affective meaning; black box; dimension; interpretation; language; Osgood; semantics; word2vec",
"Svanberg J., Ardeshiri T., Samsten I., Öhman P., Neidermeyer P.E., Rana T., Semenova N., Danielson M.","Corporate governance performance ratings with machine learning","10.1002/isaf.1505","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126475278&doi=10.1002%2fisaf.1505&partnerID=40&md5=c7b43d323b242390a10fdae32c038a6b","We use machine learning with a cross-sectional research design to predict governance controversies and to develop a measure of the governance component of the environmental, social, governance (ESG) metrics. Based on comprehensive governance data from 2,517 companies over a period of 10 years and investigating nine machine-learning algorithms, we find that governance controversies can be predicted with high predictive performance. Our proposed governance rating methodology has two unique advantages compared with traditional ESG ratings: it rates companies' compliance with governance responsibilities and it has predictive validity. Our study demonstrates a solution to what is likely the greatest challenge for the finance industry today: how to assess a company's sustainability with validity and accuracy. Prior to this study, the ESG rating industry and the literature have not provided evidence that widely adopted governance ratings are valid. This study describes the only methodology for developing governance performance ratings based on companies' compliance with governance responsibilities and for which there is evidence of predictive validity. © 2022 The Authors. Intelligent Systems in Accounting, Finance and Management published by John Wiley & Sons Ltd.","artificial intelligence; ESG; governance controversies; machine learning; performance of ESG ratings; prediction; socially responsible investment",
"Swapna M., Uma Maheswari V., Aluvalu R., Vardharajan V., Kotecha K.","Bio-Signals in Medical Applications and Challenges Using Artificial Intelligence","10.3390/jsan11010017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126993111&doi=10.3390%2fjsan11010017&partnerID=40&md5=d28759488ee7272159c7ff1c7d1ebb65","Artificial Intelligence (AI) has broadly connected the medical field at various levels of diagnosis based on the congruous data generated. Different types of bio-signal can be used to monitor a patient’s condition and in decision making. Medical equipment uses signals to communicate information to care staff. AI algorithms and approaches will help to predict health problems and check the health status of organs, while AI prediction, classification, and regression algorithms are helping the medical industry to protect from health hazards. The early prediction and detection of health conditions will guide people to stay healthy. This paper represents the scope of bio-signals using AI in the medical area. It will illustrate possible case studies relevant to bio-signals generated through IoT sensors. The bio-signals that retrospectively occur are discussed, and the new challenges of medical diagnosis using bio-signals are identified. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","artificial intelligence; bio-medical signal processing; bio-signals; sensors; signal processing; smart health devices",
"Sykes A.L., Silva G.S., Holtkamp D.J., Mauch B.W., Osemeke O., Linhares D.C.L., Machado G.","Interpretable machine learning applied to on-farm biosecurity and porcine reproductive and respiratory syndrome virus","10.1111/tbed.14369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119013326&doi=10.1111%2ftbed.14369&partnerID=40&md5=dbe3a17981d7e6ab54299b14ff06b3f5","Effective biosecurity practices in swine production are key in preventing the introduction and dissemination of infectious pathogens. Ideally, on-farm biosecurity practices should be chosen by their impact on bio-containment and bio-exclusion; however, quantitative supporting evidence is often unavailable. Therefore, the development of methodologies capable of quantifying and ranking biosecurity practices according to their efficacy in reducing disease risk has the potential to facilitate better-informed choices of biosecurity practices. Using survey data on biosecurity practices, farm demographics, and previous outbreaks from 139 herds, a set of machine learning algorithms were trained to classify farms by porcine reproductive and respiratory syndrome virus status, depending on their biosecurity practices and farm demographics, to produce a predicted outbreak risk. A novel interpretable machine learning toolkit, MrIML-biosecurity, was developed to benchmark farms and production systems by predicted risk and quantify the impact of biosecurity practices on disease risk at individual farms. By quantifying the variable impact on predicted risk, 50% of 42 variables were associated with fomite spread while 31% were associated with local transmission. Results from machine learning interpretations identified similar results, finding substantial contribution to predicted outbreak risk from biosecurity practices relating to the turnover and number of employees, the surrounding density of swine premises and pigs, the sharing of haul trailers, distance from the public road and farm production type. In addition, the development of individualized biosecurity assessments provides the opportunity to better guide biosecurity implementation on a case-by-case basis. Finally, the flexibility of the MrIML-biosecurity toolkit gives it the potential to be applied to wider areas of biosecurity benchmarking, to address biosecurity weaknesses in other livestock systems and industry-relevant diseases. © 2021 Wiley-VCH GmbH.","disease of swine; interpretable machine learning; on-farm biosecurity; PRRSV","agricultural land; animal experiment; area under the curve; Article; biosecurity; controlled study; demography; diagnostic test accuracy study; disease risk assessment; female; learning algorithm; livestock; machine learning; nonhuman; pig; porcine reproductive and respiratory syndrome; Porcine reproductive and respiratory syndrome virus; predictive value; sensitivity and specificity; support vector machine; swine disease; agricultural land; animal; animal husbandry; disease predisposition; human; machine learning; porcine reproductive and respiratory syndrome; procedures; veterinary medicine; Animal Husbandry; Animals; Biosecurity; Disease Susceptibility; Farms; Humans; Machine Learning; Porcine Reproductive and Respiratory Syndrome; Porcine respiratory and reproductive syndrome virus; Swine"
"Szatmári G., Bakacsi Z., Laborczi A., Petrik O., Pataki R., Tóth T., Pásztor L.","Elaborating hungarian segment of the global map of salt-affected soils (Gssmap): National contribution to an international initiative","10.3390/rs12244073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098288283&doi=10.3390%2frs12244073&partnerID=40&md5=9241cb4cbf9b33468eb54f18224092d3","Recently, the Global Map of Salt-affected Soils (GSSmap) was launched, which pursued a country-driven approach and aimed to update the global and country-level information on salt-affected soils (SAS). The aim of this paper was to present how Hungary contributed to GSSmap by preparing its own SAS maps using advanced digital soil mapping techniques. We used not just a combination of random forest and multivariate geostatistical techniques for predicting the spatial distribution of SAS indicators (i.e., pH, electrical conductivity and exchangeable sodium percentage) for the topsoil (0–30 cm) and subsoil (30–100 cm), but also a number of indices derived from Sentinel-2 satellite images as environmental covariates. The importance plots of random forests showed that in addition to climatic, geomorphometric parameters and legacy soil information, image indices were the most important covariates. The performance of spatial modelling was checked by 10-fold cross validation showing that the accuracy of the SAS maps was acceptable. By this study and by the resulting maps of it, we not just contributed to GSSmap, but also renewed the SAS mapping methodology in Hungary, where we paid special attention to modelling and quantifying the prediction uncertainty that had not been quantified or even taken into consideration earlier. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Digital soil mapping; Hungary; Machine learning; Multivariate geostatistics; Salt-affected soils; Uncertainty assessment","Decision trees; Mapping; Random forests; Soil surveys; Uncertainty analysis; 10-fold cross-validation; Digital soil mappings; Electrical conductivity; Exchangeable sodium percentages; Geostatistical techniques; Mapping methodology; Prediction uncertainty; Salt-affected soil; Soils"
"Taghavi N., Niven R.K., Paull D.J., Kramer M.","Groundwater vulnerability assessment: A review including new statistical and hybrid methods","10.1016/j.scitotenv.2022.153486","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124167654&doi=10.1016%2fj.scitotenv.2022.153486&partnerID=40&md5=cfbb1cc27700ffb7e4dcb46836a9c22a","The concept of groundwater vulnerability was first introduced in the 1970s in France to recognize sensitive areas in which surface pollution could affect groundwater, and to enable others to develop management methods for groundwater protection against surface pollutants. Since this time, numerous methods have been developed for groundwater vulnerability assessment (GVA). These can be categorized into four groups: (i) overlay and index-based methods, (ii) process-based simulation models, (iii) statistical methods, and (iv) hybrid methods. This work provides a comprehensive review of modern GVA methods, which in contrast to previous reviews, examines the last two categories in detail. First, the concept of groundwater vulnerability is defined, then the major GVA methods are introduced and classified. This includes detailed accounts of statistical methods, which can be subdivided into orthodox statistical, data-driven and Bayesian methods, and their advantages and disadvantages, as well as modern hybrid methods. It is concluded that Bayesian inference offers many advantages compared with other GVA methods. It combines theory and data to give the posterior probabilities of different models, which can be continually updated with new data. Furthermore, using the Bayesian approach, it is possible to calculate the probability of a proposition, which is exactly what is needed to make decisions. However, despite the advantages of Bayesian inference, its applications to date have been very limited. © 2022","Bayesian inference; Groundwater vulnerability assessment; Overlay and index-based methods; Process-based methods; Statistical methods","Groundwater; Groundwater pollution; Inference engines; Statistics; Bayesian inference; Groundwater vulnerability; Groundwater vulnerability assessments; Hybrid method; Management method; Overlay and index-based method; Process-based; Process-based method; Sensitive area; Surface pollution; Bayesian networks; ground water; Bayesian analysis; groundwater pollution; groundwater resource; statistical analysis; vulnerability; Bayes theorem; classification; decision making; evolution; probability; Review; statistical analysis; computer simulation; environmental monitoring; France; procedures; Bayes Theorem; Computer Simulation; Environmental Monitoring; France; Groundwater"
"Taghikhah F., Voinov A., Filatova T., Polhill J.G.","Machine-assisted agent-based modeling: Opening the black box","10.1016/j.jocs.2022.101854","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138337611&doi=10.1016%2fj.jocs.2022.101854&partnerID=40&md5=bd5d9733437330938e52a3f68dc51d3a","While agent-based modeling (ABM) has become one of the most powerful tools in quantitative social sciences, it remains difficult to explain their structure and performance. We propose to use artificial intelligence both to build the models from data, and to improve the way we communicate models to stakeholders. Although machine learning is actively employed for pre-processing data, here for the first time, we used it to facilitate model development of a simulation model directly from data. Our suggested framework, ML-ABM accounts for causality and feedback loops in a complex nonlinear system and at the same time keeps it transparent for stakeholders. As a result, beside the development of a behavioral ABM, we open the ‘blackbox’ of purely empirical models. With our approach, artificial intelligence in the simulation field can open a new stream in modeling practices and provide insights for future applications. © 2022 Elsevier B.V.","Behavioral analytics; Conceptual modeling; Interpretable artificial intelligence; Social communications; Systems thinking","Computational methods; Data handling; Simulation platform; Systems thinking; Agent-based model; Behavioral analytic; Black boxes; Conceptual model; Interpretable artificial intelligence; Machine-learning; Pre-processing; Social communications; Structure and performance; System thinkings; Autonomous agents"
"Taghikhah F., Voinov A., Shukla N., Filatova T.","Shifts in consumer behavior towards organic products: Theory-driven data analytics","10.1016/j.jretconser.2021.102516","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104209408&doi=10.1016%2fj.jretconser.2021.102516&partnerID=40&md5=ed8e4c35ff3156e79d184a816a28035d","Consumer behavior is key in shifts towards organic products. A diversity of factors influences consumer preferences, driving planned, impulsive, and unplanned purchasing decisions. We study choices among organic and conventional wine using an extensive survey among Australian consumers (N = 1003). We integrate five behavioral theories in the survey design, and use supervised and unsupervised machine learning algorithms for analysis. We quantify a gap between intention and behavior, and emphasize the importance of cognitive factors. Findings go beyond correlation to the causation of behavior when combining predictive prowess with explanatory power. Results reveal that affective factors and normative cues may prompt unplanned and spontaneous purchasing behavior, causing consumers to act against their beliefs. © 2021 Elsevier Ltd","Data mining; Emotion; Explainable artificial intelligence; Habit; Impulsive purchasing; Organic food","artificial intelligence; cognition; consumption behavior; correlation; data mining; food preference; food quality; theoretical study; Australia"
"Taghizadeh-Mehrjardi R., Schmidt K., Amirian-Chakan A., Rentschler T., Zeraatpisheh M., Sarmadian F., Valavi R., Davatgar N., Behrens T., Scholten T.","Improving the spatial prediction of soil organic carbon content in two contrasting climatic regions by stacking machine learning models and rescanning covariate space","10.3390/rs12071095","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084260910&doi=10.3390%2frs12071095&partnerID=40&md5=17a5e73a038ac9677271fd933475bb37","Understanding the spatial distribution of soil organic carbon (SOC) content over different climatic regions will enhance our knowledge of carbon gains and losses due to climatic change. However, little is known about the SOC content in the contrasting arid and sub-humid regions of Iran, whose complex SOC-landscape relationships pose a challenge to spatial analysis. Machine learning (ML) models with a digital soil mapping framework can solve such complex relationships. Current research focusses on ensemble ML models to increase the accuracy of prediction. The usual ensemble method is boosting or weighted averaging. This study proposes a novel ensemble technique: the stacking of multiple ML models through a meta-learning model. In addition, we tested the ensemble through rescanning the covariate space to maximize the prediction accuracy. We first applied six state-of-the-art ML models (i.e., Cubist, random forests (RF), extreme gradient boosting (XGBoost), classical artificial neural network models (ANN), neural network ensemble based on model averaging (AvNNet), and deep learning neural networks (DNN)) to predict and map the spatial distribution of SOC content at six soil depth intervals for both regions. In addition, the stacking of multiple ML models through a meta-learning model with/without rescanning the covariate space were tested and applied to maximize the prediction accuracy. Out of six ML models, the DNN resulted in the best modeling accuracies, followed by RF, XGBoost, AvNNet, ANN, and Cubist. Importantly, the stacking of models indicated a significant improvement in the prediction of SOC content, especially when combined with rescanning the covariate space. For instance, the RMSE values for SOC content prediction of the upper 0-5 cm of the soil profiles of the arid site and the sub-humid site by the proposed stacking approaches were 17% and 9% respectively, less than that obtained by the DNN models-the best individual model. This indicates that rescanning the original covariate space by a meta-learning model can extract more information and improve the SOC content prediction accuracy. Overall, our results suggest that the stacking of diverse sets of models could be used to more accurately estimate the spatial distribution of SOC content in different climatic regions. © 2020, by the authors.","Deep learning; Digital soil mapping; Machine learning models; Spatial block cross-validation; Stacking of models","Complex networks; Decision trees; Deep learning; Forecasting; Neural networks; Organic carbon; Soil surveys; Soils; Spatial distribution; Artificial neural network models; Complex relationships; Digital soil mappings; Learning neural networks; Machine learning models; Meta-learning models; Neural network ensembles; Soil organic carbon content; Learning systems"
"Taj I., Jhanjhi N.Z.","Towards Industrial Revolution 5.0 and Explainable Artificial Intelligence: Challenges and Opportunities","10.12785/ijcds/120124","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135748085&doi=10.12785%2fijcds%2f120124&partnerID=40&md5=a782eeb948a5a8d49b3dc5019b3e7f73","Technological growth is changing our everyday living, making it smarter and more convenient day by day; Smart society 5.0, Healthcare 5.0, Agriculture 5.0 are only a few examples indicative of our fast-evolving lifestyle. The Industrial Revolution 5.0 (IR 5.0) encapsulates future industry development trends to achieve prosperity beyond jobs by incorporating more intelligence in our everyday living with the help of cutting-edge technologies such as Explainable Artificial Intelligence. This paper reviews the enabling technologies for Industry 5.0 and suggests some pertinent research areas requiring more focus. The transition of manufacturing processes from mass production to mass personalization, the anticipated reliance on Cyber-Physical Systems (CPS) and digital twins is visualized, to identify the gaps in fully realizing the revolution. The operations of smart factories to enhance the overall productivity, modern workforce comprising of human-machine collaboration, means of heterogeneous data transmission & data interoperability, and security & privacy issues are reviewed to identify hot research spots, that will eventually fill in the gaps within societal domains to realize Industry 5.0. The potential of the new domain of Explainable Artificial intelligence to understand the application of right tools in a data connected Industry 5.0 compliant smart society is explored. Altogether, this research explores several research challenges and opportunities linked with IR 5.0. © 2022 University of Bahrain. All rights reserved.","Big data analysis; Cloud Storage; Cyber Physical System; Digital Twins; Explainable AI; Smart Society",
"Takeshige R., Onishi M., Aoyagi R., Sawada Y., Imai N., Ong R., Kitayama K.","Mapping the Spatial Distribution of Fern Thickets and Vine-Laden Forests in the Landscape of Bornean Logged-Over Tropical Secondary Rainforests","10.3390/rs14143354","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137268393&doi=10.3390%2frs14143354&partnerID=40&md5=d3ca5c682ae182248db58861b5167c58","Forest degradation has been most frequently defined as an anthropogenic reduction in biomass compared with reference biomass in extant forests. However, so-defined “degraded forests” may widely vary in terms of recoverability. A prolonged loss of recoverability, commonly described as a loss of resilience, poses a true threat to global environments. In Bornean logged-over forests, dense thickets of ferns and vines have been observed to cause arrested secondary succession, and their area may indicate the extent of slow biomass recovery. Therefore, we aimed to discriminate the fern thickets and vine-laden forests from those logged-over forests without dense ferns and vines, as well as mapping their distributions, with the aid of Landsat-8 satellite imagery and machine learning modeling. During the process, we tested whether the gray-level co-occurrence matrix (GLCM) textures of Landsat data and Sentinel-1 C-band SAR data were helpful for this classification. Our study sites were Deramakot and Tangkulap Forest Reserves—commercial production forests in Sabah, Malaysian Borneo. First, we flew drones and obtained aerial images that were used as ground truth for the supervised classification. Subsequently, a machine-learning model with a gradient-boosting decision tree was iteratively tested in order to derive the best model for the classification of the vegetation. Finally, the best model was extrapolated to the entire forest reserve and used to map three classes of vegetation (fern thickets, vine-laden forests, and logged-over forests without ferns and vines) and two non-vegetation classes (bare soil and open water). The overall classification accuracy of the best model was 86.6%; however, by combining the fern and vine classes into the same category, the accuracy was improved to 91.5%. The GLCM texture variables were especially effective at separating fern/vine vegetation from the non-degraded forest, but the SAR data showed a limited effect. Our final vegetation map showed that 30.7% of the reserves were occupied by ferns or vines, which may lead to arrested succession. Considering that our study site was once certified as a well-managed forest, the area of degraded forests with a high risk of loss of resilience is expected to be much broader in other Bornean production forests. © 2022 by the authors.","arrested succession; climbing bamboo; forest degradation; GLCM texture; Landsat-8; liana; resilience; Sentinel-1; UAV; XGBoost","Adaptive boosting; Antennas; Biomass; Decision trees; Forestry; Supervised learning; Textures; Tropics; Unmanned aerial vehicles (UAV); Vegetation mapping; Arrested succession; Climbing bamboo; Forest degradation; Gray-level co-occurrence matrix; Gray-level co-occurrence matrix texture; Grey-level co-occurrence matrixes; LANDSAT; Landsat-8; Lianum; Resilience; Sentinel-1; Xgboost; Landsat"
"Tamagno S., Eagle A.J., McLellan E.L., Van Kessel C., Linquist B.A., Ladha J.K., Lundy M.E., Pittelkow C.M.","Predicting nitrate leaching loss in temperate rainfed cereal crops: Relative importance of management and environmental drivers","10.1088/1748-9326/ac70ee","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132106392&doi=10.1088%2f1748-9326%2fac70ee&partnerID=40&md5=d554fc72bdc2c420e3c5b4e9d94d49bc","Nitrate (NO3) leaching from agriculture represents the primary source of groundwater contamination and freshwater ecosystem degradation. At the field level, NO3 leaching is highly variable due to interactions among soil, weather and crop management factors, but the relative effects of these drivers have not been quantified on a global scale. Using a global database of 82 field studies in temperate rainfed cereal crops with 961 observations, our objectives were to (a) quantify the relative importance of environmental and management variables to identify key leverage points for NO3 mitigation and (b) determine associated changes in crop productivity and potential tradeoffs for high and low NO3 loss scenarios. Machine learning algorithms (XGboost) and feature importance analysis showed that the amount and intensity of rainfall explained the most variability in NO3 leaching (up to 24 kg N ha-1), followed by nitrogen (N) fertilizer rate and crop N removal. In contrast, other soil and management variables such as soil texture, crop type, tillage and N source, timing and placement had less importance. To reduce N losses from global agriculture under changing weather and climatic conditions, these results highlight the need for better targeting and increased adoption of science-based, locally adapted management practices for improving N use efficiency. Future policy discussions should support this transition through different instruments while also promoting more advanced weather prediction analytics, especially in areas susceptible to extreme climatic variation. © 2022 The Author(s). Published by IOP Publishing Ltd.","agriculture; climate change; fertilizer; nitrate leaching; nitrogen","Climate change; Crops; Ecosystems; Environmental management; Groundwater; Groundwater pollution; Leaching; Learning algorithms; Machine learning; Nitrogen fertilizers; Nitrogen removal; Soil pollution; Soils; Textures; Cereal crop; Ecosystem degradation; Field level; Freshwater ecosystem; Groundwater contamination; Nitrate leaching; Nitrate leaching loss; Primary sources; Rainfed; Soil management; Nitrates; algorithm; cereal; crop production; leaching; nitrate; rainfall"
"Tang A., Kemp L.","A Fate Worse Than Warming? Stratospheric Aerosol Injection and Global Catastrophic Risk","10.3389/fclim.2021.720312","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123182485&doi=10.3389%2ffclim.2021.720312&partnerID=40&md5=2cb3df98bd9e7ce2112f1c1ca535f366","Injecting particles into atmosphere to reflect sunlight, stratospheric aerosol injection (SAI), represents a potential technological solution to the threat of climate change. But could the cure be worse than the disease? Understanding low probability, yet plausible, high-impact cases is critical to prudent climate risk management and SAI deliberation. But analyses of such high impact outcomes are lacking in SAI research. This paper helps resolve this gap by investigating SAI's contributions to global catastrophic risk. We split SAI's contributions to catastrophic risk into four interrelated dimensions: 1. Acting as a direct catastrophic risk through potentially unforeseen ecological blowback. 2. Interacting with other globally catastrophic hazards like nuclear war. 3. Exacerbating systemic risk (risks that cascade and amplify across different systems); 4. Acting as a latent risk (risk that is dormant but can later be triggered). The potential for major unforeseen environmental consequences seems highly unlikely but is ultimately unknown. SAI plausibly interacts with other catastrophic calamities, most notably by potentially exacerbating the impacts of nuclear war or an extreme space weather event. SAI could contribute to systemic risk by introducing stressors into critical systems such as agriculture. SAI's systemic stressors, and risks of systemic cascades and synchronous failures, are highly understudied. SAI deployment more tightly couples different ecological, economic, and political systems. This creates a precarious condition of latent risk, the largest cause for concern. Thicker SAI masking extreme warming could create a planetary Sword of Damocles. That is, if SAI were removed but underlying greenhouse gas concentrations not reduced, there would be extreme warming in a very short timeframe. Sufficiently large global shocks could force SAI termination and trigger SAI's latent risk, compounding disasters and catastrophic risks. Across all these dimensions, the specific SAI deployment, and associated governance, is critical. A well-coordinated use of a small amount of SAI would incur negligible risks, but this is an optimistic scenario. Conversely, larger use of SAI used in an uncoordinated manner poses many potential dangers. We cannot equivocally determine whether SAI will be worse than warming. For now, a heavy reliance on SAI seems an imprudent policy response. Copyright © 2021 Tang and Kemp.","climate engineering; global catastrophic risk; governance; latent risk; stratospheric aerosol injection; systemic risk; termination shock",
"Tang L., Li C.","Artificial intelligent for speech reproduction of information and knowledge of ancient books","10.1109/ICAIS50930.2021.9395993","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104995874&doi=10.1109%2fICAIS50930.2021.9395993&partnerID=40&md5=34eadc64352cd077faafdeb756436d8e","Artificial intelligent for speech reproduction of the information and knowledge of ancient books is discussed in this paper. The integrated retrieval of digital libraries has gone through several different development stages, including platform integration, system integration and the data integration. Among them, the data integration of literature is the most difficult and most critical. Therefore, in this paper, the feature extraction method based on deep learning domain is mainly expanded from two processing methods: convolution neural network structure and convolution cyclic neural network structure. At the same time, the feature extraction methods under the two methods are explained in detail in order to express the content of the text information more accurately and to obtain better classification effect. Besides this, the speech reproduction of information and knowledge is also integrated to improve the robustness of the model. The simulation results have pointed out the effectiveness. © 2021 IEEE.","Artificial intelligent; book recognition; computer system; information mining; speech reproduction","Cell proliferation; Classification (of information); Convolution; Deep learning; Digital libraries; Extraction; Facsimile; Feature extraction; Neural networks; Search engines; Text processing; Artificial intelligent; Convolution neural network; Development stages; Feature extraction methods; Integrated retrieval; Neural network structures; Platform integrations; System integration; Data integration"
"Tang Q., Yu F.R., Xie R., Boukerche A., Huang T., Liu Y.","Internet of Intelligence: A Survey on the Enabling Technologies, Applications, and Challenges","10.1109/COMST.2022.3175453","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130448973&doi=10.1109%2fCOMST.2022.3175453&partnerID=40&md5=dc8d249226a9ccf450879bae24987fe3","The Internet of Intelligence is conceived as an emerging networking paradigm, which will make intelligence as easy to obtain as information. This paper provides an overview of the Internet of Intelligence, focusing on motivations, architecture, enabling technologies, applications, and existing challenges. This can provide a good foundation for those who are interested to gain insights into the concept of the Internet of Intelligence and the key enablers of this emerging networking paradigm. Specifically, this paper starts by investigating the evolution of networking paradigms and artificial intelligence (AI), based on which we present the motivations of the Internet of Intelligence by demonstrating that networking needs intelligence and intelligence needs networking. We then present the layered architecture to characterize the Internet of Intelligence systems and discuss the enabling technologies of each layer. Moreover, we discuss the critical applications and their integration with the Internet of Intelligence paradigm. Finally, some technical challenges and open issues are summarized to fully exploit the benefits of the Internet of Intelligence. © 2022 IEEE.","applications; architecture; artificial intelligence; challenges; enabling technologies; Internet of Intelligence; networking paradigm","Artificial intelligence; Blockchain; Data privacy; Motivation; Block-chain; Challenge.; Enabling technologies; Gain insight; Internet of intelligence; Networking paradigm; Privacy; Security; Technology application; Technology challenges; Computer architecture"
"Tarling P., Cantor M., Clapés A., Escalera S.","Deep learning with self-supervision and uncertainty regularization to count fish in underwater images","10.1371/journal.pone.0267759","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129439886&doi=10.1371%2fjournal.pone.0267759&partnerID=40&md5=9eec9de7ad5bc349a15b5472538024fe","Effective conservation actions require effective population monitoring. However, accurately counting animals in the wild to inform conservation decision-making is difficult. Monitoring populations through image sampling has made data collection cheaper, wide-reaching and less intrusive but created a need to process and analyse this data efficiently. Counting animals from such data is challenging, particularly when densely packed in noisy images. Attempting this manually is slow and expensive, while traditional computer vision methods are limited in their generalisability. Deep learning is the state-of-the-art method for many computer vision tasks, but it has yet to be properly explored to count animals. To this end, we employ deep learning, with a density-based regression approach, to count fish in low-resolution sonar images. We introduce a large dataset of sonar videos, deployed to record wild Lebranche mullet schools (Mugil liza), with a subset of 500 labelled images. We utilise abundant unlabelled data in a self-supervised task to improve the supervised counting task. For the first time in this context, by introducing uncertainty quantification, we improve model training and provide an accompanying measure of prediction uncertainty for more informed biological decision-making. Finally, we demonstrate the generalisability of our proposed counting framework through testing it on a recent benchmark dataset of high-resolution annotated underwater images from varying habitats (DeepFish). From experiments on both contrasting datasets, we demonstrate our network outperforms the few other deep learning models implemented for solving this task. By providing an open-source framework along with training data, our study puts forth an efficient deep learning template for crowd counting aquatic animals thereby contributing effective methods to assess natural populations from the ever-increasing visual data. © 2022 Tarling et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"article; computer vision; decision making; deep learning; habitat; human; Mugil; natural population; nonhuman; prediction; uncertainty; videorecording; animal; benchmarking; ecosystem; fish; uncertainty; Animals; Benchmarking; Deep Learning; Ecosystem; Fishes; Uncertainty"
"Tesic M., Hahn U.","Explanation in AI systems",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132683948&partnerID=40&md5=99e1d8087da3e2c01d6a005b02ff5c95",[No abstract available],,
"Thai H.-T., Le K.-H., Nguyen N.L.-T.","FormerLeaf: An efficient vision transformer for Cassava Leaf Disease detection","10.1016/j.compag.2022.107518","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145564178&doi=10.1016%2fj.compag.2022.107518&partnerID=40&md5=9864d6235bab7c30b73d5c7899eaca66","Leaf diseases have become more prevalent in recent years due to climate change, increased growth of outdoor air pollutants, and global warming. They may severely damage crop yield, leading to detrimental effects on global food security. The timely and precise detection of leaf diseases is thus crucial for preventing their spread and ensuring the sustainability of agricultural production. In this paper, we introduce a transformer-based leaf disease detection model, namely FormerLeaf along with two optimization methods to enhance the model performance. In more detail, we propose the Least Important Attention Pruning (LeIAP) algorithm to select the most important attention heads of each layer in the Transformer model. It could reduce the model size up to 28% and accelerate the evaluation speed by 15% with about 3% accuracy enhancement. In addition, we employ the sparse matrix-matrix multiplication (SPMM) to calculate matrix correlation in the model. This reduces the model's complexity from O(n2) to [Formula presented], resulting in lowering training time by 10% while keeping a similar performance. The evaluation results on the Cassava Leaf Disease Dataset show that our proposal outperforms the state-of-the-art models in most cases. © 2022 Elsevier B.V.","Deep learning; Efficient vision transformer; Image classification; Leaf Disease detection; Precision agriculture","Deep learning; Food supply; Global warming; Matrix algebra; Plants (botany); Precision agriculture; Air pollutants; Crop yield; Deep learning; Efficient vision transformer; Global food security; Images classification; Leaf disease; Leaf disease detections; Outdoor air; Precision Agriculture; Image classification; accuracy assessment; algorithm; complexity; correlation; global warming; image classification; machine learning; optimization; precision agriculture; sustainability; training"
"Thakker D., Mishra B.K., Abdullatif A., Mazumdar S., Simpson S.","Explainable artificial intelligence for developing smart cities solutions","10.3390/smartcities3040065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103519567&doi=10.3390%2fsmartcities3040065&partnerID=40&md5=f2c6c30c3c3ff732ff0bd0f278f6fda2","Traditional Artificial Intelligence (AI) technologies used in developing smart cities solutions, Machine Learning (ML) and recently Deep Learning (DL), rely more on utilising best representative training datasets and features engineering and less on the available domain expertise. We argue that such an approach to solution development makes the outcome of solutions less explainable, i.e., it is often not possible to explain the results of the model. There is a growing concern among policymakers in cities with this lack of explainability of AI solutions, and this is considered a major hindrance in the wider acceptability and trust in such AI-based solutions. In this work, we survey the concept of ‘explainable deep learning’ as a subset of the ‘explainable AI’ problem and propose a new solution using Semantic Web technologies, demonstrated with a smart cities flood monitoring application in the context of a European Commission-funded project. Monitoring of gullies and drainage in crucial geographical areas susceptible to flooding issues is an important aspect of any flood monitoring solution. Typical solutions for this problem involve the use of cameras to capture images showing the affected areas in real-time with different objects such as leaves, plastic bottles etc., and building a DL-based classifier to detect such objects and classify blockages based on the presence and coverage of these objects in the images. In this work, we uniquely propose an Explainable AI solution using DL and Semantic Web technologies to build a hybrid classifier. In this hybrid classifier, the DL component detects object presence and coverage level and semantic rules designed with close consultation with experts carry out the classification. By using the expert knowledge in the flooding context, our hybrid classifier provides the flexibility on categorising the image using objects and their coverage relationships. The experimental results demonstrated with a real-world use case showed that this hybrid approach of image classification has on average 11% improvement (F-Measure) in image classification performance compared to DL-only classifier. It also has the distinct advantage of integrating experts’ knowledge on defining the decision-making rules to represent the complex circumstances and using such knowledge to explain the results. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Coverage detection; Explainable AI; Flood monitoring; Hybrid image classification; Multi-object; Semantic rules",
"Thakur P.S., Khanna P., Sheorey T., Ojha A.","Trends in vision-based machine learning techniques for plant disease identification: A systematic review","10.1016/j.eswa.2022.118117","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134723850&doi=10.1016%2fj.eswa.2022.118117&partnerID=40&md5=c719db6c8aabe7012eb0d9fb6890d7ef","Globally, all the major crops are significantly affected by diseases every year, as manual inspection across diverse fields is time-consuming, tedious, and requires expert knowledge. This leads to significant crop loss in different parts of the world. To provide effective solutions, several smart agriculture solutions are deployed for the control of pests and plant diseases using vision-based machine learning techniques. Despite rapid growth in the field, not many methods have been explored for their suitability in real-time applications. Several open challenges need to be addressed for the applicability of machine learning techniques in IoT-based smart agriculture solutions. Starting from data capturing methods and the availability of public datasets, the present paper provides a comprehensive review of vision-based machine learning techniques for plant disease detection. Initially, 1337 articles were selected from various scholarly resources to perform the survey. Based on the saliency of approaches, 148 articles are reviewed in this paper. Interestingly, a significant amount of research in this direction is taken up by Chinese and Indian researchers, and deep learning is the current research trend, as in other fields. The review concludes that a majority of existing methods exhibit their efficacy on public datasets captured mostly in controlled environmental conditions, but their generalization capability for in-field plant disease detection has not been explored. Lightweight CNN-based methods, on the other hand, have been designed for a limited number of diseases only, and are generally trained on small datasets. The scarcity of large-scale, in-field public datasets is one of the major bottlenecks in developing solutions that can work for a wide variety of plant diseases. © 2022 Elsevier Ltd","Convolutional neural network; Deep learning; Image processing; Machine learning; Plant disease detection","Computer vision; Crops; Deep learning; Disease control; Large dataset; Learning algorithms; Learning systems; Convolutional neural network; Deep learning; Disease detection; Images processing; Machine learning techniques; Machine-learning; Plant disease; Plant disease detection; Public dataset; Vision based; Convolutional neural networks"
"Thota S., Nethravathi R., Kumar S.N., Shyamsunder M.","An analysis of reinforcement learning interpretation techniques","10.1063/5.0083695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131865094&doi=10.1063%2f5.0083695&partnerID=40&md5=7b1d44ed71ddb8a136e77167f7297795","Reinforcement Learning (RL) technologies have demonstrated excellent resultsfor a multiple of areas, including such Atari sports, finance &self-driving vehicles. Fortunately, their black-box design complicates its usage, particularly in essential areas like healthcare. Scholars have reported various ways to interpret Reinforcement Learning systems to reduce this issue. A few of these techniques have been used in deep learning, whilst others are specifically developed with RL. This same main purpose of this paper is also to demonstrate and clarify the techniques of Reinforcement Learning interpretation, the measures used to define them, and how certain metrics were being used to consider the internal features of Reinforcement Learning models. © 2022 Author(s).","Interpretability; Interpretation; Machine Learning; Reinforcement Learning; Survey",
"Tian Z., Zhu Q., Chen Y., Zhou Y., Hu K., Li H., Lu K., Zhou J., Liu Y., Chen X.","Studies on Flavor Compounds and Free Amino Acid Dynamic Characteristics of Fermented Pork Loin Ham with a Complex Starter","10.3390/foods11101501","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130933671&doi=10.3390%2ffoods11101501&partnerID=40&md5=df4e6c8b8b8982bed738cf8d7bc9175a","Staphylococcus simulans and Lactobacillus plantarum screened from Guizhou specialty food were used to prepare fermented pork loin ham. The sensory qualities and flavor profiles of fermented pork loin hams from 0 to 42 days were investigated in order to reveal the dynamics of fermented pork loin ham. The results show that total free amino acids (TFAA) content reached the highest value on the 35th day, and the umami amino acids, including aspartic acid (ASP), glutamic acid (GLU), glycine (GLY), and alanine (ALA), were the main amino acids in all periods. Notably, the RV coefficient (0.875) indicates that free amino acids (FAA) are highly correlated with the sensory score of the E-tongue. In terms of the volatile compounds identified, the esters content gradually increased between 7 and 42 days, and ethyl octanoate was the most abundant compound during all periods. These esters imparted a characteristic aroma component to the fermented pork loin ham. The most important finding was that the increase in the content of esters represented by octanoic acid-ethyl ester might be related to the increase in the content of FAA with the increase in fermentation time. Both the E-nose and E-tongue showed good discrimination ability for fermented tenderloin ham with different fermentation times, which was crucial in cases with large clusters. In addition, the multiple factor analysis (MFA) indicated that the E-nose aroma value might be the key factor in distinguishing fermented pork loin ham with different fermentation times. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","dynamic characteristics; FAA; fermented loins; GC-MS",
"Tiboni M., Remino C., Bussola R., Amici C.","A Review on Vibration-Based Condition Monitoring of Rotating Machinery","10.3390/app12030972","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124341596&doi=10.3390%2fapp12030972&partnerID=40&md5=43c07a97a414af5d32cfc8dc256d1855","Monitoring vibrations in rotating machinery allows effective diagnostics, as abnormal functioning states are related to specific patterns that can be extracted from vibration signals. Extensively studied issues concern the different methodologies used for carrying out the main phases (signal measurements, pre-processing and processing, feature selection, and fault diagnosis) of a malfunction automatic diagnosis. In addition, vibration-based condition monitoring has been applied to a number of different mechanical systems or components. In this review, a systematic study of the works related to the topic was carried out. A preliminary phase involved the analysis of the publication distribution, to understand what was the interest in studying the application of the method to the various rotating machineries, to identify the interest in the investigation of the main phases of the diagnostic process, and to identify the techniques mainly used for each single phase of the process. Subsequently, the different techniques of signal processing, feature selection, and diagnosis are analyzed in detail, highlighting their effectiveness as a function of the investigated aspects and of the results obtained in the various studies. The most significant research trends, as well as the main innovations related to the various phases of vibration-based condition monitoring, emerge from the review, and the conclusions provide hints for future ideas. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Condition monitoring; Diagnostics; Predictive maintenance; Rotary machines; Vibrations",
"Tinte M.M., Chele K.H., van der Hooft J.J.J., Tugizimana F.","Metabolomics-guided elucidation of plant abiotic stress responses in the 4IR era: An overview","10.3390/metabo11070445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110806757&doi=10.3390%2fmetabo11070445&partnerID=40&md5=8a617f7f796b882f90ab182ce9fb6027","Plants are constantly challenged by changing environmental conditions that include abiotic stresses. These are limiting their development and productivity and are subsequently threatening our food security, especially when considering the pressure of the increasing global population. Thus, there is an urgent need for the next generation of crops with high productivity and resilience to climate change. The dawn of a new era characterized by the emergence of fourth industrial revolution (4IR) technologies has redefined the ideological boundaries of research and applications in plant sciences. Recent technological advances and machine learning (ML)-based computational tools and omics data analysis approaches are allowing scientists to derive comprehensive metabolic descriptions and models for the target plant species under specific conditions. Such accurate metabolic descriptions are imperatively essential for devising a roadmap for the next generation of crops that are resilient to environmental deterioration. By synthesizing the recent literature and collating data on metabolomics studies on plant responses to abiotic stresses, in the context of the 4IR era, we point out the opportunities and challenges offered by omics science, analytical intelligence, computational tools and big data analytics. Specifically, we highlight technological advancements in (plant) metabolomics workflows and the use of machine learning and computational tools to decipher the dynamics in the chemical space that define plant responses to abiotic stress conditions. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","4IR technologies; Abiotic stress; Automation; Machine learning; Metabolomics","abiotic stress; automation; big data; climate resilience; crop; data analysis; deterioration; food security; intelligence; machine learning; metabolomics; nonhuman; plant response; productivity; review; workflow"
"Togneri R., Felipe dos Santos D., Camponogara G., Nagano H., Custódio G., Prati R., Fernandes S., Kamienski C.","Soil moisture forecast for smart irrigation: The primetime for machine learning","10.1016/j.eswa.2022.117653","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133406278&doi=10.1016%2fj.eswa.2022.117653&partnerID=40&md5=d52757db38965061d552fddc257782f3","The rise of the Internet of Things allowed higher spatial–temporal resolution soil moisture data captured through in situ sensing. Such abundance of data enables machine learning-based soil moisture forecast as an alternative to traditional mechanistic approaches for irrigation water need estimation. This paper develops a guideline for soil moisture forecast modeling based on machine learning, tested in a real case analysis comprehending eight crop types in twelve fields from four farms distributed over diverse climatic scenarios in Brazil. Instead of a single value, we predict the following days' minimum and maximum values as targets to monitor risks of extreme soil moisture values. Furthermore, modeling soil moisture directly in volumetric water content (VWC) is better than modeling soil matric potential (SMP) to later convert in soil moisture VWC. We test several algorithms and find out that LightGBM outperforms linear regression, decision tree, random forest, multilayer perceptron, LSTM, and StemGNN. Also, blending predictions via algorithm ensemble provides an additional accuracy gain. For model training and accuracy measurement, we use weighted datasets to privilege rare but critical data points. We show that soil moisture forecast reaches its maximum performance considering only past soil moisture, a context-aware index, and a precipitation forecast. Finally, we demonstrate that traditional domain-knowledge features - such as evapotranspiration, crop phenology, and soil hydraulic behavior - are not relevant to improving SM forecast performance. Consequently, our paper suggests full data-driven approaches for irrigation water need estimation, observed some care regarding data quality. © 2022 Elsevier Ltd","Internet-of-Things; Machine learning; Smart irrigation; Soil moisture forecast; Water need estimation","Blending; Crops; Decision trees; Internet of things; Irrigation; Long short-term memory; Water content; Weather forecasting; Irrigation waters; Machine-learning; Moisture data; Smart irrigation; Soil moisture forecast; Spatial temporals; Temporal resolution; Volumetric water content; Water need estimation; Water needs; Soil moisture"
"Toro M., Weller D., Ramos R., Diaz L., Alvarez F.P., Reyes-Jara A., Moreno-Switt A.I., Meng J., Adell A.D.","Environmental and anthropogenic factors associated with the likelihood of detecting Salmonella in agricultural watersheds","10.1016/j.envpol.2022.119298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129723276&doi=10.1016%2fj.envpol.2022.119298&partnerID=40&md5=6c4fc2fd61007056196de76f4dd2b8ef","Surface water is one of the primary sources of irrigation water for produce production; therefore, its contamination by foodborne pathogens, such as Salmonella, may substantially impact public health. In this study, we determined the presence of Salmonella in surface water and characterized the relationship between Salmonella detection and environmental and anthropogenic factors. From April 2019 to February 2020, 120 samples from 30 sites were collected monthly in four watersheds located in two different central Chile agricultural regions (N = 1080). Water samples from rivers, canals, streams, and ponds linked to each watershed were obtained. Surface water (10 L) was filtrated in situ, and samples were analyzed for the presence of Salmonella. Salmonella was detected every month in all watersheds, with a mean detection percentage of 28% (0%–90%) across sampling sites, regardless of the season. Overall, similar detection percentages were observed for both regions: 29.1% for Metropolitan and 27.0% for Maule. Salmonella was most often detected in summer (39.8% of all summer samples tested positive) and least often in winter (14.4% of winter samples). Random forest analysis showed that season, water source, and month, followed by latitude and river, were the most influential factors associated with Salmonella detection. The influences of water pH and temperature (categorized as environmental factors) and factors associated with human activity (categorized as anthropogenic factors) registered at the sampling site were weakly or not associated with Salmonella detection. In conclusion, Salmonella was detected in surface water potentially used for irrigation, and its presence was linked to season and water source factors. Interventions are necessary to prevent contamination of produce, such as water treatment before irrigation. © 2022 Elsevier Ltd","Food safety; Microbiological contamination; Random forest; Salmonella; Surface water; Water quality; Waterborne pathogens","Contamination; Decision trees; Food safety; Irrigation; Rivers; Salmonella; Water treatment; Watersheds; Agricultural watersheds; Anthropogenic factors; Environmental factors; Food-safety; Microbiological contaminations; Random forests; Salmonella detections; Sampling site; Water source; Water-borne pathogens; Water quality; anthropogenic effect; coliform bacterium; environmental factor; food safety; machine learning; pathogen; surface water; water quality; watershed; air temperature; Article; autumn; bacterium detection; catchment area (hydrology); Chile; controlled study; environmental factor; human impact (environment); irrigation (agriculture); k fold cross validation; latitude; longitude; nonhuman; pH; random forest; Salmonella; seasonal variation; spring; summer; water temperature; winter; agriculture; human; microbiology; river; Salmonella; Chile; Agricultural Irrigation; Agriculture; Anthropogenic Effects; Humans; Rivers; Salmonella; Water Microbiology"
"Torre-Bastida A.I., Díaz-de-Arcaya J., Osaba E., Muhammad K., Camacho D., Del Ser J.","Bio-inspired computation for big data fusion, storage, processing, learning and visualization: state of the art and future directions","10.1007/s00521-021-06332-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111886159&doi=10.1007%2fs00521-021-06332-9&partnerID=40&md5=bb91b900f46b59b118083575cd16f3b5","This overview gravitates on research achievements that have recently emerged from the confluence between Big Data technologies and bio-inspired computation. A manifold of reasons can be identified for the profitable synergy between these two paradigms, all rooted on the adaptability, intelligence and robustness that biologically inspired principles can provide to technologies aimed to manage, retrieve, fuse and process Big Data efficiently. We delve into this research field by first analyzing in depth the existing literature, with a focus on advances reported in the last few years. This prior literature analysis is complemented by an identification of the new trends and open challenges in Big Data that remain unsolved to date, and that can be effectively addressed by bio-inspired algorithms. As a second contribution, this work elaborates on how bio-inspired algorithms need to be adapted for their use in a Big Data context, in which data fusion becomes crucial as a previous step to allow processing and mining several and potentially heterogeneous data sources. This analysis allows exploring and comparing the scope and efficiency of existing approaches across different problems and domains, with the purpose of identifying new potential applications and research niches. Finally, this survey highlights open issues that remain unsolved to date in this research avenue, alongside a prescription of recommendations for future research. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Big data; Bio-inspired computation; Data fusion; Evolutionary computation; Fuzzy logic; Neural networks; Swarm intelligence","Big data; Biomimetics; Data fusion; Data visualization; Bio inspired computation; Bio-inspired algorithms; Biologically inspired; Data technologies; Heterogeneous data sources; Literature analysis; Research achievements; State of the art; Digital storage"
"Torres-Tello J., Ko S.-B.","Interpretability of artificial intelligence models that use data fusion to predict yield in aeroponics","10.1007/s12652-021-03470-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114651956&doi=10.1007%2fs12652-021-03470-9&partnerID=40&md5=54716cb3e444df15655413eb8a07b3f4","There is an increasing demand for healthy and fresh foods, and predicting yield effectively is important to improve production, especially in methods like aeroponics. This paper has two main goals: (i) use data fusion to improve yield prediction in aeroponics, and (ii) find which features are more relevant for yield prediction of six different crops. To reach these goals, a number of artificial intelligence models and an interpretability analysis based on SHapley Additive exPlanations (SHAP) have been implemented. The models were trained using 200 samples that were collected in a nine-month period, including information from different air and water quality sensors in addition to manually recorded data, reaching in the end a coefficient of determination value R2 = 0.752 for the validation dataset in the best case (CNN-based model). As a result, two main features were identified in the dataset: Room CO2 and Reservoir Temperature, along with other useful insights of how these features influence predictions. SHAP values also provided important information for feature selection. These results could be the first steps towards the full automation of an aeroponics crop production system. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Aeroponics; Artificial intelligence; Feature selection; Model interpretability; Yield prediction","Crops; Cultivation; Data fusion; Forecasting; Reservoirs (water); Water quality; A-coefficient; Crop production systems; Fresh food; Influence predictions; Interpretability; Reservoir temperatures; Water quality sensors; Yield prediction; Artificial intelligence"
"Tsakiridis N.L., Diamantopoulos T., Symeonidis A.L., Theocharis J.B., Iossifides A., Chatzimisios P., Pratos G., Kouvas D.","Versatile Internet of Things for Agriculture: An eXplainable AI Approach","10.1007/978-3-030-49186-4_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086181553&doi=10.1007%2f978-3-030-49186-4_16&partnerID=40&md5=62df3a310d4be25bb7caddf927de2ab3","The increase of the adoption of IoT devices and the contemporary problem of food production have given rise to numerous applications of IoT in agriculture. These applications typically comprise a set of sensors that are installed in open fields and measure metrics, such as temperature or humidity, which are used for irrigation control systems. Though useful, most contemporary systems have high installation and maintenance costs, and they do not offer automated control or, if they do, they are usually not interpretable, and thus cannot be trusted for such critical applications. In this work, we design Vital, a system that incorporates a set of low-cost sensors, a robust data store, and most importantly an explainable AI decision support system. Our system outputs a fuzzy rule-base, which is interpretable and allows fully automating the irrigation of the fields. Upon evaluating Vital in two pilot cases, we conclude that it can be effective for monitoring open-field installations. © 2020, IFIP International Federation for Information Processing.","eXplainable AI; Internet of Things; Precision irrigation","Agricultural robots; Artificial intelligence; Costs; Decision support systems; Fuzzy inference; Fuzzy rules; Humidity control; Irrigation; Automated control; Critical applications; Food production; Fuzzy rule base; Irrigation controls; Low-cost sensors; Maintenance cost; System output; Internet of things"
"Tsakiridis N.L., Theocharis J.B., Ben-Dor E., Zalidis G.C.","Using interpretable fuzzy rule-based models for the estimation of soil organic carbon from VNIR/SWIR spectra and soil texture","10.1016/j.chemolab.2019.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064255669&doi=10.1016%2fj.chemolab.2019.03.011&partnerID=40&md5=ef16139944b084f7b431439b13123c1b","In this paper, the use of a novel evolutionary fuzzy rule-based system (FRBS) for the prediction of Soil Organic Carbon from visible, near-infrared, and short-wave infrared (VNIR/SWIR) spectra and the textural information as additional predictor is examined. Compared to other techniques, the proposed model generates a compact set of rules with a high interpretation degree, mapping local input to local output regions. This is achieved through an evolutionary learning procedure which is applied to establish linguistic rules and assist in the interpretation of the association between spectra and the target property. The rule base may be also decomposed into texture-specific sets of rules, allowing a more detailed analysis on a per textural class basis. These intrinsic properties enable the development of spectral prototype signatures and sparse feature utilization histograms at different levels of aggregation, i.e. per textural class and/or output region. The proposed model is applied to the LUCAS topsoil database comprised of roughly 18,000 mineral samples across 23 European Union member-states. We first demonstrate the enhanced interpretation capabilities of our fuzzy approach, which can assist in the extraction of fruitful knowledge governing the association between soil properties and VNIR/SWIR spectra. The model is then compared with other contemporary approaches, namely PLS, SVM, and Cubist. The results indicate that our approach produced compact and interpretable results with fair prediction accuracies (equivalent with the best approach). © 2019 Elsevier B.V.","Evolutionary learning; Feature utilization histograms; Interpretable fuzzy rule-based systems; Soil textural class; Spectral prototypes; VNIR/SWIR spectroscopy","organic carbon; accuracy; analytical error; Article; fuzzy system; histogram; learning algorithm; mathematical computing; near infrared spectroscopy; particle size; priority journal; soil analysis; soil property; soil texture; statistical model"
"Tsarapatsani K.-H., Sakellarios A., Pezoulas V.C., Tsakanikas V.D., Matsopoulos G.K., Marz W., Kleber M., Fotiadis D.I.","Machine Learning Models to Predict Myocardial Infarction Within 10-Years Follow-up of Cardiovascular Disease Progression","10.1109/BHI56158.2022.9926803","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143060675&doi=10.1109%2fBHI56158.2022.9926803&partnerID=40&md5=fabdb02e3c11d097dfccc4026cf3d917","The early prevention of myocardial infarction (MI), a complication of cardiovascular disease (CVD), is an urgent need for the timely provision of medical intervention and the reduction of cardiovascular mortality. The performance of machine learning (ML) has proven useful in aiding the early diagnosis of this disease. In this work, we utilize clinical cardiovascular disease risk factors and biochemical data, employing machine learning models i.e. Random Forest (RF), Extreme Grading Boosting (XGBoost) and Adaptive Boosting (AdaBoost), to predict the 10-year risk of myocardial infarction in patients with 10-years follow-up for CVD. We used the cohort of the Ludwigshafen Risk and Cardiovascular Health (LURIC) study, while 3267 patients were included in the analysis (1361 suffered from MI). We calculated the performance of machine learning models, more specifically the mean values of Accuracy (ACC), Sensitivity, Specificity and the area under the receiver operating characteristic curve (AUC) of each model. We also plotted the corresponding receiver operating characteristic curve for each model. The findings of the analysis reveal that the Extreme Gradient Boosting model detects MI with the highest accuracy (74.27 %). Moreover, explainable artificial intelligence was applied, especially the Shapley values were calculated to identify the most important features and interpret the results with XGBoost. © 2022 IEEE.","10-years follow-up; explainable artificial intelligence; machine learning; myocardial infraction; predictive models","Cardiology; Decision trees; Diagnosis; Diseases; Grading; Health risks; Machine learning; Risk assessment; 10-year follow-up; Cardiovascular disease; Explainable artificial intelligence; Follow up; Machine learning models; Machine-learning; Myocardial Infarction; Myocardial infraction; Performance; Predictive models; Adaptive boosting"
"Tuda M., Luna-Maldonado A.I.","Image-based insect species and gender classification by trained supervised machine learning algorithms","10.1016/j.ecoinf.2020.101135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089822212&doi=10.1016%2fj.ecoinf.2020.101135&partnerID=40&md5=c12db306bee3475ead5c46882597ccab","Classification of specimens is the important first step to characterize populations and species assemblages. Although species-level classification has been a popular goal, the sex difference and sex ratio are also an important property in ecology and pest control. Here we focus on the images of mixed sex specimens of a stored product pest beetle (Callosobruchus chinensis) and its parasitoids (parasitic wasps; Anisopteromalus and Heterospilus) in various postures and classify them into species and sex, by training supervised machine learning programs: logistic model trees (LMT), random forest, support vector machine (SVM), simple logistic regression, multilayer perceptron and AdaBoost (adaptive boosting). Both object-based features and pixel-based features were extracted from each image. Simple logistic regression, LMT and AdaBoost (employing simple logistic regression as base learner) performed well to classify sexes or species/sexes; average true positive rates (prediction accuracy) of 88.5–98.5% were achieved for within-species sexing of beetles or wasps, 97.3% for two species sexing and 93.3% for three species sexing. For most datasets, the best performed models incorporated both object-based features and pixel-based features. LMT models were identical to simple logistic regression models in most cases. Robust performance and small variation in prediction accuracy of simple logistic regression, irrespective of classification target (sexes or species), was shown, and this is probably because of the efficient feature selection implemented in the algorithm. This study is one of the earliest to classify the gender of insects using machine learning based on still images. © 2020 Elsevier B.V.","AdaBoost; Artificial intelligence; Image-based machine learning; Insect sex classification; Object-based and pixel-based features; Random forest; Simple logistic regression","accuracy assessment; beetle; classification; gender; image analysis; image classification; prediction; sex ratio; support vector machine; Anisopteromalus; Callosobruchus chinensis; Coleoptera; Heterospilus; Hexapoda; Vespoidea"
"Tuersong W., Liu X., Wang Y., Wu S., Qin P., Zhu S., Liu F., Wang C., Hu M.","Comparative Metabolome Analyses of Ivermectin-Resistant and -Susceptible Strains of Haemonchus contortus","10.3390/ani13030456","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147670602&doi=10.3390%2fani13030456&partnerID=40&md5=96c6299ae4430a8f1a9c4f90aba50f44","Resistance to anthelmintics such as ivermectin (IVM) is currently a major problem in the treatment of Haemonchus contortus, an important parasitic nematode of small ruminants. Although many advances have been made in understanding the IVM resistance mechanism, its exact mechanism remains unclear for H. contortus. Therefore, understanding the resistance mechanism becomes increasingly important for controlling haemonchosis. Recent research showed that the metabolic state of bacteria influences their susceptibility to antibiotics. However, little information is available on the roles of metabolites and metabolic pathways in IVM resistance of H. contortus. In this study, comparative analyses of the metabolomics of IVM-susceptible and -resistant adult H. contortus worms were carried out to explore the role of H. contortus metabolism in IVM resistance. In total, 705 metabolites belonging to 42 categories were detected, and 86 differential metabolites (17 upregulated and 69 downregulated) were identified in the IVM-resistant strain compared to the susceptible one. A KEGG pathway analysis showed that these 86 differential metabolites were enriched in 42 pathways that mainly included purine metabolism; the biosynthesis of amino acids; glycine, serine, and threonine metabolism; and cysteine and methionine metabolism. These results showed that amino acid metabolism may be mediated by the uptake of IVM and related with IVM resistance in H. contortus. This study contributes to our understanding of the mechanisms of IVM resistance and may provide effective approaches to manage infection by resistant strains of H. contortus. © 2023 by the authors.","Haemonchus contortus; ivermectin resistance; metabolomics",
"Tufariello M., Pati S., Palombi L., Grieco F., Losito I.","Use of Multivariate Statistics in the Processing of Data on Wine Volatile Compounds Obtained by HS-SPME-GC-MS","10.3390/foods11070910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127552536&doi=10.3390%2ffoods11070910&partnerID=40&md5=44f3acee0e1f6829cf69cb7648f3de6e","This review takes a snapshot of the main multivariate statistical techniques and methods used to process data on the concentrations of wine volatile molecules extracted by means of solid phase micro-extraction and analyzed using GC-MS. Hypothesis test, exploratory analysis, regression models, and unsupervised and supervised pattern recognition methods are illustrated and discussed. Several applications in the wine volatolomic sector are described to highlight different interactions among the various matrix components and volatiles. In addition, the use of Artificial Intelligence-based methods is discussed as an innovative class of methods for validating wine varietal authenticity and geographical traceability. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","artificial intelligence; HS-SPME-GC-MS; multivariate statistical analysis; volatile compounds; wine",
"Tyagi S., Zhang X., Saraswat D., Sahany S., Mishra S.K., Niyogi D.","Flash Drought: Review of Concept, Prediction and the Potential for Machine Learning, Deep Learning Methods","10.1029/2022EF002723","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143236333&doi=10.1029%2f2022EF002723&partnerID=40&md5=870893a763c556bb6d6fa3a513404d0d","This paper reviews the Flash Drought concept, the uncertainties associated with FD prediction, and the potential of Machine Learning (ML) and Deep learning (DL) for future applications. For this, 121 relevant articles covering different aspects of FD - definitions, key indicators, distinguishing characteristics, and the current methods for FD assessment (i.e., - monitoring, prediction, and impact assessment) are examined. FD is typically a short-term drought event - characterized by the rapid progression of heat waves and precipitation deficits, causing cascading impacts on the land and surface hydrology. FD prediction is constrained by the lack of consistent FD definitions, key indicators, the limited predictability of FD at the subseasonal- to-seasonal (S2S) timescale, and uncertainties associated with the current prediction methods. Some of the uncertainties in the current methods are associated with a lack of our understanding of the physical processes. They are also related to the error in the input datasets (imperfect representation of indicators), parameter uncertainty (parameterization scheme adopted by the prediction model), multicollinearity, nonlinear, and non-stationary interactions among different indicators. Combining traditional methods and multisource fusion data with ML and DL methods shows promise to better understand FD evolution and improves prediction. © 2022 The Authors. Earth's Future published by Wiley Periodicals LLC on behalf of American Geophysical Union.","data-driven drought assessment; drought prediction; flash droughts","assessment method; drought; heat wave; machine learning; precipitation (climatology); seasonal variation"
"Tziolas N., Tsakiridis N., Chabrillat S., Demattê J.A.M., Ben-Dor E., Gholizadeh A., Zalidis G., van Wesemael B.","Earth observation data-driven cropland soil monitoring: A review","10.3390/rs13214439","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118704392&doi=10.3390%2frs13214439&partnerID=40&md5=bff6c8b6e4a65414fe485e3cef2de0ab","We conducted a systematic review and inventory of recent research achievements related to spaceborne and aerial Earth Observation (EO) data-driven monitoring in support of soil-related strategic goals for a three-year period (2019–2021). Scaling, resolution, data characteristics, and modelling approaches were summarized, after reviewing 46 peer-reviewed articles in international journals. Inherent limitations associated with an EO-based soil mapping approach that hinder its wider adoption were recognized and divided into four categories: (i) area covered and data to be shared; (ii) thresholds for bare soil detection; (iii) soil surface conditions; and (iv) infrastructure capabilities. Accordingly, we tried to redefine the meaning of what is expected in the next years for EO data-driven topsoil monitoring by performing a thorough analysis driven by the upcoming technological waves. The review concludes that the best practices for the advancement of an EO data-driven soil mapping include: (i) a further leverage of recent artificial intelligence techniques to achieve the desired representativeness and reliability; (ii) a continued effort to share harmonized labelled datasets; (iii) data fusion with in situ sensing systems; (iv) a continued effort to overcome the current limitations in terms of sensor resolution and processing limitations of this wealth of EO data; and (v) political and administrative issues (e.g., funding, sustainability). This paper may help to pave the way for further interdisciplinary research and multi-actor coordination activities and to generate EO-based benefits for policy and economy. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Carbon farming; Common agricultural policy; Deep learning; Earth observation; Food security; Hyperspectral; Soil organic carbon; Spectral signatures","Agricultural robots; Antennas; Data fusion; Deep learning; Mapping; Monitoring; Network security; Observatories; Organic carbon; Soil surveys; Soils; Carbon farming; Common agricultural policy; Data driven; Deep learning; Earth observation data; Earth observations; Food security; HyperSpectral; Soil organic carbon; Spectral signature; Food supply"
"Tziolas N., Tsakiridis N., Ben-Dor E., Theocharis J., Zalidis G.","Employing a multi-input deep convolutional neural network to derive soil clay content from a synergy of multi-temporal optical and radar imagery data","10.3390/RS12091389","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085257255&doi=10.3390%2fRS12091389&partnerID=40&md5=96dcc24c44815be46f1ad324136dd55a","Earth observation (EO) has an immense potential as being an enabling tool formapping spatial characteristics of the topsoil layer. Recently, deep learning based algorithms and cloud computing infrastructure have become available with a great potential to revolutionize the processing of EO data. This paper aims to present a novel EO-based soil monitoring approach leveraging open-access Copernicus Sentinel data and Google Earth Engine platform. Building on key results from existing data mining approaches to extract bare soil reflectance values the current study delivers valuable insights on the synergistic use of open access optical and radar images. The proposed framework is driven by the need to eliminate the influence of ambient factors and evaluate the efficiency of a convolutional neural network (CNN) to effectively combine the complimentary information contained in the pool of both optical and radar spectral information and those form auxiliary geographical coordinates mainly for soil. We developed and calibrated our multi-input CNN model based on soil samples (calibration = 80% and validation 20%) of the LUCAS database and then applied this approach to predict soil clay content. A promising prediction performance (R2 = 0.60, ratio of performance to the interquartile range (RPIQ) = 2.02, n = 6136) was achieved by the inclusion of both types (synthetic aperture radar (SAR) and laboratory visible near infrared-short wave infrared (VNIR-SWIR) multispectral) of observations using the CNN model, demonstrating an improvement of more than 5.5% in RMSE using the multi-year median optical composite and current state-of-the-art non linear machine learning methods such as random forest (RF; R2 = 0.55, RPIQ = 1.91, n = 6136) and artificial neural network (ANN; R2 = 0.44, RPIQ = 1.71, n = 6136). Moreover, we examined post-hoc techniques to interpret the CNN model and thus acquire an understanding of the relationships between spectral information and the soil target identified by the model. Looking to the future, the proposed approach can be adopted on the forthcoming hyperspectral orbital sensors to expand the current capabilities of the EO component by estimating more soil attributes with higher predictive performance. © 2020 by the authors.","Copernicus data; Deep learning; Earth observation; Hyper and multi spectral remote sensing; SAR data; Soil texture mapping; Spectral signatures","Convolution; Convolutional neural networks; Data handling; Data mining; Decision trees; Deep learning; Deep neural networks; Infrared devices; Infrared radiation; Learning systems; Orbits; Reflection; Soils; Synthetic aperture radar; Tracking radar; Cloud computing infrastructures; Geographical coordinates; Inter quartile ranges; Learning-based algorithms; Prediction performance; Predictive performance; Spatial characteristics; Visible near-infrared; Radar imaging"
"Udenwagu N.E., Azeta A.A., Misra S., Nwaocha V.O., Enosegbe D.L., Sharma M.M.","ExplainEx: An Explainable Artificial Intelligence Framework for Interpreting Predictive Models","10.1007/978-3-030-73050-5_51","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105938022&doi=10.1007%2f978-3-030-73050-5_51&partnerID=40&md5=6ff145ae8730999d5ef243913dee7e16","Artificial Intelligence (AI) systems are increasingly dependent on machine learning models which lack interpretability and algorithmic transparency, and hence may not be trusted by its users. The fear of failure in these systems is driving many governments to demand more explanation and accountability. Take, for example, the “Right of Explanation” rule proposed in the European Union in 2019, which gives citizens the right to demand an explanation from AI-based predictions. Explainable Artificial Intelligence (XAI) is an attempt to open up the “black box” and create more explainable systems which create predictive models whose results are easily understandable to humans. This paper describes an explanation model called ExplainEx which automatically generates natural language explanation for predictive models by consuming REST API provided by ExpliClas open-source web service. The classification model consists of four main decision tree algorithms including J48, Random Tree, RepTree and FURIA. The user interface was designed based on Microsoft.Net Framework programming platform. At the background is a software engine automating a seamless interaction between Expliclas API and the trained datasets, to provide natural language explanation to users. Unlike other studies, our proposed model is both a stand-alone and client-server based system capable of providing global explanations for any decision tree classifier. It supports multiple concurrent users in a client-server environment and can apply all four algorithms concurrently on a single dataset, returning both precision score and explanation. It is a ready tool for researchers who have datasets and classifiers prepared for explanation. This work bridges the gap between prediction and explanation, thereby allowing researchers to concentrate on data analysis and building state-of-the-art predictive models. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Explainable Artificial Intelligence; Interpretable machine learning; Machine learning; Predictive models","Biomimetics; Boron compounds; Classification (of information); Decision trees; Intelligent systems; Machine learning; Open source software; Sodium compounds; User interfaces; Web services; Classification models; Client-server environment; Decision tree classifiers; Decision-tree algorithm; Interpretability; Natural language explanations; Predictive models; State of the art; Predictive analytics"
"Ullah A., Qayyum H., Khan M.K., Ahmad F.","Sepsis Detection Using Extreme Gradient Boost (XGB): A Supervised Learning Approach","10.1109/MAJICC53071.2021.9526260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115704690&doi=10.1109%2fMAJICC53071.2021.9526260&partnerID=40&md5=eea3c64650825de8fe83088746a51e92","Sepsis is one of the major trending topics in the field of Bio-Medical Sciences, Sepsis is a major disease, causing a lot of causalities, and a large amount of money is consumed for the diagnosis and treatment of sepsis found in patients. Early sepsis detection can decrease patients' death rates and give a big economic relief to patients' families. Many techniques have been used to detect sepsis earlier than clinical results are known, but machine learning approaches are leading one among all other techniques and tools. Many datasets are available which are used for more precise results, and some of the researchers use their own datasets, which are not easily available publicly. We used two datasets, Set A and Set B, for training and testing of our model, and these are publicly available at Physionet.org. We used Set A as a whole and a big proportion of Set B for the training of our algorithm and the remaining proportion of Set B for testing purpose [1]. We applied forward filling and backward filling on the dataset to fill the missing valuesand achieve the required training sets, then the extreme gradient boost (XGB) classifier is applied, which gives the result that sepsisis found. The sepsis is detection shows 92% accuracy. This algorithm would be used to increase patients' chances of survival and would save the amount of money that is being used for diagnosis and treatment of sepsis annually. © 2021 IEEE.","Backward Filling; Forward Filling; Machine Learning Approach; Sepsis Detection; Sepsis Prediction","Classification (of information); Patient treatment; Bio-medical; Large amounts; Machine learning approaches; Supervised learning approaches; Techniques and tools; Training and testing; Training sets; Trending topics; Diagnosis"
"Ullah K., Wang Y., Fang Z., Wang L., Rahman M.","Multi-hazard susceptibility mapping based on Convolutional Neural Networks","10.1016/j.gsf.2022.101425","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133660548&doi=10.1016%2fj.gsf.2022.101425&partnerID=40&md5=d9edab1b2b7756875457237d1ab5abb4","Multi-hazard susceptibility prediction is an important component of disasters risk management plan. An effective multi-hazard risk mitigation strategy includes assessing individual hazards as well as their interactions. However, with the rapid development of artificial intelligence technology, multi-hazard susceptibility prediction techniques based on machine learning has encountered a huge bottleneck. In order to effectively solve this problem, this study proposes a multi-hazard susceptibility mapping framework using the classical deep learning algorithm of Convolutional Neural Networks (CNN). First, we use historical flash flood, debris flow and landslide locations based on Google Earth images, extensive field surveys, topography, hydrology, and environmental data sets to train and validate the proposed CNN method. Next, the proposed CNN method is assessed in comparison to conventional logistic regression and k-nearest neighbor methods using several objective criteria, i.e., coefficient of determination, overall accuracy, mean absolute error and the root mean square error. Experimental results show that the CNN method outperforms the conventional machine learning algorithms in predicting probability of flash floods, debris flows and landslides. Finally, the susceptibility maps of the three hazards based on CNN are combined to create a multi-hazard susceptibility map. It can be observed from the map that 62.43% of the study area are prone to hazards, while 37.57% of the study area are harmless. In hazard-prone areas, 16.14%, 4.94% and 30.66% of the study area are susceptible to flash floods, debris flows and landslides, respectively. In terms of concurrent hazards, 0.28%, 7.11% and 3.13% of the study area are susceptible to the joint occurrence of flash floods and debris flow, debris flow and landslides, and flash floods and landslides, respectively, whereas, 0.18% of the study area is subject to all the three hazards. The results of this study can benefit engineers, disaster managers and local government officials involved in sustainable land management and disaster risk mitigation. © 2022 China University of Geosciences (Beijing)","Convolutional Neural Network; Eastern Hindukush; Machine learning; Multi-hazard; Pakistan","algorithm; artificial neural network; disaster management; geological mapping; hazard assessment; land management; Hindu Kush"
"Ur Rehman A., Arshad J., Sadiq M.T., Rehman A., Ahmad M., Hasan M.K., Al Hamadi H., Faiz T.","Implementation of an Intelligent Animal Monitoring System Using Wireless Sensor Network and IoT Platform","10.1109/ICCR56254.2022.9996080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146492931&doi=10.1109%2fICCR56254.2022.9996080&partnerID=40&md5=d0d1e703370f5f551a811acf1bce5ca5","Meat and dairy products are negatively impacted by a lack of technology in the livestock industry in developing countries. To cater for this challenge, the Internet of Things (IoT), Node-MCU, and intelligent wireless sensor nodes are deployed to create a new smart dairy monitoring system. A cow collar with a temperature sensor, a GPS module, and an environmental parameter regularization system are included. Data from modules is stored in a separate database using an innovative IoT -based front end. All the deployed WS nodes can determine whether the environment is stable or not at any given time. Sensors built inside cow collars can assess vital indications like temperature and pulse rate, as well as the animal's exact location. The design of the Cow collar also has a feature that automatically alerts the owner. The plug-and-play technology offered is designed to be easy to adapt. When a farm has many animals, automation decreases the need for human involvement and so lowers labor expenses. The exploitation of remote monitoring systems improves the health of the animals and hence yields a better amount of dairy. This study also includes a detailed comparison of the proposed implementation with current systems to demonstrate its originality. Other applications, such as smart monitoring of zoo animals and poultry, may be derived from the proposed technology. © 2022 IEEE.","animal health monitoring; Cow Collar; Internet of Things (IoT); microcontroller; Node MCU; Wireless Sensor Nodes","Agriculture; Animals; Developing countries; Internet of things; Sensor nodes; Animal health; Animal health monitoring; Cow collar; Environmental parameter; Health monitoring; Internet of thing; Monitoring system; Node MCU; Regularisation; Wireless sensor node; Microcontrollers"
"Uslu S., Kaur D., Rivera S.J., Durresi A., Babbar-Sebens M., Tilt J.H.","A Trustworthy Human–Machine framework for collective decision making in Food–Energy–Water management: The role of trust sensitivity","10.1016/j.knosys.2020.106683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098709139&doi=10.1016%2fj.knosys.2020.106683&partnerID=40&md5=0a1e5e61ce5c5c4c0f53253092de7a23","We propose a hybrid Trustworthy Human–Machine collective decision-making framework to manage Food–Energy–Water (FEW) resources. Decisions for managing such resources impact not only the environment but also influence the economic productivity of FEW sectors and the well-being of society. Therefore, while algorithms can be used to develop optimal solutions under various criteria, it is essential to explain such solutions to the community. More importantly, the community should accept such solutions to be able realistically to apply them. In our collaborative computational framework for decision support, machines and humans interact to converge on the best solutions accepted by the community. In this framework, trust among human actors during decision making is measured and managed using a novel trust management framework. Furthermore, such trust is used to encourage human actors, depending on their trust sensitivity, to choose among the solutions generated by algorithms that satisfy the community's preferred trade-offs among various objectives. In this paper, we show different scenarios of decision making with continuous and discrete solutions. Then, we propose a game-theory approach where actors maximize their payoff regarding their share and trust weighted by their trust sensitivity. We run simulations for decision-making scenarios with actors having different distributions of trust sensitivities. Results showed that when actors have high trust sensitivity, a consensus is reached 52% faster than scenarios with low trust sensitivity. The utilization of ratings of ratings increased the solution trustworthiness by 50%. Also, the same level of solution trustworthiness is reached 2.7 times faster when ratings of ratings included. © 2020 Elsevier B.V.","Decision support systems; Food–Energy–Water management; Game theory; Trust management; Trustworthy Human–Machine systems","Computation theory; Decision support systems; Economic and social effects; Game theory; Water management; Collective decision making; Computational framework; Decision supports; Different distributions; Economic productivity; Human actor; Optimal solutions; Trust management frameworks; Decision making"
"Usman M., Komaruddin M., Sarida M., Wamiliana, Russel E., Kufepaksi M., Alam I.A., Elfaki F.A.M.","Analysis of Some Variable Energy Companies by Using VAR(p)-GARCH(r,s) Model: Study From Energy Companies of Qatar over the Years 2015–2022","10.32479/ijeep.13333","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139128305&doi=10.32479%2fijeep.13333&partnerID=40&md5=f01cc432d4bfdefcc0c89bf49260f1db","In this study, the nature of the weekly stock price relationships of several Qatar energy companies, namely the weekly stock price of Qatar Fuel Company (QFLS), Qatar Gas Transport Company (QGTS), and Qatar Electricity and Water Company (QEWC), will be discussed. The duration of data weekly stock price is from January 2015 to April 2022. This study aimed to obtain the best model for the weekly stock price relationship of the three companies QFLS, QGTS, and QEWC. The multivariate time series analysis method will be used to evaluate the data. From the analysis using multivariate time series modeling, the best model is VAR(3)-GARCH)(1,1). Based on this best model, further analysis is carried out, namely Granger causality, impulse response function (IRF), and forecasting for the next 12 periods. The Granger causality test found that the QFLS has Granger causality on the QGTS (unidirectional), while the QGTS and QEWC variables have bidirectional Granger causality. The IRF analysis indicated that if there is a shock of 1 standard deviation in QFLS, then QFLS and QEWC will fluctuate for the first 6 weeks and move toward equilibrium from the 7th week onwards, while the impact on QGTS can be ignored. Suppose there is a shock of 1 standard deviation in the QGTS. In that case, the QFLS and QEWC will respond by fluctuating for the first 6 weeks, and at the 7th week and move toward equilibrium, while the impact on QGTS can be ignored; and if there is a shock of 1 standard deviation in QEWC, then QFLS and QEWC will respond negatively and fluctuating for the first 6 weeks, and at the 7th week toward equilibrium, while the impact on QGTS is negligible. Forecasting for the next 12 periods shows that the farther the forecasting period, the larger the standard error. This indicates that the ffarther the period is, the more unstable it is. © 2022, Econjournals. All rights reserved.","Forecasting; Granger Causality; Impulse Response Function; Multivariate Time Series; VAR(p)-GARC(r,s)",
"Vakili A.R., Ehtesham S., Danesh-Mesgaran M., Rohani A., Rahimi M.","Toward Modeling the in Vitro Gas Production Process by Using Propolis Extract Oil Treatment: Machine Learning and Kinetic Models","10.1021/acs.iecr.2c02318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142004956&doi=10.1021%2facs.iecr.2c02318&partnerID=40&md5=3c1c8adcb85ec88f4e5c5f33e099737c","To overcome challenges with in vivo digestibility assessment, in vitro digestibility techniques have been created. The biobased additive in concentrate can effectively promote the in vitro digestibility performance. The primary goal of this study was to evaluate the propolis effect on produced gas by an in vitro procedure in 25-75% proportion of concentrate. Then, machine learning (ML) models such as nonlinear regression techniques and multilayer perceptron neural networks (MLP-NNs) were applied to assess the prediction performance of gas generation during in vitro digestion using propolis treatments with diverse diet components. The MLP-NN was created using 11 nonlinear regression (NLR) and 12 training algorithms. The findings revealed that the logistic-exponential without lag time (LE0) model was chosen as the best nonlinear model for eight diet interventions. Also, the achievements of the MLP-NN model evaluation revealed that the trainbr training procedure with six neurons in the hidden layer can accurately predict the gas output. The prediction errors of the MLP-NN and NLR approaches were not significantly different (R2 ∼0.99). Three-dimensional response surface graphs were drawn with the help of a neural network, and the optimal value was calculated based on it in a simple and intuitive way. This route displayed the optimum propolis treatment, in which the application of 75% propolis ethanol extract in concentrate could significantly increase gas production between 1 and 4 mL/h. The MLP-NN model has more capabilities than NLR in such studies. © 2022 American Chemical Society.",,"Forecasting; Gases; Machine components; Machine learning; Neural network models; Extract oil; Gas production process; In-vitro; In-vitro gas productions; Machine learning models; Multilayers perceptrons; Neural network model; Non-linear regression; Perceptron neural networks; Vitro digestibilities; Multilayer neural networks"
"Vals-Delgado C., Alcala-Diaz J.F., Molina-Abril H., Roncero-Ramos I., Caspers M.P.M., Schuren F.H.J., Van den Broek T.J., Luque R., Perez-Martinez P., Katsiki N., Delgado-Lista J., Ordovas J.M., van Ommen B., Camargo A., Lopez-Miranda J.","An altered microbiota pattern precedes Type 2 diabetes mellitus development: From the CORDIOPREV study","10.1016/j.jare.2021.05.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107419940&doi=10.1016%2fj.jare.2021.05.001&partnerID=40&md5=f2bbfa536df51302476acfcdc6c70395","Introduction: A distinctive gut microbiome have been linked to type 2 diabetes mellitus (T2DM). Objectives: We aimed to evaluate whether gut microbiota composition, in addition to clinical biomarkers, could improve the prediction of new incident cases of diabetes in patients with coronary heart disease. Methods: All the patients from the CORDIOPREV (Clinical Trials.gov.Identifier: NCT00924937) study without T2DM at baseline were included (n = 462). Overall, 107 patients developed it after a median of 60 months. The gut microbiota composition was determined by 16S rRNA gene sequencing and predictive models were created using hold-out method. Results: A gut microbiota profile associated with T2DM development was determined through a microbiome-based predictive model. The addition of microbiome data to clinical parameters (variables included in FINDRISC risk score and the diabetes risk score of the American Diabetes Association, HDL, triglycerides and HbA1c) improved the prediction increasing the area under the curve from 0.632 to 0.946. Furthermore, a microbiome-based risk score including the ten most discriminant genera, was associated with the probability of develop T2DM. Conclusion: These results suggest that a microbiota profile is associated to the T2DM development. An integrate predictive model of microbiome and clinical data that can improve the prediction of T2DM is also proposed, if is validated in independent populations to prevent this disease. © 2021","CORDIOPREV; Coronary heart disease; Intestinal microbiota; Predictive model; Type 2 diabetes mellitus","biological marker; RNA 16S; genetics; human; intestine flora; microflora; non insulin dependent diabetes mellitus; Biomarkers; Diabetes Mellitus, Type 2; Gastrointestinal Microbiome; Humans; Microbiota; RNA, Ribosomal, 16S"
"Van De Looverbosch T., He J., Tempelaere A., Kelchtermans K., Verboven P., Tuytelaars T., Sijbers J., Nicolai B.","Inline nondestructive internal disorder detection in pear fruit using explainable deep anomaly detection on X-ray images","10.1016/j.compag.2022.106962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128410274&doi=10.1016%2fj.compag.2022.106962&partnerID=40&md5=37ba797f9cc2360b1e068b6ac8dd6d75","To preserve the quality of fresh fruit after harvest and to meet the year-round demand for high-quality fruit, pears are stored under a controlled atmosphere. However, due to preharvest events or suboptimal storage conditions, internal disorders might develop resulting in severe quality loss. Examples include internal browning and cavities, which are invisible externally. Here, X-ray radiography is investigated as a technique for internal quality inspection. The detection of defect fruit is approached as an anomaly detection (AD) problem, in which a model is constructed using nominal data and an anomaly score is used to identify defect fruit. In this work, multiple deep AD methods are shown to be effective to detect pears with internal cavity and browning disorders using X-ray radiographs (mean area under the receiver operating characteristic curve (AUC) up to 0.962). The best performing methods were found on par with a state-of-the-art multisensor disorder detection method (mean AUC up to 0.966). By investigating AD performance in function of internal disorder severity, it was shown that defect fruit with a cavity volume percentage > 1.0% could be detected 100% accurate using inline X-ray imaging. For lower cavity area percentages, the accuracy depended on the internal browning severity. Additionally, the explainability of the deep AD methods, i.e., how well human interpretable insight can be provided from each method's predictions, were qualitatively evaluated using anomaly heatmaps, which provided useful insight in the execution of the deep learning algorithms. © 2022 Elsevier B.V.","Deep learning; Food quality inspection; Image processing; Outlier detection; Postharvest technology","Anomaly detection; Deep learning; Defects; Digital storage; Image processing; Learning algorithms; Nondestructive examination; Quality control; Anomaly detection; Anomaly detection methods; Deep learning; Food quality; Food quality inspection; Images processing; Non destructive; Pear fruit; Postharvest technologies; Quality inspection; Fruits; anomaly; detection method; disability; food quality; fruit; image processing; learning; nondestructive testing; X-ray analysis"
"van der Peijl E., Najjar A., Mualla Y., Bourscheid T.J., Spinola-Elias Y., Karpati D., Nouzri S.","Toward XAI & Human Synergies to Explain the History of Art: The Smart Photobooth Project","10.1007/978-3-030-82017-6_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113349021&doi=10.1007%2f978-3-030-82017-6_13&partnerID=40&md5=26d0fbc9db0500aecb441881b6218b11","The advent of Artificial Intelligence (AI) has brought about significant changes in our daily lives with applications including industry, smart cities, agriculture, and telemedicine. Despite the successes of AI in other “less-technical” domains, human-AI synergies are required to ensure user engagement and provide interactive expert knowledge. This is notably the case of applications related to art since the appreciation and the comprehension of art is considered to be an exclusively human capacity. This paper discusses the potential human-AI synergies aiming at explaining the history of art and artistic style transfer. This work is done in the context of the “Smart Photobooth” a project which runs within the AI & Art pavilion. The latter is a satellite event of Esch2022 European Capital of Culture whose main aim is to reflect on AI and the future of art. The project is mainly an outreach and knowledge dissemination project, it uses a smart photo-booth, capable of automatically transforming the user’s picture into a well-known artistic style (e.g., impressionism), as an interactive approach to introduce the principles of the history of art to the open public and provide them with a simple explanation of different art painting styles. Whereas some of the cutting-edge AI algorithms can provide insights on what constitutes an artistic style on the visual level, the information provided by human experts is essential to explain the historical and political context in which the style emerged. To bridge this gap, this paper explores Human-AI synergies in which the explanation generated by the eXplainable AI (XAI) mechanism is coupled with insights from the human expert to provide explanations for school students as well as a wider audience. Open issues and challenges are also identified and discussed. © 2021, Springer Nature Switzerland AG.","Agents; AI & Art; Cultural heritage; Neural style transfer; XAI","Agricultural robots; Intelligent agents; Artistic style transfer; Expert knowledge; Interactive approach; Issues and challenges; Knowledge dissemination; Political context; School students; User engagement; Multi agent systems"
"van Dijk A.D.J., Kootstra G., Kruijer W., de Ridder D.","Machine learning in plant science and plant breeding","10.1016/j.isci.2020.101890","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097898312&doi=10.1016%2fj.isci.2020.101890&partnerID=40&md5=c5124cca72796dfc1eae1d808f5852bb","Technological developments have revolutionized measurements on plant genotypes and phenotypes, leading to routine production of large, complex data sets. This has led to increased efforts to extract meaning from these measurements and to integrate various data sets. Concurrently, machine learning has rapidly evolved and is now widely applied in science in general and in plant genotyping and phenotyping in particular. Here, we review the application of machine learning in the context of plant science and plant breeding. We focus on analyses at different phenotype levels, from biochemical to yield, and in connecting genotypes to these. In this way, we illustrate how machine learning offers a suite of methods that enable researchers to find meaningful patterns in relevant plant data. © 2020 The Author(s)Plant Biotechnology; Plant Bioinformatics; Artificial Intelligence © 2020 The Author(s)","Artificial Intelligence; Plant Bioinformatics; Plant Biotechnology",
"van Rijmenam M.","The Organisation of Tomorrow: How AI, blockchain and analytics turn your business into a data organisation","10.4324/9780429279973","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076015163&doi=10.4324%2f9780429279973&partnerID=40&md5=ab1c74ae5f4187d8ce17cbe5b4f19cec","The Organisation of Tomorrow presents a new model of doing business and explains how big data analytics, blockchain and artificial intelligence force us to rethink existing business models and develop organisations that will be ready for human-machine interactions. It also asks us to consider the impacts of these emerging information technologies on people and society. Big data analytics empowers consumers and employees. This can result in an open strategy and a better understanding of the changing environment. Blockchain enables peer-to-peer collaboration and trustless interactions governed by cryptography and smart contracts. Meanwhile, artificial intelligence allows for new and different levels of intensity and involvement among human and artificial actors. With that, new modes of organising are emerging: where technology facilitates collaboration between stakeholders; and where human-to-human interactions are increasingly replaced with human-to-machine and even machine-to-machine interactions. This book offers dozens of examples of industry leaders such as Walmart, Telstra, Alibaba, Microsoft and T-Mobile, before presenting the D2 + A2 model - a new model to help organisations datafy their business, distribute their data, analyse it for insights and automate processes and customer touchpoints to be ready for the data-driven and exponentially-changing society that is upon us This book offers governments, professional services, manufacturing, finance, retail and other industries a clear approach for how to develop products and services that are ready for the twenty-first century. It is a must-read for every organisation that wants to remain competitive in our fast-changing world. © 2020 Mark van Rijmenam. All rights reserved.",,
"Vanbuis J., Feuilloy M., Baffet G., Meslier N., Gagnadoux F., Girault J.-M.","Towards a user-friendly sleep staging system for polysomnography part I: Automatic classification based on medical knowledge","10.1016/j.imu.2020.100454","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097386004&doi=10.1016%2fj.imu.2020.100454&partnerID=40&md5=f5f2d5f9ae2ed339ebc9faf2922cee6b","Manual sleep scoring is a time-consuming task that requires a high level of medical expertise. For this reason, a number of automatic sleep scoring algorithms have recently been implemented. However, their use by physicians remains limited for various reasons: a lack of transparency of the approach used, insufficient heterogeneity among the patients used for testing, or a lack of practicality. This paper presents a system for facilitated sleep scoring that will overcome these limitations. The proposed system, a user-friendly tool based on electrophysiological channels, was trained and tested on large datasets of 300 and 100 distinct recordings from patients with various sleep disorders. The method replicates the manual sleep scoring process, in accordance with the American Academy of Sleep Medicine (AASM) guidelines and generates patient-dependent sleep scoring (using the SATUD system). For an improved level of precision and confidence with regard to scoring, our approach also provides a table that gives indications about the confidence level of the algorithm when scoring sleep. In contrast to recent deep learning approaches, the algorithms used were chosen for their resilience and as they are easy to understand. Medical knowledge was included in the process as much as possible. Results showed that the system is consistent with manual scoring (mean Cohen's Kappa of 0.69 and accuracy rate of 77.8%). It proves that a facilitated interpretation of the model, crucial in such fields as sleep diagnosis, can be provided when using automatic tools. This new system thereby generates sleep scoring decision support tools, which should easily contribute to significant time-saving and help sleep specialists to perform sleep diagnosis. © 2020 The Author(s)","Automatic sleep staging for polysomnography; Decision support system; Patient-dependent sleep scoring using the SATUD system; Respect of AASM Guidelines; User-friendly and interpretable sleep scoring","accuracy; adult; aged; algorithm; Article; controlled study; data analysis software; decision support system; female; human; male; middle aged; polysomnography; practice guideline; sleep medicine; sleep stage; young adult"
"VaniB V., Guruprakash C.D.","A review on Smart Agricultural Applications: Crop yield and Plant disease Prediction","10.1109/ICAAIC53929.2022.9792736","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133412570&doi=10.1109%2fICAAIC53929.2022.9792736&partnerID=40&md5=1b9af64d1ddb9b92ffe4f8d6076492ae","Internet-of- Things (IoT) is considered as a type of large-scale and distributed network, which consists of massive low-cost, and battery-constrained sensor nodes deployed in the environment. In traditional networks, sensor nodes perceive environmental information periodically and trans mit the collected data to the base station or sink node for analysis. IoT finds valuable application in many research areas and particularly, in agricultural applications mainly, disease prediction, and yield prediction. There are so many methods existing in the literature to facilitate an effective prediction in agricultural applications. Hence, this survey analyzes the existing research concentrating on prediction problems associated with IoT agricultural applications, bringing into light various shortcomings of existing methodologies for prediction problems associated with IoT-agricultural applications. Here, analysis of various methods is facilitated based on several factors, such as performance metrics, year of publication and journals, achievements of the techniques in numerical evaluations, and so on. On the other hand, an analysis of the methods concerningthe merits and demerits of the methods are presented. Lastly, the paper discusses potential future research directions and challenges in achieving better prediction accuracy in s mart agricultural applications. © 2022 IEEE.","Agriculture; crop yield prediction; deep learning; IoT; Machine learning; plant disease prediction","Agricultural technology; Crops; Deep learning; Internet of things; Learning systems; Numerical methods; Sensor nodes; Crop plants; Crop yield; Crop yield prediction; Deep learning; Large-scale network; Machine-learning; Plant disease; Plant disease prediction; Prediction problem; Yield prediction; Forecasting"
"Varadharajan C., Appling A.P., Arora B., Christianson D.S., Hendrix V.C., Kumar V., Lima A.R., Müller J., Oliver S., Ombadi M., Perciano T., Sadler J.M., Weierbach H., Willard J.D., Xu Z., Zwart J.","Can machine learning accelerate process understanding and decision-relevant predictions of river water quality?","10.1002/hyp.14565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128939341&doi=10.1002%2fhyp.14565&partnerID=40&md5=aee3eda4f561980232a2494f40ca0c7f","The global decline of water quality in rivers and streams has resulted in a pressing need to design new watershed management strategies. Water quality can be affected by multiple stressors including population growth, land use change, global warming, and extreme events, with repercussions on human and ecosystem health. A scientific understanding of factors affecting riverine water quality and predictions at local to regional scales, and at sub-daily to decadal timescales are needed for optimal management of watersheds and river basins. Here, we discuss how machine learning (ML) can enable development of more accurate, computationally tractable, and scalable models for analysis and predictions of river water quality. We review relevant state-of-the art applications of ML for water quality models and discuss opportunities to improve the use of ML with emerging computational and mathematical methods for model selection, hyperparameter optimization, incorporating process knowledge into ML models, improving explainablity, uncertainty quantification, and model-data integration. We then present considerations for using ML to address water quality problems given their scale and complexity, available data and computational resources, and stakeholder needs. When combined with decades of process understanding, interdisciplinary advances in knowledge-guided ML, information theory, data integration, and analytics can help address fundamental science questions and enable decision-relevant predictions of riverine water quality. © 2022 The Authors. Hydrological Processes published by John Wiley & Sons Ltd. This article has been contributed to by U.S. Government employees and their work is in the public domain in the USA.","analysis; machine learning; models; predictions; rivers; streams; water quality","Data integration; Decision theory; Ecosystems; Forecasting; Global warming; Information theory; Machine learning; Population statistics; Quality control; Rivers; Soil conservation; Water conservation; Water management; Analyse; Pressung; Process decisions; Process understanding; River water quality; Riverine waters; Rivers and streams; Stream; Water quality in river; Watersheds management; Water quality; acceleration; decision making; machine learning; optimization; prediction; river water; water quality"
"Vela D., Sharp A., Zhang R., Nguyen T., Hoang A., Pianykh O.S.","Temporal quality degradation in AI models","10.1038/s41598-022-15245-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133690585&doi=10.1038%2fs41598-022-15245-z&partnerID=40&md5=49911ea22d43872f726baf1b4c029667","As AI models continue to advance into many real-life applications, their ability to maintain reliable quality over time becomes increasingly important. The principal challenge in this task stems from the very nature of current machine learning models, dependent on the data as it was at the time of training. In this study, we present the first analysis of AI “aging”: the complex, multifaceted phenomenon of AI model quality degradation as more time passes since the last model training cycle. Using datasets from four different industries (healthcare operations, transportation, finance, and weather) and four standard machine learning models, we identify and describe the main temporal degradation patterns. We also demonstrate the principal differences between temporal model degradation and related concepts that have been explored previously, such as data concept drift and continuous learning. Finally, we indicate potential causes of temporal degradation, and suggest approaches to detecting aging and reducing its impact. © 2022, The Author(s).",,"aging; article; finance; learning; machine learning; weather; artificial intelligence; Artificial Intelligence; Machine Learning"
"Vélez-Bedoya Á.R., Mendoza-Saboyá L.A., Luna-Eraso J.L.","Determination of Competitive Management Perception in Family Business Leaders Using Data Mining","10.1007/978-3-030-71115-3_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107845393&doi=10.1007%2f978-3-030-71115-3_19&partnerID=40&md5=8e1e259688bc8f5ca8257679001252b5","This work seeks to determine competitive management perception of family business leaders, in order to establish working assumptions in new research and propose improvement and consolidation initiatives for these types of companies. This non-probabilistic, intentional study applied an instrument with 10 dimensions and 94 variables to a sample of 133 family business leaders from an intermediate city and a large city in Colombia. Data collection was achieved using supervised machine learning algorithms in the Python programming language, using techniques such as Cronbach’s Alpha Test, KMO, Levene, Bartlett, Discriminant Analysis and Decision Trees. The results allow us to identify four main components in 19 variables: Management and technology, Quality Management, Compensation, and Country competitiveness. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Competitiveness; Data mining; Family business; Machine learning; Perception",
"Venkatraj V., Dixit M.K.","Challenges in implementing data-driven approaches for building life cycle energy assessment: A review","10.1016/j.rser.2022.112327","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125593544&doi=10.1016%2fj.rser.2022.112327&partnerID=40&md5=1f7be30fd72a26619bf25a9cf9b81590","Over the last few decades, the construction sector's energy consumption has increased tremendously. Buildings consume both embodied energy (EE) and operational energy (OE) during their life cycle. EE is consumed by processes associated with construction, whereas OE is spent operating the building. Studies show that improving the operational efficiency of a building may have serious implications for EE. Building life cycle energy assessments (LCEA) is, therefore, essential to understanding the dichotomy between EE and OE. In recent years, increased availability and accessibility of large-scale data have made data-driven approaches a popular choice for building performance assessments. In this context, numerous review articles have highlighted and tracked current trends in building load prediction methods. While this work is significant, there remains a lack of reviews focusing on data-driven approaches from a building life cycle energy perspective. In this paper, we conduct a systematic review of literature to identify key factors hindering the application of machine learning techniques specifically for building LCEA. They include: (i) issues of data collection, quality, and availability; (ii) lack of standardized methodologies; and (iii) temporal representativeness and granularity of prediction. Finally, we discuss potential solutions, future directions, and research opportunities for data-driven LCEA research. © 2022","Building energy modelling; Building load prediction; Challenges; Data-driven; Embodied energy; Life cycle energy; Machine learning; Operating energy","Construction; Construction industry; Energy utilization; Forecasting; Life cycle; Machine learning; Building energy model; Building load; Building load prediction; Challenge; Data driven; Embodied energy; Life cycle energies; Load predictions; Machine-learning; Operating energies; Buildings"
"Verwiebe P.A., Seim S., Burges S., Schulz L., Müller-Kirchenbauer J.","Modeling energy demand—a systematic literature review","10.3390/en14237859","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119970215&doi=10.3390%2fen14237859&partnerID=40&md5=bdd89a5bdf447811585399023dd80562","In this article, a systematic literature review of 419 articles on energy demand modeling, published between 2015 and 2020, is presented. This provides researchers with an exhaustive overview of the examined literature and classification of techniques for energy demand modeling. Unlike in existing literature reviews, in this comprehensive study all of the following aspects of energy demand models are analyzed: techniques, prediction accuracy, inputs, energy carrier, sector, temporal horizon, and spatial granularity. Readers benefit from easy access to a broad literature base and find decision support when choosing suitable data-model combinations for their projects. Results have been compiled in comprehensive figures and tables, providing a structured summary of the literature, and containing direct references to the analyzed articles. Drawbacks of techniques are discussed as well as countermeasures. The results show that among the articles, machine learning (ML) techniques are used the most, are mainly applied to short-term electricity forecasting on a regional level and rely on historic load as their main data source. Engineering-based models are less dependent on historic load data and cover appliance consumption on long temporal horizons. Metaheuristic and uncertainty techniques are often used in hybrid models. Statistical techniques are frequently used for energy demand modeling as well and often serve as benchmarks for other techniques. Among the articles, the accuracy measured by mean average percentage error (MAPE) proved to be on similar levels for all techniques. This review eases the reader into the subject matter by presenting the emphases that have been made in the current literature, suggesting future research directions, and providing the basis for quantitative testing of hypotheses regarding applicability and dominance of specific methods for sub-categories of demand modeling. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Electricity load forecasting; Energy demand drivers; Energy demand modeling; Energy demand sectors; Energy forecasting techniques; Heating demand; Level of detail; Natural gas consumption; Prediction; Systematic literature review","Decision support systems; Energy management; Natural gas; Demand drivers; Electricity load forecasting; Energy demand driver; Energy demand models; Energy demand sector; Energy demands; Energy forecasting; Energy forecasting technique; Forecasting techniques; Heating demand; Level-of-detail; Natural gas consumption; Systematic literature review; Forecasting"
"Viana C.M., Santos M., Freire D., Abrantes P., Rocha J.","Evaluation of the factors explaining the use of agricultural land: A machine learning and model-agnostic approach","10.1016/j.ecolind.2021.108200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114831277&doi=10.1016%2fj.ecolind.2021.108200&partnerID=40&md5=48998a273c86bec04678cbffd6b4730f","To effectively plan and manage the use of agricultural land, it is crucial to identify and evaluate the multiple human and environmental factors that influence it. In this study, we propose a model framework to identify the factors potentially explaining the use of agricultural land for wheat, maize, and olive grove plantations at the regional level. By developing a machine-learning model coupled with a model-agnostic approach, we provide global and local interpretations of the most influential factors. We collected nearly 140 variables related to biophysical, bioclimatic, and agricultural socioeconomic conditions. Overall, the results indicated that biophysical and bioclimatic conditions were more influential than socioeconomic conditions. At the global interpretation level, the proposed model identified a strong contribution of conditions related to drainage density, slope, and soil type. In contrast, the local interpretation level indicated that socioeconomic conditions such as the degree of mechanisation could be influential in specific parcels of wheat. As demonstrated, the proposed analytical approach has the potential to serve as a decision-making tool instrument to better plan and control the use of agricultural land. © 2021 The Author(s)","Artificial intelligence; Cropland; Interpretability; LIME; xAI","Agricultural robots; Agriculture; Decision making; Economics; Land use; Machine learning; Agricultural land; Condition; Cropland; Environmental factors; Interpretability; Local interpretation; Modelling framework; Olive grove; Socio-economic conditions; XAI; Lime; agricultural land; decision making; land use planning; machine learning; plantation; regional climate; socioeconomic conditions"
"Viktorovich G.P., Periklovich T.H., Nikolaevich S.S., Igorevich B.A., Alekseevich S.K.","Machine learning in the diagnosis and treatment of ophthalmic diseases [机器学习在眼科疾病的诊断和治疗中的应用] [Машинное обучение в диагностике и лечении офтальмологических заболеваний]","10.25792/HN.2022.10.1.83-90","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134474630&doi=10.25792%2fHN.2022.10.1.83-90&partnerID=40&md5=fbf4e9aed38e8c535c3fc7a460dafc81","Machine learning is a branch of artificial intelligence that aims to adapt computer algorithms to learning. The ability to solve problems without a predetermined algorithm is formed during the processing of a training dataset, which in medicine includes the response of the patient's body or a medical decision made in the context of a specific clinical situation. There are a number of machine learning methods, including classical methods, ensemble methods, and neural networks; depending on the method of training, there are training with a teacher, without a teacher, with partial involvement of a teacher, and training with reinforcement. The article describes the principles of operation, areas of application, advantages, and limitations of these methods in solving clinical problems encountered in ophthalmological practice. The problems encountering at the stages of data collection, development, implementation, and further use of medical artificial intelligence systems are discussed, as well as possible ways to solve them. © Team of authors, 2022","Artificial intelligence; decision support systems; eye diseases; medical visualization; neural network; teacher training",
"Vinod D.N., Prabaharan S.R.S.","COVID-19-The Role of Artificial Intelligence, Machine Learning, and Deep Learning: A Newfangled","10.1007/s11831-023-09882-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146623540&doi=10.1007%2fs11831-023-09882-4&partnerID=40&md5=17e4c980bf38e464eeb5bfdf5d582a7d","The absolute previously infected novel coronavirus (COVID-19) was found in Wuhan, China, in December 2019. The COVID-19 epidemic has spread to more than 220 nations and territories globally and has altogether influenced each part of our day-to-day lives. As of 9th March 2022, a total aggregate of 44,78,82,185 (60,07,317) contaminated (dead) COVID-19 cases were accounted for all over the world. The quantities of contaminated cases passing despite everything increment essentially and do not indicate a controlled circumstance. The scope of this paper is to address this issue by presenting a comprehensive and comparative analysis of the existing Machine Learning (ML), Deep Learning (DL) and Artificial Intelligence (AI) based approaches used in significance in reacting to the COVID-19 epidemic and diagnosing the severe impacts. The paper provides, firstly, an overview of COVID-19 infection and highlights of this article; Secondly, an overview of exploring various executive innovations by utilizing different resources to stop the spread of COVID-19; Thirdly, a comparison of existing predicting methods of COVID-19 in the literature, with focus on ML, DL and AI-driven techniques with performance metrics; and finally, a discussion on the results of the work as well as future scope. © 2023, The Author(s) under exclusive licence to International Center for Numerical Methods in Engineering (CIMNE).",,"Deep learning; Learning systems; Numerical methods; Comparative analyzes; Comprehensive analysis; Coronaviruses; Machine-learning; On-machines; Performance metrices; Predicting method; Total aggregates; COVID-19"
"Virro H., Kmoch A., Vainu M., Uuemaa E.","Random forest-based modeling of stream nutrients at national level in a data-scarce region","10.1016/j.scitotenv.2022.156613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132396653&doi=10.1016%2fj.scitotenv.2022.156613&partnerID=40&md5=33a4328341e89140541e876731c88415","Nutrient runoff from agricultural production is one of the main causes of water quality deterioration in river systems and coastal waters. Water quality modeling can be used for gaining insight into water quality issues in order to implement effective mitigation efforts. Process-based nutrient models are very complex, requiring a lot of input parameters and computationally expensive calibration. Recently, ML approaches have shown to achieve an accuracy comparable to the process-based models and even outperform them when describing nonlinear relationships. We used observations from 242 Estonian catchments, amounting to 469 yearly TN and 470 TP measurements covering the period 2016–2020 to train random forest (RF) models for predicting annual N and P concentrations. We used a total of 82 predictor variables, including land cover, soil, climate and topography parameters and applied a feature selection strategy to reduce the number of dependent features in the models. The SHAP method was used for deriving the most relevant predictors. The performance of our models is comparable to previous process-based models used in the Baltic region with the TN and TP model having an R2 score of 0.83 and 0.52, respectively. However, as input data used in our models is easier to obtain, the models offer superior applicability in areas, where data availability is insufficient for process-based approaches. Therefore, the models enable to give a robust estimation for nutrient losses at national level and allows to capture the spatial variability of the nutrient runoff which in turn enables to provide decision-making support for regional water management plans. © 2022","Machine learning; Nutrient concentration; Random forest; Water quality","Agriculture; Catchments; Climate models; Decision trees; Deterioration; Nutrients; Random forests; Runoff; Topography; Water management; Water quality; Agricultural productions; Based modelling; Machine-learning; National level; Nutrient concentrations; Process-based modeling; Random forests; River systems; Stream nutrient; Water quality deterioration; Machine learning; agricultural production; concentration (composition); data set; machine learning; nutrient dynamics; runoff; streamflow; water quality; article; catchment area (hydrology); climate; data availability; decision making; feature selection; land use; machine learning; nutrient concentration; predictor variable; random forest; runoff; soil; topography; water management; water quality; environmental monitoring; river; water quality; nitrogen; phosphorus; Environmental Monitoring; Nitrogen; Nutrients; Phosphorus; Rivers; Water Quality"
"Viscarra Rossel R.A., Behrens T., Ben-Dor E., Chabrillat S., Demattê J.A.M., Ge Y., Gomez C., Guerrero C., Peng Y., Ramirez-Lopez L., Shi Z., Stenberg B., Webster R., Winowiecki L., Shen Z.","Diffuse reflectance spectroscopy for estimating soil properties: A technology for the 21st century","10.1111/ejss.13271","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135921473&doi=10.1111%2fejss.13271&partnerID=40&md5=a307e76ec358b27adad9c5f698719e8b","Spectroscopic measurements of soil samples are reliable because they are highly repeatable and reproducible. They characterise the samples' mineral–organic composition. Estimates of concentrations of soil constituents are inevitably less precise than estimates obtained conventionally by chemical analysis. But the cost of each spectroscopic estimate is at most one-tenth of the cost of a chemical determination. Spectroscopy is cost-effective when we need many data, despite the costs and errors of calibration. Soil spectroscopists understand the risks of over-fitting models to highly dimensional multivariate spectra and have command of the mathematical and statistical methods to avoid them. Machine learning has fast become an algorithmic alternative to statistical analysis for estimating concentrations of soil constituents from reflectance spectra. As with any modelling, we need judicious implementation of machine learning as it also carries the risk of over-fitting predictions to irrelevant elements of the spectra. To use the methods confidently, we need to validate the outcomes with appropriately sampled, independent data sets. Not all machine learning should be considered ‘black boxes’. Their interpretability depends on the algorithm, and some are highly interpretable and explainable. Some are difficult to interpret because of complex transformations or their huge and complicated network of parameters. But there is rapidly advancing research on explainable machine learning, and these methods are finding applications in soil science and spectroscopy. In many parts of the world, soil and environmental scientists recognise the merits of soil spectroscopy. They are building spectral libraries on which they can draw to localise the modelling and derive soil information for new projects within their domains. We hope our article gives readers a more balanced and optimistic perspective of soil spectroscopy and its future. Highlights: Spectroscopy is reliable because it is a highly repeatable and reproducible analytical technique. Spectra are calibrated to estimate concentrations of soil properties with known error. Spectroscopy is cost-effective for estimating soil properties. Machine learning is becoming ever more powerful for extracting accurate information from spectra, and methods for interpreting the models exist. Large libraries of soil spectra provide information that can be used locally to aid estimates from new samples. © 2022 The Authors. European Journal of Soil Science published by John Wiley & Sons Ltd on behalf of British Society of Soil Science.","calibration; machine learning; model localization; reflectance spectroscopy; regression; soil constituents; spectral libraries; validation","calibration; database; machine learning; model validation; regression analysis; soil property; soil science; spectroscopy; twenty first century"
"Vitali G., Francia M., Golfarelli M., Canavari M.","Crop Management with the IoT: An Interdisciplinary Survey","10.3390/agronomy11010181","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100942957&doi=10.3390%2fagronomy11010181&partnerID=40&md5=2a6e8cceb09b9bb9b8ac7abfffe568de","In this study, we analyze how crop management will benefit from the Internet of Things (IoT) by providing an overview of its architecture and components from agronomic and technological perspectives. The present analysis highlights that IoT is a mature enabling technology with articulated hardware and software components. Cheap networked devices can sense crop fields at a finer grain to give timeliness warnings on the presence of stress conditions and diseases to a wider range of farmers. Cloud computing allows reliable storage, access to heterogeneous data, and machine-learning techniques for developing and deploying farm services. From this study, it emerges that the Internet of Things will draw attention to sensor quality and placement protocols, while machine learning should be oriented to produce understandable knowledge, which is also useful to enhance cropping system simulation systems. © 2021 by the authors.","Cloud computing; Crop management; Internet of Things; Sensors; Smart farming",
"Vizcarra G., Bermejo D., Mauricio A., Zarate Gomez R., Dianderas E.","The Peruvian Amazon forestry dataset: A leaf image classification corpus","10.1016/j.ecoinf.2021.101268","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103308612&doi=10.1016%2fj.ecoinf.2021.101268&partnerID=40&md5=88de1c84fc2c3ebc8069b767f6a4d3dc","Forest census allows getting precise data for logging planning and elaboration of the forest management plan. Species identification blunders carry inadequate forest management plans and high risks inside forest concessions. Hence, an identification protocol prevents the exploitation of non-commercial or endangered timber species. The current Peruvian legislation allows the incorporation of non-technical experts, called “materos”, during the identification. Materos use common names given by the folklore and traditions of their communities instead of formal ones, which generally lead to misclassifications. In the real world, logging companies hire materos instead of botanists due to cost/time limitations. Given such a motivation, we explore an end-to-end software solution to automatize the species identification. This paper introduces the Peruvian Amazon Forestry Dataset, which includes 59,441 leaves samples from ten of the most profitable and endangered timber-tree species. The proposal contemplates a background removal algorithm to feed a pre-trained CNN by the ImageNet dataset. We evaluate the quantitative (accuracy metric) and qualitative (visual interpretation) impacts of each stage by ablation experiments. The results show a 96.64% training accuracy and 96.52% testing accuracy on the VGG-19 model. Furthermore, the visual interpretation of the model evidences that leaf venations have the highest correlation in the plant recognition task. © 2021","Deep learning; Interpretation; Leaves dataset; Peruvian Amazon; Visual interpretation","accuracy assessment; algorithm; community forestry; forest management; forestry; image classification; timber; Amazon River; Peru"
"Volkmar G., Fischer P.M., Reinecke S.","Artificial Intelligence and Machine Learning: Exploring drivers, barriers, and future developments in marketing management","10.1016/j.jbusres.2022.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131124066&doi=10.1016%2fj.jbusres.2022.04.007&partnerID=40&md5=241655914af5314dfb3bdf304a5e1708","Companies neither fully exploit the potential of Artificial Intelligence (AI), nor that of Machine Learning (ML), its most prominent method. This is true in particular of marketing, where its possible use extends beyond mere segmentation, personalization, and decision-making. We explore the drivers of and barriers to AI and ML in marketing by adopting a dual strategic and behavioral focus, which provides both an inward (AI and ML for marketers) and an outward (AI and ML for customers) perspective. From our mixed-method approach (a Delphi study, a survey, and two focus groups), we derive several research propositions that address the challenges facing marketing managers and organizations in three distinct domains: (1) Culture, Strategy, and Implementation; (2) Decision-Making and Ethics; (3) Customer Management. Our findings contribute to better understanding the human factor behind AI and ML, and aim to stimulate interdisciplinary inquiry across marketing, organizational behavior, psychology, and ethics. © 2022 The Authors","Artificial Intelligence; Decision- Making; Delphi Method; Ethics; Machine Learning; Marketing Management",
"Vyas S., Shabaz M., Pandit P., Parvathy L.R., Ofori I.","Integration of Artificial Intelligence and Blockchain Technology in Healthcare and Agriculture","10.1155/2022/4228448","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131409592&doi=10.1155%2f2022%2f4228448&partnerID=40&md5=334b5960e498cce877054cddff976923","Over the last decade, the healthcare sector has accelerated its digitization and electronic health records (EHRs). As information technology progresses, the notion of intelligent health also gathers popularity. By combining technologies such as the internet of things (IoT) and artificial intelligence (AI), innovative healthcare modifies and enhances traditional medical systems in terms of efficiency, service, and personalization. On the other side, intelligent healthcare systems are incredibly vulnerable to data breaches and other malicious assaults. Recently, blockchain technology has emerged as a potentially transformative option for enhancing data management, access control, and integrity inside healthcare systems. Integrating these advanced approaches in agriculture is critical for managing food supply chains, drug supply chains, quality maintenance, and intelligent prediction. This study reviews the literature, formulates a research topic, and analyzes the applicability of blockchain to the agriculture/food industry and healthcare, with a particular emphasis on AI and IoT. This article summarizes research on the newest blockchain solutions paired with AI technologies for strengthening and inventing new technological standards for the healthcare ecosystems and food industry. © 2022 Sonali Vyas et al.",,"Access control; Agriculture; Artificial intelligence; Food supply; Health care; Information management; Internet of things; Supply chains; Block-chain; Digitisation; Drug supply; Food industries; Food supply chain; Healthcare sectors; Healthcare systems; Medical systems; Personalizations; Technology progress; Blockchain"
"Wade M.J.","Not just numbers: Mathematical modelling and its contribution to anaerobic digestion processes","10.3390/PR8080888","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089706705&doi=10.3390%2fPR8080888&partnerID=40&md5=c5d544c63c30524c068f6f33771ad8f2","Mathematical modelling of bioprocesses has a long and notable history, with eminent contributions from fields including microbiology, ecology, biophysics, chemistry, statistics, control theory and mathematical theory. This richness of ideas and breadth of concepts provide great motivation for inquisitive engineers and intrepid scientists to try their hand at modelling, and this collaboration of disciplines has also delivered significant milestones in the quality and application of models for both theoretical and practical interrogation of engineered biological systems. The focus of this review is the anaerobic digestion process, which, as a technology that has come in and out of fashion, remains a fundamental process for addressing the global climate emergency. Whether with conventional anaerobic digestion systems, biorefineries, or other anaerobic technologies, mathematical models are important tools that are used to design, monitor, control and optimise the process. Both highly structured, mechanistic models and data-driven approaches have been used extensively over half a decade, but recent advances in computational capacity, scientific understanding and diversity and quality of process data, presents an opportunity for the development of new modelling paradigms, augmentation of existing methods, or even incorporation of tools from other disciplines, to ensure that anaerobic digestion research can remain resilient and relevant in the face of emerging and future challenges. © 2020 by the authors.","Anaerobic digestion; Data-driven models; Hybrid modelling; Mathematical analysis; Mathematical modelling; Mechanistic models; Thermodynamics",
"Wadoux A.M.J.-C., Saby N.P.A., Martin M.P.","Shapley values reveal the drivers of soil organic carbon stock prediction","10.5194/soil-9-21-2023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147272479&doi=10.5194%2fsoil-9-21-2023&partnerID=40&md5=1ed8d817dc4f1a22596ecabe5d7b3c3f","Insights into the controlling factors of soil organic carbon (SOC) stock variation are necessary both for our scientific understanding of the terrestrial carbon balance and to support policies that intend to promote carbon storage in soils to mitigate climate change. In recent years, complex statistical and algorithmic tools from the field of machine learning have become popular for modelling and mapping SOC stocks over large areas. In this paper, we report on the development of a statistical method for interpreting complex models, which we implemented for the study of SOC stock variation. We fitted a random forest machine learning model with 2206 measurements of SOC stocks for the 0-50 cm depth interval from mainland France and used a set of environmental covariates as explanatory variables. We introduce Shapley values, a method from coalitional game theory, and use them to understand how environmental factors influence SOC stock prediction: what is the functional form of the association in the model between SOC stocks and environmental covariates, and how does the covariate importance vary locally from one location to another and between carbon-landscape zones? Results were validated both in light of the existing and well-described soil processes mediating soil carbon storage and with regards to previous studies in the same area. We found that vegetation and topography were overall the most important drivers of SOC stock variation in mainland France but that the set of most important covariates varied greatly among locations and carbon-landscape zones. In two spatial locations with equivalent SOC stocks, there was nearly an opposite pattern in the individual covariate contribution that yielded the prediction - in one case climate variables contributed positively, whereas in the second case climate variables contributed negatively - and this effect was mitigated by land use. We demonstrate that Shapley values are a methodological development that yield useful insights into the importance of factors controlling SOC stock variation in space. This may provide valuable information to understand whether complex empirical models are predicting a property of interest for the right reasons and to formulate hypotheses on the mechanisms driving the carbon sequestration potential of a soil. © 2023 Alexandre M. J.-C. Wadoux et al.",,"carbon balance; carbon sequestration; carbon storage; environmental factor; landscape; soil carbon; France"
"Wadoux A.M.J.-C., Molnar C.","Beyond prediction: methods for interpreting complex models of soil variation","10.1016/j.geoderma.2022.115953","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131094237&doi=10.1016%2fj.geoderma.2022.115953&partnerID=40&md5=b03d63389aa2a9a3b59806ead5b15564","Understanding the spatial variation of soil properties is central to many sub-disciplines of soil science. Commonly in soil mapping studies, a soil map is constructed through prediction by a statistical or non-statistical model calibrated with measured values of the soil property and environmental covariates of which maps are available. In recent years, the field has gradually shifted attention towards more complex statistical and algorithmic tools from the field of machine learning. These models are particularly useful for their predictive capabilities and are often more accurate than classical models, but they lack interpretability and their functioning cannot be readily visualized. There is a need to understand how these models can be used for purposes other than making accurate prediction and whether it is possible to extract information on the relationships among variables found by the models. In this paper we describe and evaluate a set of methods for the interpretation of complex models of soil variation. An overview is presented of how model-independent methods can serve the purpose of interpreting and visualizing different aspects of the model. We illustrate the methods with the interpretation of two mapping models in a case study mapping topsoil organic carbon in France. We reveal the importance of each driver of soil variation, their interaction, as well as the functional form of the association between environmental covariate and the soil property. Interpretation is also conducted locally for an area and two spatial locations with distinct land use and climate. We show that in all cases important insights can be obtained, both into the overall model functioning and into the decision made by the model for a prediction at a location. This underpins the importance of going beyond accurate prediction in soil mapping studies. Interpretation of mapping models reveal how the predictions are made and can help us formulating hypotheses on the underlying soil processes and mechanisms driving soil variation. © 2022 Elsevier B.V.","Accumulated local effect; H-statistic; Machine learning; Partial dependence; Shapley; Surrogate modelling","Association reactions; Forecasting; Land use; Mapping; Organic carbon; Soil surveys; Soils; Accumulated local effect; Complex model; H-statistic; Local effects; Partial dependence; Shapley; Soil mapping; Soil property; Soil variation; Surrogate modeling; Machine learning; data interpretation; land use change; machine learning; organic carbon; soil property; spatial variation; statistical analysis; topsoil; France"
"Wadoux A.M.J.-C., Minasny B., McBratney A.B.","Machine learning for digital soil mapping: Applications, challenges and suggested solutions","10.1016/j.earscirev.2020.103359","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091029724&doi=10.1016%2fj.earscirev.2020.103359&partnerID=40&md5=b626f8718315bc899ecedafd4c275be0","The uptake of machine learning (ML) algorithms in digital soil mapping (DSM) is transforming the way soil scientists produce their maps. Within the past two decades, soil scientists have applied ML to a wide range of scenarios, by mapping soil properties or classes with various ML algorithms, on spatial scale from the local to the global, and with depth. The wide adoption of ML for soil mapping was made possible by the increase in data availability, the ease of accessing environmental spatial data, and the development of software solutions aided by computational tools to analyse them. In this article, we review the current use of ML in DSM, identify the key challenges and suggest solutions from the existing literature. There is a growing interest of the use of ML in DSM. Most studies emphasize prediction and accuracy of the predicted maps for applications, such as baseline production of quantitative soil information. Few studies account for existing soil knowledge in the modelling process or quantify the uncertainty of the predicted maps. Further, we discuss the challenges related to the application of ML for soil mapping and suggest solutions from existing studies in the natural sciences. The challenges are: sampling, resampling, accounting for the spatial information, multivariate mapping, uncertainty analysis, validation, integration of pedological knowledge and interpretation of the models. Overall, the current literature shows few attempts in understanding the underlying soil structure or process using the predicted maps and the ML model, for example by generating hypotheses on mechanistic relationships among variables. In this regard, several additional challenging aspects need to be considered, such as the inclusion of pedological knowledge in the ML algorithm or the interpretability of the calibrated ML model. Tackling these challenges is critical for ML to gain credibility and scientific consistency in soil science. We conclude that for future developments, ML could incorporate three core elements: plausibility, interpretability, and explainability, which will trigger soil scientists to couple model prediction with pedological explanation and understanding of the underlying soil processes. © 2020 Elsevier B.V.","Data mining; Geostatistics; Pedometrics; Random forest; Soil science; Spatial data","algorithm; data mining; geostatistics; machine learning; mapping; pedology; soil property"
"Wagle S.A., Harikrishnan R., Ali S.H.M., Faseehuddin M.","Classification of plant leaves using new compact convolutional neural network models","10.3390/plants11010024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121469471&doi=10.3390%2fplants11010024&partnerID=40&md5=448ae46763a5a9d262e45b384c918fe2","Precision crop safety relies on automated systems for detecting and classifying plants. This work proposes the detection and classification of nine species of plants of the PlantVillage dataset using the proposed developed compact convolutional neural networks and AlexNet with transfer learning. The models are trained using plant leaf data with different data augmentations. The data augmentation shows a significant improvement in classification accuracy. The proposed models are also used for the classification of 32 classes of the Flavia dataset. The proposed developed N1 model has a classification accuracy of 99.45%, N2 model has a classification accuracy of 99.65%, N3 model has a classification accuracy of 99.55%, and AlexNet has a classification accuracy of 99.73% for the PlantVillage dataset. In comparison to AlexNet, the proposed models are compact and need less training time. The proposed N1 model takes 34.58%, the proposed N2 model takes 18.25%, and the N3 model takes 20.23% less training time than AlexNet. The N1 model and N3 models are size 14.8 MB making it 92.67% compact, and the N2 model is 29.7 MB which makes it 85.29% compact as compared to AlexNet. The proposed models are giving good accuracy in classifying plant leaf, as well as diseases in tomato plant leaves. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Classification; Compact model; Convolutional neural network; Plant lea",
"Wagner D.N.","The nature of the Artificially Intelligent Firm - An economic investigation into changes that AI brings to the firm","10.1016/j.telpol.2020.101954","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082515877&doi=10.1016%2fj.telpol.2020.101954&partnerID=40&md5=6bab4d760ffccb064914b925c57e9dc4","With the arrival of Artificial Intelligence (AI), the nature of the firm is changing and economic theory can provide guidance to businesses as well as to politics when formulating adequate strategies for this unknown terrain. By interpreting AI as a new type of agent within the firm, the theory of the firm can serve as a lingua franca to connect computer sciences and social sciences when dealing with the interdisciplinary phenomenon of AI. To achieve this, this paper adopts the perspective of the economic theory of the firm to systematically explore the changes that AI brings to the institution of the firm. In total, five interrelated propositions are discussed that are rooted in the traditional theory but trace the nature of the Artificially Intelligent Firm: AI intensifies the effects of economic rationality on the firm (1). AI introduces a new type of information asymmetry (2). AI can perforate the boundaries of the firm (3). AI can create triangular agency relationships (4) and AI has the potential to remove traditional limits of integration (5). © 2020 Elsevier Ltd","Artificial intelligence; Asymmetric information; Machine learning; Principal-agent problem; Theory of the firm","Artificial intelligence; Learning systems; Social computing; Asymmetric information; Economic investigation; Economic rationality; Economic theories; Information asymmetry; Principal-agent problems; Provide guidances; Theory of the firm; Economics"
"Wan J., Li X., Dai H.-N., Kusiak A., Martinez-Garcia M., Li D.","Artificial-Intelligence-Driven Customized Manufacturing Factory: Key Technologies, Applications, and Challenges","10.1109/JPROC.2020.3034808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097199226&doi=10.1109%2fJPROC.2020.3034808&partnerID=40&md5=bc15bb18d3d42376d3c07733a579c80b","The traditional production paradigm of large batch production does not offer flexibility toward satisfying the requirements of individual customers. A new generation of smart factories is expected to support new multivariety and small-batch customized production modes. For this, artificial intelligence (AI) is enabling higher value-added manufacturing by accelerating the integration of manufacturing and information communication technologies, including computing, communication, and control. The characteristics of a customized smart factory are: self-perception, operations optimization, dynamic reconfiguration, and intelligent decision-making. The AI technologies will allow manufacturing systems to perceive the environment, adapt to the external needs, and extract the process knowledge, including business models, such as intelligent production, networked collaboration, and extended service models. This article focuses on the implementation of AI in customized manufacturing (CM). The architecture of an AI-driven customized smart factory is presented. Details of intelligent manufacturing devices, intelligent information interaction, and construction of a flexible manufacturing line are showcased. The state-of-the-art AI technologies of potential use in CM, that is, machine learning, multiagent systems, Internet of Things, big data, and cloud-edge computing, are surveyed. The AI-enabled technologies in a customized smart factory are validated with a case study of customized packaging. The experimental results have demonstrated that the AI-assisted CM offers the possibility of higher production flexibility and efficiency. Challenges and solutions related to AI in CM are also discussed. © 1963-2012 IEEE.","Artificial intelligence (AI); customized manufacturing (CM); Industry 4.0; smart factory; software-defined network","Decision making; Dynamic models; Engineering education; Multi agent systems; Dynamic re-configuration; Flexible manufacturing lines; Information communication technology; Intelligent decision making; Intelligent information; Intelligent Manufacturing; Networked collaboration; Value-added manufacturing; Manufacture"
"Wang B., Spessa A.C., Feng P., Hou X., Yue C., Luo J.-J., Ciais P., Waters C., Cowie A., Nolan R.H., Nikonovas T., Jin H., Walshaw H., Wei J., Guo X., Liu D.L., Yu Q.","Extreme fire weather is the major driver of severe bushfires in southeast Australia","10.1016/j.scib.2021.10.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119197971&doi=10.1016%2fj.scib.2021.10.001&partnerID=40&md5=02172c16566c0f67f883cbe2b673bfa9","In Australia, the proportion of forest area that burns in a typical fire season is less than for other vegetation types. However, the 2019–2020 austral spring-summer was an exception, with over four times the previous maximum area burnt in southeast Australian temperate forests. Temperate forest fires have extensive socio-economic, human health, greenhouse gas emissions, and biodiversity impacts due to high fire intensities. A robust model that identifies driving factors of forest fires and relates impact thresholds to fire activity at regional scales would help land managers and fire-fighting agencies prepare for potentially hazardous fire in Australia. Here, we developed a machine-learning diagnostic model to quantify nonlinear relationships between monthly burnt area and biophysical factors in southeast Australian forests for 2001–2020 on a 0.25° grid based on several biophysical parameters, notably fire weather and vegetation productivity. Our model explained over 80% of the variation in the burnt area. We identified that burnt area dynamics in southeast Australian forest were primarily controlled by extreme fire weather, which mainly linked to fluctuations in the Southern Annular Mode (SAM) and Indian Ocean Dipole (IOD), with a relatively smaller contribution from the central Pacific El Niño Southern Oscillation (ENSO). Our fire diagnostic model and the non-linear relationships between burnt area and environmental covariates can provide useful guidance to decision-makers who manage preparations for an upcoming fire season, and model developers working on improved early warning systems for forest fires. © 2021 Science China Press","Burnt area modelling; Climate drivers; Forest fires; Machine learning; Remote sensing; Southeast Australia","Atmospheric pressure; Biodiversity; Climate change; Decision making; Fire hazards; Fires; Gas emissions; Greenhouse gases; Machine learning; Remote sensing; Vegetation; Australia; Burn area modeling; Burn-in; Burnt areas; Climate driver; Fire weather; Forest fires; Remote-sensing; Southeast australia; Temperate forests; Deforestation"
"Wang D., Li R., Zhu B., Liu T., Sun C., Guo W.","Estimation of Wheat Plant Height and Biomass by Combining UAV Imagery and Elevation Data","10.3390/agriculture13010009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146747213&doi=10.3390%2fagriculture13010009&partnerID=40&md5=fd279ade370f48371b5edba9761f88f1","Aboveground biomass (AGB) is an important basis for wheat yield formation. It is useful to timely collect the AGB data to monitor wheat growth and to build high-yielding wheat groups. However, as traditional AGB data acquisition relies on destructive sampling, it is difficult to adapt to the modernization of agriculture, and the estimation accuracy of spectral data alone is low and cannot solve the problem of index saturation at later stages. In this study, an unmanned aerial vehicle (UAV) with an RGB camera and the real-time kinematic (RTK) was used to obtain imagery data and elevation data at the same time during the critical fertility period of wheat. The cumulative percentile and the mean value methods were then used to extract the wheat plant height (PH), and the color indices (CIS) and PH were combined to invert the AGB of wheat using parametric and non-parametric models. The results showed that the accuracy of the model improved with the addition of elevation data, and the model with the highest accuracy of multi-fertility period estimation was PLSR (PH + CIS), with R2, RMSE and NRMSE of 0.81, 1248.48 kg/ha and 21.77%, respectively. Compared to the parametric models, the non-parametric models incorporating PH and CIS greatly improved the prediction of AGB during critical fertility periods in wheat. The inclusion of elevation data therefore greatly improves the accuracy of AGB prediction in wheat compared to traditional spectral prediction models. The fusion of UAV-based elevation data and image information provides a new technical tool for multi-season wheat AGB monitoring. © 2022 by the authors.","AGB; color indices; elevation; regression models; UAV RGB image; wheat",
"Wang D., Han F., Zhao Q., Lv Y.","Teaching Practice of Engineering Management Course for Engineering Education Certification under Background of Artificial Intelligence","10.1155/2022/3106491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140086808&doi=10.1155%2f2022%2f3106491&partnerID=40&md5=6a4d27efdffa243739d8754474b7c460","With the advancement of China's industrial construction, the field of engineering management has also attracted more attention. However, China's engineering management major is currently in a growing stage due to the issue of the opening years, and the teaching and practice setting of each course is also in an immature stage, which makes China's engineering management majors present more and more problems. The truancy rate has been increasing year by year, the students' dominant position in the class has become objectified, and their trust in teachers has decreased. Students' learning shows the characteristics of individualization and diversity. Higher requirements are put forward for teachers' teaching quality, and schools lack an effective supervision mechanism. In order to solve these problems better, it is imperative to reform and innovate the course teaching of engineering management majors. The core of engineering education accreditation is to confirm that engineering graduates meet established quality standards recognized by the industry. It is a unique method to test whether the course teaching of engineering management majors is qualified and attracts many scholars to discuss it. Engineering education accreditation has attracted many scholars to discuss it because it is a unique means to test the qualifications of engineering management students' course teaching. This study was based on an in-depth exploration of the teaching practice of engineering management courses and combines artificial intelligence with an engineering education certification. Through the research and analysis of colleges and universities, the research finally showed that the engineering management professional course teaching of engineering education certification under the background of artificial intelligence can promote the attendance of students in school by about 20%. The achievement of course teaching objectives has increased by about 13% and the comprehensive ability level of graduates has increased by about 8%. It improved the overall level of students and the teaching quality and efficiency of engineering management courses and also promoted the development of college education so that today's engineering management graduates can better meet the needs of today's society. © 2022 Dan Wang et al.",,"Accreditation; Artificial intelligence; Curricula; Students; Teaching; Technical presentations; Course teachings; Engineering management; Engineering management course; Engineering management majors; Growing stages; Industrial construction; Student learning; Teachers'; Teaching practices; Teaching quality; Engineering education"
"Wang F., Wang Y., Zhang K., Hu M., Weng Q., Zhang H.","Spatial heterogeneity modeling of water quality based on random forest regression and model interpretation","10.1016/j.envres.2021.111660","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110260359&doi=10.1016%2fj.envres.2021.111660&partnerID=40&md5=975266dcc9a5efcb6e059247601c6bee","A systematic understanding of the spatial distribution of water quality is critical for successful watershed management; however, the limited number of physical monitoring stations has restricted the evaluation of spatial water quality distribution and the identification of features impacting the water quality. To fill this gap, we developed a modeling process that employed the random forest regression (RFR) to model the water quality distribution for the Taihu Lake basin in Zhejiang Province, China, and adopted the Shapley Additive exPlanations (SHAP) method to interpret the underlying driving forces. We first used RFR to model three water quality parameters: permanganate index (CODMn), total phosphorus (TP), and total nitrogen (TN), based on 16 watershed features. We then applied the built models to generate water quality distribution maps for the basin, with the CODMn ranging from 1.39 to 6.40 mg/L, TP from 0.02 to 0.23 mg/L, and TN from 1.43 to 4.27 mg/L. These maps showed generally consistent patterns among the CODMn, TN, and TP with minor differences in the spatial distribution. The SHAP analysis showed that the TN was mainly affected by agricultural non-point sources, while the CODMn and TP were affected by agricultural and domestic sources. Due to differences in sewage collection and treatment between urban and rural areas, the water quality in highly populated urban areas was better than that in rural areas, which led to an unexpected positive relationship between water quality and population density. Overall, with the RFR models and SHAP interpretation, we obtained a continuous distribution pattern of the water quality and identified its driving forces in the basin. These findings provided important information to assist water quality restoration projects. © 2021 Elsevier Inc.","Driving force analysis; Machine learning; Random forest regression; Shapley additive explanations; Water quality assessment","nitrogen; nitrogen fertilizer; phosphorus; surface water; nitrogen; phosphorus; forest; hydrological modeling; nitrogen; sewage treatment; spatial distribution; water quality; watershed; adaboost regression; Article; artificial neural network; China; decision tree; elastic net regression; environmental parameters; eutrophication; evaporation; feature selection; gradient boosting regression; k nearest neighbor; lake basin; lasso regression; machine learning; nitrogen concentration; nonpoint source pollution; permanganate index; population density; precipitation; random forest; regression analysis; rural area; sewage; shapley additive explanation method; statistical model; support vector machine; urban area; urbanization; validation process; water monitoring; water quality; water sampling; water temperature; water treatment; watershed; environmental monitoring; lake; river; water pollutant; China; Taihu Lake; China; Environmental Monitoring; Lakes; Nitrogen; Phosphorus; Rivers; Water Pollutants, Chemical; Water Quality"
"Wang H., Wu Y., Xiang H., Sun-Waterhouse D., Zhao Y., Chen S., Li L., Wang Y.","UHPLC-Q-Exactive Orbitrap MS/MS-based untargeted lipidomics reveals molecular mechanisms and metabolic pathways of lipid changes during golden pomfret (Trachinotus ovatus) fermentation","10.1016/j.foodchem.2022.133676","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134571704&doi=10.1016%2fj.foodchem.2022.133676&partnerID=40&md5=308274fa47303f9669013d2f44cc4be8","Fermented golden pomfret (a popular marine fish product) is prepared via spontaneous fermentation. However, no comprehensive analysis has been reported on its lipid composition and metabolism. Herein, UHPLC-MS/MS-based untargeted lipidomic analysis identified 998 lipids (six classes; 29 subclasses) in fermented golden pomfret, including glycerolipids (47.70%) and glycerophospholipids (32.06%). As fermentation proceeded, triglyceride and diglyceride contents increased and subsequently decreased, while that of poly-unsaturated fatty acid-containing lipids increased (including those with docosahexaenoic acid, eicosapentaenoic acid, and docosapentaenoic acid). Pathway enrichment analysis identified seven lipid-related metabolic pathways, with the glycerophospholipid pathway found to be the most pertinent. Moreover, the decreased abundance of phosphatidylethanolamines and phosphatidylcholines during fermentation results from their high unsaturated fatty acid (FA) content. Indeed, essential FA contents increase following fermentation, due to their occurrence as glycerolipid side chains. Collectively, the results of this study provide a theoretical reference for optimizing the quality of fermented fish products. © 2022 Elsevier Ltd","Fermentation; Golden pomfret; Metabolic pathway; Molecular mechanism; Untargeted lipidomics","Fish; Lipids; Metabolism; Unsaturated fatty acids; Fatty acid contents; Glycerolipids; Glycerophospholipids; Golden pomfret; Lipidomics; Metabolic pathways; Molecular mechanism; Orbitrap MS; Q Exactive; Untargeted lipidomic; Fermentation; 2 propanol; acetonitrile; ammonia; ceramide; dichloromethane; lipid; lipidome; solvent; sphingosine; sulfatide; tert butyl methyl ether; water; glycerophospholipid; lipid; unsaturated fatty acid; Article; China; extraction; fermentation; fish; lipid metabolism; lipidomics; nonhuman; tandem mass spectrometry; ultra performance liquid chromatography; animal; chemistry; fermentation; high performance liquid chromatography; metabolism; Animals; Chromatography, High Pressure Liquid; Fatty Acids, Unsaturated; Fermentation; Glycerophospholipids; Lipidomics; Lipids; Metabolic Networks and Pathways; Tandem Mass Spectrometry"
"Wang H., Wu Y., Wang Y.","Whole-Genome Sequencing of a Potential Ester-Synthesizing Bacterium Isolated from Fermented Golden Pomfret and Identification of Its Lipase Encoding Genes","10.3390/foods11131954","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133703694&doi=10.3390%2ffoods11131954&partnerID=40&md5=25e1b953a37a95723f8c6c89392a63b9","Microbial ester synthases are regarded as valuable catalysts in the food industry. Here, one strain of Acinetobacter venetianus with ester synthase-production capacity, SCSMX-3, was isolated from traditional fermented golden pomfret. It exhibited good growth in mesophilic, low salt, and slightly alkaline environments. The ester synthase produced by SCSMX-3 displayed maximum activity at pH 8.0 and 35 °C. Genome sequencing revealed that the strain contains one circular chromosome of 336313 bp and two circular plasmids (plasmid A-14424 bp and plasmid B-11249 bp). Six CRISPR structures enhance the genomic stability of SCSMX-3 and provide the opportunity to create new functional strains. Gene function analysis indicated that SCSMX-3 produces the necessary enzymes for survival under different conditions and for flavor substance synthesis. Furthermore, 49 genes encoding enzymes associated with lipid metabolism, including three triacylglycerol lipases and two esterases, were identified through the NCBI Non-Redundant Protein Database. The lipase encoded by gene0302 belongs to the GX group and the abH15.02 (Burkholderia cepacia lipase) homolog of the abH15 superfamily. Our results shed light on the genomic diversity of and lipid metabolism in A. venetianus isolated from fermented golden pomfret, laying a foundation for the exploration of new ester synthases to improve the flavor of fermented fish products. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","Acinetobacter venetianus; ester synthesis; traditional fermented golden pomfret; whole genome",
"Wang H., Cimen E., Singh N., Buckler E.","Deep learning for plant genomics and crop improvement","10.1016/j.pbi.2019.12.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078202598&doi=10.1016%2fj.pbi.2019.12.010&partnerID=40&md5=c6544a3870ec53b0dbc180e72480d963","Our era has witnessed tremendous advances in plant genomics, characterized by an explosion of high-throughput techniques to identify multi-dimensional genome-wide molecular phenotypes at low costs. More importantly, genomics is not merely acquiring molecular phenotypes, but also leveraging powerful data mining tools to predict and explain them. In recent years, deep learning has been found extremely effective in these tasks. This review highlights two prominent questions at the intersection of genomics and deep learning: 1) how can the flow of information from genomic DNA sequences to molecular phenotypes be modeled; 2) how can we identify functional variants in natural populations using deep learning models? Additionally, we discuss the possibility of unleashing the power of deep learning in synthetic biology to create novel genomic elements with desirable functions. Taken together, we propose a central role of deep learning in future plant genomics research and crop genetic improvement. © 2020 The Authors",,"genetics; genomics; phenotype; plant; plant genome; Deep Learning; Genome, Plant; Genomics; Phenotype; Plants"
"Wang J., Zhao R., Li P., Fang Z., Li Q., Han Y., Zhou R., Zhang Y.","Clinical Progress and Optimization of Information Processing in Artificial Visual Prostheses","10.3390/s22176544","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137599254&doi=10.3390%2fs22176544&partnerID=40&md5=18bc7786d78e373931c462ecfa3f4709","Visual prostheses, used to assist in restoring functional vision to the visually impaired, convert captured external images into corresponding electrical stimulation patterns that are stimulated by implanted microelectrodes to induce phosphenes and eventually visual perception. Detecting and providing useful visual information to the prosthesis wearer under limited artificial vision has been an important concern in the field of visual prosthesis. Along with the development of prosthetic device design and stimulus encoding methods, researchers have explored the possibility of the application of computer vision by simulating visual perception under prosthetic vision. Effective image processing in computer vision is performed to optimize artificial visual information and improve the ability to restore various important visual functions in implant recipients, allowing them to better achieve their daily demands. This paper first reviews the recent clinical implantation of different types of visual prostheses, summarizes the artificial visual perception of implant recipients, and especially focuses on its irregularities, such as dropout and distorted phosphenes. Then, the important aspects of computer vision in the optimization of visual information processing are reviewed, and the possibilities and shortcomings of these solutions are discussed. Ultimately, the development direction and emphasis issues for improving the performance of visual prosthesis devices are summarized. © 2022 by the authors.","artificial vision; computer vision; dropout and distorted phosphenes; optimization strategy; visual prosthesis","Image enhancement; Microelectrodes; Neural prostheses; Prosthetics; Vision; Artificial visual prosthesis; Dropout and distorted phosphene; Electrical stimulations; Optimisations; Optimization strategy; Stimulation pattern; Visual information; Visual perception; Visual prosthesis; Visually impaired; Computer vision; image processing; physiology; procedures; vision; visual prosthesis; Image Processing, Computer-Assisted; Phosphenes; Vision, Ocular; Visual Perception; Visual Prosthesis"
"Wang J., Zhang W., Wang L., Yang H.","Investigating the Evolution of Tree Boosting Models with Visual Analytics","10.1109/PacificVis52677.2021.00032","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107452875&doi=10.1109%2fPacificVis52677.2021.00032&partnerID=40&md5=16a30987edef15c7c0fa95f69c69d973","Tree boosting models are widely adopted predictive models and have demonstrated superior performance than other conventional and even deep learning models, especially since the recent release of their parallel and distributed implementations, e.g., XGBoost, LightGMB, and CatBoost. Tree boosting uses a group of sequentially generated weak learners (i.e., decision trees), each learns from the mistakes of its predecessor, to push the model's decision boundary towards the true boundary. As the number of trees keeps increasing over training, it is important to reveal how the newly-added trees change the predictions of individual data instances, and how the impacts of different data features evolve. To accomplish these goals, in this paper, we introduce a new design of the temporal confusion matrix, providing users with an effective interface to track data instances' predictions across the tree boosting process. Also, we present an improved visualization to better illustrate and compare the impacts of individual data features (based on their SHAP values) across training iterations. Integrating these components with a tree structure visualization component, we propose a visual analytics system for tree boosting models. Through case studies with domain experts using real-world datasets, we validated the system's effectiveness. © 2021 IEEE.",,"Data visualization; Decision trees; Deep learning; Forestry; Learning systems; Predictive analytics; Visualization; Confusion matrices; Decision boundary; Distributed implementation; Predictive models; Real-world datasets; Tree structures; Visual analytics; Visual analytics systems; Trees (mathematics)"
"Wang K., Yan L.Z., Li W.Z., Jiang C., Wang N.N., Zheng Q., Dong N.G., Shi J.W.","Comparison of Four Machine Learning Techniques for Prediction of Intensive Care Unit Length of Stay in Heart Transplantation Patients","10.3389/fcvm.2022.863642","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138634271&doi=10.3389%2ffcvm.2022.863642&partnerID=40&md5=f4a8747b77f6037a475bb4a65d3d613e","Background: Post-operative heart transplantation patients often require admission to an intensive care unit (ICU). Early prediction of the ICU length of stay (ICU-LOS) of these patients is of great significance and can guide treatment while reducing the mortality rate among patients. However, conventional linear models have tended to perform worse than non-linear models. Materials and Methods: We collected the clinical data of 365 patients from Wuhan Union Hospital who underwent heart transplantation surgery between April 2017 and August 2020. The patients were randomly divided into training data (N = 256) and test data (N = 109) groups. 84 clinical features were collected for each patient. Features were validated using the Least Absolute Shrinkage and Selection Operator (LASSO) regression’s fivefold cross-validation method. We obtained Shapley Additive explanations (SHAP) values by executing package “shap” to interpret model predictions. Four machine learning models and logistic regression algorithms were developed. The area under the receiver operating characteristic curve (AUC-ROC) was used to compare the prediction performance of different models. Finally, for the convenience of clinicians, an online web-server was established and can be freely accessed via the website https://wuhanunion.shinyapps.io/PredictICUStay/. Results: In this study, 365 consecutive patients undergoing heart transplantation surgery for moderate (NYHA grade 3) or severe (NYHA grade 4) heart failure were collected in Wuhan Union Hospital from 2017 to 2020. The median age of the recipient patients was 47.2 years, while the median age of the donors was 35.58 years. 330 (90.4%) of the donor patients were men, and the average surgery duration was 260.06 min. Among this cohort, 47 (12.9%) had renal complications, 25 (6.8%) had hepatic complications, 11 (3%) had undergone chest re-exploration and 19 (5.2%) had undergone extracorporeal membrane oxygenation (ECMO). The following six important clinical features were selected using LASSO regression, and according to the result of SHAP, the rank of importance was (1) the use of extracorporeal membrane oxygenation (ECMO); (2) donor age; (3) the use of an intra-aortic balloon pump (IABP); (4) length of surgery; (5) high creatinine (Cr); and (6) the use of continuous renal replacement therapy (CRRT). The eXtreme Gradient Boosting (XGBoost) algorithm presented significantly better predictive performance (AUC-ROC = 0.88) than other models [Accuracy: 0.87; sensitivity: 0.98; specificity: 0.51; positive predictive value (PPV): 0.86; negative predictive value (NPV): 0.93]. Conclusion: Using the XGBoost classifier with heart transplantation patients can provide an accurate prediction of ICU-LOS, which will not only improve the accuracy of clinical decision-making but also contribute to the allocation and management of medical resources; it is also a real-world example of precision medicine in hospitals. Copyright © 2022 Wang, Yan, Li, Jiang, Wang, Zheng, Dong and Shi.","AUC-ROC; heart transplantation; ICU-LOS; machine learning; SHAP (Shapley Additive explanations); XGboost","alanine aminotransferase; albumin; amino terminal pro brain natriuretic peptide; angiotensin receptor antagonist; aspartate aminotransferase; beta adrenergic receptor blocking agent; bilirubin; cholesterol; creatinine; dipeptidyl carboxypeptidase inhibitor; dopamine; liothyronine; low density lipoprotein; potassium ion; thyroid hormone; thyrotropin; triacylglycerol; troponin I; uric acid; adult; algorithm; area under the curve; Article; Bayesian learning; cardiovascular disease; clinical decision making; comparative study; continuous renal replacement therapy; creatinine blood level; cross clamp time; diabetes mellitus; diagnostic test accuracy study; erythrocyte; extracorporeal oxygenation; female; heart donor; heart failure; heart transplantation; hematocrit; human; hyperlipidemia; hypertension; hyperthyroidism; intensive care unit; international normalized ratio; k fold cross validation; least absolute shrinkage and selection operator; length of stay; leukocyte; linear regression analysis; liver injury; logistic regression analysis; machine learning; major clinical study; male; middle aged; mortality rate; neutrophil lymphocyte ratio; New York Heart Association class; operation duration; prediction; predictive value; random forest; receiver operating characteristic; sensitivity and specificity; septic shock; support vector machine; survival time; thrombin time; urea nitrogen blood level"
"Wang P., Tian H., Zhang Y., Han D., Wang J., Yin M.","Crop Growth Monitoring and Yield Estimation Based on Deep Learning: State of the Art and Beyond [基于深度学习的作物长势监测和产量估测研究进展]","10.6041/j.issn.1000-1298.2022.02.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126137139&doi=10.6041%2fj.issn.1000-1298.2022.02.001&partnerID=40&md5=cd94d721527065c553bccc66ecfbd681","Crop growth conditions are key information sources for estimating and forecasting crop yields, which are of great value to food security and trade. With the continuous appearance of high spatial and temporal resolution remote sensing data, the remote sensing data have presented obvious characteristics of big data. Therefore, crop growth monitoring and yield estimation based on deep learning has become one of the important means to guide agricultural production. The research status of deep learning at the regional scale was investigated, which focused on the development of model samples and model structure. Among them, the model samples were summarized through two aspects of sample construction and sample augmentation. The progress of the deep learning model structure of convolutional neural network (CNN), recurrent neural network (RNN), and their optimized structures and model interpretability were also summarized. Besides, the latest progress of crop growth monitoring and yield estimation at field scale at home and abroad was elaborated from two aspects: unmanned aerial vehicle (UAV) platform and satellite platform. Finally, the existing problems and the future perspective were analyzed and discussed, including improving the limitation of small samples through region-based and parameter-based transfer learning, the organic combination of deep learning model and crop growth model to improve the interpretability of the model, and the combination of UAV platform and satellite platform to ensure the precision of scale conversion in the process of spatio-temporal fusion, which can further explore the potential of deep learning in crop growth monitoring. © 2022, Chinese Society of Agricultural Machinery. All right reserved.","Crops; Deep learning; Growth monitoring; Remote sensing; Yield estimation","Antennas; Convolutional neural networks; Crops; Food supply; Recurrent neural networks; Remote sensing; Crop growth; Deep learning; Growth monitoring; Growth yield; Interpretability; Learning models; Model samples; Remote sensing data; Remote-sensing; Yield estimation; Unmanned aerial vehicles (UAV)"
"Wang P., Tseng H.-W., Chen T.-C., Hsia C.-H.","Deep convolutional neural network for coffee bean inspection","10.18494/SAM.2021.3277","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111109955&doi=10.18494%2fSAM.2021.3277&partnerID=40&md5=f43f13607c7e2b6c4fa5c24bad0f120b","Coffee is one of the most popular drinks in the world. It contains antioxidants and health-promoting nutrients that can boost one's energy and focus. However, defective beans mixed in with raw beans can easily affect the flavor and even be harmful to human health. The traditional human visual inspection of defective beans is extremely laborious and time-consuming and may result in low-quality coffee due to worker stress and fatigue. We propose a lightweight and explainable intelligent coffee bean quality inspection system that uses deep learning (DL) and computer vision (CV) technologies to assist operators in detecting defects, including mold, fermentation, insect bites, and crushed beans. We use knowledge distillation (KD) to achieve model compression. The basic explainable convolutional neural network (CNN) model is established using the explainable AI (XAI) method. The implemented system has a high identification rate, low complexity, and low power consumption, and can explain the judgment criteria of the complex classification model. © MYU K.K.","Convolutional neural network; Knowledge distillation; Lightweight explainable coffee bean quality testing system","Beverages; Complex networks; Convolution; Deep learning; Deep neural networks; Defects; Distillation; Inspection; Classification models; Detecting defects; Human visual inspection; Identification rates; Low qualities; Low-power consumption; Model compression; Quality inspection systems; Convolutional neural networks"
"Wang Q., Liu X., Zhang C.","Evolutionary game analysis of FinTech transformation: A social co-governance pattern of peer-to-peer lending market in China","10.3389/fpsyg.2022.954132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144299330&doi=10.3389%2ffpsyg.2022.954132&partnerID=40&md5=1ba866064f487d343c9ad441147aa488","Benign exit has become the main theme of the transformation in China's peer-to-peer (P2P) lending industry. To protect the interests of investors in the benign exit process, this paper proposes a social co-governance pattern using a tripartite evolutionary game model to capture the behavior strategies of P2P lending platforms, investors, and financial regulators. The results demonstrate that there are four evolutionary stable strategies for the game model, among which the positive disposal of P2P lending platforms, the participation of the investors, and the co-governance policy of financial regulators is the optimal strategy in the benign exit process. The results also show that the initial proportion of P2P lending platforms, investors, and financial regulators would significantly affect the convergence speed of the evolutionary stable strategy. The proposed social co-governance pattern would effectively safeguard the interests of investors if incentive, penalty, and reputation mechanisms are well-designed. This paper provides in-depth implications for protecting investors' interests in the transformation of the P2P lending industry and enhancing the sustainable development of the FinTech industry. Copyright © 2022 Wang, Liu and Zhang.","Financial Technology (FinTech); peer-to-peer lending; social co-governance; transformation; tripartite evolutionary game",
"Wang R., Ma Y., Zhao G., Zhou Y., Shehab I., Burton A.","Investigating water quality sensitivity to climate variability and its influencing factors in four Lake Erie watersheds","10.1016/j.jenvman.2022.116449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139835976&doi=10.1016%2fj.jenvman.2022.116449&partnerID=40&md5=ecf0626e39102e168392754774c02a7e","Climate change alters weather patterns and hydrological cycle, thus potentially aggravating water quality impairment. However, the direct relationships between climate variability and water quality are complicated by a multitude of hydrological and biochemical mechanisms dominate the process. Thus, little is known regarding how water quality responds to climate variability in the context of changing meteorological conditions and human activities. Here, a longitudinal study was conducted using trend, correlation, and redundancy analyses to explore stream water quality sensitivity to temperature, precipitation, streamflow, and how the sensitivity was affected by watershed climate, land cover percentage, landscape configuration, fertilizer application, and tillage types. Specifically, daily pollutant concentration data of suspended solid (SS), total phosphorus (TP), soluble reactive phosphorus (SRP), total Kjeldahl nitrogen (TKN), nitrate and nitrite (NOx), and chloride (Cl) were used as water quality indicators in four Lake Erie watersheds from 1985 to 2017, during which the average temperature has increased 0.5 °C and the total precipitation has increased 9%. Results show that precipitation and flow were positively associated with SRP, NOx, TKN, TP, and SS, except for SRP and NOx in the urban basin. The rising temperatures led to increasing concentrations of SS, TKN, and TP in the urban basin. SRP and NOx sensitivity to precipitation was higher in the years with more precipitation and higher precipitation seasonality, and the basins with more spatially aggregated cropland. No-tillage and reduced tillage management could decrease both precipitation and temperature sensitivity for most pollutants. As one of the first studies leveraging multiple watershed environmental variables with long-term historical climate and water quality data, this study can assist target land use planning and management policy to mitigate future climate change effects on surface water quality. © 2022 Elsevier Ltd","Climate change; Conservation practice; Great lake; Land cover; Soluble reactive phosphorus","chloride; lake water; nitrate; nitrite; nitrogen; phosphorus; nitrogen; phosphorus; climate change; land cover; analytic method; Article; climate change; concentration (parameter); controlled study; correlational study; cropland; fertilizer application; lake; land use; longitudinal study; no tillage; precipitation; redundancy analysis; seasonal variation; sensitivity analysis; stream (river); suspended particulate matter; temperature sensitivity; time series analysis; trend study; United States; water quality; water temperature; watershed management; climate change; environmental monitoring; human; river; Great Lakes [North America]; Lake Erie; Climate Change; Environmental Monitoring; Humans; Lakes; Longitudinal Studies; Nitrogen; Phosphorus; Rivers; Water Quality"
"Wang R., Liu Y., Müller R.","Detection of passageways in natural foliage using biomimetic sonar","10.1088/1748-3190/ac7aff","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136037545&doi=10.1088%2f1748-3190%2fac7aff&partnerID=40&md5=f1463d405b169175c61d0ef5873d6a7c","The ability of certain bat species to navigate in dense vegetation based on trains of short biosonar echoes could provide for an alternative parsimonious approach to obtaining the sensory information that is needed to achieve autonomy in complex natural environments. Although bat biosonar has much lower data rates and spatial (angular) resolution than commonly used human-made sensing systems such as LiDAR or stereo cameras, bat species that live in dense habitats have the ability to reliably detect narrow passageways in foliage. To study the sensory information that the animals may have available to accomplish this, we have used a biomimetic sonar system that was combined with a camera to record echoes and synchronized images from 10 different field sites that featured narrow passageways in foliage. The synchronized camera and sonar data allowed us to create a large data set (130 000 samples) of labeled echoes using a teacher-student approach that used class labels derived from the images to provide training data for echo-based classifiers. The performance achieved in detecting passageways based on the field data closely matched previous results obtained for gaps in an artificial foliage setup in the laboratory. With a deep feature extraction neural network (VGG16) a foliage-versus-passageway classification accuracy of 96.64% was obtained. A transparent artificial intelligence approach (class-activation mapping) indicated that the classifier network relied heavily on the initial rising flank of the echoes. This finding could be exploited with a neuromorphic echo representation that consisted of times where the echo envelope crossed a certain amplitude threshold in a given frequency channel. Whereas a single amplitude threshold was sufficient for this in the previous laboratory study, multiple thresholds were needed to achieve an accuracy of 92.23%. These findings indicate that despite many sources of variability that shape clutter echoes from natural environments, these signals contain sufficient sensory information to enable the detection of passageways in foliage. © 2022 IOP Publishing Ltd.","biosonar; deep learning; field robotics; passageway detection in foliage; transfer learning; transparent AI","Air navigation; Biomimetics; Cameras; Classification (of information); Deep learning; Personnel training; Sonar; Amplitude threshold; Biosonar; Deep learning; Dense vegetation; Field robotics; Natural environments; Passageway detection in foliage; Sensory information; Transfer learning; Transparent AI; Stereo image processing; animal; artificial intelligence; bat; biomimetics; echolocation; human; physiology; sound; Animals; Artificial Intelligence; Biomimetics; Chiroptera; Echolocation; Humans; Sound"
"Wang R., Kim J.-H., Li M.-H.","Predicting stream water quality under different urban development pattern scenarios with an interpretable machine learning approach","10.1016/j.scitotenv.2020.144057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098157653&doi=10.1016%2fj.scitotenv.2020.144057&partnerID=40&md5=7ac3871aa3ab2e31e01a7502c802643b","Urban development pattern significantly impacts stream water quality by influencing pollutant generation, build-up, and wash-off processes. It is thus necessary to understand and predict stream water quality in accordance with different urban development patterns to effectively advise urban growth planning and policies. To do so, we collected pollutant concentration data on nitrate (NO3−-N), total phosphate (TP), and Escherichia coli (E. coli) from 1047 sampling stations in the Texas Gulf Region. We utilized a Random Forest (RF) machine learning model to predict stream water quality under four planning scenarios with different urban densities and configurations. SHapley Additive exPlanations (SHAP) was used to prove the importance of urban development pattern in influencing stream water quality. The spatial variations of the impact of these patterns were explored with Geographically Weighted Regression (GWR). SHAP results indicated that Largest Patch Index (LPI), Patch Cohesion Index (COHESION), Splitting Index (SPLIT), and Landscape Division Index (DIVISION) were the most important urban development pattern metrics affecting stream water quality. The spatial variations of such patterns were shown to impact stream water quality depending on pollutants, seasonality, climate, and urbanization level. RF prediction results suggested that high density aggregated development was more effective in reducing TP and NO3−-N concentrations than the current sprawl development, but had the potential risk of increasing E. coli pollution in the wet season. The results of this study provide empirical evidence and a potential mechanistic explanation that stream water quality degradation is a consequence of urban sprawl. Lastly, machine learning is a powerful tool for scenario prediction in land use planning to forecast environmental impacts under different urban development pattern scenarios. © 2020 Elsevier B.V.","Landscape metrics; Machine learning; Scenario planning; Urban form; Urban sprawl; Water quality","Decision trees; Escherichia coli; Forecasting; Land use; Machine learning; River pollution; Rivers; Water quality; Water treatment; Escherichia coli (E. coli); Geographically weighted regression; Largest patch indices; Machine learning approaches; Machine learning models; Pollutant concentration; Scenario predictions; Stream water quality; Urban growth; nitrate; phosphate; land use planning; machine learning; pollutant; streamwater; urban development; urban planning; urban policy; urban sprawl; urbanization; water quality; Article; bioremediation; climate; concentration (parameter); environmental impact; environmental parameters; environmental planning; Escherichia coli; forecasting; geographically weighted regression; landscape; Landscape Division Index; Largest Patch Index; machine learning; Patch Cohesion Index; prediction; priority journal; rainy season; random forest; seasonal variation; Splitting Index; statistical model; stream (river); urban area; urbanization; water pollutant; water pollution; water quality; water sampling; Escherichia coli"
"Wang S., Cai W., Tao Y., Sun Q.C., Wong P.P.Y., Huang X., Liu Y.","Unpacking the inter- and intra-urban differences of the association between health and exposure to heat and air quality in Australia using global and local machine learning models","10.1016/j.scitotenv.2023.162005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147855138&doi=10.1016%2fj.scitotenv.2023.162005&partnerID=40&md5=425ffe45461f0bf0985851966352702a","Environmental stressors including high temperature and air pollution cause health problems. However, understanding how the combined exposure to heat and air pollution affects both physical and mental health remains insufficient due to the complexity of such effects mingling with human society, urban and natural environments. Our study roots in the Social Ecological Theory and employs a tri-environmental conceptual framework (i.e., across social, built and natural environment) to examine how the combined exposure to heat and air pollution affect self-reported physical and mental health via, for the first time, the fine-grained nationwide investigation in Australia and highlight how such effects vary across inter- and intra-urban areas. We conducted an ecological study to explore the importance of heat and air quality to physical and mental health by considering 48 tri-environmental confounders through the global and local random forest regression models, as advanced machine learning methods with the advantage of revealing the spatial heterogeneity of variables. Our key findings are threefold. First, the social and built environmental factors are important to physical and mental health in both urban and rural areas, and even more important than exposure to heat and air pollution. Second, the relationship between temperature and air quality and health follows a V-shape, reflecting people's different adaptation and tolerance to temperature and air quality. Third, the important roles that heat and air pollution play in physical and mental health are most obvious in the inner-city and near inner-city areas of the major capital cities, as well as in the industrial zones in peri-urban regions and in Darwin city with a low-latitude. We draw several policy implications to minimise the inter- and intra-urban differences in healthcare access and service distribution to populations with different sensitivity to heat and air quality across urban and rural areas. Our conceptual framework can also be applied to examine the relationship between other environmental problems and health outcomes in the era of a warming climate. © 2023","Air quality; Built environment; Geographically weighted random forest; Heat; Mental health; Self-reported physical health; Social environment","Forestry; Machine learning; Public policy; Regression analysis; Rural areas; Australia; Built environment; Geographically weighted random forest; Heat; Mental health; Natural environments; Physical health; Random forests; Self-reported physical health; Social environment; Air quality; air pollution; air quality; article; Australia; built environment; city; conceptual framework; confounding variable; environmental factor; health; health care access; heat; human; human experiment; latitude; machine learning; mental health; random forest; regression model; rural area; social environment; theoretical study; urban area; warming"
"Wang S., Cai W., Tao Y., Sun Q.C., Wong P.P.Y., Thongking W., Huang X.","Nexus of heat-vulnerable chronic diseases and heatwave mediated through tri-environmental interactions: A nationwide fine-grained study in Australia","10.1016/j.jenvman.2022.116663","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141272761&doi=10.1016%2fj.jenvman.2022.116663&partnerID=40&md5=57cbfd69fa045643ed08d67df63e6cd0","The warming trend over recent decades has already contributed to the increased prevalence of heat-vulnerable chronic diseases in many regions of the world. However, understanding the relationship between heat-vulnerable chronic diseases and heatwaves remains incomplete due to the complexity of such a relationship mingling with human society, urban and natural environments. Our study extends the Social Ecological Theory by constructing a tri-environmental conceptual framework (i.e., across social, built, and natural environments) and contributes to the first nationwide study of the relationship between heat-vulnerable chronic diseases and heatwaves in Australia. We utilize the random forest regression model to explore the importance of heatwaves and 48 tri-environmental variables that contribute to the prevalence of six types of heat-vulnerable diseases. We further apply the local interpretable model-agnostic explanations and the accumulated local effects analysis to interpret how the heat-disease nexus is mediated through tri-environments and varied across urban and rural space. The overall effect of heatwaves on diseases varies across disease types and geographical contexts (latitudes; inland versus coast). The local heat-disease nexus follows a J-shape function—becoming sharply positive after a certain threshold of heatwaves—reflecting that people with the onset of different diseases have various sensitivity and tolerance to heatwaves. However, such effects are relatively marginal compared to tri-environmental variables. We propose a number of policy implications on reducing urban-rural disparity in healthcare access and service distribution, delineating areas, and identifying the variations of sensitivity to heatwaves across urban/rural space and disease types. Our conceptual framework can be further applied to examine the relationship between other environmental problems and health outcomes. © 2022 The Authors","Australia; Built environment; Heat-vulnerable diseases; Heatwaves; Natural environment; Social environment","conceptual framework; health care; heat wave; regression analysis; vulnerability; warming; Article; Australia; built environment; chronic disease; conceptual framework; environmental policy; heat wave; human; random forest; regression model; rural area; social environment; urban area; chronic disease; epidemiology; heat; rural population; Australia; Australia; Chronic Disease; Hot Temperature; Humans; Rural Population"
"Wang S., Wang Y., Wang Y., Wang Z.","Assessment of influencing factors on non-point source pollution critical source areas in an agricultural watershed","10.1016/j.ecolind.2022.109084","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132759861&doi=10.1016%2fj.ecolind.2022.109084&partnerID=40&md5=596a3345c83f47cb839e0ff1b6a0979a","Critical Source Areas (CSAs) are areas that contribute disproportionate high levels of non-point source (NPS) pollution to receiving waters, and their occurrence is the result of the complex interaction between the factors related to the sources and transport processes of NPS pollution. A systematic understanding of how these influencing factors affect CSAs is essential for successful watershed management. In this study, we applied a statistical data mining technique boosted regression tree model to quantify the contribution of eight influencing factors (soil type, slope, elevation, RUSLE LS factor, RUSLE K factor, runoff, fertilizer application rate and land use) on two types of CSAs (TN-CSAs and TP-CSAs), as well as the marginal effects and potential thresholds of influencing factors on the occurrence of CSAs. Results show that land use (37.35%, 25.03%), fertilizer application (36.93%, 57.83%) and soil type (17.59%, 13.70%) have higher importance in determining the occurrence of TN-CSAs and TP-CSAs; and the incidence of ﻿TN-CSAs is positively correlated with most factors before the threshold for each influencing factor, after which the marginal effect largely leveled off or dropped slightly; TP-CSAs have essentially the same characteristics as TN-CSAs, but TP-CSAs are more likely to occur in areas with an annual runoff of around 244.92 mm. In addition, this study discussed the application of machine learning techniques in predicting CSAs under climate change without physical-based models, as well as a preliminary watershed management planning for NPS pollution control in the study watershed. These results provided important information for nutrient management regulations. © 2022 The Author(s)","AnnAGNPS model; Boosted regression tree; Critical source areas; Non-point source pollution; Watershed planning","Climate change; Climate models; Data mining; Fertilizers; Forestry; Learning systems; Pollution control; Runoff; Soil conservation; Trees (mathematics); Water conservation; Water management; Water pollution; Watersheds; Agricultural watersheds; AnnAGNPS models; Boosted regression trees; Critical source areas; Fertilizer applications; Marginal effects; Nonpoint-source pollution (NPS); Soil types; Watershed planning; Watersheds management; Land use; agricultural catchment; assessment method; climate change; data mining; factor analysis; fertilizer application; land use change; machine learning; nonpoint source pollution; numerical model; regression analysis; watershed"
"Wang S., Peng H., Hu Q., Jiang M.","Analysis of runoff generation driving factors based on hydrological model and interpretable machine learning method","10.1016/j.ejrh.2022.101139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132431898&doi=10.1016%2fj.ejrh.2022.101139&partnerID=40&md5=65abf18fe5e6c0023143a3a89b3ad7cc","Study Region: Xiaoqing River Basin, Shandong Province, China Study Focus: Identifying the driving factors of temporal and spatial variation in runoff is key to water resource management. The traditional machine learning model lacks transparency and interpretability, which affects the wide application of machine learning in the identification of influencing factors of hydrology. Interpretable machine learning method can improve the interpretability of machine learning model. The extreme gradient boosting (XGBoost) is established based on the data generated by the calibrated Soil Water Assessment Tool (SWAT), and the XGBoost is interpreted using the Shapely additive explanations (SHAP) method to identify the impact of driving factors on runoff generation. New hydrological insights for the region: The results show that XGBoost can simulate the simulation ability of SWAT, and SHAP can identify the factors affecting runoff generation by interpreting XGBoost. It was found that climatic features have different effects on runoff in different sub-basins, and rainfall at high elevations (or slope) has stronger effects on runoff than that at low elevations. There is an obvious threshold effect of land use combination (or slope) on the generation of runoff, and this threshold effect is driven by high precipitation. The results of this study can provide a new method for factor analysis of runoff. © 2022 The Authors","Runoff; Shapely additive explanations; SWAT; XGBoost; Xiaoqing River Basin",
"Wang S., Xiong W., Wang Y., Nie Y., Wu Q., Xu Y., Geisen S.","Temperature-induced annual variation in microbial community changes and resulting metabolome shifts in a controlled fermentation system","10.1128/mSystems.00555-20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090464369&doi=10.1128%2fmSystems.00555-20&partnerID=40&md5=db0a4648211ba9b63ffb8c1c371f2494","We are rapidly increasing our understanding on the spatial distribution of microbial communities. However, microbial functioning, as well as temporal differences and mechanisms causing microbial community shifts, remains comparably little explored. Here, using Chinese liquor fermentation as a model system containing a low microbial diversity, we studied temporal changes in microbial community structure and functioning. For that, we used high-throughput sequencing to analyze the composition of bacteria and fungi and analyzed the microbially derived metabolome throughout the fermentation process in all four seasons in both 2018 and 2019. We show that microbial communities and the metabolome changed throughout the fermentation process in each of the four seasons, with metabolome diversity increasing throughout the fermentation process. Across seasons, bacterial and fungal communities as well as the metabolome driven by 10 indicator microorganisms and six metabolites varied even more. Daily average temperature in the external surroundings was the primary determinant of the observed temporal microbial community and metabolome changes. Collectively, our work reveals critical insights into patterns and processes determining temporal changes of microbial community composition and functioning. We highlight the importance of linking taxonomic to functional changes in microbial ecology to enable predictions of human-relevant applications. IMPORTANCE We used Chinese liquor fermentation as a model system to show that microbiome composition changes more dramatically across seasons than throughout the fermentation process within seasons. These changes translate to differences in the metabolome as the ultimate functional outcome of microbial activity, suggesting that temporal changes in microbiome composition are translating into functional changes. This result is striking as it suggests that microbial functioning, despite controlled conditions in the fermentors, fluctuates over season along with external temperature differences, which threatens a reproducible food taste. As such, we believe that our study provides a stepping-stone into novel taxonomy-functional studies that promote future work in other systems and that also is relevant in applied settings to better control surrounding conditions in food production. Copyright © 2020 Wang et al. This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International license.","Fermentation system; Microbiome; Seasonal factors; Temperature-induced","2 butanol; 2 octanol; 2,3 butanediol; ethyl hexanoate; hexanol; isovaleric acid; microbial products not classified elsewhere; unclassified drug; alcoholic beverage; Article; autumn; bacterial metabolism; biogeography; chinese liquor; community dynamics; community structure; fermentation model; fungal community; fungal metabolism; high throughput sequencing; metabolite; metabolome; microbial community; microbial diversity; microbial population dynamics; nonhuman; seasonal variation; spatial analysis; species composition; spring; summer; temperature; winter"
"Wang X., Yin M.","Are Explanations Helpful? A Comparative Study of the Effects of Explanations in AI-Assisted Decision-Making","10.1145/3397481.3450650","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104503567&doi=10.1145%2f3397481.3450650&partnerID=40&md5=540530411079bab7baf95420e80402fb","This paper contributes to the growing literature in empirical evaluation of explainable AI (XAI) methods by presenting a comparison on the effects of a set of established XAI methods in AI-assisted decision making. Specifically, based on our review of previous literature, we highlight three desirable properties that ideal AI explanations should satisfy-improve people's understanding of the AI model, help people recognize the model uncertainty, and support people's calibrated trust in the model. Through randomized controlled experiments, we evaluate whether four types of common model-agnostic explainable AI methods satisfy these properties on two types of decision making tasks where people perceive themselves as having different levels of domain expertise in (i.e., recidivism prediction and forest cover prediction). Our results show that the effects of AI explanations are largely different on decision making tasks where people have varying levels of domain expertise in, and many AI explanations do not satisfy any of the desirable properties for tasks that people have little domain expertise in. Further, for decision making tasks that people are more knowledgeable, feature contribution explanation is shown to satisfy more desiderata of AI explanations, while the explanation that is considered to resemble how human explain decisions (i.e., counterfactual explanation) does not seem to improve calibrated trust. We conclude by discussing the implications of our study for improving the design of XAI methods to better support human decision making. © 2021 Owner/Author.","explainable AI; human-subject experiments; interpretable machine learning; trust; trust calibration","Behavioral research; Decision making; Uncertainty analysis; User interfaces; Common models; Comparative studies; Controlled experiment; Domain expertise; Empirical evaluations; Forest cover; Human decision making; Model uncertainties; Artificial intelligence"
"Wang X., Zhi J.","A machine learning-based analytical framework for employee turnover prediction","10.1080/23270012.2021.1961318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113530632&doi=10.1080%2f23270012.2021.1961318&partnerID=40&md5=489741bead1447483bc1e7f6b48d72dd","Employee turnover (ET) can cause severe consequences to a company, which are hard to be replaced or rebuilt. It is thus crucial to develop an intelligent system that can accurately predict the likelihood of ET, allowing the human resource management team to take pro-active action for retention or plan for succession. However, building such a system faces challenges due to the variety of influential human factors, the lack of training data, and the large pool of candidate models to choose from. Solutions offered by existing studies only adopt essential learning strategies. To fill this methodological gap, we propose a machine learning-based analytical framework that adopts a streamlined approach to feature engineering, model training and validation, and ensemble learning towards building an accurate and robust predictive model. The proposed framework is evaluated on two representative datasets with different sizes and feature settings. Results demonstrate the superior performance of the final model produced by our framework. © 2021 Antai College of Economics and Management, Shanghai Jiao Tong University.","Employee turnover; ensemble learning; feature encoding; feature engineering; feature interaction; feature selection; machine learning; model selection","Human resource management; Intelligent systems; Machine learning; Personnel training; Turing machines; Candidate models; Different sizes; Employee turnover; Ensemble learning; Feature engineerings; Learning strategy; Model training; Predictive modeling; Predictive analytics"
"Wang Y., Li B., Yang G.","Stream water quality optimized prediction based on human activity intensity and landscape metrics with regional heterogeneity in Taihu Basin, China","10.1007/s11356-022-22536-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136227503&doi=10.1007%2fs11356-022-22536-5&partnerID=40&md5=e26a64a23726e8ca4dfc88af1fb0f323","The driving effects of landscape metrics on water quality have been acknowledged widely, however, the guiding significance of human activity intensity and landscape metrics based on reference conditions for water environment management remains to be explored. Thus, we used the self-organized map, long- and short-term memory (LSTM) algorithm, and geographic detectors to simulate the response of human activity intensity and landscape metrics to water quality in Taihu Lake Basin, China. Fitting results of LSTM displayed that the accuracy was acceptable, and scenario 2 (regional heterogeneity) was more efficient than scenario 1 (regional consistent) in the improvement of water quality. In the driving analysis for the reference conditions, clusters I and II (urban agglomeration areas) were mainly affected by the amount of production wastewater per unit of developed land and the amount of livelihood wastewater per unit of developed land, respectively. Their optimal values were 0.09 × 103 t/km2 (reduction of 35.71%) and 0.2 × 103 t/km2 (reduction of 4.76%). Cluster III (agricultural production areas) was mainly affected by interference intensity, and the optimal value was 2.17 (increased 38.22%), and cluster IV (ecological forest areas) was mainly affected by the fragmentation of cropland, and the optimal value was 1.14 (reduction of 1.72%). The research provides a reference for the prediction of water quality response and presents an ecological and economic sustainability way for watershed governance. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Landscape; Long and short-term memory (LSTM); Reference conditions; Sample; Stream water quality; Taihu Basin","agglomeration; heterogeneity; human activity; landscape change; optimization; prediction; reference sample; streamwater; water quality; China; Taihu Basin; benchmarking; China; environmental monitoring; human; human activities; procedures; river; wastewater; water quality; Benchmarking; China; Environmental Monitoring; Human Activities; Humans; Rivers; Wastewater; Water Quality"
"Wang Y., Wang H., Wu Y., Xiang H., Zhao Y., Chen S., Qi B., Li L.","Insights into lipid oxidation and free fatty acid profiles to the development of volatile organic compounds in traditional fermented golden pomfret based on multivariate analysis","10.1016/j.lwt.2022.114112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141319147&doi=10.1016%2fj.lwt.2022.114112&partnerID=40&md5=f3f64e24f564a2ca39cbab9f3e92ae5e","Golden pomfret is rich in polyunsaturated fatty acids (PUFAs), which are susceptible to oxidative hydrolysis during fermentation. Therefore, the objective of this study was to examine the roles of lipid oxidation and lipid oxidation-derived fatty acids (FAs) to the formation of specific volatile organic compounds in fermented golden pomfret. The results showed there was more drastic in lipid oxidation during the pre-fermentation period. There was a persistent increase in superoxide, hydroxyl, singlet oxygen, and alkoxy radical levels. Besides, FA levels increased, and unsaturated fatty acids (UFAs) levels were the highest at all time points. A total of 95 potential volatile compounds were identified and their contents increased during fermentation. Eleven volatile compounds, including hexanal, octanal, 1-octen-3-ol, and 3-methyl-1-butanol, were identified as characteristic volatile compounds in fermented fish. Most of the characteristic volatile compounds comprised lipid oxidation-derived aldehydes and alcohols. Furthermore, the levels of important FAs, such as oleic acid (C18:1, n9c), linoleic acid (C18:2, n6c), and palmitic acid (C16:0), were correlated with the levels of propanal, hexanal, and 1-octen-3-ol. Overall, these results indicated FAs are important precursors of characteristic volatile compounds in fermented golden pomfret and can be manipulated to enhance the flavor of fermented fish. © 2022","Fermented golden pomfret; Free fatty acid; Free radical; Lipid oxidation; Volatile compound","Fermentation; Fish; Free radicals; Gas chromatography; Linoleic acid; Multivariant analysis; Oxidation; Palmitic acid; Polyunsaturated fatty acids; Saturated fatty acids; Volatile fatty acids; 1-octen-3-ol; Fatty acids profiles; Fermentation periods; Fermented fishes; Fermented golden pomfret; Free fatty acid; Hexanal; Lipid oxidation; Multi variate analysis; Volatile compounds; Volatile organic compounds"
"Wang Y., Yang G., Li B., Wang C., Su W.","Measuring the zonal responses of nitrogen output to landscape pattern in a flatland with river network: a case study in Taihu Lake Basin, China","10.1007/s11356-021-15842-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123102427&doi=10.1007%2fs11356-021-15842-x&partnerID=40&md5=010366f0de422dcdfb74b46d494bdc20","Landscape pattern changes induced by rapid urbanization and intensified agricultural activities have exerted great pressure on regional water purification services. Relationship between landscape metrics and nitrogen-related ecosystem services has been a major concern of many scholars and has been widely used for guidance for land use and cover (LULC) management. However, clear zonal differences may exist, especially in highly developed reticular river network area, thus limiting our understanding of nitrogen output (NOP) to landscape pattern in the details. The spatial distribution of regional NOP was obtained based on the InVEST model. The zonal responses of NOP to landscape patter were examined under hydraulic subregions and subbasin scale. The results show that the unit value of average NOP in the Taihu Lake Basin (TLB) was 146.14 (kg/km2), and the total output reached 23677.92 t in 2020. The simulation NOP showed reasonable agreement with verified water quality observations in the lake inlet stations, with an R2 of 0.76. In terms of space composition, merely cropland have significant effects on NOP in the whole basin scale, while the explanatory variables include cropland and developed land in Pudong (PD), Puxi (PX), Wuchengxiyu (WC), and Hangjiahu (HJ) regions. In Huxi (HX) and Yangchengdianmao (YC) regions, cropland and forest are the significant impact types, while in (Zhexi) ZX region, cropland, developed land, and forest are significant impact types. In the space configuration, the percentage of landscape (PLAND) or largest patch index (LPI) of cropland showed positive effects about NOP, whether in the whole basin or the hydraulic subregions. Edge density (ED) (−3.48), number of patches (NP) (−3.91), and percentage of like adjacencies (PLAND) (−2.80) of the forest exhibit negative correlations with NOP, in the HX, ZX, and YC region, respectively. It displays diversiform in the response of NOP to the landscape metric of developed land, which speculate that the heterogeneity of developed land can also have a constraint on NOP, in the highly urbanized areas with less forest area. In addition, the total nitrogen output of the TLB needs to be controlled, especially in HJ region which was identified as the sensitive area of pollution sources with the largest NOP and should be paid more attention to. Compared with the administrative management unit, it is more reasonable to control and manage the pollution sources by referring to the hydraulic subregions and subbasin units. Senior managers are required to strengthen communication and cooperation with hydraulic subregions across administrative regions. However, when managing NOP through the landscape modifications, measures should be taken to reduce the aggregation of nitrogen sources and increase the fragmentation of nitrogen sinks. As for high aggregation developed and agricultural land regions, the types of land used should be enriched to help the sustainable development. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","InVEST model; Landscape pattern metrics; Nitrogen output; Stepwise multiple regression analysis; Taihu Lake Basin","model; multiple regression; river basin; spatiotemporal analysis; Taihu Basin; urbanization; China; China; Taihu Basin; nitrogen; China; ecosystem; environmental monitoring; lake; procedures; river; China; Ecosystem; Environmental Monitoring; Lakes; Nitrogen; Rivers"
"Wang Y., Wu Y., Li C., Zhao Y., Xiang H., Li L., Yang X., Chen S., Sun L., Qi B.","Genome-Resolved Metaproteomic Analysis of Microbiota and Metabolic Pathways Involved in Taste Formation During Chinese Traditional Fish Sauce (Yu-lu) Fermentation","10.3389/fnut.2022.851895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127750210&doi=10.3389%2ffnut.2022.851895&partnerID=40&md5=7af8a48c8d6f05733af3ccda388897d1","Complex microbial metabolism is key to taste formation in high-quality fish sauce during fermentation. To guide quality supervision and targeted regulation, we analyzed the function of microbial flora during fermentation based on a previously developed metagenomic database. The abundance of most identified genes involved in metabolic functions showed an upward trend in abundance during fermentation. In total, 571 proteins extracted from fish sauce at different fermentation stages were identified. These proteins were mainly derived from Halanaerobium, Psychrobacter, Photobacterium, and Tetragenococcus. Functional annotation revealed 15 pathways related to amino acid metabolism, including alanine, aspartate, glutamate, and histidine metabolism; lysine degradation; and arginine biosynthesis. This study demonstrated the approaches to identify microbiota functions and metabolic pathways, thereby providing a theoretical basis for taste formation mechanisms during traditional fish sauce fermentation. Copyright © 2022 Wang, Wu, Li, Zhao, Xiang, Li, Yang, Chen, Sun and Qi.","fermentation; fish sauce; metaproteomics; microbial enzymes; taste formation",
"Wang Y., Nie S., Li C., Xiang H., Zhao Y., Chen S., Li L., Wu Y.","Application of Untargeted Metabolomics to Reveal the Taste-Related Metabolite Profiles during Mandarin Fish (Siniperca chuatsi) Fermentation","10.3390/foods11070944","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128222408&doi=10.3390%2ffoods11070944&partnerID=40&md5=8523710406a8110cb8db1be059cfdeee","Spontaneous fermentation is a critical processing step that determines the taste quality of fermented mandarin fish (Siniperca chuatsi). Here, untargeted metabolomics using ultra-highperformance liquid chromatography coupled with Q Exactive tandem mass spectrometry was employed to characterize the taste-related metabolite profiles during the fermentation of mandarin fish. The results demonstrated that the taste profiles of mandarin fish at different stages of fermentation could be distinguished using an electronic tongue technique. Sixty-two metabolites, including amino acids, small peptides, fatty acids, alkaloids, and organic acids, were identified in fermented mandarin fish samples. Additional quantitative analysis of amino acids revealed glutamic acid and aspartic acid as significant contributors to the fresh flavor. Furthermore, the Kyoto Encyclopedia of Genes and Genomes pathway enrichment analysis revealed that amino acid metabolism was the dominant pathway throughout the fermentation process. This study provides a scientific and theoretical reference for the targeted regulation of the quality of fermented mandarin fish. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","fermentation; mandarin fish fermentation; metabolomic profile; quality control; Siniperca chuatsi; water-soluble metabolite",
"Wang Y., Yang G., Li B.","Exploring the pivotal response relationship between landscape composition–configuration–intensity metrics and water quality in Taihu basin, China","10.1016/j.ecolind.2022.108638","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124007936&doi=10.1016%2fj.ecolind.2022.108638&partnerID=40&md5=6bc18ce1612d64c7eee9e959f636532b","Declining water quality has exacerbated water scarcity worldwide, and effective water quality management requires a solid understanding of the factors of water quality. The response of water quality to landscape composition and configuration has been extensively studied, but landscape intensity has been disregarded. Therefore, constructing a comprehensive impact factor indicator and determining the pivotal factors are essential. This study focused on the response relationship of landscape composition, configuration, and intensity metrics to water quality. Water quality index included total nitrogen (TN) and total phosphorus (TP) from 43 monthly sites in the main rivers of the Taihu Lake Basin (TLB) in 2017. The TN:TP index was calculated. We used the partial least squares regression (PLS) method to explore the response strength between each index at different temporal and spatial scales, and the coefficient of determination (R2) calculated based on PLS was 0.4677 to 0.9039, in which the simulation effect was acceptable. In terms of pivotal influenced factors, industrial and domestic effluents for TN and TP showed a major effect in crop (CDR) and forest dominated region (FDR). For the TN:TP index, the pivotal influencing factors was merely industrial waste water discharge. In the fitting based on the pivotal factors of polynomial regression (PR), the landscape threshold of industrial and domestic effluents intensities to TN in CDR were higher than FDR, and landscape threshold substantially exceeded the water quality standard lines in CDR. This research can provide a reference for water quality precision management, distribution of pollutant emissions, and regional sustainable planning from the perspective of landscape regulation in TLB. © 2022","Landscape intensity; Landscape pattern; Landscape threshold; Water quality","Clock and data recovery circuits (CDR circuits); Effluents; Least squares approximations; Quality management; Water conservation; Water management; Water pollution; Landscape composition; Landscape intensity; Landscape pattern; Landscape thresholds; Nitrogen phosphorus; Partial least square regression; Phosphorus indices; Taihu Lake basin; Total nitrogen; Total phosphorus; Water quality; industrial waste; landscape; pollutant; precision; water quality; China; Taihu; Taihu Basin; Taihu Lake"
"Wang Y., Chandrasekaran J., Haberkorn F., Dong Y., Gopinath M., Batarseh F.A.","DeepFarm: AI-Driven Management of Farm Production using Explainable Causality","10.1109/STC55697.2022.00013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143434951&doi=10.1109%2fSTC55697.2022.00013&partnerID=40&md5=69032a77ab65df69633e3116fdd26e52","American agriculture has been afflicted by numerous outlier events in the past decade, such as several natural disasters, cyber-attacks, trade wars, and a global pandemic. Such unprecedented black-swans have created outcome uncertainties throughout the food supply chain, starting at the farm level for agricultural producers and aggregating at the consumption level for households and international trade flows. The primary drivers behind the shocks in agricultural productivity include strong weather-related events, transitory transportation disruptions, shipping delays, and policy shifts. This paper presents DeepFarm, an Artificial Intelligence (AI)-enabled framework to measure and manage uncertainties while evaluating multiple cause-effect scenarios in agricultural farm production. We deploy Deep Learning (DL) models to predict the impact of crop yield during outlier events such as extreme weather events and cyber-attacks. Additionally, we use a causal inference-based approach to quantity the impact of such events affecting the critical phases of farm production. Models are developed; experiments are performed; the results are recorded, evaluated, and discussed. Our results suggest that DeepFarm can effectively forecast and quantity the impact of outlier events on crop yield across different regions in the US. © 2022 IEEE.","AI for Agriculture; Causality; DeepAR; Farm Production; GAN; Synthetic Data","Computer crime; Crime; Crops; Deep learning; Disasters; Food supply; Network security; Productivity; Statistics; Supply chains; Artificial intelligence for agriculture; Causality; Crop yield; Cyber-attacks; Deepar; Farm production; GAN; Natural disasters; Synthetic data; Uncertainty; International trade"
"Wang Y., Wu Y., Shen Y., Li C., Zhao Y., Qi B., Li L., Chen Y.","Metabolic Footprint Analysis of Volatile Organic Compounds by Gas Chromatography-Ion Mobility Spectrometry to Discriminate Mandarin Fish (Siniperca chuatsi) at Different Fermentation Stages","10.3389/fbioe.2021.805364","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123047657&doi=10.3389%2ffbioe.2021.805364&partnerID=40&md5=25abb6eaedb0835f4cb2ff9326e26f5c","Chinese fermented mandarin fish (Siniperca chuatsi) have unique aroma characteristics that are appreciated by local consumers. In this study, electronic nose (E-nose) and gas chromatography–ion mobility spectrometry analyses were combined to establish a volatile fingerprint of fermented mandarin fish during fermentation. Clear separation of the data allowed mandarin fish samples at different fermentation stages to be distinguishing using E-nose analysis. Forty-three volatile organic compounds were identified during fermentation. Additionally, partial least squares discrimination analysis was performed to screen for different VOC metabolites in the fermented mandarin fish; the levels of six VOCs changed significantly during fermentation (variable importance in projection >1; p < 0.05). Three VOCs, i.e., hexanal-D, nonanal, and limonene were identified as potential biomarkers for fermentation. This study provided a theoretical basis for flavor real-time monitoring and quality control of traditional mandarin fish fermentation. Copyright © 2021 Wang, Wu, Shen, Li, Zhao, Qi, Li and Chen.","electronic nose; fermented Mandarin fish; gas chromatography-mass spectrometry; metabolic footprint; quality control; volatile organic compound","Electronic nose; Fermentation; Fish; Ion mobility spectrometers; Least squares approximations; Mass spectrometry; Metabolism; Metabolites; Principal component analysis; Quality control; Volatile organic compounds; Fermentation variables; Fermented mandarin fish; Fish samples; Footprint analysis; Gaschromatography-mass spectrometry; Ion mobility spectrometry; Metabolic footprint; Partial least squares discrimination analysis; Quality control; VOC metabolites; Gas chromatography"
"Wang Y., Wang M., Huang B., Li S., Lin Y.","Evaluation and analysis of poverty-stricken counties under the framework of the un sustainable development goals: A case study of hunan province, china","10.3390/rs13234778","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120304355&doi=10.3390%2frs13234778&partnerID=40&md5=2c03b30c3b28bcc044f1339cddfaab16","Eliminating all forms of poverty in the world is the first United Nations Sustainable Development Goal (SDG). Developing a scientific and feasible method for monitoring and evaluating local poverty is important for the implementation of the SDG agenda. Based on the 2030 United Nations SDGs, in this paper, a quantitative evaluation model is built and applied to all poverty-stricken counties in Hunan Province. First, based on the SDG global index framework and local index system of China, a local SDG index system for poverty-related goals is designed, and the weights of the indexes are derived using an entropy method. The scores obtained for counties and districts with data available are then taken as the true value for the poverty assessment. Second, using National Polar-orbiting Visible Infrared Imaging Radiometer Suite (NPP-VIIRS) nighttime light images and land use and digital elevation model data, six factors, including socioeconomic, land cover, terrain and traffic factors, are extracted. Third, we then construct multiple linear evaluation models of poverty targets defined by the SDGs and machine learning evaluation models, including regression trees, support vector machines, Gaussian process regressions and ensemble trees. Last, combined with statistical data of poverty-stricken counties in Hunan Province, model validation and accuracy evaluation are carried out. The results show that the R2 and relative error of the localized, multiple linear evaluation model, including all six factors, are 0.76 and 19.12%, respectively. The poverty-stricken counties in Hunan Province were spatially aggregated and distributed mainly in the southeastern and northwestern regions. The proposed method for regional poverty assessment based on multisource geographic data provides an effective poverty monitoring reference scheme for the implementation of the poverty eradication goals in the 2030 agenda. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Machine learning; Multiple linear regression model; Multisource geographic data; Poverty index system; Sustainable development goals","Economics; Forestry; Land use; Linear regression; Planning; Sustainable development; Thermography (imaging); Geographic data; Hunan province; Indices systems; Linear evaluation model; Multi-Sources; Multiple linear regression models; Multisource geographic data; Poverty index system; Sustainable development goal; United Nations; Support vector machines"
"Wang Y., Huntington T., Scown C.D.","Tree-Based Automated Machine Learning to Predict Biogas Production for Anaerobic Co-digestion of Organic Waste","10.1021/acssuschemeng.1c04612","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116296052&doi=10.1021%2facssuschemeng.1c04612&partnerID=40&md5=ccd779d46f739ca1067d272d814e2830","The dynamics of microbial communities involved in anaerobic digestion of mixed organic waste are notoriously complex and difficult to model, yet successful operation of anaerobic digestion is critical to the goals of diverting high-moisture organic waste from landfills. Machine learning (ML) is ideally suited to capturing complex and nonlinear behavior that cannot be modeled mechanistically. This study uses 8 years of data collected from an industrial-scale anaerobic co-digestion (AcoD) operation at a municipal wastewater treatment plant in Oakland, California, combined with a powerful automated ML method, Tree-based Pipeline Optimization Tool, to develop an improved understanding of how different waste inputs and operating conditions impact biogas yield. The model inputs included daily input volumes of 31 waste streams and 5 operating parameters. Because different wastes are broken down at varying rates, the model explored a range of time lags ascribed to each waste input ranging from 0 to 30 days. The results suggest that the waste types (including rendering waste, lactose, poultry waste, and fats, oils, and greases) differ considerably in their impact on biogas yield on both a per-gallon basis and a mass of volatile solids basis, while operating parameters were not good predictors of yield at this facility. © 2021 The Authors. Published by American Chemical Society","anaerobic digestion; bioenergy; biogas; machine learning; organic waste; TPOT; wastewater treatment","Anaerobic digestion; Industrial water treatment; Trees (mathematics); Wastewater treatment; Anaerobic co-digestion; Automated machines; Bio-energy; Biogas production; Machine-learning; Operating parameters; Organic wastes; TPOT; Tree-based; Wastewater treatment; Biogas"
"Wang Y.-H., Su W.-H.","Convolutional Neural Networks in Computer Vision for Grain Crop Phenotyping: A Review","10.3390/agronomy12112659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141654790&doi=10.3390%2fagronomy12112659&partnerID=40&md5=36bb71034723e4e2fb45271a97594895","Computer vision (CV) combined with a deep convolutional neural network (CNN) has emerged as a reliable analytical method to effectively characterize and quantify high-throughput phenotyping of different grain crops, including rice, wheat, corn, and soybean. In addition to the ability to rapidly obtain information on plant organs and abiotic stresses, and the ability to segment crops from weeds, such techniques have been used to detect pests and plant diseases and to identify grain varieties. The development of corresponding imaging systems to assess the phenotypic parameters, yield, and quality of crop plants will increase the confidence of stakeholders in grain crop cultivation, thereby bringing technical and economic benefits to advanced agriculture. Therefore, this paper provides a comprehensive review of CNNs in computer vision for grain crop phenotyping. It is meaningful to provide a review as a roadmap for future research in such a thriving research area. The CNN models (e.g., VGG, YOLO, and Faster R-CNN) used CV tasks including image classification, object detection, semantic segmentation, and instance segmentation, and the main results of recent studies on crop phenotype detection are discussed and summarized. Additionally, the challenges and future trends of the phenotyping techniques in grain crops are presented. © 2022 by the authors.","computer vision; convolutional neural network; grain crops; phenotype detection",
"Wang Z., Brenning A.","Active‐learning approaches for landslide mapping using support vector machines","10.3390/rs13132588","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109954856&doi=10.3390%2frs13132588&partnerID=40&md5=b3822d632901b2b504ffc881aa1266ec","Ex post landslide mapping for emergency response and ex ante landslide susceptibility modelling for hazard mitigation are two important application scenarios that require the development of accurate, yet cost‐effective spatial landslide models. However, the manual labelling of instances for training machine learning models is time‐consuming given the data requirements of flexible data‐driven algorithms and the small percentage of area covered by landslides. Active learning aims to reduce labelling costs by selecting more informative instances. In this study, two common active‐learning strategies, uncertainty sampling and query by committee, are combined with the support vector machine (SVM), a state‐of‐the‐art machine‐learning technique, in a landslide mapping case study in order to assess their possible benefits compared to simple random sampling of training locations. By selecting more “informative” instances, the SVMs with active learning based on uncertainty sampling outperformed both random sampling and query‐by‐committee strategies when considering mean AUROC (area under the receiver operating characteristic curve) as performance measure. Uncertainty sampling also produced more stable performances with a smaller AUROC standard deviation across repetitions. In conclusion, under limited data conditions, uncertainty sampling reduces the amount of expert time needed by selecting more informative instances for SVM training. We therefore recommend incorporating active learning with uncertainty sampling into interactive landslide modelling workflows, especially in emergency response settings, but also in landslide susceptibility modelling. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Active learning; Landslide modelling; Machine learning; Support vector machine","Emergency services; Landslides; Mapping; Support vector machines; Uncertainty analysis; Application scenario; Landslide modelling; Landslide susceptibility; Learning techniques; Performance measure; Receiver operating characteristic curves; Simple random sampling; Uncertainty samplings; Learning systems"
"Wang Z., Shen J., Sun F., Zhang Z., Zhang D., Jia Y., Zhang K.","A pricing model for groundwater rights in Ningxia, China based on the fuzzy mathematical model","10.3390/ijerph16122176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068451422&doi=10.3390%2fijerph16122176&partnerID=40&md5=ff75843f72c45e4deddc97c2c819bdb9","To reduce groundwater overexploitation and alleviate water shortages, market mechanisms are introduced to allocate water rights. Scientific and reasonable pricing of groundwater rights is key to ensuring the effectiveness of the groundwater market. Because of the complexity and uncertainty of water resources, this study calculates the price of groundwater rights based on the value of water resources with an evaluation indicator system. The system includes 14 indicators developed with a fuzzy mathematics model addressing three dimensions: environment, society, and economy. The weights of the indicators are determined through the analytic network process (ANP) and the entropy method. The results show that the price of groundwater rights in Ningxia, China increased from 5.11 yuan/m3 to 5.73 yuan/m3 between 2013 and 2017; this means the price was basically stable, with a slight increase. The ratio of residents’ water fee expenditures to real disposable income also remained essentially stable, fluctuating around 0.37%, far below the normal level. These data demonstrated that the current regional water price policy does not reflect the true value of groundwater resources; there is room to increase urban water prices. Local governments need speed up water price system reforms and adopt water rights systems to optimize water resource allocations. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","Fuzzy mathematical model; Groundwater; Pricing model; Water rights","ground water; fuzzy mathematics; groundwater; legal rights; numerical model; price dynamics; pricing policy; water economics; Article; China; cost; environmental factor; environmental monitoring; fluid intake; fuzzy logic; government; mathematical model; society; urban area; water supply; economics; organization and management; theoretical model; China; Ningxia Huizu; China; Costs and Cost Analysis; Groundwater; Models, Theoretical; Ownership; Water Resources"
"Wanner J., Heinrich K., Janiesch C., Zschech P.","How much AI do you require? Decision factors for adopting AI technology",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099537611&partnerID=40&md5=0958a73e399d8c123e887e8063c1955c","Artificial intelligence (AI) based on machine learning technology disrupts how knowledge is gained. Nevertheless, ML's improved accuracy of prediction comes at the cost of low traceability due to its black-box nature. The field of explainable AI tries to counter this. However, for practical use in IT projects, these two research streams offer only partial advice for AI adoption as the trade-off between accuracy and explainability has not been adequately discussed yet. Thus, we simulate a decision process by implementing three best practice AI-based decision support systems for a high-stake maintenance decision scenario and evaluate the decision and attitude factors using the Analytical Hierarchy Process (AHP) through an expert survey. The combined results indicate that system performance is still the most important factor and that implementation effort and explainability are relatively even factors. Further, we found that systems using similarity-based matching or direct modeling for remaining useful life estimation performed best. © ICIS 2020. All rights reserved.","AI Adoption; Analytical hierarchy process; Artificial intelligence; Explainable AI","Blending; Decision support systems; Economic and social effects; Information systems; Information use; AI Technologies; Analytical Hierarchy Process; Best practices; Decision factors; Decision process; Expert survey; Maintenance decisions; Remaining useful lives; Artificial intelligence"
"Washburn J.D., Cimen E., Ramstein G., Reeves T., O’Briant P., McLean G., Cooper M., Hammer G., Buckler E.S.","Predicting phenotypes from genetic, environment, management, and historical data using CNNs","10.1007/s00122-021-03943-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113598473&doi=10.1007%2fs00122-021-03943-7&partnerID=40&md5=9eb9501e9c43650e6dfc85c827406f28","Key Message: Convolutional Neural Networks (CNNs) can perform similarly or better than standard genomic prediction methods when sufficient genetic, environmental, and management data are provided. Abstract: Predicting phenotypes from genetic (G), environmental (E), and management (M) conditions is a long-standing challenge with implications to agriculture, medicine, and conservation. Most methods reduce the factors in a dataset (feature engineering) in a subjective and potentially oversimplified manner. Deep neural networks such as Multilayer Perceptrons (MPL) and Convolutional Neural Networks (CNN) can overcome this by allowing the data itself to determine which factors are most important. CNN models were developed for predicting agronomic yield from a combination of replicated trials and historical yield survey data. The results were more accurate than standard methods when tested on held-out G, E, and M data (r = 0.50 vs. r = 0.43), and performed slightly worse than standard methods when only G was held out (r = 0.74 vs. r = 0.80). Pre-training on historical data increased accuracy compared to trial data alone. Saliency map analysis indicated the CNN has “learned” to prioritize many factors of known agricultural importance. © 2021, This is a U.S. government work and not under copyright protection in the U.S.; foreign copyright protection may apply.",,"Agricultural robots; Agriculture; Convolution; Convolutional neural networks; Deep neural networks; Environmental management; Forecasting; Agronomic yields; Feature engineerings; Genomic predictions; Historical data; Management data; Pre-training; Saliency map; Survey data; Multilayer neural networks; crop; data mining; genetics; genomics; growth, development and aging; machine learning; maize; phenotype; procedures; Crops, Agricultural; Data Mining; Genomics; Machine Learning; Neural Networks, Computer; Phenotype; Zea mays"
"Washburn J.D., Mejia-Guerra M.K., Ramstein G., Kremling K.A., Valluru R., Buckler E.S., Wang H.","Evolutionarily informed deep learning methods for predicting relative transcript abundance from DNA sequence","10.1073/pnas.1814551116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063274469&doi=10.1073%2fpnas.1814551116&partnerID=40&md5=70dd46a3382f3b10eeff7bde45c5e9db","Deep learning methodologies have revolutionized prediction in many fields and show potential to do the same in molecular biology and genetics. However, applying these methods in their current forms ignores evolutionary dependencies within biological systems and can result in false positives and spurious conclusions. We developed two approaches that account for evolutionary relatedness in machine learning models: (i) gene-family–guided splitting and (ii) ortholog contrasts. The first approach accounts for evolution by constraining model training and testing sets to include different gene families. The second approach uses evolutionarily informed comparisons between orthologous genes to both control for and leverage evolutionary divergence during the training process. The two approaches were explored and validated within the context of mRNA expression level prediction and have the area under the ROC curve (auROC) values ranging from 0.75 to 0.94. Model weight inspections showed biologically interpretable patterns, resulting in the hypothesis that the 3′ UTR is more important for fine-tuning mRNA abundance levels while the 5′ UTR is more important for large-scale changes. © 2019 National Academy of Sciences. All Rights Reserved.","Convolutional neural networks; Machine learning; Regulation; RNA","DNA; messenger RNA; DNA; 3' untranslated region; 5' untranslated region; Article; controlled study; deep learning; DNA sequence; DNA transcription; molecular evolution; mRNA expression level; multigene family; nonhuman; prediction; priority journal; receiver operating characteristic; DNA sequence; gene expression regulation; genetic transcription; genetics; metabolism; nucleotide sequence; theoretical model; Base Sequence; Deep Learning; DNA; Evolution, Molecular; Gene Expression Regulation; Models, Theoretical; Sequence Analysis, DNA; Transcription, Genetic"
"Webb M.E., Fluck A., Magenheim J., Malyn-Smith J., Waters J., Deschênes M., Zagami J.","Machine learning for human learners: opportunities, issues, tensions and threats","10.1007/s11423-020-09858-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096341025&doi=10.1007%2fs11423-020-09858-2&partnerID=40&md5=dfa3b51d58e88c8434d5b935c66c6f0c","Machine learning systems are infiltrating our lives and are beginning to become important in our education systems. This article, developed from a synthesis and analysis of previous research, examines the implications of recent developments in machine learning for human learners and learning. In this article we first compare deep learning in computers and humans to examine their similarities and differences. Deep learning is identified as a sub-set of machine learning, which is itself a component of artificial intelligence. Deep learning often depends on backwards propagation in weighted neural networks, so is non-deterministic—the system adapts and changes through practical experience or training. This adaptive behaviour predicates the need for explainability and accountability in such systems. Accountability is the reverse of explainability. Explainability flows through the system from inputs to output (decision) whereas accountability flows backwards, from a decision to the person taking responsibility for it. Both explainability and accountability should be incorporated in machine learning system design from the outset to meet social, ethical and legislative requirements. For students to be able to understand the nature of the systems that may be supporting their own learning as well as to act as responsible citizens in contemplating the ethical issues that machine learning raises, they need to understand key aspects of machine learning systems and have opportunities to adapt and create such systems. Therefore, some changes are needed to school curricula. The article concludes with recommendations about machine learning for teachers, students, policymakers, developers and researchers. © 2020, The Author(s).","Accountability; Deep learning; Explainability; Human learning; Machine learning",
"Webber H., Rezaei E.E., Ryo M., Ewert F.","Framework to guide modeling single and multiple abiotic stresses in arable crops","10.1016/j.agee.2022.108179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138158160&doi=10.1016%2fj.agee.2022.108179&partnerID=40&md5=e3570f44381e9beddb3beb894e247ba9","With the occurrence of extreme events projected to increase under climate change, it is critical to assess the risk they pose to food security and identify suitable adaptation options. While mechanisms and impacts of climatic stressors (e.g. frost, drought, heat or flooding) have been studied individually, little is known their combined impacts on crops to be expected under actual production conditions. This lack of process knowledge is reflected in the few instances of crop models considering multiple stressors. Here we provide an overview of the representation of single stressors in process based crop models. From this basis, a framework to consider multiple stressors in current models is presented, defining four stressor combination types: 1. Single exposure; 2. No direct interaction; 3. Known interaction; and 4. Unknown interaction. An analytical framework from ecological sciences is then presented as an approach to consider when formulating algorithms for the 4th type of unknown interactions. In a final section, we discuss new data driven and model based exploration options to support understanding multiple stressor interactions in recognition of the challenges of experimentation around multiple stressors. We assert that process based modeling has a large and largely untapped potential to support scientific investigations of the underlying mechanisms driving crop response to multiple stressors. © 2022 The Authors","Climate risk; Compounded events; Compounded perturbations; Crop models; Extreme events; Model improvement; Multiple stressors; Synergy and antagonism","abiotic factor; arable land; crop plant; crop production; environmental risk; environmental stress; extreme event; food security"
"Wei H., Huang Y., Santiago P.J., Labachyan K.E., Ronaghi S., Magana M.P.B., Huang Y.-H., Jiang S.C., Hochbaum A.I., Ragan R.","Decoding the metabolic response of Escherichia coli for sensing trace heavy metals in water","10.1073/pnas.2210061120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147461209&doi=10.1073%2fpnas.2210061120&partnerID=40&md5=f102054cb01b1bdf0f09c15bdc86f40b","Heavy metal contamination due to industrial and agricultural waste represents a growing threat to water supplies. Frequent and widespread monitoring for toxic metals in drinking and agricultural water sources is necessary to prevent their accumulation in humans, plants, and animals, which results in disease and environmental damage. Here, the metabolic stress response of bacteria is used to report the presence of heavy metal ions in water by transducing ions into chemical signals that can be fingerprinted using machine learning analysis of vibrational spectra. Surface-enhanced Raman scattering surfaces amplify chemical signals from bacterial lysate and rapidly generate large, reproducible datasets needed for machine learning algorithms to decode the complex spectral data. Classification and regression algorithms achieve limits of detection of 0.5 pM for As3+ and 6.8 pM for Cr6+, 100,000 times lower than the World Health Organization recommended limits, and accurately quantify concentrations of analytes across six orders of magnitude, enabling early warning of rising contaminant levels. Trained algorithms are generalizable across water samples with different impurities; water quality of tap water and wastewater was evaluated with 92% accuracy. Copyright © 2023 the Author(s).","bacterial metabolism; environmental sensors; machine learning; vibrational spectroscopy","heavy metal; agriculture; animal; environmental monitoring; Escherichia coli; human; procedures; water pollutant; water quality; Agriculture; Animals; Environmental Monitoring; Escherichia coli; Humans; Metals, Heavy; Water Pollutants, Chemical; Water Quality"
"Wei H., Chen W., Zhu L., Chu X., Liu H., Mu Y., Ma Z.","Improved Lightweight Mango Sorting Model Based on Visualization","10.3390/agriculture12091467","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141773023&doi=10.3390%2fagriculture12091467&partnerID=40&md5=a570f04ea2dcf302a374a8941c3e79fc","Neural networks are widely used in fruit sorting and have achieved some success. However, due to the limitations of storage space and power consumption, the storage and computing of a neural network model on embedded devices remain a massive challenge. Aiming at realizing a lightweight mango sorting model, the feature-extraction characteristics of the shallow and deep networks of the SqueezeNet model were analyzed by a visualization method, and then eight lightweight models were constructed by removing redundant layers or modifying the convolution kernel. It was found that the model designated Model 4 performed well after training and testing. The class activation mapping method was used to explain the basis of the classification decision, and the model was compared with ten classical classification models. The results showed that the calculation performance of the model was significantly improved without reducing accuracy. The parameter storage requirement is 0.87 MB, and the calculation amount is 181 MFLOPS, while the average classification accuracy can still be maintained at 95.64%. This model has a high-cost performance and can be widely used in embedded devices. © 2022 by the authors.","deep learning; lightweight convolutional neural network; mango sorting; visualization",
"Wei H.-E., Grafton M., Bretherton M., Irwin M., Sandoval E.","Evaluation of the Use of UAV-Derived Vegetation Indices and Environmental Variables for Grapevine Water Status Monitoring Based on Machine Learning Algorithms and SHAP Analysis","10.3390/rs14235918","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143793984&doi=10.3390%2frs14235918&partnerID=40&md5=333fb79fbe9d33091d545432a553c6c2","Monitoring and management of grapevine water status (GWS) over the critical period between flowering and veraison plays a significant role in producing grapes of premium quality. Although unmanned aerial vehicles (UAVs) can provide efficient mapping across the entire vineyard, most commercial UAV-based multispectral sensors do not contain a shortwave infrared band, which makes the monitoring of GWS problematic. The goal of this study is to explore whether and which of the ancillary variables (vegetation characteristics, temporal trends, weather conditions, and soil/terrain data) may improve the accuracy of GWS estimation using multispectral UAV and provide insights into the contribution, in terms of direction and intensity, for each variable contributing to GWS variation. UAV-derived vegetation indices, slope, elevation, apparent electrical conductivity (ECa), weekly or daily weather parameters, and day of the year (DOY) were tested and regressed against stem water potential (Ψstem), measured by a pressure bomb, and used as a proxy for GWS using three machine learning algorithms (elastic net, random forest regression, and support vector regression). Shapley Additive exPlanations (SHAP) analysis was used to assess the relationship between selected variables and Ψstem. The results indicate that the root mean square error (RMSE) of the transformed chlorophyll absorption reflectance index-based model improved from 213 to 146 kPa when DOY and elevation were included as ancillary inputs. RMSE of the excess green index-based model improved from 221 to 138 kPa when DOY, elevation, slope, ECa, and daily average windspeed were included as ancillary inputs. The support vector regression best described the relationship between Ψstem and selected predictors. This study has provided proof of the concept for developing GWS estimation models that potentially enhance the monitoring capacities of UAVs for GWS, as well as providing individual GWS mapping at the vineyard scale. This may enable growers to improve irrigation management, leading to controlled vegetative growth and optimized berry quality. © 2022 by the authors.","apparent electrical conductivity; day of the year; elastic net; elevation; multispectral UAV; random forest regression; slope; support vector regression; weather parameter","Antennas; Commercial vehicles; Electric conductivity; Forestry; Learning algorithms; Machine learning; Mean square error; Parameter estimation; Quality control; Regression analysis; Unmanned aerial vehicles (UAV); Vegetation; Aerial vehicle; Apparent electrical conductivity; Day of the year; Elastic net; Elevation; Multi-spectral; Multispectral unmanned aerial vehicle; Random forest regression; Random forests; Slope; Support vector regressions; Weather parameters; Mapping"
"Weller D.L., Love T.M.T., Wiedmann M.","Interpretability Versus Accuracy: A Comparison of Machine Learning Models Built Using Different Algorithms, Performance Measures, and Features to Predict E. coli Levels in Agricultural Water","10.3389/frai.2021.628441","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110188747&doi=10.3389%2ffrai.2021.628441&partnerID=40&md5=856e6799846a5eaaccd89b5a88c1d26a","Since E. coli is considered a fecal indicator in surface water, government water quality standards and industry guidance often rely on E. coli monitoring to identify when there is an increased risk of pathogen contamination of water used for produce production (e.g., for irrigation). However, studies have indicated that E. coli testing can present an economic burden to growers and that time lags between sampling and obtaining results may reduce the utility of these data. Models that predict E. coli levels in agricultural water may provide a mechanism for overcoming these obstacles. Thus, this proof-of-concept study uses previously published datasets to train, test, and compare E. coli predictive models using multiple algorithms and performance measures. Since the collection of different feature data carries specific costs for growers, predictive performance was compared for models built using different feature types [geospatial, water quality, stream traits, and/or weather features]. Model performance was assessed against baseline regression models. Model performance varied considerably with root-mean-squared errors and Kendall’s Tau ranging between 0.37 and 1.03, and 0.07 and 0.55, respectively. Overall, models that included turbidity, rain, and temperature outperformed all other models regardless of the algorithm used. Turbidity and weather factors were also found to drive model accuracy even when other feature types were included in the model. These findings confirm previous conclusions that machine learning models may be useful for predicting when, where, and at what level E. coli (and associated hazards) are likely to be present in preharvest agricultural water sources. This study also identifies specific algorithm-predictor combinations that should be the foci of future efforts to develop deployable models (i.e., models that can be used to guide on-farm decision-making and risk mitigation). When deploying E. coli predictive models in the field, it is important to note that past research indicates an inconsistent relationship between E. coli levels and foodborne pathogen presence. Thus, models that predict E. coli levels in agricultural water may be useful for assessing fecal contamination status and ensuring compliance with regulations but should not be used to assess the risk that specific pathogens of concern (e.g., Salmonella, Listeria) are present. © Copyright © 2021 Weller, Love and Wiedmann.","E. coli; food safety; machine learning; predictive model; water quality",
"Wells M.J., Gilmore T.E., Nelson N., Mittelstet A., Böhlke J.K.","Determination of vadose zone and saturated zone nitrate lag times using long-Term groundwater monitoring data and statistical machine learning","10.5194/hess-25-811-2021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101220166&doi=10.5194%2fhess-25-811-2021&partnerID=40&md5=0ede5c67531b8e3c9404a91337835930","In this study, we explored the use of statistical machine learning and long-Term groundwater nitrate monitoring data to estimate vadose zone and saturated zone lag times in an irrigated alluvial agricultural setting. Unlike most previous statistical machine learning studies that sought to predict groundwater nitrate concentrations within aquifers, the focus of this study was to leverage available groundwater nitrate concentrations and other environmental variables to determine mean regional vertical velocities (transport rates) of water and solutes in the vadose zone and saturated zone (3.50 and 3.75myr-1, respectively). The statistical machine learning results are consistent with two primary recharge processes in this western Nebraska aquifer, namely (1) diffuse recharge from irrigation and precipitation across the landscape and (2) focused recharge from leaking irrigation conveyance canals. The vadose zone mean velocity yielded a mean recharge rate (0.46myr-1) consistent with previous estimates from groundwater age dating in shallow wells (0.38myr-1). The saturated zone mean velocity yielded a recharge rate (1.31myr-1) that was more consistent with focused recharge from leaky irrigation canals, as indicated by previous results of groundwater age dating in intermediate-depth wells (1.22myr-1). Collectively, the statistical machine learning model results are consistent with previous observations of relatively high water fluxes and short transit times for water and nitrate in the primarily oxic aquifer. Partial dependence plots from the model indicate a sharp threshold in which high groundwater nitrate concentrations are mostly associated with total travel times of 7 years or less, possibly reflecting some combination of recent management practices and a tendency for nitrate concentrations to be higher in diffuse infiltration recharge than in canal leakage water. Limitations to the machine learning approach include the non-uniqueness of different transport rate combinations when comparing model performance and highlight the need to corroborate statistical model results with a robust conceptual model and complementary information such as groundwater age. © 2021 Massachussetts Medical Society. All rights reserved.",,"Agricultural robots; Aquifers; Groundwater resources; Hydraulic structures; Hydrogeology; Irrigation; Irrigation canals; Leakage (fluid); Machine learning; Monitoring; Nitrates; Statistics; Travel time; Agricultural setting; Environmental variables; Groundwater age dating; Groundwater monitoring; Machine learning approaches; Nitrate concentration; Statistical machine learning; Statistical modeling; Recharging (underground waters); environmental monitoring; flow velocity; groundwater resource; long-term change; machine learning; nitrate; phreatic zone; statistical analysis; vadose zone; well water"
"Wen R., Li S.","Spatial Decision Support Systems with Automated Machine Learning: A Review","10.3390/ijgi12010012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146712902&doi=10.3390%2fijgi12010012&partnerID=40&md5=fb44763316d9c0a5c01a5e6a218ea90e","Many spatial decision support systems suffer from user adoption issues in practice due to lack of trust, technical expertise, and resources. Automated machine learning has recently allowed non-experts to explore and apply machine-learning models in the industry without requiring abundant expert knowledge and resources. This paper reviews recent literature from 136 papers, and proposes a general framework for integrating spatial decision support systems with automated machine learning as an opportunity to lower major user adoption barriers. Challenges of data quality, model interpretability, and practical usefulness are discussed as general considerations for system implementation. Research opportunities related to spatially explicit models in AutoML, and resource-aware, collaborative/connected, and human-centered systems are also discussed to address these challenges. This paper argues that integrating automated machine learning into spatial decision support systems can not only potentially encourage user adoption, but also mutually benefit research in both fields—bridging human-related and technical advancements for fostering future developments in spatial decision support systems and automated machine learning. © 2022 by the authors.","automation; AutoML; decision support; framework; GIS; machine learning; SDSS; spatial; system",
"Westhues C.C., Simianer H., Beissinger T.M.","learnMET: an R package to apply machine learning methods for genomic prediction using multi-environment trial data","10.1093/g3journal/jkac226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143164060&doi=10.1093%2fg3journal%2fjkac226&partnerID=40&md5=e5237c85c24d8138ec08a44fa3c2c22b","We introduce the R-package learnMET, developed as a flexible framework to enable a collection of analyses on multi-environment trial breeding data with machine learning-based models. learnMET allows the combination of genomic information with environmental data such as climate and/or soil characteristics. Notably, the package offers the possibility of incorporating weather data from field weather stations, or to retrieve global meteorological datasets from a NASA database. Daily weather data can be aggregated over specific periods of time based on naive (for instance, nonoverlapping 10-day windows) or phenological approaches. Different machine learning methods for genomic prediction are implemented, including gradient-boosted decision trees, random forests, stacked ensemble models, and multilayer perceptrons. These prediction models can be evaluated via a collection of cross-validation schemes that mimic typical scenarios encountered by plant breeders working with multi-environment trial experimental data in a user-friendly way. The package is published under an MIT license and accessible on GitHub. © The Author(s) 2022. Published by Oxford University Press on behalf of Genetics Society of America.","genomic prediction; genotype × environment interaction; machine learning; multienvironment trials; R software","article; breeding; climate; cross validation; decision tree; genotype; genotype environment interaction; human; licence; machine learning; multilayer perceptron; prediction; random forest; software; soil; weather"
"Widianto M.H., Sinaga A., Ginting M.A.","A Systematic Review of LPWAN and Short-Range Network using AI to Enhance Internet of Things","10.18196/jrc.v3i4.15419","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142924262&doi=10.18196%2fjrc.v3i4.15419&partnerID=40&md5=de1d1ef7520a1721dc9e6af30d47d00a","Artificial intelligence (AI) has recently been used frequently, especially concerning the Internet of Things (IoT). However, IoT devices cannot work alone, assisted by Low Power Wide Area Network (LPWAN) for long-distance communication and Short-Range Network for a short distance. However, few reviews about AI can help LPWAN and Short-Range Network. Therefore, the author took the opportunity to do this review. This study aims to review LPWAN and Short-Range Networks AI papers in systematically enhancing IoT performance. Reviews are also used to systematically maximize LPWAN systems and Short-Range networks to enhance IoT quality and discuss results that can be applied to a specific scope. The author utilizes selected reporting items for systematic review and meta-analysis (PRISMA). The authors conducted a systematic review of all study results in support of the authors' objectives. Also, the authors identify development and related study opportunities. The author found 79 suitable papers in this systematic review, so a discussion of the presented papers was carried out. Several technologies are widely used, such as LPWAN in general, with several papers originating from China. Many reports from conferences last year and papers related to this matter were from 2020-2021. The study is expected to inspire experimental studies in finding relevant scientific papers and become another review. © 2022 Department of Agribusiness, Universitas Muhammadiyah Yogyakarta. All Rights Reserved.","Artificial Intelligence (AI); Internet of Things (IoT); Low Power Wide Area Network (LPWAN); Preferred reporting items for systematic reviews and meta-analyses (PRISMA); Short-Range Network",
"Wilson K.M., McCool W.C., Brewer S.C., Zamora-Wilson N., Schryver P.J., Lamson R.L.F., Huggard A.M., Brenner Coltrain J., Contreras D.A., Codding B.F.","Climate and demography drive 7000 years of dietary change in the Central Andes","10.1038/s41598-022-05774-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124263797&doi=10.1038%2fs41598-022-05774-y&partnerID=40&md5=29776746cf628a12b9343b814c08159f","Explaining the factors that influence past dietary variation is critically important for understanding changes in subsistence, health, and status in past societies; yet systematic studies comparing possible driving factors remain scarce. Here we compile the largest dataset of past diet derived from stable isotope δ13C‰ and δ15N‰ values in the Americas to quantitatively evaluate the impact of 7000 years of climatic and demographic change on dietary variation in the Central Andes. Specifically, we couple paleoclimatic data from a general circulation model with estimates of relative past population inferred from archaeologically derived radiocarbon dates to assess the influence of climate and population on spatiotemporal dietary variation using an ensemble machine learning model capable of accounting for interactions among predictors. Results reveal that climate and population strongly predict diet (80% of δ15N‰ and 66% of δ13C‰) and that Central Andean diets correlate much more strongly with local climatic conditions than regional population size, indicating that the past 7000 years of dietary change was influenced more by climatic than socio-demographic processes. Visually, the temporal pattern suggests decreasing dietary variation across elevation zones during the Late Horizon, raising the possibility that sociopolitical factors overrode the influence of local climatic conditions on diet during that time. The overall findings and approach establish a general framework for understanding the influence of local climate and demography on dietary change across human history. © 2022, The Author(s).",,
"Winkler D.A.","Probing the properties of molecules and complex materials using machine learning","10.1071/CH22138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139731584&doi=10.1071%2fCH22138&partnerID=40&md5=61049666b71d05916bd7a6c8fa3a3690","The application of machine learning to predicting the properties of small and large discrete (single) molecules and complex materials (polymeric, extended or mixtures of molecules) has been increasing exponentially over the past few decades. Unlike physics-based and rule-based computational systems, machine learning algorithms can learn complex relationships between physicochemical and process parameters and their useful properties for an extremely diverse range of molecular entities. Both the breadth of machine learning methods and the range of physical, chemical, materials, biological, medical and many other application areas have increased markedly in the past decade. This Account summarises three decades of research into improved cheminformatics and machine learning methods and their application to drug design, regenerative medicine, biomaterials, porous and 2D materials, catalysts, biomarkers, surface science, physicochemical and phase properties, nanomaterials, electrical and optical properties, corrosion and battery research. © 2022 The Author(s) (or their employer(s)). Published by CSIRO Publishing. This is an open access article distributed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.","2D materials; artificial intelligence; batteries; Bayesian methods; biomaterials; catalysts; complex systems; computational molecular design; drug design; machine learning; nanomaterials; organic photovoltaic (OPV) devices; porous materials; quantitative structure-activity relationships (QSAR); regenerative medicine; science","Bayesian networks; Computational chemistry; Computational methods; Corrosion; Degradation; Electric batteries; Learning algorithms; Materials properties; Molecules; Nanostructured materials; Optimization; Physicochemical properties; Porous materials; 2d material; Battery; Bayesian methods; Computational molecular design; Drug Design; Machine-learning; Molecular design; Organic photovoltaic devices; Quantitative structure activity relationship; Quantitative structure-activity relationship; Regenerative medicine; Science; ]+ catalyst; Machine learning"
"Wirtz J., Kunz W.H., Hartley N., Tarbit J.","Corporate Digital Responsibility in Service Firms and Their Ecosystems","10.1177/10946705221130467","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139447621&doi=10.1177%2f10946705221130467&partnerID=40&md5=3391bc5b7ed1dbc8d986506b83e5adb6","Digitization, artificial intelligence, and service robots carry serious ethical, privacy, and fairness risks. Using the lens of corporate digital responsibility (CDR), we examine these risks and their mitigation in service firms and make five contributions. First, we show that CDR is critical in service contexts because of the vast streams of customer data involved and digital service technology’s omnipresence, opacity, and complexity. Second, we synthesize the ethics, privacy, and fairness literature using the CDR data and technology life-cycle perspective to understand better the nature of these risks in a service context. Third, to provide insights on the origins of these risks, we examine the digital service ecosystem and the related flows of money, service, data, insights, and technologies. Fourth, we deduct that the underlying causes of CDR issues are trade-offs between good CDR practices and organizational objectives (e.g., profit opportunities versus CDR risks) and introduce the CDR calculus to capture this. We also conclude that regulation will need to step in when a firm’s CDR calculus becomes so negative that good CDR is unlikely. Finally, we advance a set of strategies, tools, and practices service firms can use to manage these trade-offs and build a strong CDR culture. © The Author(s) 2022.","artificial intelligence; corporate digital responsibility; data; ethics; fairness; privacy",
"Wöber W., Mehnen L., Sykacek P., Meimberg H.","Investigating explanatory factors of machine learning models for plant classification","10.3390/plants10122674","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120608545&doi=10.3390%2fplants10122674&partnerID=40&md5=0c6142148c38d14ca80e9637ee503f1c","Recent progress in machine learning and deep learning has enabled the implementation of plant and crop detection using systematic inspection of the leaf shapes and other morphological characters for identification systems for precision farming. However, the models used for this approach tend to become black-box models, in the sense that it is difficult to trace characters that are the base for the classification. The interpretability is therefore limited and the explanatory factors may not be based on reasonable visible characters. We investigate the explanatory factors of recent machine learning and deep learning models for plant classification tasks. Based on a Daucus carota and a Beta vulgaris image data set, we implement plant classification models and compare those models by their predictive performance as well as explainability. For comparison we implemented a feed forward convolutional neuronal network as a default model. To evaluate the performance, we trained an unsupervised Bayesian Gaussian process latent variable model as well as a convolutional autoencoder for feature extraction and rely on a support vector machine for classification. The explanatory factors of all models were extracted and analyzed. The experiments show, that feed forward convolutional neuronal networks (98.24% and 96.10% mean accuracy) outperforms the Bayesian Gaussian process latent variable pipeline (92.08% and 94.31% mean accuracy) as well as the convolutional autoenceoder pipeline (92.38% and 93.28% mean accuracy) based approaches in terms of classification accuracy, even though not significant for Beta vulgaris images. Additionally, we found that the neuronal network used biological uninterpretable image regions for the plant classification task. In contrast to that, the unsupervised learning models rely on explainable visual characters. We conclude that supervised convolutional neuronal networks must be used carefully to ensure biological interpretability. We recommend unsupervised machine learning, careful feature investigation, and statistical feature analysis for biological applications. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Explainable AI; Machine learning; Plant leaf morphometrics",
"Wocher M., Berger K., Verrelst J., Hank T.","Retrieval of carbon content and biomass from hyperspectral imagery over cultivated areas","10.1016/j.isprsjprs.2022.09.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138073251&doi=10.1016%2fj.isprsjprs.2022.09.003&partnerID=40&md5=213af84d5b8628ab96eb0100dce6e720","Spaceborne imaging spectroscopy is a highly promising data source for all agricultural management and research disciplines that require spatio-temporal information on crop properties. Recently launched science-driven missions, such as the Environmental Mapping and Analysis Program (EnMAP), deliver unprecedented data from the Earth's surface. This new kind of data should be explored to develop robust retrieval schemes for deriving crucial variables from future routine missions. Therefore, we present a workflow for inferring crop carbon content (Carea), and aboveground dry and wet biomass (AGBdry, AGBfresh) from EnMAP data. To achieve this, a hybrid workflow was generated, combining radiative transfer modeling (RTM) with machine learning regression algorithms. The key concept involves: (1) coupling the RTMs PROSPECT-PRO and 4SAIL for simulation of a wide range of vegetation states, (2) using dimensionality reduction to deal with collinearity, (3) applying a semi-supervised active learning technique against a 4-years campaign dataset, followed by (4) training of a Gaussian process regression (GPR) machine learning algorithm and (5) validation with an independent in situ dataset acquired during the ESA Hypersense experiment campaign at a German test site. Internal validation of the GPR-Careaand GPR-AGB models achieved coefficients of determination (R2) of 0.80 for Carea and 0.80, 0.71 for AGBdry and AGBfresh, respectively. The mapping capability of these models was successfully demonstrated using airborne AVIRIS-NG hyperspectral imagery, which was spectrally resampled to EnMAP spectral properties. Plausible estimates were achieved over both bare and green fields after adding bare soil spectra to the training data. Validation over green winter wheat fields generated reliable estimates as suggested by low associated model uncertainties (&lt; 40%). These results suggest a high degree of model reliability for cultivated areas during active growth phases at canopy closure. Overall, our proposed carbon and biomass models based on EnMAP spectral sampling demonstrate a promising path toward the inference of these crucial variables over cultivated areas from future spaceborne operational hyperspectral missions. © 2022 The Author(s)","Active learning; AVIRIS-NG; Biomass; Carbon content; EnMAP; Gaussian process regression","Bayesian networks; Carbon; Crops; Gaussian distribution; Gaussian noise (electronic); Learning algorithms; Learning systems; Machine learning; NASA; Photomapping; Regression analysis; Remote sensing; Spectroscopy; Statistical tests; Uncertainty analysis; Active Learning; AVIRIS-NG; Carbon content; Environmental analysis; Environmental mapping; Environmental mapping and analyse program; Gaussian process regression; Hyper-spectral imageries; Space-borne; Work-flows; Biomass; agricultural management; algorithm; bare soil; biomass; estimation method; experimental study; Gaussian method; model validation; training"
"Wolanin A., Mateo-Garciá G., Camps-Valls G., Gómez-Chova L., Meroni M., Duveiller G., Liangzhi Y., Guanter L.","Estimating and understanding crop yields with explainable deep learning in the Indian Wheat Belt","10.1088/1748-9326/ab68ac","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080115378&doi=10.1088%2f1748-9326%2fab68ac&partnerID=40&md5=fdb1ec26dc240cd0456ada545d6e392f","Forecasting crop yields is becoming increasingly important under the current context in which food security needs to be ensured despite the challenges brought by climate change, an expanding world population accompanied by rising incomes, increasing soil erosion, and decreasing water resources. Temperature, radiation, water availability and other environmental conditions influence crop growth, development, and final grain yield in a complex nonlinear manner. Machine learning (ML) techniques, and deep learning (DL) methods in particular, can account for such nonlinear relations between yield and its covariates. However, they typically lack transparency and interpretability, since the way the predictions are derived is not directly evident. Yet, in the context of yield forecasting, understanding which are the underlying factors behind both a predicted loss or gain is of great relevance. Here, we explore how to benefit from the increased predictive performance of DL methods while maintaining the ability to interpret how the models achieve their results. To do so, we applied a deep neural network to multivariate time series of vegetation and meteorological data to estimate the wheat yield in the Indian Wheat Belt. Then, we visualized and analyzed the features and yield drivers learned by the model with the use of regression activation maps. The DL model outperformed other tested models (ridge regression and random forest) and facilitated the interpretation of variables and processes that lead to yield variability. The learned features were mostly related to the length of the growing season, and temperature and light conditions during this time. For example, our results showed that high yields in 2012 were associated with low temperatures accompanied by sunny conditions during the growing period. The proposed methodology can be used for other crops and regions in order to facilitate application of DL models in agriculture. © 2020 The Author(s). Published by IOP Publishing Ltd.","deep learning (DL); explainable artificial intelligence (XAI); food security; Indian Wheat Belt; regression activation map (RAM); remote sensing; wheat yield","Chemical activation; Climate change; Crops; Decision trees; Deep neural networks; Food supply; Forecasting; Random forests; Regression analysis; Remote sensing; Water resources; Environmental conditions; explainable artificial intelligence (XAI); Food security; Multivariate time series; Nonlinear relations; Predictive performance; regression activation map (RAM); Wheat yield; Deep learning; artificial intelligence; climate change; crop yield; environmental conditions; estimation method; food security; greenbelt; machine learning; regression analysis; remote sensing; wheat; Triticum aestivum"
"Wu S.-L., Tung H.-Y., Hsu Y.-L.","Deep Learning for Automatic Quality Grading of Mangoes: Methods and Insights","10.1109/ICMLA51294.2020.00076","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102519311&doi=10.1109%2fICMLA51294.2020.00076&partnerID=40&md5=c9d5b3d7eae3f6308ecec847a357bd11","The quality grading of mangoes is a crucial task for mango growers as it vastly affects their profit. However, until today, this process still relies on laborious efforts of humans, who are prone to fatigue and errors. To remedy this, the paper approaches the grading task with various convolutional neural networks (CNN), a tried-and-tested deep learning technology in computer vision. The models involved include Mask R-CNN (for background removal), the numerous past winners of the ImageNet challenge, namely AlexNet, VGGs, and ResNets; and, a family of self-defined convolutional autoencoder-classifiers (ConvAE-Clfs) inspired by the claimed benefit of multi-task learning in classification tasks. Transfer learning is also adopted in this work via utilizing the ImageNet pretrained weights. Besides elaborating on the preprocessing techniques, training details, and the resulting performance, we go one step further to provide explainable insights into the model's working with the help of saliency maps and principal component analysis (PCA). These insights provide a succinct, meaningful glimpse into the intricate deep learning black box, fostering trust, and can also be presented to humans in real-world use cases for reviewing the grading results. © 2020 IEEE.","computer vision; convolutional neural networks (CNN); mangoes; quality grading of fruits; transfer learning","Convolution; Convolutional neural networks; Grading; Learning systems; Multi-task learning; Transfer learning; Auto encoders; Background removal; Black boxes; Classification tasks; Learning technology; Preprocessing techniques; Quality grading; Saliency map; Deep learning"
"Wu W., Lu B.","Construction of Wireless Sensor Network Video Surveillance System for Multimedia Classroom Education and Teaching under 5G Communication Network","10.1155/2022/6385391","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133129161&doi=10.1155%2f2022%2f6385391&partnerID=40&md5=75623ce4ac81e1879c1974bddc91e3ca","Research on wireless sensor network video surveillance system is a hot field of media classroom education and teaching. Based on the 5G communication network theory, this paper constructs a wireless sensor network video monitoring system for multimedia classroom education and teaching, systematically analyzes the new distance education model under the condition of the integration of the two networks, and improves the interactive live classroom education model. For the classroom teaching mode, the model studies the isochronous transmission technology of data collection and video encoding and decoding, adopts hardware compression encoding, integrates key technologies such as reliable multicast and conditional access, and proposes the design of the system scheme, which solves the problem of multimedia classroom education and teaching digital issues. During the simulation process, the MATLAB software platform was used to study the effect of the number of 5G communication network nodes and node attributes (such as node position, node perception angle, instantaneous perception direction, or direction difference between neighboring nodes, node speed, etc.) on the target area or target point. The experimental results show that the performance of the joint optimization of transmission video quality and network lifetime performs well under multipath conditions. The total utility under multipath finally converges to 8.3, while the single path finally converges to 6.5, which further promotes the real-time performance of the multimedia network classroom teaching system. © 2022 Wenping Wu and Biao Lu.",,"5G mobile communication systems; Distance education; Encoding (symbols); Security systems; Signal encoding; Simulation platform; Video signal processing; Classroom education; Classroom teaching; Communications networks; Condition; Modelling studies; Network video; Network video monitoring; Teaching modes; Video monitoring systems; Video surveillance systems; MATLAB"
"Wu X., Zhou Q., Mu L., Hu X.","Machine learning in the identification, prediction and exploration of environmental toxicology: Challenges and perspectives","10.1016/j.jhazmat.2022.129487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133929628&doi=10.1016%2fj.jhazmat.2022.129487&partnerID=40&md5=0ce335d0265825da638ec537bc05a9c2","Over the past few decades, data-driven machine learning (ML) has distinguished itself from hypothesis-driven studies and has recently received much attention in environmental toxicology. However, the use of ML in environmental toxicology remains in the early stages, with knowledge gaps, technical bottlenecks in data quality, high-dimensional/heterogeneous/small-sample data analysis and model interpretability, and a lack of an in-depth understanding of environmental toxicology. Given the above problems, we review the recent progress in the literature and highlight state-of-the-art toxicological studies using ML (such as learning and predicting toxicity in complicated biosystems and multiple-factor environmental scenarios of long-term and large-scale pollution). Beyond predicting simple biological endpoints by integrating untargeted omics and adverse outcome pathways, ML development should focus on revealing toxicological mechanisms. The integration of data-driven ML with other methods (e.g., omics analysis and adverse outcome pathway frameworks) endows ML with widely promising application in revealing toxicological mechanisms. High-quality databases and interpretable algorithms are urgently needed for toxicology and environmental science. Addressing the core issues and future challenges for ML in this review may narrow the knowledge gap between environmental toxicity and computational science and facilitate the control of environmental risk in the future. © 2022 Elsevier B.V.","Big data; Chemical; Environmental health; Machine learning; Toxicity","Chemical analysis; Data integration; Forecasting; Machine learning; Quality control; Toxicity; 'omics'; Adverse outcomes; Data driven; Data quality; Environmental health; Environmental toxicology; High-dimensional; Higher-dimensional; Knowledge gaps; Machine-learning; Big data; data set; database; environmental risk; exploration; identification method; machine learning; prediction; toxicity; toxicology; adverse outcome pathway; article; attention; big data; data analysis; data quality; environmental health; environmental risk; environmental science; learning; machine learning; outcome assessment; prediction; toxicology; algorithm; dangerous goods; ecotoxicology; factual database; Algorithms; Databases, Factual; Ecotoxicology; Hazardous Substances; Machine Learning"
"Wu Y., Liu Q., Ma J., Zhao W., Chen H., Qu Y.","Antimony, beryllium, cobalt, and vanadium in urban park soils in Beijing: Machine learning-based source identification and health risk-based soil environmental criteria","10.1016/j.envpol.2021.118554","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119402352&doi=10.1016%2fj.envpol.2021.118554&partnerID=40&md5=8d4349debfb79b0ea10e0cd55100e2fe","The pollution situation of antimony (Sb), beryllium (Be), cobalt (Co), and vanadium (V) is poorly understood, although they are widely used in daily life and production processes. Moreover, threshold levels (“soil environmental criteria”, SEC) for these pollutants are lacking in China, which impedes effective soil quality management. This study explored pollution characteristics for park soils in urban area of Beijing, China at first. Then multivariate statistical analysis and machine learning model were used to identify the main sources of pollutants. Additionally, probabilistic health risk and SEC were studied to assess the risks of pollutants and manage soil pollutants. The results revealed that the overall pollution levels of Be, Co, Sb, and V were low, but Be and Sb were enriched to varying degrees. Source apportionment showed that Sb (85.5%) was mainly derived from fuel combustion and industrial legacy, Co (66.7%) and V (82.5%) from natural processes, and Be from the natural background (39.3%) and anthropogenic sources (53.8%). Risk assessment indicated that the pollutants' carcinogenic and noncarcinogenic risks were negligible. Exposure frequency and soil ingestion rate were the most important parameters affecting health risks. The SEC of Be, Co, Sb, and V were 31, 39.7, 41.3, and 348 mg/kg, respectively, all of which are higher than the corresponding soil quality standards in China, indicating that current soil quality standards may be too conservative for urban park land. This study provides a reference for the management of soil pollutants in Beijing's urban parks, and the formulation of soil environmental quality standards. © 2021 Elsevier Ltd","Health risk; Machine learning; Soil environmental criteria; Source apportionment; Urban park soil","Beryllium; Chromium; Cobalt; Fuels; Health; Health risks; Manganese; Multivariant analysis; Quality control; Risk assessment; Soil pollution; Soils; Vanadium; Daily lives; Daily production; Quality standard; Risk-based; Soil environmental criteria; Soils qualities; Source apportionment; Sources identifications; Urban park soils; Urban parks; Machine learning; antimony; beryllium; cobalt; fuel; vanadium; antimony; beryllium; cobalt; heavy metal; vanadium; antimony; beryllium; cobalt; health risk; machine learning; soil pollution; source apportionment; source identification; urban area; vanadium; adult; Article; carcinogenicity; child; China; combustion; concentration (parameter); controlled study; environmental exposure; environmental parameters; health hazard; human; industry; ingestion; machine learning; multiple linear regression analysis; multivariate analysis; principal component analysis; risk assessment; soil; soil environmental criteria; soil pollution; soil quality; urban area; environmental monitoring; machine learning; recreational park; soil pollutant; Beijing [Beijing (ADS)]; Beijing [China]; China; Antimony; Beijing; Beryllium; China; Cobalt; Environmental Monitoring; Machine Learning; Metals, Heavy; Parks, Recreational; Risk Assessment; Soil; Soil Pollutants; Vanadium"
"Wu Z., Yin H., He H., Li Y.","Dynamic-LSTM hybrid models to improve seasonal drought predictions over China","10.1016/j.jhydrol.2022.128706","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141762249&doi=10.1016%2fj.jhydrol.2022.128706&partnerID=40&md5=5e726a3c795a434c0c7812a7979aebab","Accurate drought prediction is essential for drought resilience and water resources management. The skill of seasonal drought prediction from dynamical and statistical models has limitations. This study combines dynamical models and deep learning to construct hybrid (dynamical-statistical) models. We use the random forest to extract typical grids based on the geopotential height, sea-level pressure, and 2-m temperature. The long short-term memory (LSTM) is used to construct the statistical models, with atmospheric variables as predictors and the 3-month Standardized Precipitation Index (SPI3) as the predictand. The hindcasts of atmospheric variables from the European Centre for Medium-Range Weather Forecasts (ECMWF) SEAS5 model are processed as predictors to force the statistical models. The hybrid model, constructed using the dynamical models and the LSTM, is named dynamic-LSTM (“D-LSTM”). The results suggest that the LSTM models are of information-extraction capability and robustness. When the lead time exceeds one month, the prediction skills are significantly improved by the D-LSTM models, especially in the East, Northwest, Southwest, and Tibet. In most regions, the D-LSTM models are more skillful across all seasons for lead times exceeding 30 days and are reliable in predicting droughts in spring and summer when the ECMWF SEAS5 loses skills at the seasonal scale. Furthermore, the D-LSTM models are more accurate in drought onset prediction. © 2022 Elsevier B.V.","Hybrid models; LSTM; Seasonal drought prediction","Decision trees; Drought; Sea level; Water resources; Weather forecasting; Atmospheric variables; Dynamical modeling; European center for medium-range weather forecasts; Hybrid model; Leadtime; Memory modeling; Seasonal drought prediction; Seasonal droughts; Statistic modeling; Water resources management; Long short-term memory; climate prediction; drought; geopotential; hybrid; resilience; water resource; China; Xizang"
"Xie W., Kimura M., Takaki K., Asada Y., Iida T., Jia X.","Interpretable Framework of Physics-Guided Neural Network With Attention Mechanism: Simulating Paddy Field Water Temperature Variations","10.1029/2021WR030493","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130605509&doi=10.1029%2f2021WR030493&partnerID=40&md5=15585a16eb565a8faf6d9e95543954f6","With the development of large-scale rice cultivation management initiatives in East Asia, there is concern that a reduction in the number of human cultivators per unit area may lead to poor water management, which could result in decreased land productivity, owing to abnormally high- and low-temperature damage to crops. Accurate simulation of paddy field water temperature is important for studying its impact on crops and providing timely information to aid in decision-making for more efficient management under limited resources. We propose a neural-network framework that considers the heat transfer by the vegetation canopy and applies physical-theory constraints in its training. A novel tuning method is proposed to cope with the trade-off between water temperature accuracy and physical consistency during training to ensure that the calculated water temperature variations in a paddy field enjoy high accuracy and physical consistency. In the experiments, the proposed framework outperforms physical process models and pure neural network models while maintaining high accuracy in the case of sparse data sets. Furthermore, an attention-mechanism input layer is integrated into the model to rank feature importance, providing global interpretation to the proposed framework. We also perform sensitivity analysis on the physical process and propose models to compare their different strategies of feature ranking. The results show that the two methods have different sensitivities to different feature patterns, but they complement each other. In summary, the proposed model is credible and stable for practical applications and has the potential to guide more efficient paddy management. © 2022. American Geophysical Union. All Rights Reserved.","deep learning; global interpretation; PGNN","Cultivation; Decision making; Deep learning; Economic and social effects; Heat transfer; Information management; Sensitivity analysis; Temperature control; Temperature distribution; Water management; Attention mechanisms; Deep learning; Global interpretation; High-accuracy; Neural-networks; Paddy field waters; PGNN; Physical process; Temperature variation; Water temperatures; Crops; artificial neural network; cultivation; heat transfer; temperature gradient; trade-off; water temperature; Far East"
"Xing Q., Yu H., Liu Y., Li J., Tian Y., Bakun A., Cao C., Tian H., Li W.","Application of a fish habitat model considering mesoscale oceanographic features in evaluating climatic impact on distribution and abundance of Pacific saury (Cololabis saira)","10.1016/j.pocean.2022.102743","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123580606&doi=10.1016%2fj.pocean.2022.102743&partnerID=40&md5=ed80d301725ccf6be9f10945d5daed4e","The continuing development of appropriate environmental predictors is important to improving the performance of fish habitat models. Mesoscale oceanographic features (MOFs) such as fronts, eddies, or upwelling zones, sometimes appearing as “oases in a fluid desert” occupying >50 km ocean surface, have customarily been regarded as key factors driving fish distributions. However, previous algorithms quantifying oceanographic features have not provided greatly enhanced predictive power to the fish habitat models which are characterized by a low variable importance due to inadequate attention having been paid to its scale-specific aspects. Here, a new predictor representing MOFs is introduced and a reappraisal by common fish habitat models of the role of the MOFs in fish distribution within a case study on Pacific saury (Cololabis saira) in the northwestern Pacific is reported. When the new predictor with MOFs was introduced, the performances of three commonly used fish habitat models were all improved significantly (26%–30%), together with the paramount importance of MOFs among all predictive variables, suggesting that MOFs may exert significant effects on Pacific saury distribution. Using the optimal model (Random Forest) selected among the three, the habitat distribution of Pacific saury in Oyashio water was then reconstructed for the period of 1993–2020 to explore its spatio-temporal variations and its relationship with the abundance variation. The “suitable habitats” (areas of reconstructed catch > 12 tons) during major fishing seasons (August–November) estimated by the optimal habitat model for Pacific saury showed a clear northward shift of 0.045°/year for the period of 1993–2020, associated with the poleward movement of both oceanic isotherms and the Oyashio extension due to northward movement of the whole wind field in concert with global warming. The estimated annual suitable habitat area (SHA) during the early fishing seasons (June–September) showed large inter-annual variations with a peak around 2010 and a valley in 2015, and correlated significantly with the abundance index of Pacific saury, implying that the SHA can be regarded as a practical indicator of abundance. Moreover, it was also found that a marked decline in the SHA was involved in the dramatic decrease in the abundance and catch of Pacific saury after 2010, while eastward movements of SHA resulted from MOFs possibly aggravated the decrease in the catch of Japanese waters by changing its southern migration route. This study illustrates the significance of MOFs in predicting fish distribution by means of empirical habitat models and may provide new insights for understanding fish habitat variability in relation to physical-biological interactions in the ocean. © 2022 Elsevier Ltd","Climate change; Habitat variations; Machine learning; Oceanic front; Oyashio current; Species distribution model","Climate models; Decision trees; Ecosystems; Fish; Fisheries; Landforms; Machine learning; Population distribution; Population dynamics; 'current; Fish distributions; Fish habitat modeling; Habitat variation; Meso scale; Oceanic fronts; Oyashio current; Performance; Species distribution modeling; Suitable habitat; Global warming; abundance; abundance index; annual variation; climate effect; ecological modeling; global warming; mesoscale eddy; population distribution; wind field; Pacific Ocean"
"Xiong R., Zheng Y., Chen N., Tian Q., Liu W., Han F., Jiang S., Lu M., Zheng Y.","Predicting Dynamic Riverine Nitrogen Export in Unmonitored Watersheds: Leveraging Insights of AI from Data-Rich Regions","10.1021/acs.est.2c02232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134720781&doi=10.1021%2facs.est.2c02232&partnerID=40&md5=f54c06dcf88bbf28e25db1718582c072","Terrestrial export of nitrogen is a critical Earth system process, but its global dynamics remain difficult to predict at a high spatiotemporal resolution. Here, we use deep learning (DL) to model daily riverine nitrogen export in response to hydrometeorological and anthropogenic drivers. Long short-term memory (LSTM) models for the daily concentration and flux of dissolved inorganic nitrogen (DIN) were built in a coastal watershed in southeastern China with a typical subtropical monsoon climate. The DL models exhibited excellent accuracy for both DIN concentration and flux, with Nash-Sutcliffe efficiency coefficients (NSEs) up to 0.67 and 0.92, respectively, a performance unlikely to be achieved by generic process-based models with comparable data quality. The flux model ensemble, without retraining, performed well (mean NSE = 0.32-0.84) in seven distinct watersheds in Asia, Europe, and North America, and retraining with multi-watershed data further improved the lowest NSE from 0.32 to 0.68. DL interpretation confirmed that interbasin consistency of riverine nitrogen export exists across different continents, which stems from the similarities in rainfall-runoff relationships. The multi-watershed flux model projects 0.60-12.4% increases in the nitrogen export to oceans from the studied watersheds under a 20% increase in fertilizer consumption, which rises to 6.7-20.1% with a 10% increase in runoff, indicating the synergistic effect of human activities and climate change. The DL-based method represents a successful case of explainable artificial intelligence in environmental science, providing a potential shortcut to a consistent understanding of the global daily-resolution dynamics of riverine nitrogen export under the currently limited data conditions. © 2022 American Chemical Society.","artificial intelligence; deep learning; LSTM; nitrogen; nonpoint sources; riverine export; transfer learning","Climate change; Climate models; Earth system models; Learning systems; Runoff; Watersheds; Deep learning; Dissolved inorganic nitrogens; Earth systems; Efficiency coefficient; Flux modeling; Nitrogen export; Nonpoint sources; Riverine export; Riverine nitrogens; Transfer learning; Long short-term memory; fertilizer; ground water; inorganic compound; nitrogen; rain; nitrogen; artificial intelligence; human activity; machine learning; nitrogen; nonpoint source pollution; pollutant transport; prediction; river pollution; watershed; Article; artificial intelligence; Asia; China; climate change; coastal waters; concentration (parameter); deep learning; dry season; environmental science; Europe; fertilizer application; growing season; human activities; human impact (environment); livestock; long short term memory network; meteorology; monsoon climate; nitrogen concentration; North America; ocean environment; rainy season; river basin; runoff; runoff model (hydrology); seasonal variation; transfer of learning; water monitoring; watershed; watershed management; environmental monitoring; human; river; Asia; China; Europe; North America; Artificial Intelligence; China; Environmental Monitoring; Fertilizers; Humans; Nitrogen; Rivers"
"Xu G., Fan H., Oliver D.M., Dai Y., Li H., Shi Y., Long H., Xiong K., Zhao Z.","Decoding river pollution trends and their landscape determinants in an ecologically fragile karst basin using a machine learning model","10.1016/j.envres.2022.113843","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136613722&doi=10.1016%2fj.envres.2022.113843&partnerID=40&md5=0c67150f02f1fd21c47c061f02d87a79","Karst watersheds accommodate high landscape complexity and are influenced by both human-induced and natural activity, which affects the formation and process of runoff, sediment connectivity and contaminant transport and alters natural hydrological and nutrient cycling. However, physical monitoring stations are costly and labor-intensive, which has confined the assessment of water quality impairments on spatial scale. The geographical characteristics of catchments are potential influencing factors of water quality, often overlooked in previous studies of highly heterogeneous karst landscape. To solve this problem, we developed a machining learning method and applied Extreme Gradient Boosting (XGBoost) to predict the spatial distribution of water quality in the world's most ecologically fragile karst watershed. We used the Shapley Addition interpretation (SHAP) to explain the potential determinants. Before this process, we first used the water quality damage index (WQI-DET) to evaluate the water quality impairment status and determined that CODMn, TN and TP were causing river water quality impairments in the WRB. Second, we selected 46 watershed features based on the three key processes (sources-mobilization-transport) which affect the temporal and spatial variation of river pollutants to predict water quality in unmonitored reaches and decipher the potential determinants of river impairments. The predicting range of CODMn spanned from 1.39 mg/L to 17.40 mg/L. The predictions of TP and TN ranged from 0.02 to 1.31 mg/L and 0.25–5.72 mg/L, respectively. In general, the XGBoost model performs well in predicting the concentration of water quality in the WRB. SHAP explained that pollutant levels may be driven by three factors: anthropogenic sources (agricultural pollution inputs), fragile soils (low organic carbon content and high soil permeability to water flow), and pollutant transport mechanisms (TWI, carbonate rocks). Our study provides key data to support decision-making for water quality restoration projects in the WRB and information to help bridge the science:policy gap. © 2022 Elsevier Inc.","Determinant analysis; Ecologically fragile karst basin; Shapley additive explanations; Water quality assessment; XGBoost regression","carbonic acid; organic carbon; river water; nitrogen; machine learning; numerical model; pollutant transport; river pollution; river water; water quality; Article; catchment area (hydrology); controlled study; electric conductivity; environmental protection; fluid balance; land use; machine learning; monsoon climate; nutrient cycling; pollution transport; prediction; runoff; sediment; water pollution; water quality; water transport; watershed; China; environmental monitoring; human; machine learning; procedures; river; soil; water pollutant; water quality; China; Environmental Monitoring; Humans; Machine Learning; Nitrogen; Rivers; Soil; Water Pollutants, Chemical; Water Quality"
"Xu J.-X., Ma J., Tang Y.-N., Wu W.-X., Shao J.-H., Wu W.-B., Wei S.-Y., Liu Y.-F., Wang Y.-C., Guo H.-Q.","Estimation of sugarcane yield using a machine learning approach based on uav-lidar data","10.3390/rs12172823","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095430705&doi=10.3390%2frs12172823&partnerID=40&md5=acc341c70d72d0696aa4fe970fe8e334","Sugarcane is a multifunctional crop mainly used for sugar and renewable bioenergy production. Accurate and timely estimation of the sugarcane yield before harvest plays a particularly important role in the management of agroecosystems. The rapid development of remote sensing technologies, especially Light Detecting and Ranging (LiDAR), significantly enhances aboveground fresh weight (AFW) estimations. In our study, we evaluated the capability of LiDAR mounted on an Unmanned Aerial Vehicle (UAV) in estimating the sugarcane AFW in Fusui county, Chongzuo city of Guangxi province, China. We measured the height and the fresh weight of sugarcane plants in 105 sampling plots, and eight variables were extracted from the field-based measurements. Six regression algorithms were used to build the sugarcane AFW model: multiple linear regression (MLR), stepwise multiple regression (SMR), generalized linear model (GLM), generalized boosted model (GBM), kernel-based regularized least squares (KRLS), and random forest regression (RFR). The results demonstrate that RFR (R2 = 0.96, RMSE = 1.27 kg m−2) performs better than other models in terms of prediction accuracy. The final fitted sugarcane AFW distribution maps exhibited good agreement with the observed values (R2 = 0.97, RMSE = 1.33 kg m−2). Canopy cover, the distance to the road, and tillage methods all have an impact on sugarcane AFW. Our study provides guidance for calculating the optimum planting density, reducing the negative impact of human activities, and selecting suitable tillage methods in actual cultivation and production. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Aboveground fresh weight; Agricultural management; Random forest regression; Sugarcane; UAV-LiDAR","Agriculture; Antennas; Decision trees; Linear regression; Machine learning; Remote sensing; Sugar industry; Turing machines; Unmanned aerial vehicles (UAV); Field-based measurements; Generalized linear model; Machine learning approaches; Multiple linear regressions; Regression algorithms; Regularized least squares; Remote sensing technology; Stepwise multiple regression; Optical radar"
"Xu X., Yu J., Wang F.","Analysis of ecosystem service drivers based on interpretive machine learning: a case study of Zhejiang Province, China","10.1007/s11356-022-20311-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128823211&doi=10.1007%2fs11356-022-20311-0&partnerID=40&md5=ffd5479580b41a37ab7392601b683858","A systematic understanding of the driving mechanisms of ecosystem services (ESs) and the relationships among them is critical for successful ecosystem management. However, the impact of driving factors on the relationships between ESs and the formation of ecosystem service bundles (ESBs) remains unclear. To address this gap, we developed a modeling process that used random forest (RF) to model the ESs and ESBs of Zhejiang Province, China, in regression and classification mode, respectively, and the Shapley Additive Explanations (SHAP) method to interpret the underlying driving forces. We first mapped the spatial distribution of seven ESs in Zhejiang Province at a 1 × 1 km spatial resolution and then used the K-means clustering algorithm to obtain four ESBs. Combining the RF models with SHAP analysis, the results showed that each ES had key driving factors, and the relationships of synergy and trade-off between ESs were determined by the driving direction and intensity of the key factors. The driving factors affect the relationships of ESs and consequently affect the formation of ESBs. Thus, managing the dominant drivers is key to improving the supply capacity of ESs. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Driving force analysis; Ecosystem service; Ecosystem service bundles; Random forest; Shapley additive explanations","ecosystem service; machine learning; regression; spatial distribution; China; Zhejiang; China; ecosystem; environmental protection; machine learning; procedures; China; Conservation of Natural Resources; Ecosystem; Machine Learning"
"Xu Y., Zhang X., Li H., Zheng H., Zhang J., Olsen M.S., Varshney R.K., Prasanna B.M., Qian Q.","Smart breeding driven by big data, artificial intelligence, and integrated genomic-enviromic prediction","10.1016/j.molp.2022.09.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139728305&doi=10.1016%2fj.molp.2022.09.001&partnerID=40&md5=9aeda23ac4888c8a9261f178a502e75c","The first paradigm of plant breeding involves direct selection-based phenotypic observation, followed by predictive breeding using statistical models for quantitative traits constructed based on genetic experimental design and, more recently, by incorporation of molecular marker genotypes. However, plant performance or phenotype (P) is determined by the combined effects of genotype (G), envirotype (E), and genotype by environment interaction (GEI). Phenotypes can be predicted more precisely by training a model using data collected from multiple sources, including spatiotemporal omics (genomics, phenomics, and enviromics across time and space). Integration of 3D information profiles (G-P-E), each with multidimensionality, provides predictive breeding with both tremendous opportunities and great challenges. Here, we first review innovative technologies for predictive breeding. We then evaluate multidimensional information profiles that can be integrated with a predictive breeding strategy, particularly envirotypic data, which have largely been neglected in data collection and are nearly untouched in model construction. We propose a smart breeding scheme, integrated genomic-enviromic prediction (iGEP), as an extension of genomic prediction, using integrated multiomics information, big data technology, and artificial intelligence (mainly focused on machine and deep learning). We discuss how to implement iGEP, including spatiotemporal models, environmental indices, factorial and spatiotemporal structure of plant breeding data, and cross-species prediction. A strategy is then proposed for prediction-based crop redesign at both the macro (individual, population, and species) and micro (gene, metabolism, and network) scales. Finally, we provide perspectives on translating smart breeding into genetic gain through integrative breeding platforms and open-source breeding initiatives. We call for coordinated efforts in smart breeding through iGEP, institutional partnerships, and innovative technological support. © 2022 The Author","artificial intelligence; big data; crop design; genomic selection; integrated genomic-enviromic selection; machine and deep learning; smart breeding; spatiotemporal omics","artificial intelligence; genetic selection; genome; genomics; genotype; phenotype; plant breeding; procedures; Artificial Intelligence; Big Data; Genome; Genomics; Genotype; Phenotype; Plant Breeding; Selection, Genetic"
"Yan C., Li Z., Boota M.W., Zohaib M., Liu X., Shi C., Xu J.","River pattern discriminant method based on Rough Set theory","10.1016/j.ejrh.2022.101285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145589206&doi=10.1016%2fj.ejrh.2022.101285&partnerID=40&md5=1f59cf54171bfba54db0e544388f33b3","Study region: The Yellow River located in the north of China, the most hyper-concentrated sediment-laden rivers in the world, is featured by complicated spatiotemporal variation of river patterns. Study focus: River patterns contribute to comprehending the spatial morphological evolution of rivers associated with hydrological processes. However, it is still a challenge to effectively discriminate different river patterns due to the dynamics and variability of rivers. A solution is proposed to discriminate river patterns based on Rough Set theory via a holistic synthesis of multi-dimensional morphological information. First, a hierarchical structure integrating the boundary and the interior was suggested to maximally describe the morphological feature of river patterns. Rough Set theory was applied to select the main feature factors from multiple geometric indexes and landscape pattern indexes. Finally, river pattern discriminant rules were generated based on the reduced feature subsets. New hydrological insights for the region: Results demonstrate that 81 discriminant rules efficiently express the morphological feature of four river patterns. Compared with several competitive machine learning methods, river pattern discriminant rules display good performance, with the advantages of interpretability, simple modelling, and fewer training samples. Furthermore, the established discriminant rules of river patterns have achieved an accuracy of 98.63% in the application of the Lower Yellow River, which is expected to analyse the spatiotemporal evolution and geomorphological processes of different river patterns. © 2022","Discriminant rule; Feature selection; River patterns; Rough Set theory",
"Yan J., Cai J., Zhang B., Wang Y., Wong D.F., Siu S.W.I.","Recent Progress in the Discovery and Design of Antimicrobial Peptides Using Traditional Machine Learning and Deep Learning","10.3390/antibiotics11101451","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140486633&doi=10.3390%2fantibiotics11101451&partnerID=40&md5=6ae160de0081025b7e816b2a0601405a","Antimicrobial resistance has become a critical global health problem due to the abuse of conventional antibiotics and the rise of multi-drug-resistant microbes. Antimicrobial peptides (AMPs) are a group of natural peptides that show promise as next-generation antibiotics due to their low toxicity to the host, broad spectrum of biological activity, including antibacterial, antifungal, antiviral, and anti-parasitic activities, and great therapeutic potential, such as anticancer, anti-inflammatory, etc. Most importantly, AMPs kill bacteria by damaging cell membranes using multiple mechanisms of action rather than targeting a single molecule or pathway, making it difficult for bacterial drug resistance to develop. However, experimental approaches used to discover and design new AMPs are very expensive and time-consuming. In recent years, there has been considerable interest in using in silico methods, including traditional machine learning (ML) and deep learning (DL) approaches, to drug discovery. While there are a few papers summarizing computational AMP prediction methods, none of them focused on DL methods. In this review, we aim to survey the latest AMP prediction methods achieved by DL approaches. First, the biology background of AMP is introduced, then various feature encoding methods used to represent the features of peptide sequences are presented. We explain the most popular DL techniques and highlight the recent works based on them to classify AMPs and design novel peptide sequences. Finally, we discuss the limitations and challenges of AMP prediction. © 2022 by the authors.","antimicrobial peptide; classification; deep learning; machine learning; medicine; regression; therapeutic peptide","alpha helical peptide; beta sheet peptide; food preservative; peptide; polypeptide antibiotic agent; unclassified drug; agriculture; amino acid composition; animal husbandry; antibiotic resistance; antimicrobial activity; artificial intelligence; beta sheet; biomedicine; classification; contextual embedding; convolutional neural network; data processing; deep learning; deep neural network; drug design; drug development; drug industry; drug mechanism; ensemble learning; feature encoding; food industry; food packaging; food preservation; generative adversarial network; health survey; human; hybrid learning; information processing; learning; learning algorithm; long short term memory network; machine learning; medicine; nonhuman; pharmaceutics; prediction; process optimization; recurrent neural network; reproducibility; Review; sequence analysis; structure analysis; transfer of learning; vae machine learning; word embedding; workflow"
"Yan J., Wang X.","Unsupervised and semi-supervised learning: the next frontier in machine learning for plant systems biology","10.1111/tpj.15905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135171216&doi=10.1111%2ftpj.15905&partnerID=40&md5=e7855e1075f5b3d27f35caefb97debd8","Advances in high-throughput omics technologies are leading plant biology research into the era of big data. Machine learning (ML) performs an important role in plant systems biology because of its excellent performance and wide application in the analysis of big data. However, to achieve ideal performance, supervised ML algorithms require large numbers of labeled samples as training data. In some cases, it is impossible or prohibitively expensive to obtain enough labeled training data; here, the paradigms of unsupervised learning (UL) and semi-supervised learning (SSL) play an indispensable role. In this review, we first introduce the basic concepts of ML techniques, as well as some representative UL and SSL algorithms, including clustering, dimensionality reduction, self-supervised learning (self-SL), positive-unlabeled (PU) learning and transfer learning. We then review recent advances and applications of UL and SSL paradigms in both plant systems biology and plant phenotyping research. Finally, we discuss the limitations and highlight the significance and challenges of UL and SSL strategies in plant systems biology. © 2022 Society for Experimental Biology and John Wiley & Sons Ltd.","deep learning; machine learning; plant systems biology; semi-supervised learning; unsupervised learning","Big data; Clustering algorithms; Deep learning; Learning algorithms; Learning systems; Plants (botany); Supervised learning; Deep learning; High-throughput; Machine-learning; Omics technologies; Performance; Plant biology; Plant system biology; Plant systems; Semi-supervised learning; Systems biology; Unsupervised learning; algorithm; genetics; machine learning; plant; supervised machine learning; systems biology; Algorithms; Machine Learning; Plants; Supervised Machine Learning; Systems Biology"
"Yan Y., Chow A.H.F., Ho C.P., Kuo Y.-H., Wu Q., Ying C.","Reinforcement learning for logistics and supply chain management: Methodologies, state of the art, and future opportunities","10.1016/j.tre.2022.102712","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129696892&doi=10.1016%2fj.tre.2022.102712&partnerID=40&md5=9efb5306f7b2e34a7b37a6ca9ebcb43f","With advances in technologies, data science techniques, and computing equipment, there has been rapidly increasing interest in the applications of reinforcement learning (RL) to address the challenges resulting from the evolving business and organisational operations in logistics and supply chain management (SCM). This paper aims to provide a comprehensive review of the development and applications of RL techniques in the field of logistics and SCM. We first provide an introduction to RL methodologies, followed by a classification of previous research studies by application. The state-of-the-art research is reviewed and the current challenges are discussed. It is found that Q-learning (QL) is the most popular RL approach adopted by these studies and the research on RL for urban logistics is growing in recent years due to the prevalence of E-commerce and last mile delivery. Finally, some potential directions are presented for future research. © 2022 Elsevier Ltd","Actor-critic methods; Logistics; Markov decision process; Neural network; Q-learning; Reinforcement learning; Supply chain","artificial neural network; electronic commerce; future prospect; logistics; machine learning; Markov chain; supply chain management; urban transport"
"Yang C., Teng Z., Dong C., Lin Y., Chen R., Wang J.","In-Field Citrus Disease Classification via Convolutional Neural Network from Smartphone Images","10.3390/agriculture12091487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141775897&doi=10.3390%2fagriculture12091487&partnerID=40&md5=c13cf839d77edf7248e4bedd091be530","A high-efficiency, nondestructive, rapid, and automatic crop disease classification method is essential for the modernization of agriculture. To more accurately extract and fit citrus disease image features, we designed a new 13-layer convolutional neural network (CNN13) consisting of multiple convolutional layer stacks and dropout in this study. To address the problem created by the uneven number of disease images in each category, we used the VGG16 network module for transfer learning, which we combined with the proposed CNN13 to form a new joint network, which we called OplusVNet. To verify the performance of the proposed OplusVNet network, we collected 1869 citrus pest and disease images and 202 normal citrus images from the field. The experimental results showed that the proposed OplusVNet can more effectively solve the problem caused by uneven data volume and has higher recognition accuracy, especially for image categories with a relatively small data volume. Compared with the state of the art networks, the generalization ability of the proposed OplusVNet network is stronger for classifying diseases. The classification accuracy of the model prediction results was 0.99, indicating the model can be used as a reference for crop image classification. © 2022 by the authors.","citrus diseases; classification; convolutional neural network; field image; smartphone image; transfer learning",
"Yang C., Hou J., Wang Y.","Extraction of land covers from remote sensing images based on a deep learning model of NDVI-RSU-Net","10.1007/s12517-021-08420-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115716267&doi=10.1007%2fs12517-021-08420-5&partnerID=40&md5=174daa3ca92685a9a75ad0dada78501b","The acquisition of land-cover types is of great importance for land use and land planning. However, extracting accurate land-cover types using traditional methods such as visual interpretation, statistical analysis, and cluster analysis is difficult. Image segmentation method based on deep learning can effectively extract accurate land cover from a remote sensing image. First, a ReSidual U-block (RSU-Net) is first constructed in this paper according to the combination of U-Net, residual network, and attention mechanism. Then, a normalized vegetation index (NDVI) is added to the input feature channel to construct an NDVI-RSU-Net model to improve the extraction accuracy of land cover from the GaoFen-2 remote sensing images. Finally, the extraction results of the NDVI-RSU-Net model are compared with those of the full convolutional neural network (FCN), U-Net, LinkNet, VNet, RSU-Net, and ResU-Net models to verify the effectiveness of the NDVI-RSU-Net model in extracting land-cover types. The NDVI-RSU-Net model can extract the best classification accuracies of land-cover types with mean pixel accuracy (MPA) and mean intersection over union (MIOU) of 88.36% and 71.18%, respectively. The MPA and MIOU of the RSU-Net are higher than those of U-Net (85.34% and 65.10%, respectively), FCN (84.38% and 65.36%, respectively), ResU-Net (86.37% and 66.09%, respectively), LinkNet (81.89% and 55.43%, respectively), VNet (79.63% and 57.69%, respectively), and RSU-Net (87.24% and 67.69%, respectively). The combination of visible band, near infrared band, and NDVI is the best input channel of RSU-Net. The NDVI-RSU-Net model has a better segmentation effect on land-cover types from high-resolution remote sensing images than other deep learning algorithms. © 2021, Saudi Society for Geosciences.","Deep learning; High-resolution remote sensing image; Land cover; NDVI; RSU-Net","data acquisition; data interpretation; land cover; land use planning; machine learning; NDVI; remote sensing; satellite imagery; segmentation; visual analysis"
"Yang G., Li W., Meng B.","Spatiotemporal Distribution of Groundwater Ammonia Nitrogen Based on Machine Learning Methods [基于机器学习方法的地下水氨氮时空分布规律]","10.13278/j.cnki.jjuese.20220187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142322987&doi=10.13278%2fj.cnki.jjuese.20220187&partnerID=40&md5=8d5b7c2a0153cd4d94a8f39cf87ae341","Ammonia nitrogen is one of the main inorganic pollutants in groundwater, which mainly comes from agricultural, industrialy and domestic pollution. Excessive ammonia nitrogen will endanger human health. Temporal and spatial distribution of ammonia nitrogen is affected by factors such as meteorology, hydrology, hydrogeology, and land use type, so groundwater ammonia nitrogen analysis based on limited sampling points will generate great uncertainty. In this study, firstly, the Songhua River basin in the Sanjiang Plain was taken as an example, and soil organic matter mass fraction, soil total nitrogen mass fraction, soil cation exchange capacity (CEC), soil pH value, groundwater depth, thickness of clay layer in vadose zone and land use type were selected as potential influencing factors, a machine learning model for fitting ammonia nitrogen concentration was established. Secondly, significant influencing factors were identified using the shapley additive explanations (SHAP) method of interpreting machine learning models. Finally, a machine learning prediction model was established according to the significant influencing factors, and the data of groundwater ammonia nitrogen in the study area was interpolated. And the temporal and spatial variation of ammonia nitrogen was analyzed. The results showed that groundwater depth, land use type, CEC and soil organic matter mass fraction were the main influencing factors of groundwater ammonia nitrogen in this area. The area of groundwater ammonia nitrogen in the Ⅰ-Ⅲ water quality level showed an increasing trend. The proportion of area increased from 31% to 87%. And the area of Ⅳ-Ⅴ water quality showed a decreasing trend. The proportion of area decreased from 69% to 13%. The overall water quality was improved from 2011 to 2018. © 2022, Editorial Department of Journal of Jilin University(Earth Science Edition). All right reserved.","Ammonia; Machine learning; Random forest; SHAP; Spatial interpolation",
"Yang J., Zhu Y., Xiao S., Lan G., Li Y.","A controllable face forgery framework to enrich face-privacy-protection datasets","10.1016/j.imavis.2022.104566","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139368092&doi=10.1016%2fj.imavis.2022.104566&partnerID=40&md5=6462c371512101162598646d1f422d3d","Deep learning not only brings convenience to people, but also promotes the development of facial forgery technology. Considering the current personal portrait security issues, the tampering and forgery of facial data has attracted more and more attention. In order to solve the above issues, we try to implement from another novel angle, that is, enrich the face-privacy-protection dataset to improve the detection ability of forgery faces. Therefore, we propose a controllable face forgery framework. In this work, we firstly analyze the identity information in the latent features and construct an identity latent space based on StyleGAN's w+ latent space. Then, we propose an adaptive identity mapping network to edit the latent codes of the image through encoder and realize the identity transform. Finally, we further enhance the authenticity of the image through post-processing. In order to verify the superiority of our proposed method, we design extensive experiments. Experiments show the effectiveness of identity latent space and the controllability of our model. At the same time, it also shows that our proposed network can generate photo-level results and achieve excellent results in the comparison of other face swapping methods. © 2022 Elsevier B.V.","Data diversity; Explainable artificial intelligence; Facial forgery; Generative adversarial network; Latent feature analysis and manipulation; Privacy and security","Deep learning; Image enhancement; 'current; Data diversity; Explainable artificial intelligence; Facial data; Facial forgery; Feature analysis; Latent feature analyse and manipulation; Privacy and security; Privacy protection; Security issues; Generative adversarial networks"
"Yang M., Lim M.K., Qu Y., Ni D., Xiao Z.","Supply chain risk management with machine learning technology: A literature review and future research directions","10.1016/j.cie.2022.108859","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144046633&doi=10.1016%2fj.cie.2022.108859&partnerID=40&md5=3e21a36aa73c9e1d1c06e37278761d77","Coronavirus disease 2019 (COVID-19) has placed tremendous pressure on supply chain risk management (SCRM) worldwide. Recent technological advances, especially machine learning (ML) technology, have shown the possibility to prevent supply chain risk (SCR) by decreasing the need for human labor, increasing response speed, and predicting risk. However, the literature lacks a comprehensive analysis of the relationship between ML and SCRM. This work conducts a comprehensive review of the relatively limited literature in this field. An analysis of 67 shortlisted articles from 9 databases shows that this area is still in the rapid development stage and that researchers have shown extraordinary interest in it. The main purpose of this study is to review the current research status so that researchers have a clear understanding of the research gaps in this area. Moreover, this study provides an opportunity for researchers and practitioners to pay attention to ML algorithms for SCRM during the COVID-19 pandemic. © 2022 The Author(s)","Algorithm; COVID-19; Machine learning; Research status; Supply chain risk management","Engineering education; Machine learning; Risk management; Supply chain management; Supply chains; Future research directions; Human labor; Literature reviews; Machine learning technology; Machine-learning; Research status; Risks management; Supply chain risk management; Supply-chain risks; Technological advances; COVID-19"
"Yang P., Henle E.A., Fern X.Z., Simon C.M.","Classifying the toxicity of pesticides to honey bees via support vector machines with random walk graph kernels","10.1063/5.0090573","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135008849&doi=10.1063%2f5.0090573&partnerID=40&md5=732db954af33e7f563ce2b988e9b3662","Pesticides benefit agriculture by increasing crop yield, quality, and security. However, pesticides may inadvertently harm bees, which are valuable as pollinators. Thus, candidate pesticides in development pipelines must be assessed for toxicity to bees. Leveraging a dataset of 382 molecules with toxicity labels from honey bee exposure experiments, we train a support vector machine (SVM) to predict the toxicity of pesticides to honey bees. We compare two representations of the pesticide molecules: (i) a random walk feature vector listing counts of length-L walks on the molecular graph with each vertex- and edge-label sequence and (ii) the Molecular ACCess System (MACCS) structural key fingerprint (FP), a bit vector indicating the presence/absence of a list of pre-defined subgraph patterns in the molecular graph. We explicitly construct the MACCS FPs but rely on the fixed-length-L random walk graph kernel (RWGK) in place of the dot product for the random walk representation. The L-RWGK-SVM achieves an accuracy, precision, recall, and F1 score (mean over 2000 runs) of 0.81, 0.68, 0.71, and 0.69, respectively, on the test data set - with L = 4 being the mode optimal walk length. The MACCS-FP-SVM performs on par/marginally better than the L-RWGK-SVM, lends more interpretability, but varies more in performance. We interpret the MACCS-FP-SVM by illuminating which subgraph patterns in the molecules tend to strongly push them toward the toxic/non-toxic side of the separating hyperplane. © 2022 Author(s).",,"Food products; Molecules; Pesticides; Random processes; Statistical tests; Toxicity; Vectors; Access system; Crop yield; Features vector; Graph kernels; Honey bee; Molecular graphs; Random Walk; Subgraphs; Support vectors machine; Yield quality; Support vector machines; pesticide; animal; bee; support vector machine; Animals; Bees; Pesticides; Support Vector Machine"
"Yang P., Cai X., Khanna M.","Farmers' heterogeneous perceptions of marginal land for biofuel crops in US Midwestern states considering biophysical and socioeconomic factors","10.1111/gcbb.12821","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102559833&doi=10.1111%2fgcbb.12821&partnerID=40&md5=fab8f3a611d89be800a12bc95daea3bb","Planting bioenergy crops on marginal land is critical for avoiding competition with food crop production. While many studies have estimated marginal land availability using various methods, only a few studies have considered the role of socioeconomic factors in affecting perceptions about the availability of marginal land. This study analyzes land-use survey data to examine the determinants of farmers' perceptions of marginal land availability on their farms. We find that farmers' perceptions are affected by a combination of unfavorable biophysical (e.g., soil water capacity, temperature variability, and slope) and socioeconomic factors, of which farm size appears to be significant. Interestingly, we identify different determinants of perceptions among farmers that claim to have marginal land and those that do not; the former are determined mainly by unfavorable biophysical factors, while the latter are mainly explained by small farm size. We further apply a prediction model that is trained by a machine learning algorithm to Midwestern states, and derive maps of marginal land likelihood and associated dominant influencing factors. The results suggest that marginal land is primarily under pastureland and grassland cover and in the Dakotas and Nebraska; there is also some marginal land under crop production in the Corn Belt. Our findings contribute to improving understanding of the complex determinants of heterogeneous perceptions of marginal land and can inform the design of more targeted policies for bioenergy crop adoption. © 2021 The Authors. GCB Bioenergy Published by John Wiley & Sons Ltd","cellulosic biofuel development; land-use perceptions; machine learning; marginal land; survey analysis; US Midwestern states","Biofuels; Biophysics; Cultivation; Economics; Land use; Learning algorithms; Machine learning; Predictive analytics; Soil moisture; Surveys; Turing machines; Bioenergy crops; Biophysical factors; Crop production; Farmers' perceptions; Marginal lands; Prediction model; Socio-economic factor; Temperature variability; Crops; algorithm; bioenergy; biofuel; cellulose; computer simulation; crop production; farm size; physiological response; socioeconomic indicator; Corn Belt; United States"
"Yang Q., Wu L., Meng J., Ma L., Zuo E., Sun Y.","EpiCas-DL: Predicting sgRNA activity for CRISPR-mediated epigenome editing by deep learning","10.1016/j.csbj.2022.11.034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143845922&doi=10.1016%2fj.csbj.2022.11.034&partnerID=40&md5=85cd7965d75b1f2975dbc107c6971997","CRISPR-mediated epigenome editing enables gene expression regulation without changing the underlying DNA sequence, and thus has vast potential for basic research and gene therapy. Effective selection of a single guide RNA (sgRNA) with high on-target efficiency and specificity would facilitate the application of epigenome editing tools. Here we performed an extensive analysis of CRISPR-mediated epigenome editing tools on thousands of experimentally examined on-target sites and established EpiCas-DL, a deep learning framework to optimize sgRNA design for gene silencing or activation. EpiCas-DL achieves high accuracy in sgRNA activity prediction for targeted gene silencing or activation and outperforms other available in silico methods. In addition, EpiCas-DL also identifies both epigenetic and sequence features that affect sgRNA efficacy in gene silencing and activation, facilitating the application of epigenome editing for research and therapy. EpiCas-DL is available at http://www.sunlab.fun:3838/EpiCas-DL. © 2022 The Authors","Convolutional neural network; CRISPR-mediated epigenome editing; Deep learning; EpiCas-DL; Gene activation; Gene silencing","Activation analysis; Convolutional neural networks; Deep learning; Gene expression; Gene therapy; Genetic engineering; Convolutional neural network; CRISPR-mediated epigenome editing; Deep learning; Editing tools; Epica-DL; Epigenomes; Gene activation; Gene silencing; Learning frameworks; Target sites; Chemical activation; guide RNA; Article; chromatin; clustered regularly interspaced short palindromic repeat; comparative study; controlled study; convolutional neural network; cross validation; deep learning; DNA methylation age; DNA sequence; epigenome; gene activation; gene editing; gene expression; gene silencing; human; machine learning; nucleosome"
"Yang R., Wibowo S.","User trust in artificial intelligence: A comprehensive conceptual framework","10.1007/s12525-022-00592-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141343234&doi=10.1007%2fs12525-022-00592-6&partnerID=40&md5=e4e6565586ef55d1b9b78a960bc15307","This paper provides a systematic literature review of current studies between January 2015 and January 2022 on user trust in artificial intelligence (AI) that has been conducted from different perspectives. Such a review and analysis leads to the identification of the various components, influencing factors, and outcomes of users’ trust in AI. Based on the findings, a comprehensive conceptual framework is proposed for a better understanding of users’ trust in AI. This framework can further be tested and validated in various contexts for enhancing our knowledge of users’ trust in AI. This study also provides potential future research avenues. From a practical perspective, it helps AI-supported service providers comprehend the concept of user trust from different perspectives. The findings highlight the importance of building trust based on different facets to facilitate positive cognitive, affective, and behavioral changes among the users. © 2022, The Author(s), under exclusive licence to Institute of Applied Informatics at University of Leipzig.","AI; Comprehensive framework; Literature review; Trust; User",
"Yang R., Liu L., Liu Q., Li X., Yin L., Hao X., Ma Y., Song Q.","Validation of leaf area index measurement system based on wireless sensor network","10.1038/s41598-022-08373-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126714765&doi=10.1038%2fs41598-022-08373-z&partnerID=40&md5=09ef8fa828a711599a12c6c2da44ce10","Accurate measurement of leaf area index (LAI) is important for agricultural analysis such as the estimation of crop yield, which makes its measurement work important. There are mainly two ways to obtain LAI: ground station measurement and remote sensing satellite monitoring. Recently, reliable progress has been made in long-term automatic LAI observation using wireless sensor network (WSN) technology under certain conditions. We developed and designed an LAI measurement system (LAIS) based on a wireless sensor network to select and improve the appropriate algorithm according to the image collected by the sensor, to get a more realistic leaf area index. The corn LAI was continuously observed from May 30 to July 16, 2015. Research on hardware has been published, this paper focuses on improved system algorithm and data verification. By improving the finite length average algorithm, the data validation results are as follows: (1) The slope of the fitting line between LAIS measurement data and the real value is 0.944, and the root means square error (RMSE) is 0.264 (absolute error ~ 0–0.6), which has high consistency with the real value. (2) The measurement error of LAIS is less than LAI2000, although the result of our measurement method will be higher than the actual value, it is due to the influence of weeds on the ground. (3) LAIS data can be used to support the retrieval of remote sensing products. We find a suitable application situation of our LAIS system data, and get our application value as ground monitoring data by the verification with remote sensing product data, which supports its application and promotion in similar research in the future. © 2022, The Author(s).",,"agriculture; algorithm; ecosystem; plant leaf; remote sensing; Agriculture; Algorithms; Ecosystem; Plant Leaves; Remote Sensing Technology"
"Yang S.J.H., Ogata H., Matsui T., Chen N.-S.","Human-centered artificial intelligence in education: Seeing the invisible through the visible","10.1016/j.caeai.2021.100008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102959137&doi=10.1016%2fj.caeai.2021.100008&partnerID=40&md5=b61e5ac9c4597c56a6418daeb4c2b337","The inevitable rise and development of artificial intelligence (AI) was not a sudden occurrence. The greater the effect that AI has on humans, the more pressing the need is for us to understand it. This paper addresses research on the use of AI to evaluate new design methods and tools that can be leveraged to advance AI research, education, policy, and practice to improve the human condition. AI has the potential to educate, train, and improve the performance of humans, making them better at their tasks and activities. The use of AI can enhance human welfare in numerous respects, such as through improving the productivity of food, health, water, education, and energy services. However, the misuse of AI due to algorithm bias and a lack of governance could inhibit human rights and result in employment, gender, and racial inequality. We envision that AI can evolve into human-centered AI (HAI), which refers to approaching AI from a human perspective by considering human conditions and contexts. Most current discussions on AI technology focus on how AI can enable human performance. However, we explore AI can also inhibit the human condition and advocate for an in-depth dialog between technology- and humanity-based researchers to improve understanding of HAI from various perspectives. © 2021 The Author(s)","Explainable AI; Human-centered AI; Interpretable ML; Smart learning; Sustainable AI",
"Yang Y., Shahbeik H., Shafizadeh A., Masoudnia N., Rafiee S., Zhang Y., Pan J., Tabatabaei M., Aghbashlo M.","Biomass microwave pyrolysis characterization by machine learning for sustainable rural biorefineries","10.1016/j.renene.2022.11.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143124076&doi=10.1016%2fj.renene.2022.11.028&partnerID=40&md5=127841404b6b4bc2590820af205815a2","Microwave heating is a promising solution to overcome the shortcomings of conventional heating in biomass pyrolysis. Nevertheless, biomass microwave pyrolysis is a complex thermochemical process governed by several endogenous and exogenous parameters. Modeling such a complicated process is challenging due to the need for many experimental measurements. Machine learning can effectively cope with the time and cost constraints of experiments. Hence, this study uses machine learning to model the quantity and quality of products (biochar, bio-oil, and syngas) that evolve in biomass microwave pyrolysis. An inclusive dataset encompassing different biomass types, microwave absorbers, and reaction conditions is selected from the literature and subjected to data mining. Three machine learning models (support vector regressor, random forest regressor, and gradient boost regressor) are used to model the process based on 14 descriptors. The gradient boost regressor model provides better prediction performance (R2 &gt; 0.822, RMSE &lt;12.38, and RRMSE &lt;0.765) than the other models. SHAP analysis generally reveals the significance of operating temperature, microwave power, and reaction time in predicting the output responses. Overall, the developed machine learning model can effectively save cost and time during biomass microwave pyrolysis while serving as a valuable tool for guiding experiments and facilitating optimization. © 2022 Elsevier Ltd","Bio-oil; Biochar; Biomass microwave pyrolysis; Gradient boost regressor; Machine learning; Syngas","Data mining; Decision trees; Learning systems; Microwave heating; Microwaves; Pyrolysis; Support vector machines; Synthesis gas; Bio-oils; Biochar; Biomass microwave pyrolyse; Biorefineries; Gradient boost regressor; Machine learning models; Machine-learning; Microwave pyrolysis; Microwave reactions; Syn gas; Biomass; biofuel; biomass; heating; machine learning; pyrolysis"
"Yang Z., Li H.-Q., Zhai J.-N., Zhang L.-H., Nan Q.","Review on the assessment model of nutrient recycling with agricultural residues treatment technologies [农业废弃物养分循环利用技术模式评估模型的研究进展]","10.13287/j.1001-9332.202212.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145463211&doi=10.13287%2fj.1001-9332.202212.022&partnerID=40&md5=7fb1350306bc165a087935d0cc291977","The technology for nutrient resource utilization of agricultural residues is crucial to realizing a circular agricultural economy. The assessment model provides essential support to optimize nutrient recovery and treatment technologies. We specifically summarized research progress in the assessment framework of agricultural residues nutrient recycling technology, assessment models and evaluation indicators, data sources of models and their uncertainty analysis, and the application scale of models. We found that process mathematical models and industrial eco-logy models are the common nutrient flow assessment models. Process mathematical and industrial ecology models differed greatly in terms of the reliability of assessment results and the simulation scale. The former mainly focused at laboratory or pilot scale, with higher accuracy. The latter could achieve multi-scale simulation from microscopic to macroscopic and had higher uncertainty, due to the way its data were obtained. Finally, we provided an outlook on the research on the assessment model of agricultural residues nutrient resource utilisation technology. In order to achieve accurate assessment of waste resource utilisation technology in agricultural production systems at the regional scale, a reliable model framework and database should be established by combining process mathematical models with industrial ecology models. Meanwhile, we should carry out research on model expansion at the geographical scales of factory scale, farm scale, village scale, township scale, and regional scale. © 2022, Science Press. All right reserved.","Agricultural waste; Anaerobic digestion; Composting; Industrial ecology modelling; Nutrient recovery; Process modelling","agricultural production; industrial ecology; recycling; village; waste treatment; agriculture; geography; recycling; reproducibility; technology; Agriculture; Geography; Nutrients; Recycling; Reproducibility of Results; Technology"
"Ye Y., Zhou H., Yu H., Hu H., Zhang G., Hu J., He T.","An Improved EfficientNetV2 Model Based on Visual Attention Mechanism: Application to Identification of Cassava Disease","10.1155/2022/1569911","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140936294&doi=10.1155%2f2022%2f1569911&partnerID=40&md5=c4646101f0aee06e836caa0052d07509","With the characteristic of high recognition rate and strong network robustness, convolutional neural network has now become the most mainstream method in the field of crop disease recognition. Aiming at the problems with insufficient numbers of labeled samples, complex backgrounds of sample images, and difficult extraction of useful feature information, a novel algorithm is proposed in this study based on attention mechanisms and convolutional neural networks for cassava leaf recognition. Specifically, a combined data augmentation strategy for datasets is used to prevent single distribution of image datasets, and then the PDRNet (plant disease recognition network) combining channel attention mechanism and spatial attention mechanism is proposed. The algorithm is designed as follows. Firstly, an attention module embedded in the network layer is deployed to establish remote dependence on each feature layer, strengthen the key feature information, and suppress the interference feature information, such as background noise. Secondly, a stochastic depth learning strategy is formulated to accelerate the training and inference of the network. And finally, a transfer learning method is adopted to load the pretrained weights into the model proposed in this study, with the recognition accuracy of the model enhanced by means of detailed parameter adjustments and dynamic changes in the learning rate. A large number of comparative experiments demonstrate that the proposed algorithm can deliver a recognition accuracy of 99.56% on the cassava disease image dataset, reaching the state-of-the-art level among CNN-based methods in terms of accuracy. © 2022 Yuanbo Ye et al.",,"Behavioral research; Convolution; Large dataset; Learning systems; Network layers; Plants (botany); Stochastic systems; Attention mechanisms; Complex background; Convolutional neural network; Crop disease; Feature information; Image datasets; Model-based OPC; Network robustness; Recognition accuracy; Visual attention mechanisms; Convolutional neural networks; algorithm; Manihot; methodology; Algorithms; Manihot; Neural Networks, Computer; Recognition, Psychology; Research Design"
"Yee J., Igarashi D., Yamanaka A., Tagawa Y.","Features of a Splashing Drop on a Solid Surface and the Temporal Evolution extracted through Image-Sequence Classification using an Interpretable Feedforward Neural Network","10.2514/6.2022-4174","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135223516&doi=10.2514%2f6.2022-4174&partnerID=40&md5=6ec4f47fd73877cd44f43c58d25d8193","This paper reports the features of a splashing drop on a solid surface and the temporal evolution, which are extracted through image-sequence classification using a highly interpretable feedforward neural network (FNN) with zero hidden layer. The image sequences used for training-validation and testing of the FNN show the early-stage deformation of milli-sized ethanol drops that impact a hydrophilic glass substrate with the Weber number ranges between 31–474 (splashing threshold about 173). Specific videographing conditions and digital image processing are performed to ensure the high similarity among the image sequences. As a result, the trained FNNs achieved a test accuracy higher than 96%. Remarkably, the feature extraction shows that the trained FNN identifies the temporal evolution of the ejected secondary droplets around the aerodynamically lifted lamella and the relatively high contour of the main body as the features of a splashing drop, while the relatively short and thick lamella as the feature of a nonsplashing drop. The physical interpretation for these features and their respective temporal evolution have been identified except for the difference in contour height of the main body between splashing and nonsplashing drops. The observation reported in this study is important for the development of a data-driven simulation for modeling the deformation of a splashing drop during the impact on a solid surface. © 2022, American Institute of Aeronautics and Astronautics Inc, AIAA. All rights reserved.",,"Classification (of information); Deformation; Image classification; Multilayer neural networks; Glass substrates; Hidden layers; Hydrophilic glass; Image sequence; Main bodies; Sequence classification; Solid surface; Splashing threshold; Temporal evolution; Weber numbers; Substrates"
"Yee J., Yamanaka A., Tagawa Y.","Image features of a splashing drop on a solid surface extracted using a feedforward neural network","10.1063/5.0077050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123765056&doi=10.1063%2f5.0077050&partnerID=40&md5=7adc6b2211504752c420436d5a278a21","This article reports nonintuitive characteristic of a splashing drop on a solid surface discovered through extracting image features using a feedforward neural network (FNN). Ethanol of area-equivalent radius about 1.29 mm was dropped from impact heights ranging from 4 cm to 60 cm (splashing threshold 20 cm) and impacted on a hydrophilic surface. The images captured when half of the drop impacted the surface were labeled according to their outcome, splashing or nonsplashing, and were used to train an FNN. A classification accuracy ≥ 96 % was achieved. To extract the image features identified by the FNN for classification, the weight matrix of the trained FNN for identifying splashing drops was visualized. Remarkably, the visualization showed that the trained FNN identified the contour height of the main body of the impacting drop as an important characteristic differentiating between splashing and nonsplashing drops, which has not been reported in previous studies. This feature was found throughout the impact, even when one and three-quarters of the drop impacted the surface. To confirm the importance of this image feature, the FNN was retrained to classify using only the main body without checking for the presence of ejected secondary droplets. The accuracy was still ≥ 82 %, confirming that the contour height is an important feature distinguishing splashing from nonsplashing drops. Several aspects of drop impact are analyzed and discussed with the aim of identifying the possible mechanism underlying the difference in contour height between splashing and nonsplashing drops. © 2022 Author(s).",,"Drops; Image processing; Classification accuracy; Equivalent radius; Hydrophilic surfaces; Image features; Important features; Main bodies; Secondary droplets; Solid surface; Splashing threshold; Weight matrices; Feedforward neural networks"
"Yi S., Raza Abbasi K., Hussain K., Albaker A., Alvarado R.","Environmental concerns in the United States: Can renewable energy, fossil fuel energy, and natural resources depletion help?","10.1016/j.gr.2022.12.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147207440&doi=10.1016%2fj.gr.2022.12.021&partnerID=40&md5=b9be1cba58ba04af5dca798dba5b0931","The United States is the second-largest polluter in the world, producing 4.7 billion metric tonnes of carbon dioxide in 2020. At the Leaders' Climate Summit, the US president outlined specific targets to tackle climate change, including a 50 to 52 percent reduction in net CO2 emissions from 2005 levels by 2030. Therefore, it is critical to pinpoint the key factors succumbing to the heightened commitment to accomplishing the SDGs. The study explores the relationship between renewable energy, fossil fuel energy, natural resources depletion, and globalization on CO2 emissions in the United States from 1980 to 2018 by employing the novel dynamic Autoregressive Distributed Lag (ARDL) simulations and Kernel-based Regularized Least Squares (KRLS) machine learning approach. The findings indicated that renewable energy has a positive long-term impact, suggesting that the United States has not yet reached a point where renewable energy sources are sufficient to reduce CO2 emissions. However, shock in fossil fuel energy increases CO2 emissions in the long run. The empirical findings reveal that natural resource depletion stimulates CO2 emissions in the short- and long run. Finally, globalization found no evidence to affect environmental pollution. The KRLS approach has confirmed the hypothesis substantially. The results suggest the growth of renewable energy and diminishing dependency on fossil fuel use; also, the management of ecological footprint could play an imperative role in environmental sustainability. © 2023 International Association for Gondwana Research","Dynamic ARDL; Fossil fuel energy; Natural resources depletion; Renewable energy",
"Yi Z., Wu L.","Identification of factors influencing net primary productivity of terrestrial ecosystems based on interpretable machine learning –evidence from the county-level administrative districts in China","10.1016/j.jenvman.2022.116798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142398652&doi=10.1016%2fj.jenvman.2022.116798&partnerID=40&md5=d76809cb745c2c93dfa1472ad2b4b7fa","Global climate change is rooted in the imbalance between carbon sources and sinks, and net-zero greenhouse gas emissions should focus not only on the source-side drivers but also on the sink-side influencing factors. Taking the county-level administrative districts in China as the sample, this study uses machine learning models to fit the relationship between socioeconomic development (SED) and net primary productivity (NPP) of terrestrial ecosystems. Moreover, it identifies key influencing factors and their effects based on the SHapley Additive exPlanations (SHAP) algorithm. The results show that the districts with low terrestrial NPP show the characteristics of agglomeration distribution. The eight key factors, in order, are as follows: agricultural development level, latitude, population size, longitude, animal husbandry development level, economic scale, time trend and industrialization level. In this study, via SHAP interaction plots, we found that the effects of population, economic growth, and industrialization on terrestrial NPP are regionally heterogeneous; via cluster analysis, we found the stage characteristics of the mode of SED affecting terrestrial NPP. Therefore, the conservation of terrestrial NPP needs to be combined with the stage changes of SED, as well as inter-regional differences, to develop a regionally coordinated and time-coherent ecological carbon sink conservation plan. © 2022 Elsevier Ltd","Interpretable machine learning; Net primary productivity (NPP); SHapley Additive exPlanations (SHAP); Socioeconomic development (SED)","agricultural development; animal husbandry; carbon sink; climate change; greenhouse gas; identification method; industrialization; machine learning; net primary production; socioeconomic impact; algorithm; animal husbandry; article; carbon sink; China; cluster analysis; economic development; ecosystem; human; industrialization; latitude; longitude; machine learning; population size; productivity; China"
"Yigitcanlar T., Cugurullo F.","The sustainability of artificial intelligence: an urbanistic viewpoint from the lens of smart and sustainable cities","10.3390/su12208548","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092904760&doi=10.3390%2fsu12208548&partnerID=40&md5=3f67cac92f5f69cf117c77179484ca5b","The popularity and application of artificial intelligence (AI) are increasing rapidly all around the world—where, in simple terms, AI is a technology which mimics the behaviors commonly associated with human intelligence. Today, various AI applications are being used in areas ranging from marketing to banking and finance, from agriculture to healthcare and security, from space exploration to robotics and transport, and from chatbots to artificial creativity and manufacturing. More recently, AI applications have also started to become an integral part of many urban services. Urban artificial intelligences manage the transport systems of cities, run restaurants and shops where every day urbanity is expressed, repair urban infrastructure, and govern multiple urban domains such as traffic, air quality monitoring, garbage collection, and energy. In the age of uncertainty and complexity that is upon us, the increasing adoption of AI is expected to continue, and so its impact on the sustainability of our cities. This viewpoint explores and questions the sustainability of AI from the lens of smart and sustainable cities, and generates insights into emerging urban artificial intelligences and the potential symbiosis between AI and a smart and sustainable urbanism. In terms of methodology, this viewpoint deploys a thorough review of the current status of AI and smart and sustainable cities literature, research, developments, trends, and applications. In so doing, it contributes to existing academic debates in the fields of smart and sustainable cities and AI. In addition, by shedding light on the uptake of AI in cities, the viewpoint seeks to help urban policymakers, planners, and citizens make informed decisions about a sustainable adoption of AI. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Artificial intelligence (AI); Artificially intelligent city; Climate change; Planetary challenges; Smart and sustainable cities; Smart city; Sustainable urbanism; Technological disruption; Urban artificial intelligences; Urban policy","air quality; artificial intelligence; atmospheric pollution; banking; financial market; marketing; robotics; sustainable development; trend analysis; urban area"
"Yilmazer R., Birant D.","Shelf auditing based on image classification using semi-supervised deep learning to increase on-shelf availability in grocery stores","10.3390/s21020327","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099134115&doi=10.3390%2fs21020327&partnerID=40&md5=af143d8cd41ddf31cdc6066018d386aa","Providing high on-shelf availability (OSA) is a key factor to increase profits in grocery stores. Recently, there has been growing interest in computer vision approaches to monitor OSA. However, the largest and well-known computer vision datasets do not provide annotation for store products, and therefore, a huge effort is needed to manually label products on images. To tackle the annotation problem, this paper proposes a new method that combines two concepts “semi-supervised learning” and “on-shelf availability” (SOSA) for the first time. Moreover, it is the first time that “You Only Look Once” (YOLOv4) deep learning architecture is used to monitor OSA. Furthermore, this paper provides the first demonstration of explainable artificial intelligence (XAI) on OSA. It presents a new software application, called SOSA XAI, with its capabilities and advantages. In the experimental studies, the effectiveness of the proposed SOSA method was verified on image datasets, with different ratios of labeled samples varying from 20% to 80%. The experimental results show that the proposed approach outperforms the existing approaches (RetinaNet and YOLOv3) in terms of accuracy. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Explainable artificial intelligence; Image classification; Machine learning; On-shelf availability; Semi-supervised learning","Application programs; Computer vision; Image classification; Semi-supervised learning; Grocery stores; Image datasets; Key factors; Label products; Learning architectures; On shelf availabilities; Semi-supervised; Software applications; Deep learning; article; artificial intelligence; deep learning; experimental study; semi supervised machine learning; software"
"York L.M., Cumming J.R., Trusiak A., Bonito G., von Haden A.C., Kalluri U.C., Tiemann L.K., Andeer P.F., Blanc-Betes E., Diab J.H., Favela A., Germon A., Gomez-Casanovas N., Hyde C.A., Kent A.D., Ko D.K., Lamb A., Missaoui A.M., Northen T.R., Pu Y., Ragauskas A.J., Raglin S., Scheller H.V., Washington L., Yang W.H.","Bioenergy Underground: Challenges and opportunities for phenotyping roots and the microbiome for sustainable bioenergy crop production","10.1002/ppj2.20028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145898102&doi=10.1002%2fppj2.20028&partnerID=40&md5=2f2608820603ee60a3358b1b775756fd","Bioenergy production often focuses on the aboveground feedstock production for conversion to fuel and other materials. However, the belowground component is crucial for soil carbon sequestration, greenhouse gas fluxes, and ecosystem function. Roots maximize feedstock production on marginal lands by acquiring soil resources and mediating soil ecosystem processes through interactions with the microbial community. This belowground world is challenging to observe and quantify; however, there are unprecedented opportunities using current methodologies to bring roots, microbes, and soil into focus. These opportunities allow not only breeding for increased feedstock production but breeding for increased soil health and carbon sequestration as well. A recent workshop hosted by the USDOE Bioenergy Research Centers highlighted these challenges and opportunities while creating a roadmap for increased collaboration and data interoperability through standardization of methodologies and data using F.A.I.R. principles. This article provides a background on the need for belowground research in bioenergy cropping systems, a primer on root system properties of major U.S. bioenergy crops, and an overview of the roles of root chemistry, exudation, and microbial interactions on sustainability. Crucially, we outline how to adopt standardized measures and databases to meet the most pressing methodological needs to accelerate root, soil, and microbial research to meet the pressing societal challenges of the century. © 2022 Oak Ridge National Laboratory, managed by UT-Battelle, LLC. The Plant Phenome Journal published by Wiley Periodicals LLC on behalf of American Society of Agronomy and Crop Science Society of America.",,
"Yousefinaghani S., Dara R., Poljak Z., Song F., Sharif S.","A framework for the risk prediction of avian influenza occurrence: An Indonesian case study","10.1371/journal.pone.0245116","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099817626&doi=10.1371%2fjournal.pone.0245116&partnerID=40&md5=551e85603d1f2799c0b249a653df59d8","Avian influenza viruses can cause economically devastating diseases in poultry and have the potential for zoonotic transmission. To mitigate the consequences of avian influenza, disease prediction systems have become increasingly important. In this study, we have proposed a framework for the prediction of the occurrence and spread of avian influenza events in a geographical area. The application of the proposed framework was examined in an Indonesian case study. An extensive list of historical data sources containing disease predictors and target variables was used to build spatiotemporal and transactional datasets. To combine disparate sources, data rows were scaled to a temporal scale of 1-week and a spatial scale of 1-degree × 1-degree cells. Given the constructed datasets, underlying patterns in the form of rules explaining the risk of occurrence and spread of avian influenza were discovered. The created rules were combined and ordered based on their importance and then stored in a knowledge base. The results suggested that the proposed framework could act as a tool to gain a broad understanding of the drivers of avian influenza epidemics and may facilitate the prediction of future disease events. © 2021 Yousefinaghani et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"Article; avian influenza; case study; conceptual framework; controlled study; data analysis; epidemic; geographic distribution; historical period; Indonesia; infection risk; information processing; knowledge base; prediction; risk assessment; virus transmission; animal; avian influenza; biological model; bird; Influenza A virus; Animals; Birds; Disease Outbreaks; Indonesia; Influenza A virus; Influenza in Birds; Models, Biological"
"Yu F., Lu T., Han B., Xue C.","A quantitative study of aggregation behaviour and integrity of spray-dried microcapsules using three deep convolutional neural networks with transfer learning","10.1016/j.jfoodeng.2021.110515","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100460284&doi=10.1016%2fj.jfoodeng.2021.110515&partnerID=40&md5=006259a60506c67b79a8248feca731c6","Deep convolutional neural networks (DCNN) with transfer learning were employed to automatically identify, classify, and quantify two morphological characteristics (aggregated or non-aggregated, and intact or broken) of spray-dried microcapsules in scanning electron microscope (SEM) images. Three DCNN-based models with different network depths were compared in terms of classification accuracy, training and testing times, feature visualization, and strongest activations. The novelties of this study are 1) the introduction of DCNN to analyse SEM images of microcapsules and the classification accuracy of all models is above 91%, 2) the application of transfer learning not only reduces the dependence of DCNN on high-performance computers and large-scale datasets but also reduces training time, 3) feature visualization and strongest activations demonstrate the understanding of morphological characteristics of microcapsules from the perspective of DCNN, and 4) the proposed method can be run on a personal computer and is suitable for widespread use in routine laboratories. © 2021 Elsevier Ltd","Deep convolutional neural networks; Microcapsules; Morphological characteristics; Scanning electron microscope image; Transfer learning","Chemical activation; Classification (of information); Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Large dataset; Microstructure; Personal computers; Scanning electron microscopy; Spray drying; Visualization; Aggregation behaviours; Classification accuracy; High performance computers; Large-scale datasets; Morphological characteristic; Network depths; Quantitative study; Training and testing; Transfer learning"
"Yu H., Li X., Feng Y., Han S.","Multiple attentional path aggregation network for marine object detection","10.1007/s10489-022-03622-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129723074&doi=10.1007%2fs10489-022-03622-0&partnerID=40&md5=8845121add59aa60cb1deaaac2a98dc8","Marine target detection is a challenging task because degraded underwater images cause unclear targets. Furthermore, marine targets are small in size and tend to live together. The popular object detection methods perform poorly in marine target detection. Thus, this paper proposes a novel multiple attentional path aggregation network named APAN to improve performance on marine object detection. Firstly, we design a path aggregation network structure which brings features from backbone network to bottom-up path augmentation. Each feature map is enhanced by the lower layer through the bottom-up downsampling pathway and incorporates the features from top-down upsampling layers. Specifically, the last layer fuses feature map from backbone network which enhances the semantic features and improve the ability of feature extraction. Then, a multi-attention which combines coordinate competing attention and spatial supplement attention applies to proposed path aggregation network. Multi-attention can further improve the accuracy of multiple marine object detection. Finally, a double transmission underwater image enhancement algorithm is proposed to enhance the underwater image datasets. The experiments show our method achieves 79.6% mAP in underwater image datasets and 79.03% mAP in enhanced underwater image datasets. Meanwhile, our method achieves 81.5% mAP in PASCAL VOC datasets. In addition, we also applly the method to the underwater robot. The experiments show our method achieves good performance compared with popular object detection methods. The source code is publicly available at https://github.com/yhf2022/APAN. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Marine target detection; Multi-attention; Path aggregation network; Underwater image enhancement","Image enhancement; Object recognition; Semantics; Signal sampling; Aggregation network; Image datasets; Marine objects; Marine target detections; Multi-attention; Object detection method; Objects detection; Path aggregation; Path aggregation network; Underwater image enhancements; Object detection"
"Yu H., Zhao Z., Luo D., Cheng F.","Interpretable machine learning for investigating complex nanomaterial-plant-soil interactions","10.1039/d2en00181k","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141381286&doi=10.1039%2fd2en00181k&partnerID=40&md5=cf742db7fdd4e77a4afdeb522b4ec3af","Soil serves as the main recipient of engineered nanomaterials (ENMs). Understanding the complex nanomaterial-plant-soil interactions is urgently needed to keep pace with the safety concerns of ENMs. Machine learning, suitable for learning complex patterns, has been used to predict the root uptake and translocation of ENMs. However, these models usually exist as black boxes, which are difficult to extract information and build trust. In this study, we first integrated the establishment, performance analysis, post hoc interpretation, and interpretation validation of light gradient boosting machine (LightGBM) model to investigate the root uptake of metal-oxide nanoparticles (MONPs) in the soil environment. The influence of the dataset split and data preprocessing on model performance was discussed as only limited data were available. Model predictions were explained by different post hoc interpretation methods to identify key factors and show how they affect the root uptake of MONPs and interact with the other factors. A three-step validation of the interpretation results was presented for assessing the reliability of the models and explanations. Further, a rule-based ensemble method with good interpretability, the RuleFit algorithm, was established to provide a model-based interpretation by generating rules and compared with post hoc interpretation methods. These post hoc and model-based interpretation methods can be integrated with experiments to promote the understanding of the risks and benefits of ENMs exposed to plants and help achieve a safety-by-design strategy of ENMs in numerous applications. © 2022 The Royal Society of Chemistry.",,"Metal nanoparticles; Metals; Nanostructured materials; Soils; Black boxes; Complex pattern; Engineered nanomaterials; Interpretation methods; Machine-learning; Metal oxide nanoparticles; Model-based OPC; Plant-soil interactions; Root uptake; Safety concerns; Machine learning; concentration (composition); machine learning; nanomaterial; prediction; soil-vegetation interaction"
"Yu H., Zhao Z., Liu D., Cheng F.","Integrating machine learning interpretation methods for investigating nanoparticle uptake during seed priming and its biological effects","10.1039/d2nr01904c","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139943967&doi=10.1039%2fd2nr01904c&partnerID=40&md5=1a9a26292d7c0ca4b3858606f1ec7200","Seed priming by nanoparticles is an environmentally-friendly solution for alleviating malnutrition, promoting crop growth, and mitigating environmental stress. However, there is a knowledge gap regarding the nanoparticle uptake and the underlying physiological mechanism. Machine learning has great potential for understanding the biological effects of nanoparticles. However, its interpretability is a challenge for building trust and providing insights into the learned relationships. Herein, we systematically investigated how the factors influence nanoparticle uptake during seed priming by ZnO nanoparticles and its effects on seed germination. The properties of the nanoparticles, priming solution, and seeds were considered. Post hoc interpretation and model-based interpretation of machine learning were integrated into two ways to understand the mechanism of nanoparticle uptake during seed priming and its biological effects on seed germination. The results indicated that nanoparticle concentration and ionic strength influenced the shoot fresh weight mainly by controlling the nanoparticle uptake. The nanoparticle uptake had a significant slowdown when the nanoparticle concentration exceeded 50 mg L−1. Although other factors, such as zeta potential and hydrodynamic diameter, had no obvious effects on nanoparticle uptake, their biological effects cannot be ignored. This approach can promote the safer-by-design strategy of nanomaterials for sustainable agriculture. © 2022 The Royal Society of Chemistry.",,"Cultivation; II-VI semiconductors; Ionic strength; Machine learning; Seed; Biological effects; Crop growth; Environmental stress; Integrating machines; Interpretation methods; Machine-learning; Nanoparticle concentrations; Nanoparticle uptakes; Seed germination; Seed priming; ZnO nanoparticles; nanoparticle; germination; machine learning; plant seed; seedling; Germination; Machine Learning; Nanoparticles; Seedlings; Seeds"
"Yu H., Liu S., Qin H., Zhou Z., Zhao H., Zhang S., Mao J.","Artificial intelligence-based approaches for traditional fermented alcoholic beverages’ development: review and prospect","10.1080/10408398.2022.2128034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141160209&doi=10.1080%2f10408398.2022.2128034&partnerID=40&md5=fa81c27255dd28f86c63ae6d917ca15f","Traditional fermented alcoholic beverages (TFABs) have gained widespread acceptance and enjoyed great popularity for centuries. COVID-19 pandemics lead to the surge in health demand for diet, thus TFABs once again attract increased focus for the health benefits. Though the production technology is quite mature, food companies and research institutions are looking for transformative innovation in TFABs to make healthy, nutritious offerings that give a competitive advantage in current beverage market. The implementation of intelligent platforms enables companies and researchers to gather, store and analyze data in a more convenient way. The development of data collection methods contributed to the big data environment of TFABs, providing a fresh perspective that helps brewers to observe and improve the production steps. Among data analytical tools, Artificial Intelligence (AI) is considered to be one of the most promising methodological approaches for big data analytics and decision-making of automated production, and machine learning (ML) is an important method to fulfill the goal. This review describes the development trends and challenges of TFABs in big data era and summarize the application of AI-based methods in TFABs. Finally, we provide perspectives on the potential research directions of new frontiers in application of AI approaches in the supply chain of TFABs. © 2022 Taylor & Francis Group, LLC.","artificial intelligence; big data; fermentation regulation; microbial community; Traditional fermented alcoholic beverages","Alcoholic beverages; Artificial intelligence; Competition; Data Analytics; Decision making; Supply chains; 'current; Competitive advantage; Fermentation regulation; Food companies; Food research; Health benefits; Microbial communities; Production technology; Research institutions; Traditional fermented alcoholic beverage; Big data; alcoholic beverage; artificial intelligence; big data; decision making; fermentation; machine learning; microbial community; review"
"Yu H., Luo D., Dai L., Cheng F.","In silico nanosafety assessment tools and their ecosystem-level integration prospect","10.1039/d1nr00115a","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106172510&doi=10.1039%2fd1nr00115a&partnerID=40&md5=0be147d921f14586ccff20bd3b9eb08d","Engineered nanomaterials (ENMs) have tremendous potential in many fields, but their applications and commercialization are difficult to widely implement due to their safety concerns. Recently, in silico nanosafety assessment has become an important and necessary tool to realize the safer-by-design strategy of ENMs and at the same time to reduce animal tests and exposure experiments. Here, in silico nanosafety assessment tools are classified into three categories according to their methodologies and objectives, including (i) data-driven prediction for acute toxicity, (ii) fate modeling for environmental pollution, and (iii) nano-biological interaction modeling for long-term biological effects. Released ENMs may cross environmental boundaries and undergo a variety of transformations in biological and environmental media. Therefore, the potential impacts of ENMs must be assessed from a multimedia perspective and with integrated approaches considering environmental and biological effects. Ecosystems with biodiversity and an abiotic environment may be used as an excellent integration platform to assess the community- and ecosystem-level nanosafety. In this review, the advances and challenges of in silico nanosafety assessment tools are carefully discussed. Furthermore, their integration at the ecosystem level may provide more comprehensive and reliable nanosafety assessment by establishing a site-specific interactive system among ENMs, abiotic environment, and biological communities. © 2021 The Royal Society of Chemistry.",,"Biodiversity; Biological community; Biological interactions; Engineered nanomaterials; Environmental boundaries; Environmental media; Environmental pollutions; Integrated approach; Integration platform; Ecosystems; nanomaterial; animal; computer simulation; ecosystem; Animals; Computer Simulation; Ecosystem; Nanostructures"
"Yu J., Du S., Xin Z., Huang L., Zhao J.","Application of a convolutional neural network to land use classification based on GF-2 remote sensing imagery","10.1007/s12517-021-08555-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117708677&doi=10.1007%2fs12517-021-08555-5&partnerID=40&md5=c5023722f8f7fb4e4aba1671930a3d4e","Traditional remote sensing-based land use classification methods mainly focus on pixel-based unsupervised and supervised approaches and object-based image analysis (OBIA). The primary objective of this study is to improve the land use classification accuracy by introducing a convolutional neural network (CNN). A 1-m resolution fused Chinese GaoFen-2 (GF-2) remote sensing image was used as the validation data, and the classification scheme included six land use types were identified, namely wetland, cultivated land, forestland, artificial surface, fallow land, and others. To augment the training samples, the rotation operation of 90° and 180° was carried out. A ratio of 3:1 of total samples was randomly assigned as the training set and validation set. Considering the spectral bands and spatial resolution of GF-2 imagery as well as classification scheme, a seven-layer CNN model was constructed including two convolutional layers with the kernel size of 3 × 3, two pooling layers with the kernel size of 2 × 2, and a fully connected layer. To avoid the vanishing gradient problem and accelerate model training, the ReLU activation function, adaptive moment estimation (Adam) algorithm, and cross-entropy objective function were introduced. The parameter optimization and ablation study were performed to obtain the optimal values including learning rate of 0.0001, weight decay of 0.4, batch size of 16, and iteration of 100. The novelty of our method is that four sizes of divided image block (n = 5, 7, 9, 11) were used as the input to optimally select the best classification effect. Support vector machine (SVM) classifier was comparatively used to validate the proposed method. The results showed that the best overall accuracy (OA) and Kappa coefficient (k) were respectively 94.68% and 0.9351 when n was set to 9. All the user’s and producer’s (UA and PA) accuracies were greater than 90% for each type. Conversely, for the SVM-based classification method, the OA and k were just 77.92% and 0.7328, and most of the UA and PA were less than 85%. It is obvious that our proposed CNN-based method has greatly improved the land use identification accuracy. © 2021, Saudi Society for Geosciences.","Convolutional neural network; GF-2; Land use; Remote sensing; Support vector machine","accuracy assessment; algorithm; artificial neural network; detection method; image analysis; image classification; land use; remote sensing; satellite imagery; spatial resolution; support vector machine"
"Yu Z., Li Z., Chang Y., Fong S., Liu J., Zhang N.","HeatDeCam: Detecting Hidden Spy Cameras via Thermal Emissions","10.1145/3548606.3560669","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143056116&doi=10.1145%2f3548606.3560669&partnerID=40&md5=40d719abf9d88d649d9a8cecfd83d67b","Unlawful video surveillance of unsuspecting individuals using spy cameras has become an increasing concern. To mitigate these threats, there are both commercial products and research prototypes designed to detect hidden spy cameras in household and office environments. However, existing work often relies heavily on user expertise and only applies to wireless cameras. To bridge this gap, we propose HeatDeCam, a thermal-imagery-based spy camera detector, capable of detecting hidden spy cameras with or without built-in wireless connectivity. To reduce the reliance on user expertise, HeatDeCam leverages a compact neural network deployed on a smartphone to recognize unique heat dissipation patterns of spy cameras. To evaluate the proposed system, we have collected and open-sourced a dataset of a total of 22506 thermal and visual images. These images consist of 11 spy cameras collected from 6 rooms across different environmental conditions. Using this dataset, we found HeatDeCam can achieve over 95% accuracy in detecting hidden cameras. We have also conducted a usability evaluation involving a total of 416 participants using both an online survey and an in-person usability test to validate HeatDeCam. © 2022 Owner/Author.","cyber-physical security; privacy; spy camera detection; thermal","Cyber Physical System; Cybersecurity; Heating; Security systems; Surveys; Commercial products; Cyber-Physical securities; Office environments; Privacy; Product prototype; Research prototype; Spy camera detection; Thermal; Thermal emissions; Video surveillance; Cameras"
"Yuan X., Suvarna M., Low S., Dissanayake P.D., Lee K.B., Li J., Wang X., Ok Y.S.","Applied Machine Learning for Prediction of CO2Adsorption on Biomass Waste-Derived Porous Carbons","10.1021/acs.est.1c01849","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112373113&doi=10.1021%2facs.est.1c01849&partnerID=40&md5=761464c0df2a3d202347634eae42e6db","Biomass waste-derived porous carbons (BWDPCs) are a class of complex materials that are widely used in sustainable waste management and carbon capture. However, their diverse textural properties, the presence of various functional groups, and the varied temperatures and pressures to which they are subjected during CO2adsorption make it challenging to understand the underlying mechanism of CO2adsorption. Here, we compiled a data set including 527 data points collected from peer-reviewed publications and applied machine learning to systematically map CO2adsorption as a function of the textural and compositional properties of BWDPCs and adsorption parameters. Various tree-based models were devised, where the gradient boosting decision trees (GBDTs) had the best predictive performance withR2of 0.98 and 0.84 on the training and test data, respectively. Further, the BWDPCs in the compiled data set were classified into regular porous carbons (RPCs) and heteroatom-doped porous carbons (HDPCs), where again the GBDT model hadR2of 0.99 and 0.98 on the training and 0.86 and 0.79 on the test data for the RPCs and HDPCs, respectively. Feature importance revealed the significance of adsorption parameters, textural properties, and compositional properties in the order of precedence for BWDPC-based CO2adsorption, effectively guiding the synthesis of porous carbons for CO2adsorption applications. © 2021 The Authors. Published by American Chemical Society","carbon materials; gas adsorption and separation; gradient boosting decision trees; low carbon technology; machine learning; sustainable waste management","Carbon dioxide; Decision trees; Machine learning; Porous materials; Predictive analytics; Statistical tests; Trees (mathematics); Waste management; Adsorption parameters; Applied machine learning; Complex materials; Compositional properties; Gradient boosting; Predictive performance; Sustainable waste management; Textural properties; Adsorption; carbon; carbon dioxide; hydrogen; nitrogen; oxygen; adsorption; biomass; carbon dioxide; complexity; literature review; machine learning; performance assessment; porous medium; prediction; training; waste management; adsorption; Article; biomass; decision tree; desorption; environmental impact; k fold cross validation; machine learning; prediction; temperature; waste; waste management; adsorption; biomass; machine learning; porosity; Adsorption; Biomass; Carbon; Carbon Dioxide; Machine Learning; Porosity"
"Zaji A., Liu Z., Xiao G., Sangha J.S., Ruan Y.","A survey on deep learning applications in wheat phenotyping","10.1016/j.asoc.2022.109761","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141356987&doi=10.1016%2fj.asoc.2022.109761&partnerID=40&md5=15c55fdda135c3266108ca811ffc9393","Precision farming has become a hot research topic in recent years due to the advancement of sensing technologies, increased computer performance, and advanced deep learning algorithms. As a result, several outstanding studies on deep learning applications to high-throughput phenotyping of wheat, one of the most demanding cereal crops on the planet, have been published. This paper aims to conduct a survey of publications that have used deep learning techniques to address various challenges in wheat production. To accomplish this, we propose an ontology-based knowledge management system that is specifically designed to highlight the publications’ objectives, preprocessing algorithms, deep learning models, frameworks, datasets, and results. The presented ontology is intended to serve as a robust tool for future research in wheat high-throughput phenotyping. Additionally, we compare the performance of deep learning algorithms to that of long-established methods in this field. Compared to traditional machine learning techniques, this study demonstrates that deep learning algorithms provide a more robust, accurate, and cost-effective way of measuring wheat traits. © 2022","Agriculture; Convolutional neural networks; Deep learning; Knowledge representation; Ontology; Triticum; Wheat","Agriculture; Convolutional neural networks; Cost effectiveness; Deep learning; Knowledge management; Knowledge representation; Learning systems; Ontology; Surveys; Convolutional neural network; Deep learning; High-throughput phenotyping; Hot research topics; Knowledge-representation; Ontology's; Phenotyping; Precision-farming; Triticum; Wheat; Learning algorithms"
"Zamri N., Pairan M.A., Azman W.N.A.W., Abas S.S., Abdullah L., Naim S., Tarmudi Z., Gao M.","A comparison of unsupervised and supervised machine learning algorithms to predict water pollutions","10.1016/j.procs.2022.08.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142873692&doi=10.1016%2fj.procs.2022.08.021&partnerID=40&md5=776f0b210b71486f0f13b9d65622e343","Clean and safe water is vital for our lives and public health. In recent decades, population growth, agriculture, industries, and climate change have worsened freshwater resource depletion and clean water pollution. Several studies have focused on water pollutions risk simulation and prediction in the presence of pollution hotspots. However, the increase and complexity of big data caused by uncertain water quality parameters led to a new efficient algorithm to trace the most accurate pollution hotspots. Therefore, this study proposes to offer different algorithms and comparative studies using Machine Learning (ML) algorithms. Ten different most widely used algorithms, including unsupervised and supervised ML, will be employed to categorize the pollution hotspots for the Terengganu River. Besides, we also validate algorithms' accuracies by improving and changing each parameter in ML algorithms. Our results list all the accurate and efficient ML algorithms for the classification of river pollutions. These results help to facilitate river prediction using efficient and accurate algorithms in various water quality scenario. © 2022 Elsevier B.V.. All rights reserved.","Deep Learning; Machine Learning; Terengganu River; Water Pollutions","Climate change; Deep learning; Forecasting; Learning algorithms; Parameter estimation; Population statistics; River pollution; Supervised learning; Uncertainty analysis; Water quality; Clean waters; Deep learning; Hotspots; Machine learning algorithms; Machine-learning; Population growth; Safe water; Supervised machine learning; Terengganu river; Unsupervised machine learning; Rivers"
"Zegarra E., MacHicao J.C.","Structural analysis of potato market behavior using neural network modelling in Peru","10.1109/IHTC53077.2021.9698916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127298259&doi=10.1109%2fIHTC53077.2021.9698916&partnerID=40&md5=91f7f1ffdcc7df169a0836a0a30920b3","The complex behavior of crop markets is always difficult to characterize, especially under structural market failures that cause increasingly unstable and unprofitable prices. In this paper we propose an innovative analytical tool to identify potential potato market failures related to uncoordinated decisions in production which in time causes negative effects on farmers' wellbeing and persistently high rates of poverty in potato production areas. Based on a database including geographical origin, volume and price for potato production during the period 1997-2021, this work generates a market price prediction neural network model, using it to identify coordination problems in the functioning of the market and to test an alternative micro-scenario for a critical period of high volatility and price crisis. Using AI modelling and expert knowledge allows a better understanding of market coordination problems, to design more effective strategies and policy interventions towards reduction of poverty in potato producing rural areas in Peru. © 2021 IEEE.","agriculture; explainable artificial intelligence; modelling; potato price; rural poverty; sustainability","Agriculture; Artificial intelligence; Rural areas; Sustainable development; Analytical tool; Coordination problems; Explainable artificial intelligence; Market behaviours; Market failures; Modeling; Neural network model; Potato price; Rural poverty; Structural market; Commerce"
"Zennaro F., Furlan E., Simeoni C., Torresan S., Aslan S., Critto A., Marcomini A.","Exploring machine learning potential for climate change risk assessment","10.1016/j.earscirev.2021.103752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111479936&doi=10.1016%2fj.earscirev.2021.103752&partnerID=40&md5=e268e1d7759e1c13bd0c267542663a70","Global warming is exacerbating weather, and climate extremes events and is projected to aggravate multi-sectorial risks. A multiplicity of climate hazards will be involved, triggering cumulative and interactive impacts on a variety of natural and human systems. An improved understanding of risk interactions and dynamics is required to support decision makers in their ability to better manage current and future climate change risks. To face this issue, the research community has been starting to test new methodological approaches and tools, including the application of Machine Learning (ML) leveraging the potential of the large availability and variety of spatio-temporal big data for environmental applications. Given the increasing attention on the application of ML methods to Climate Change Risk Assessment (CCRA), this review mapped out the state of art and potential of these methods to this field of research. Scientometric and systematic analysis were jointly applied providing an in-depth review of publications across the 2000–2020 timeframe. The resulting output from the analysis showed that a huge variety of ML algorithms have been already applied within CCRA, among them, the most recurrent are Decision Tree, Random Forest, and Artificial Neural Network. These algorithms are often applied in an ensemble or hybridized way to analyze most of all floods and landslides risk events. Moreover, the application of ML to deal with remote sensing data is consistent and effective across reviewed CCRA applications, allowing the identification and classification of targets and the detection of environmental and structural features. On the contrary concerning future climate change scenarios, literature seems not to be very widespread into scientific production, compared to studies evaluating risks under current conditions. The same lack can be noted also for the assessment of cascading and compound hazards and risks, since these concepts are recently emerging in CCRA literature but not yet in combination with ML-based applications. © 2021 Elsevier B.V.","Big data; Climate change risk assessment; Machine learning; Remote sensing; Scientometric analysis; Systematic review","algorithm; climate change; data set; machine learning; remote sensing; risk assessment; spatiotemporal analysis"
"Zhai Z., Cao Y., Xu H., Yuan P., Wang H.","Review of Key Techniques for Crop Disease and Pest Detection [农作物病虫害识别关键技术研究综述]","10.6041/j.issn.1000-1298.2021.07.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111178192&doi=10.6041%2fj.issn.1000-1298.2021.07.001&partnerID=40&md5=0c4cf9ecacc5655a260bfeafe594fcd2","Preventing and managing crop disease and pest has significant impacts on agricultural production. The prerequisite for disease and pest control is accurate detection. Traditional crop disease and pest detection methods rely on human labors and instructions. However, these methods can no longer meet the requirements of scientific research and production, such as detection efficiency, accuracy, and application scenarios. As a main stream of machine learning, deep learning can extract features of objects from large-scale datasets automatically and efficiently, thereby releasing traditional methods from manual feature extraction. Applying deep learning, combined with image processing techniques, to detect crop disease and pest becomes an inevitable trend of precision agriculture in the future. The key techniques in crop disease and pest detection depend on agricultural data. After reviewing the state of the art of key techniques in this domain, including data acquisition, data pre-processing, data augmentation, deep learning network optimization, data visualization, and explainability of results, the challenges of applying these key techniques were detected and summarized. Lastly, potential solutions were explored to highlight the future research lines in this domain, including defining multi-view agricultural datasets, combining transfer learning, adopting new data augmentation methods, and considering visualization and explanation issues. © 2021, Chinese Society of Agricultural Machinery. All right reserved.","Crop disease and pest; Deep learning; Detection; Review","Agricultural robots; Crops; Data acquisition; Data handling; Data visualization; Disease control; Image processing; Large dataset; Learning systems; Transfer learning; Visualization; Agricultural productions; Application scenario; Data preprocessing; Detection efficiency; Image processing technique; Inevitable trends; Large-scale datasets; Scientific researches; Deep learning"
"Zhang C., Brodeur Z.P., Steinschneider S., Herman J.D.","Leveraging Spatial Patterns in Precipitation Forecasts Using Deep Learning to Support Regional Water Management","10.1029/2021WR031910","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138878147&doi=10.1029%2f2021WR031910&partnerID=40&md5=23d09c56b1fe29197d2e032a07095466","Short-term precipitation forecasts are critical to regional water management, particularly in the Western U.S. where atmospheric rivers can be predicted reliably days in advance. However, spatial error in these forecasts may reduce their utility when the costs of false positives and negatives differ greatly. Here we investigate whether deep learning methods can leverage spatial patterns in precipitation forecasts to (a) improve the skill of predicting the occurrence of precipitation events at lead times from 1 to 14 days, and (b) balance the tradeoff between the rate of false negatives and false positives by modifying the discrimination threshold of the classifiers. This approach is demonstrated for the Sacramento River Basin, California, using the Global Ensemble Forecast System (GEFS) v2 precipitation fields as input to convolutional neural network (CNN) and multi-layer perceptron models. Results show that the deep learning models do not significantly improve the overall skill (F1 score) relative to the ensemble mean GEFS forecast with bias-corrected threshold. However, additional analysis of the CNN models suggests they often correct missed predictions from GEFS by compensating for spatial error at longer lead times. Additionally, the deep learning models provide the ability to adjust the rate of false positives and negatives based on the ratio of costs. Finally, analysis of the network activations (saliency) indicates spatial patterns consistent with physical understanding of atmospheric river events in this region, lending additional confidence in the ability of the method to support water management applications. © 2022. American Geophysical Union. All Rights Reserved.","deep learning; flood management; precipitation forecast","Convolutional neural networks; Deep learning; Flood control; Floods; Learning systems; Multilayer neural networks; Water management; Weather forecasting; Convolutional neural network; Deep learning; Ensemble forecast systems; False negatives; False positive; Flood management; Precipitation forecast; Spatial errors; Spatial patterns; Waters managements; Rivers; flood control; water management; California; Sacramento Basin; United States"
"Zhang C., Lu Y.","Study on artificial intelligence: The state of the art and future prospects","10.1016/j.jii.2021.100224","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105943123&doi=10.1016%2fj.jii.2021.100224&partnerID=40&md5=61247b29060b274a84ad6ef5d88318fa","In the world, the technological and industrial revolution is accelerating by the widespread application of new generation information and communication technologies, such as AI, IoT (the Internet of Things), and blockchain technology. Artificial intelligence has attracted much attention from government, industry, and academia. In this study, popular articles published in recent years that relate to artificial intelligence are selected and explored. This study aims to provide a review of artificial intelligence based on industry information integration. It presents an overview of the scope of artificial intelligence using background, drivers, technologies, and applications, as well as logical opinions regarding the development of artificial intelligence. This paper may play a role in AI-related research and should provide important insights for practitioners in the real world.The main contribution of this study is that it clarifies the state of the art of AI for future study. © 2021 Elsevier Inc.","Artificial intelligence (AI); Machine learning; Natural language processing (NLP)","Internet of things; Future prospects; Industrial revolutions; Information and Communication Technologies; Information integration; State of the art; Artificial intelligence"
"Zhang H., Wang F., Song X.","From collective opinion dependence to personalization: The impacts of social trust relationship in consensus formation","10.1016/j.cie.2022.108541","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136731204&doi=10.1016%2fj.cie.2022.108541&partnerID=40&md5=52dfbd1f76cc7896426cbafac9727ec3","Social network group decision-making (SNGDM) has become popular recently in the area of decision analysis as the social network can effectively model the relationship among decision makers. In the SNGDM, decision makers will present conflicting assessments due to individual differences in education backgrounds and cognitive levels. This study aims to develop a personalized consensus reaching framework considering the impact of social trust network on assessments-modifications willingness. A personalized feedback is designed for guiding assessments-modifications, which is based on the assumption that a decision maker will accept his\her trusted decision makers’ assessments when modifying assessment in a social trust network. Then, a dual optimization-based personalized feedback is proposed for supporting consensus formation, where the first personalized feedback seeks to minimize the assessments-modifications and the second aims to minimize network-modifications. Particularly, two ways are used to measure network-modifications, referred to as trust values modifications with fixed network structure and network structure modifications, respectively. Further, an interactive dual optimization-based personalized consensus reaching process is constructed. With the aim of justifying the effectiveness of the proposed model, it is applied to solve the green supplier evaluation problem. Finally, it is illustrated that our proposal can improve consensus efficiency compared with collective opinion dependence feedback. © 2022 Elsevier Ltd","Consensus; Green supply chain; Minimum adjustment; Network optimization; Social network group decision making","Economic and social effects; Supply chains; Consensus; Consensus formation; Decision makers; Green supply chain; Group Decision Making; Minimum adjustment; Network optimization; Personalized feedback; Social network group decision making; Trust networks; Decision making"
"Zhang H., Long Z., Zhang C.","When will China’s total water consumption reach the turning point? EKC simulation and influencing factors","10.1007/s11356-022-23560-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140957438&doi=10.1007%2fs11356-022-23560-1&partnerID=40&md5=ecbc07f4aaa11e61b32d3bbaca7ca127","The turning point of China’s total water consumption is very important for the understanding of the evolution trend of total water consumption and the formulation of water conservation policies. Based on the environmental Kuznets curve (EKC) model, this paper verifies the shape of water consumption Kuznets curve. Scenario analysis and Monte Carlo simulation are combined for the first time to predict water consumption Kuznets curve. The LMDI model is used to decompose the driving factors of the evolution of total water consumption, and the STIRPAT model is expanded to explore the influence mechanism of total water consumption. The results show the following: (1) The theoretical water consumption Kuznets curve exists, and the turning point is 26,448 yuan RMB (in around 2013). (2) Based on the multiple driving factors (water intensity, per capita GDP, and population) and multiple scenarios (baseline scenario, target scenario, and 2 adjusted scenarios), 32 scenarios are designed in this paper; in the S1–S8, the turning point still appeared near 2013; the curves under the S11–S14, S16, and S25–S32 were inverted U-shaped, and the turning point was 48,728 yuan RMB (in around 2025); and in the S9, S10, and S15, the curve shows an upward trend; in the S17–S24, the curve has a rising-falling-rising characteristic. (3) Domestic effect and ecological effect both play a role in promoting the total water consumption, while the production effect is in an inverted N-shaped. Economic growth has always promoted the increase in industrial and agricultural water consumption, and the role of population size is relatively weak. The intensity of production water consumption has always promoted reduction in industrial and agricultural water consumption. Industrial water intensity and industrial structure are the primary and secondary factors that promote the decline of production intensity. (4) The per capita GDP has the largest contribution to total water consumption, followed by the water intensity, and the industrial structure has the least impact. The population has a negative impact. Based on this, a number of policy implications are obtained. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","EKC; Influence mechanism; LMDI; Scenario analysis; Total water consumption",
"Zhang L., Bibi F., Hussain I., Sultan M., Arshad A., Hasnain S., Alarifi I.M., Alamir M.A., Sajjad U.","Evaluating the Stress-Strain Relationship of the Additively Manufactured Lattice Structures","10.3390/mi14010075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146813107&doi=10.3390%2fmi14010075&partnerID=40&md5=34155804465851590f9e1955d663a812","Extensive amount of research on additively manufactured (AM) lattice structures has been made to develop a generalized model that can interpret how strongly operational variables affect mechanical properties. However, the currently used techniques such as physics models and multi-physics simulations provide a specific interpretation of those qualities, and are not general enough to assess the mechanical properties of AM lattice structures of different topologies produced on different materials via several fabrication methods. To tackle this problem, this study develops an optimal deep learning (DL) model based on more than 4000 data points, which has been optimized by analyzing three different hyper-parameters optimization schemes including gradient boost regression trees (GBRT), gaussian process (GP), and random forest (RF) with different data distribution schemes such as normal distribution, nth root transformation, and robust scaler. With the robust scaler and nth root transformation, the accuracy of the model increases from R2 = 0.85 (for simple distribution) to R2 = 0.94 and R2 = 0.88, respectively. After feature engineering and data correlation, the stress, unit cell size, total height, width, and relative density are chosen to be the input parameters to model the strain. The optimal DL model is able to predict the strain of different topologies of lattices (such as circular, octagonal, Gyroid, truncated cube, Truncated cuboctahedron, Rhombic do-decahedron, and many others) with decent accuracy (R2 = 0.936, MAE = 0.05, and MSE = 0.025). The parametric sensitivity analysis and explainable artificial intelligence (by using DeepSHAP library) based insights confirm that stress is the most sensitive input to the strain followed by the relative density from the modeling perspective of the AM lattices. The findings of this study would be helpful for the industry and the researchers to design AM lattice structures of different topologies for various engineering applications. © 2022 by the authors.","additive manufacturing; Bayesian optimization; deep learning; explainable artificial intelligence; lattice structure; mechanical properties; stress-strain relationship","3D printers; Additives; Artificial intelligence; Forestry; Metadata; Sensitivity analysis; Strain; Stress-strain curves; Topology; Bayesian optimization; Deep learning; Explainable artificial intelligence; Generalized models; Lattice structures; Learning models; Nth root; Relative density; Root transformation; Stress/strain relationships; Normal distribution"
"Zhang L., Zhang Z., Luo Y., Cao J., Tao F.","Combining optical, fluorescence, thermal satellite, and environmental data to predict county-level maize yield in China using machine learning approaches","10.3390/RS12010021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079678589&doi=10.3390%2fRS12010021&partnerID=40&md5=ab86d4c2397791b9006fe0ff599ba616","Maize is an extremely important grain crop, and the demand has increased sharply throughout the world. China contributes nearly one-fifth of the total production alone with its decreasing arable land. Timely and accurate prediction of maize yield in China is critical for ensuring global food security. Previous studies primarily used either visible or near-infrared (NIR) based vegetation indices (VIs), or climate data, or both to predict crop yield. However, other satellite data from different spectral bands have been underutilized, which contain unique information on crop growth and yield. In addition, although a joint application of multi-source data significantly improves crop yield prediction, the combinations of input variables that could achieve the best results have not been well investigated. Here we integrated optical, fluorescence, thermal satellite, and environmental data to predict county-level maize yield across four agro-ecological zones (AEZs) in China using a regression-based method (LASSO), two machine learning (ML) methods (RF and XGBoost), and deep learning (DL) network (LSTM). The results showed that combining multi-source data explained more than 75% of yield variation. Satellite data at the silking stage contributed more information than other variables, and solar-induced chlorophyll fluorescence (SIF) had an almost equivalent performance with the enhanced vegetation index (EVI) largely due to the low signal to noise ratio and coarse spatial resolution. The extremely high temperature and vapor pressure deficit during the reproductive period were the most important climate variables affecting maize production in China. Soil properties and management factors contained extra information on crop growth conditions that cannot be fully captured by satellite and climate data. We found that ML and DL approaches definitely outperformed regression-based methods, and ML had more computational efficiency and easier generalizations relative to DL. Our study is an important effort to combine multi-source remote sensed and environmental data for large-scale yield prediction. The proposed methodology provides a paradigm for other crop yield predictions and in other regions. © 2019 by the authors.","EVI; LST; LSTM; Machine learning; Maize; SIF; Yield prediction","Computational efficiency; Crops; Deep learning; Fluorescence; Food supply; Forecasting; Forestry; Infrared devices; Long short-term memory; Remote sensing; Satellites; Signal to noise ratio; Vegetation; Chlorophyll fluorescence; Enhanced vegetation index; Low signal-to-noise ratio; LSTM; Machine learning approaches; Maize; Vapor pressure deficit; Yield prediction; Learning systems"
"Zhang Q., Tian X., Chen W., Yang H., Lv P., Wu Y.","Unsound wheat kernel recognition based on deep convolutional neural network transfer learning and feature fusion","10.3233/JIFS-213195","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140756726&doi=10.3233%2fJIFS-213195&partnerID=40&md5=9b52933d7d5c55364a9ec71ca1a53c54","Unsound wheat kernel recognition is an important part of wheat quality inspection, and it is also a key indicator to measure wheat quality. Research on unsound wheat kernel recognition is of great significance to the correct evaluation of wheat quality. The existing researches on unsound wheat kernel recognition are mainly to directly optimize the classical classification networks, and the recognition effect is often unsatisfactory due to insufficient training data. Aiming at the problem that the recognition rate of unsound wheat kernels is not ideal due to the lack of training data, we propose a Transfer Learning Feature Fusion (TLFF) model. The model uses transfer learning and feature fusion to identify unsound wheat kernels. First, feature extraction is performed by deep Convolutional Neural Networks (CNNs) VGG-16 and VGG-19 pre-trained on the large public dataset ImageNet. Then, the features extracted by the pre-trained neural networks are fused and classified through the flattening layer, fully connected layer, Dropout layer, and Softmax layer. We conduct experiments on single model, two-model fusion, three-model fusion, and four-model fusion, and select the three-model fusion scheme to perform this task. Finally, we vote on the output results of the three best fusion models to further improve the recognition rate. The pre-trained models we use are trained on a large public dataset ImageNet. Since the scale of the dataset is very large, these pre-trained models also have good generalization performance for images other than ImageNet dataset. Therefore, although our dataset is small, we can still achieve good recognition results. Experimental results show that the recognition performance of the TLFF model is significantly better than the existing unsound wheat kernel recognition models. © 2022 - IOS Press. All rights reserved.","convolutional neural network; feature fusion; Transfer learning; unsound wheat kernel recognition; voting","Classification (of information); Convolution; Deep neural networks; Large dataset; Learning systems; Multilayer neural networks; Transfer learning; Convolutional neural network; Features fusions; Fusion model; Model fusion; Training data; Transfer learning; Unsound wheat kernel recognition; Voting; Wheat kernels; Wheat quality; Convolutional neural networks"
"Zhang R., Zhang Y., Fei X., Hou Y., Shi J., Li E., Ch W.","Limnoperna fortunei as an invasive biofouling bivalve species in freshwater: a review of its occurrence, biological traits, risks, and control strategies","10.2166/aqua.2022.238","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145652047&doi=10.2166%2faqua.2022.238&partnerID=40&md5=b00b480959d6e4de88c4df25e8bd4015","Concerns have been raised about the significant biofouling and environmental problems caused by the large numbers of Limnoperna fortunei clinging to water intake facilities. This review first provides a summary of the occurrence of L. fortunei in typical regions including China, South America, and Japan. Furthermore, this article provides a comprehensive overview of the biological traits, risks, and control of L. fortunei. Importantly, the planktonic larval stage is a critical period for the expansion of L. fortunei. Its biofouling process mainly relies on the adhesion of byssus to substrates. Various physical and chemical methods have been proposed and used to control L. fortunei. Among these methods, sodium hypochlorite has been shown to be effective in preventing the adhesion of L. fortunei by dissolving its byssus at much lower concentrations. Overall, effective and environmental-friendly antifouling strategies are still rare, particularly in drinking water treatment systems, and are encouraged to develop in future studies. This review not only provides a comprehensive understanding of L. fortunei but also helps to guide the prevention and control of L. fortunei. © 2022 The Authors.","biofouling; control; freshwater; Limnoperna fortunei; occurrence","Adhesion; Molluscs; Potable water; Water treatment; Biological controls; Biological risks; Biological traits; Bivalve species; Control strategies; Environmental problems; Fresh Water; Limnoperna fortunei; Occurrence; Risk strategies; Biofouling; antifouling; biofouling; drinking water; freshwater environment; substrate; water treatment; China; Japan; South America"
"Zhang S., Zhang C.","Modified U-Net for plant diseased leaf image segmentation","10.1016/j.compag.2022.107511","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144008696&doi=10.1016%2fj.compag.2022.107511&partnerID=40&md5=de0582287f6457ed82ccf7ec8b00ecfa","Early detection and recognition of plant disease is a prerequisite for controlling plant disease, and one of the key steps is to segment plant diseased leaf images. However, this task is challenging because diseased leaf images are often very complex, with irregular shapes, variable sizes, various shapes, rich colors, fuzzy boundaries and messy backgrounds. An improved U-Net (MU-Net) is constructed for plant diseased leaf image segmentation by introducing a residual block (Resblock) and a residual path (Respath). Resblock is introduced into U-Net to overcome gradient disappearance and explosion problems, and 2 Respaths are used instead of 2 skip connections to improve the transformation of corresponding feature information between the contraction path and the expansion path. Furthermore, Resblock and Respath are combined, which can increase the network depth and improve the network's expression ability. Experimental results on a plant diseased leaf image dataset show that the proposed method can improve the accuracy and efficiency of plant diseased leaf image segmentation. © 2022 Elsevier B.V.","Modified U-Net (MU-Net); Plant diseased leaf image segmentation; Residual block (Resblock); Residual path (Respath)","Image enhancement; Images segmentations; Irregular shape; Leaf images; Modified U-net; Plant disease; Plant diseased leaf image segmentation; Residual block; Residual path; Shape variable; Variable sizes; Image segmentation; accuracy assessment; data set; detection method; experimental study; fuzzy mathematics; image analysis; recognition; segmentation"
"Zhang W., Huang W., Tan J., Huang D., Ma J., Wu B.","Modeling, optimization and understanding of adsorption process for pollutant removal via machine learning: Recent progress and future perspectives","10.1016/j.chemosphere.2022.137044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140959210&doi=10.1016%2fj.chemosphere.2022.137044&partnerID=40&md5=7015157a4c8819db0839c1357652fd86","It is crucial to reduce the concentration of pollutants in water environment to below safe levels. Some cost-effective pollutant removal technologies have been developed, among which adsorption technology is considered as a promising solution. However, the batch experiments and adsorption isotherms widely employed at present are inefficient and time-consuming to some extent, which limits the development of adsorption technology. As a new research paradigm, machine learning (ML) is expected to innovate traditional adsorption models. This reviews summarized the general workflow of ML and commonly employed ML algorithms for pollutant adsorption. Then, the latest progress of ML for pollutant adsorption was reviewed from the perspective of all-round regulation of adsorption process, including adsorption efficiency, operating conditions and adsorption mechanism. General guidelines of ML for pollutant adsorption were presented. Finally, the existing problems and future perspectives of ML for pollutant adsorption were put forward. We highly expect that this review will promote the application of ML in pollutant adsorption and improve the interpretability of ML. © 2022","Adsorption mechanism; Artificial intelligence; Machine learning; Pollutant adsorption; Process parameter; Removal efficiency","Adsorption; Cost effectiveness; Efficiency; Water pollution; Adsorption mechanism; Adsorption process; Adsorption technology; Future perspectives; Machine-learning; Model understanding; Pollutant adsorption; Pollutants removal; Process parameters; Removal efficiencies; Machine learning; adsorption; isotherm; machine learning; optimization; pollutant removal; adsorption; machine learning; pollutant; water pollutant; Adsorption; Environmental Pollutants; Machine Learning; Water Pollutants, Chemical"
"Zhang W., Liu Y., Chen K., Li H., Duan Y., Wu W., Shi Y., Guo W.","Lightweight Fruit-Detection Algorithm for Edge Computing Applications","10.3389/fpls.2021.740936","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117906801&doi=10.3389%2ffpls.2021.740936&partnerID=40&md5=9131badde6b43cdcba88f5537f35cd22","In recent years, deep-learning-based fruit-detection technology has exhibited excellent performance in modern horticulture research. However, deploying deep learning algorithms in real-time field applications is still challenging, owing to the relatively low image processing capability of edge devices. Such limitations are becoming a new bottleneck and hindering the utilization of AI algorithms in modern horticulture. In this paper, we propose a lightweight fruit-detection algorithm, specifically designed for edge devices. The algorithm is based on Light-CSPNet as the backbone network, an improved feature-extraction module, a down-sampling method, and a feature-fusion module, and it ensures real-time detection on edge devices while maintaining the fruit-detection accuracy. The proposed algorithm was tested on three edge devices: NVIDIA Jetson Xavier NX, NVIDIA Jetson TX2, and NVIDIA Jetson NANO. The experimental results show that the average detection precision of the proposed algorithm for orange, tomato, and apple datasets are 0.93, 0.847, and 0.850, respectively. Deploying the algorithm, the detection speed of NVIDIA Jetson Xavier NX reaches 21.3, 24.8, and 22.2 FPS, while that of NVIDIA Jetson TX2 reaches 13.9, 14.1, and 14.5 FPS and that of NVIDIA Jetson NANO reaches 6.3, 5.0, and 8.5 FPS for the three datasets. Additionally, the proposed algorithm provides a component add/remove function to flexibly adjust the model structure, considering the trade-off between the detection accuracy and speed in practical usage. © Copyright © 2021 Zhang, Liu, Chen, Li, Duan, Wu, Shi and Guo.","deep learning; edge devices; fruit detection; lightweight; modern horticulture",
"Zhang X., Chen X., Zheng G., Cao G.","Improved prediction of chlorophyll-a concentrations in reservoirs by GRU neural network based on particle swarm algorithm optimized variational modal decomposition","10.1016/j.envres.2023.115259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147095890&doi=10.1016%2fj.envres.2023.115259&partnerID=40&md5=87a3c58f9bbb2a609814839c1fb6b977","The accurate and reliable prediction of chlorophyll-a (Chl-a) concentration is of great significance in reservoir environment management and pollution control. To improve the accuracy of Chl-a index prediction, a novel hybrid water quality prediction method was proposed for gated recurrent unit (GRU) neural network based on particle swarm algorithm optimized variational modal decomposition (PV-GRU). The results showed that the variational mode decomposition (VMD) optimized by particle swarm optimization (PSO) in this study effectively reduced the non-smooth of water quality data. In addition, the GRU neural network reduced the risk of overfitting the deep-learning model with small sample data. Overall, the PV-GRU prediction model exhibited significant superiority in predicting non-smooth and non-linear Chl-a sequences with a relatively small sample size. The prediction errors of PV-GRU model were all less than those of other comparative models, and the fitting determination coefficient R2 was 94.21%. These results indicated that the proposed PV-GRU model can effectively predict the content of Chl-a in reservoirs, which provides an alternative new method for water quality prediction to prevent and control eutrophication in reservoirs. © 2023 Elsevier Inc.","Data mining; Gated recurrent unit; Pearson correlation analysis; Variational modal decomposition; Water quality prediction","chlorophyll a; drinking water; algorithm; artificial neural network; chlorophyll a; eutrophication; reservoir; water quality; algorithm; Article; computer prediction; concentration (parameter); controlled study; correlation analysis; data accuracy; deep learning; eutrophication; gated recurrent unit network; intrinsic mode function; particle swarm optimization; prediction error; risk reduction; variational modal decomposition; water quality; water supply"
"Zhang X., Zheng Z.","A Novel Groundwater Burial Depth Prediction Model Based on Two-Stage Modal Decomposition and Deep Learning","10.3390/ijerph20010345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145979371&doi=10.3390%2fijerph20010345&partnerID=40&md5=87ef48f2e0ba32155fdadc9364782cdc","The variability of groundwater burial depths is critical to regional water management. In order to reduce the impact of high-frequency eigenmodal functions (IMF) generated by complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) on the prediction results, variational modal decomposition (VMD) is performed on the high frequency IMF components after the primary modal decomposition. A convolutional neural network-gated recurrent unit prediction model (CNN-GRU) is proposed to address the shortcomings of traditional machine learning which cannot handle correlation information and temporal correlation between time series. The CNN-GRU model can extract the implicit features of the coupling relationship between groundwater burial depth and time series and further predict the groundwater burial depth time series. By comparing the prediction results with GRU, CEEMDAN-GRU, and CEEMDAN-CNN-GRU models, we found that the CEEMDAN-VMD-CNN-GRU prediction model outperformed the other prediction models, with a prediction accuracy of 94.29%, good prediction results, and high model confidence. © 2022 by the authors.","complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN); convolutional neural network (CNN); gated recurrent unit (GRU); groundwater burial depth prediction; variational modal decomposition (VMD)","ground water; accuracy assessment; artificial neural network; correlation; decomposition analysis; ensemble forecasting; groundwater; machine learning; prediction; time series; water management; Article; decomposition; deep learning; environmental factor; irrigation (agriculture); machine learning; prediction; water depth; burial; Burial; Deep Learning; Groundwater; Machine Learning; Neural Networks, Computer"
"Zhang X., Yang J., Lin T., Ying Y.","Food and agro-product quality evaluation based on spectroscopy and deep learning: A review","10.1016/j.tifs.2021.04.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104454622&doi=10.1016%2fj.tifs.2021.04.008&partnerID=40&md5=01d4a64d98f22e52248ea1aecfafabc9","Background: Rapid and non-destructive infrared spectroscopy has been applied to both internal and external quality evaluations of food and agro-products. Various linear and nonlinear chemometric methods have been developed for spectral analysis. The generalizability of previous chemometric methods is hindered by changing noise under various detection conditions and biological variabilities. Recently, deep learning approaches have been developed for spectral noise reduction, feature extraction, and calibration regression modeling. Scope and approach: This review discusses the current challenges of conventional chemometric methods and the emerging deep learning approach for spectral analysis. The current state-of-the-art techniques, including unsupervised feature extraction and noise reduction models and supervised multivariate regression approaches, have been addressed in this review. The research on exploring the learning mechanism of the ‘black box’ deep learning model is also discussed. This review focuses on the application of deep learning approaches on quality evaluation of food and agro-products, lessons from current studies, and future perspectives. Key findings and conclusions: The deep learning approach combined with spectroscopic sensing techniques has shown great potential for quality evaluation of food and agro-products. Current advances in deep learning-based qualitative analysis include variety identification, geographical origin detection, adulteration recognition, and bruise detection, whereas quantitative analysis includes multiple component content prediction for fruits, grains, and crops. The main advantage of deep learning approach is the decreasing the dependence on human domain knowledge by end-to-end analysis and the improved precision and generalizability. © 2021 Elsevier Ltd","Deep learning; Generalizability; Interpretability; Model robustness; Quality evaluation; Spectral analysis","Deep learning; Extraction; Feature extraction; Infrared spectroscopy; Quality control; Regression analysis; Spectrum analysis; 'current; Agro-products; Chemometric method; Deep learning; Features extraction; Generalizability; Interpretability; Learning approach; Model robustness; Quality evaluation; Noise abatement"
"Zhang X., Xu J., Yang J., Chen L., Zhou H., Liu X., Li H., Lin T., Ying Y.","Understanding the learning mechanism of convolutional neural networks in spectral analysis","10.1016/j.aca.2020.03.055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084069965&doi=10.1016%2fj.aca.2020.03.055&partnerID=40&md5=8d71ee759aa0416970b9863d4526a91f","Deep learning approaches, especially convolutional neural network (CNN) models, have achieved excellent performances in vibrational spectral analysis. The critical drawback of the CNN approach is the lack of interpretation, and it is regarded as a black box. Interpreting the learning mechanism of chemometric models is critical for intuitive understanding and further application. In this study, an interpretable CNN model with a global average pooling layer is presented for Raman and mid-infrared spectral data analysis. A class activation mapping (CAM)-based approach is leveraged to visualize the active variables in the whole spectrum. The visualization of active variables shows a discriminative pattern in which the most contributed variables peaked around theoretical chemical characteristic bands. The visualization of the feature maps by three convolutional layers demonstrates the data transformation pipeline and how the CNN model hierarchically extracts informative spectral features. The first layer acts as a Savitzky-Golay filter and learns spectral shape characteristics, while the second layer learns enhanced patterns from typical spectral peaks on a few correlated variables. The third layer shows stable activations on critical spectral peaks. A partial least squares - linear discriminant analysis (PLS-LDA) model is presented for comparison on classification accuracy and model interpretation. The CNN model yields mean classification accuracies of 99.01 and 100% for E. coli and meat datasets on the test set, while the PLS-LDA models obtain accuracies of 98.83 and 100%. Both the CNN and PLS-LDA models demonstrate stable patterns on active variables while CNN models are more stable than PLS-LDA models on classification performances for various dataset partitions with Monte-Carlo cross-validation. © 2020 Elsevier B.V.","Class activation mapping; Deep learning; Feature visualization; Interpretation; Reliability","Chemical activation; Chemical analysis; Convolution; Convolutional neural networks; Data visualization; Deep learning; Discriminant analysis; Escherichia coli; Least squares approximations; Metadata; Spectrum analysis; Visualization; Chemical characteristic; Classification accuracy; Classification performance; Intuitive understanding; Linear discriminant analysis; Model interpretations; Partial least square (PLS); Savitzky-Golay filter; Learning systems; activation analysis; Article; chemical composition; convolutional neural network; correlation analysis; data accuracy; data analysis; data visualization; deep learning; discriminant analysis; discrimination learning; Escherichia coli; infrared spectroscopy; interpretation bias; meat; Monte Carlo cross validation; partial least squares regression; priority journal; Raman spectrometry; theoretical study; Monte Carlo method; Deep Learning; Discriminant Analysis; Monte Carlo Method; Neural Networks, Computer"
"Zhang Y., Wu M., Tian G.Y., Zhang G., Lu J.","Ethics and privacy of artificial intelligence: Understandings from bibliometrics","10.1016/j.knosys.2021.106994","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104109212&doi=10.1016%2fj.knosys.2021.106994&partnerID=40&md5=a9edffd5476395fac2cdefb54005a913","Artificial intelligence (AI) and its broad applications are disruptively transforming the daily lives of human beings and a discussion of the ethical and privacy issues surrounding AI is a topic of growing interest, not only among academics but also the general public This review identifies the key entities (i.e., leading research institutions and their affiliated countries/regions, core research journals, and communities) that contribute to the research on the ethical and privacy issues in relation to AI and their intersections using co-occurrence analysis. Topic analyses profile the topical landscape of AI ethics using a topical hierarchical tree and the changing interest of society in AI ethics over time through scientific evolutionary pathways. We also paired 15 selected AI techniques with 17 major ethical issues and identify emerging ethical issues from a core set of the most recent articles published in Nature, Science, and Proceedings of the National Science Academy of the United States. These insights bridging the knowledge base of AI techniques and ethical issues in the literature, are of interest to the AI community and audiences in science policy, technology management, and public administration. © 2021 Elsevier B.V.","Artificial intelligence; Bibliometrics; Ethics; Privacy; Topic analysis","Data privacy; Knowledge based systems; Philosophical aspects; Public administration; Artificial intelligence techniques; Bibliometric; Broad application; Daily lives; Ethical issues; General publics; Human being; Privacy; Privacy issue; Topic analysis; Artificial intelligence"
"Zhang Y., Liu Y., Chen C.-H.","Survey on blockchain and deep learning","10.1109/TrustCom50675.2020.00272","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101239547&doi=10.1109%2fTrustCom50675.2020.00272&partnerID=40&md5=e2be4d5dca76d305cdec60de6657e59a","Blockchain and deep learning have been important techniques for intelligent applications. This study surveys relevant hot research topics from January 2018 to August 2020. Furthermore, five topics of blockchain and deep learning which include (1) infrastructure, (2) finance and trade, (3) transportation and logistics, (4) smart contract, and (5) information security are discussed in this study. © 2020 IEEE.","Blockchain; Deep learning; Federated learning; Neural network","Blockchain; Security of data; Surveys; Hot research topics; Intelligent applications; Deep learning"
"Zhang Z., Pope M., Shakoor N., Pless R., Mockler T.C., Stylianou A.","Comparing Deep Learning Approaches for Understanding Genotype × Phenotype Interactions in Biomass Sorghum","10.3389/frai.2022.872858","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134380954&doi=10.3389%2ffrai.2022.872858&partnerID=40&md5=0aa15de92897a4c9e58bc843eac12fc2","We explore the use of deep convolutional neural networks (CNNs) trained on overhead imagery of biomass sorghum to ascertain the relationship between single nucleotide polymorphisms (SNPs), or groups of related SNPs, and the phenotypes they control. We consider both CNNs trained explicitly on the classification task of predicting whether an image shows a plant with a reference or alternate version of various SNPs as well as CNNs trained to create data-driven features based on learning features so that images from the same plot are more similar than images from different plots, and then using the features this network learns for genetic marker classification. We characterize how efficient both approaches are at predicting the presence or absence of a genetic markers, and visualize what parts of the images are most important for those predictions. We find that the data-driven approaches give somewhat higher prediction performance, but have visualizations that are harder to interpret; and we give suggestions of potential future machine learning research and discuss the possibilities of using this approach to uncover unknown genotype × phenotype relationships. Copyright © 2022 Zhang, Pope, Shakoor, Pless, Mockler and Stylianou.","convolutional neural networks; deep learning; explainable AI; phenotyping; single nucleotide polymorphism; sorghum; TERRA-REF; visualization",
"Zhang Z., Song X., Liu L., Yin J., Wang Y., Lan D.","Recent Advances in Blockchain and Artificial Intelligence Integration: Feasibility Analysis, Research Issues, Applications, Challenges, and Future Work","10.1155/2021/9991535","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109209787&doi=10.1155%2f2021%2f9991535&partnerID=40&md5=f2b82659bf535308780d5ae365c61599","Blockchain constructs a distributed point-to-point system, which is a secure and verifiable mechanism for decentralized transaction validation and is widely used in financial economy, Internet of Things, large data, cloud computing, and edge computing. On the other hand, artificial intelligence technology is gradually promoting the intelligent development of various industries. As two promising technologies today, there is a natural advantage in the convergence between blockchain and artificial intelligence technologies. Blockchain makes artificial intelligence more autonomous and credible, and artificial intelligence can prompt blockchain toward intelligence. In this paper, we analyze the combination of blockchain and artificial intelligence from a more comprehensive and three-dimensional point of view. We first introduce the background of artificial intelligence and the concept, characteristics, and key technologies of blockchain and subsequently analyze the feasibility of combining blockchain with artificial intelligence. Next, we summarize the research work on the convergence of blockchain and artificial intelligence in home and overseas within this category. After that, we list some related application scenarios about the convergence of both technologies and also point out existing problems and challenges. Finally, we discuss the future work. © 2021 Zhonghua Zhang et al.",,"Blockchain; Application scenario; Artificial intelligence technologies; Existing problems; Feasibility analysis; Intelligence integration; Key technologies; Point to point; Research issues; Artificial intelligence"
"Zhang Z., Yang J.","Data mining of myths, legends and folk tales in the context of artificial intelligence","10.1109/ICISC47916.2020.9171134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091778612&doi=10.1109%2fICISC47916.2020.9171134&partnerID=40&md5=80315ee244e74d19b711389b021f3cad","Data mining of myths, legends and folk tales in the context of artificial intelligence is completely studied in this paper. The core text correlation data structure all is limited, the text correlation data, has the very major difficulty in the computer daily treating processes, therefore, the text correlation content is unable through the data correlation excavation technology to carry on the solution and processing, must first carry on prompt processing to the text. Hence, the paper gives the novel ideas on information mining. We propose that SPARK has its own technical applications in the core process processing, graphics technology, machine learning, NoSQL query and so on by virtue of many years of practical experience in a big data application. We make the proper combinations of different methods to achieve the global optimal. The simulation reflected effectiveness. © 2020 IEEE.","artificial intelligence; Data mining; information sciences; text recognition","Artificial intelligence; Big data applications; Correlation data; Data correlations; Graphics technology; Information mining; Practical experience; Technical applications; Treating process; Data mining"
"Zhang Z., Jin Y., Chen B., Brown P.","California almond yield prediction at the orchard level with a machine learning approach","10.3389/fpls.2019.00809","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069488145&doi=10.3389%2ffpls.2019.00809&partnerID=40&md5=400b232878b0f552e135816dbea68b79","California’s almond growers face challenges with nitrogen management as new legislatively mandated nitrogen management strategies for almond have been implemented. These regulations require that growers apply nitrogen to meet, but not exceed, the annual N demand for crop and tree growth and nut production. To accurately predict seasonal nitrogen demand, therefore, growers need to estimate block-level almond yield early in the growing season so that timely N management decisions can be made. However, methods to predict almond yield are not currently available. To fill this gap, we have developed statistical models using the Stochastic Gradient Boosting, a machine learning approach, for early season yield projection and mid-season yield update over individual orchard blocks. We collected yield records of 185 orchards, dating back to 2005, from the major almond growers in the Central Valley of California. A large set of variables were extracted as predictors, including weather and orchard characteristics from remote sensing imagery. Our results showed that the predicted orchard-level yield agreed well with the independent yield records. For both the early season (March) and mid-season (June) predictions, a coefficient of determination (R2) of 0.71, and a ratio of performance to interquartile distance (RPIQ) of 2.6 were found on average. We also identified several key determinants of yield based on the modeling results. Almond yield increased dramatically with the orchard age until about 7 years old in general, and the higher long-term mean maximum temperature during April–June enhanced the yield in the southern orchards, while a larger amount of precipitation in March reduced the yield, especially in northern orchards. Remote sensing metrics such as annual maximum vegetation indices were also dominant variables for predicting the yield potential. While these results are promising, further refinement is needed; the availability of larger data sets and incorporation of additional variables and methodologies will be required for the model to be used as a fertilization decision support tool for growers. Our study has demonstrated the potential of automatic almond yield prediction to assist growers to manage N adaptively, comply with mandated requirements, and ensure industry sustainability. © 2019 Zhang, Jin, Chen and Brown.","Almond orchard; Central valley; Machine learning; Nitrogen management; Remote sensing; Yield prediction; Yield variation",
"Zhao M., Lu H., Yang S., Guo F.","The experience-memory Q-Learning algorithm for robot path planning in unknown environment","10.1109/ACCESS.2020.2978077","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082173319&doi=10.1109%2fACCESS.2020.2978077&partnerID=40&md5=8683bab0ac4b205368e259c5e873348b","In order to solve the problem of slow convergence speed and long planned path when the robot plans a path in unknown environment by using Q-learning algorithm, we propose the Experience-Memory Q-Learning (EMQL) algorithm based on the continuous update of the shortest distance from the current state node to the start point. The autonomous learning ability of the robot is enhanced by the different role assignments of two tables in the proposed algorithm. EM table with (m∗1) dimension is designed to record the distance information, reflecting the learning process of the robot. Q table is adopted as an auxiliary guidance for the experience transfer strategy and experience reuse strategy, and these strategies enable the robot accomplish the task even if the destination is changed or the path is blocked. Further, the learning efficiency of the robot in the EMQL algorithm is improved by the dual reward mechanism consisting of static reward and dynamic reward. The static reward is designed to prevent the robot from exploring a state node excessively. The dynamic reward is responsible for helping the robot avoid searching blindly in unknown environment. We test the effectiveness of the proposed algorithm on both grid maps and road network maps. The comparison results in planning time, iteration times and path length show that the performance of the EMQL algorithm is superior to Q-learning algorithm in convergence speed and optimization ability. Additionally, the practicability of the proposed algorithm is validated in a real-world experiment using the Turtlebot3 burger robot. © 2013 IEEE.","experience memory; experience reuse; experience transfer; Path planning; Q-learning","Iterative methods; Motion planning; Reinforcement learning; Robot programming; Robots; Transfer learning; Autonomous learning abilities; Distance information; Experience reuse; experience transfer; Optimization ability; Q-learning; Q-learning algorithms; Real world experiment; Learning algorithms"
"Zhao S., Liu J., Wu S.","Multiple disease detection method for greenhouse-cultivated strawberry based on multiscale feature fusion Faster R_CNN","10.1016/j.compag.2022.107176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133281277&doi=10.1016%2fj.compag.2022.107176&partnerID=40&md5=81b9ed2ae5927c96ca08d0fe8bf2c7ee","Disease has a significant impact on strawberry quality and yield, and deep learning has become an important approach for the detection of crop disease. To address the problems of complex backgrounds and small disease spots in strawberry disease images from natural environments, we propose a new Faster R_CNN architecture. The multiscale feature fusion network is composed of ResNet, FPN, and CBAM blocks, and it can effectively extract rich strawberry disease features. We built a dataset for strawberry leaves, flowers and fruits, and the experimental results showed that the model was able to effectively detect healthy strawberries and seven strawberry diseases under natural conditions, with an mAP of 92.18% and an average detection time of only 229 ms. The model is compared with Mask R_CNN and YOLO-v3, and we find that our model can guarantee high accuracy and fast detection operational requirements. Our method provides an effective solution for crop disease detection and can improve farmers' management of the strawberry growing process. © 2022","Disease detection; Faster R-CNN; Multiscale; Natural environment; Strawberry","Crops; Cultivation; Deep learning; Complex background; Crop disease; Detection methods; Disease detection; Fast R-CNN; Features fusions; Multi-scale features; Multiscale; Natural environments; Strawberry; Fruits; accuracy assessment; architecture; detection method; disease"
"Zhao Z., Cheng F.","Field reliability estimation of agricultural tractors based on warranty data","10.13031/TRANS.14318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105286967&doi=10.13031%2fTRANS.14318&partnerID=40&md5=c75a472d402a7a15e0a6c3423f8d63cd","Warranty data provide a valuable source of information for assessing the reliability of products in operation (called the field reliability). However, warranty data consist of failure information only. The unavailability of usage data for unfailed products makes it difficult to estimate the reliability of durable products such as agricultural tractors, for which usage is a greater concern than age for reliability analysis. Several studies have proposed methods to address this problem, but they did not include information on the usage context. This study proposes a methodology to estimate the field reliability of agricultural tractors from warranty data considering the tractors' usage context. First, by taking features representing tractors' usage context as the input, a usage rate regression model was established using a light gradient boosting machine (LightGBM). The usage of unfailed tractors was then generated. Finally, parametric estimates of the tractors' reliability were determined based on the usage of failed and unfailed tractors. By interpreting the LightGBM model using SHapley Additive exPlanations (SHAP), it was found that tractors that were used more days in October and April had higher predicted usage rates. To validate the effectiveness of the proposed methodology, the estimated reliability parameters were used to predict the warranty claims of six types of tractors. The results showed that the proposed methodology performed the best in four cases and close to the best in two other cases when compared with two other baseline methods. The proposed methodology was demonstrated using warranty data from an agricultural tractor manufacturing company in China and can be applied to improve understanding of tractor reliability. © 2021 American Society of Agricultural and Biological Engineers","Field reliability; LightGBM; SHAP; Usage context; Warranty data","Agricultural robots; Agriculture; Parameter estimation; Regression analysis; Tractors (agricultural); Baseline methods; Durable products; Failure information; Field reliability; Manufacturing companies; Regression model; Reliability parameters; Warranty claims; Reliability analysis; algorithm; data set; detection method; instrumentation; manufacturing; model validation; regression analysis; China"
"Zhao Z.-L., Yu H.-J., Cheng F.","An Analysis of Factors Affecting Agricultural Tractors' Reliability Using Random Survival Forests Based on Warranty Data","10.1109/ACCESS.2022.3172348","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129668454&doi=10.1109%2fACCESS.2022.3172348&partnerID=40&md5=f03b1070f084b87b0db7e2b2c5cbcdf3","Warranty data are a valuable and easily accessible data source for manufacturers to assess the reliability of products in the field. Knowledge about the relationships between products' reliability and reliability factors is beneficial for manufacturers to improve products' quality. For this motivation, based on warranty data from an agricultural machinery manufacturing company in China, random survival forests (RSF), which is a machine learning method for survival analysis and provides various interpretation tools, was applied for reliability modeling in this study. The model's performance was assessed by the Harrell's concordance index (C-index) and the integrated Brier score (IBS). Thirty-four factors from production and operation were collected. Nine most important and meaningful factors were selected to show their marginal effects and interaction effects, according to which decision rules for identifying high-risk products were extracted using classification trees. The results showed that the RSF model trained by considering the observed times as the age (C-index = 0.88, IBS = 0.089) outperformed that trained by considering the observed times as the usage (C-index = 0.83, IBS = 0.15); most of the nine factors, such as 'Usage Rate', had nonlinear impacts on the reliability of tractors; the marginal effects and interaction effects can be used to generate decision rules that can significantly separate high-risk products from the population. This work provides new insights for agricultural machinery manufacturers to understand their products' reliability and make reliability improvement plans and marketing plans. © 2013 IEEE.","Agricultural machinery; failure analysis; random forests; reliability engineering; warranties","Factor analysis; Learning systems; Marketing; Tractors (agricultural); Tractors (truck); Data-source; Decision rules; Interaction effect; Marginal effects; Radiofrequencies; Random survival forest; Risk products; Survival forests; Warranty; Warranty data; Reliability analysis"
"Zheng H., Liu Y., Wan W., Zhao J., Xie G.","Large-scale prediction of stream water quality using an interpretable deep learning approach","10.1016/j.jenvman.2023.117309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146467079&doi=10.1016%2fj.jenvman.2023.117309&partnerID=40&md5=68249c1b339904974bfb4100e3bbe29d","Deep learning methods, which have strong capabilities for mapping highly nonlinear relationships with acceptable calculation speed, have been increasingly applied for water quality prediction in recent studies. However, it is argued that the practicality of deep learning methods is limited due to the lack of physical mechanics to explain the prediction results of water quality changes. A knowledge gap exists in rationalizing the deep learning results for water quality predictions. To address this gap, an interpretable deep learning framework was established to predict the spatiotemporal variations of water quality parameters in a large spatial region. Mereological, land-use, and socioeconomic variables were adopted to predict the daily variations of stream water quality parameters across 138 sub-catchments in a total of over 575,250 km2 in southern China. The coefficients of determination of chemical oxygen demand (COD), total phosphorus (TP), and total nitrogen (TN) predictions were over 0.80, suggesting a satisfactory prediction performance. The model performance in terms of prediction accuracy could be improved by involving land-use and socioeconomic predictors in addition to hydrological variables. The SHapley Additive exPlanations method used in this study was demonstrated to be effective for interpreting the prediction results by identifying the significant variables and reasoning their influencing directions on the variation of each water quality parameter. The air temperature, proportion of forest area, grain production, population density, and proportion of urban area in each sub-catchment as well as the accumulated rainfall within the previous 3 days were identified as the most significant variables affecting the variations of dissolved oxygen, COD, ammoniacal nitrogen(NH3–N), TN, TP, and turbidity in the stream water in the case area, respectively. © 2023 Elsevier Ltd","Deep learning; Interpretable; Large scale; Prediction; Water quality","ammonia; nitrogen; oxygen; phosphorus; river water; surface water; machine learning; prediction; streamwater; urban area; water quality; air temperature; Article; chemical oxygen demand; controlled study; deep learning; eutrophication; feed forward neural network; fluid balance; land use; large scale production; mean absolute error; mean squared error; population density; precipitation; socioeconomics; spatiotemporal analysis; stream (river); water monitoring; water pollution; China"
"Zheng L., Zhao M., Zhu J., Huang L., Zhao J., Liang D., Zhang D.","Fusion of hyperspectral imaging (HSI) and RGB for identification of soybean kernel damages using ShuffleNet with convolutional optimization and cross stage partial architecture","10.3389/fpls.2022.1098864","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147220334&doi=10.3389%2ffpls.2022.1098864&partnerID=40&md5=7b8d852a5159cbfddececbaf5ba0aa37","Identification of soybean kernel damages is significant to prevent further disoperation. Hyperspectral imaging (HSI) has shown great potential in cereal kernel identification, but its low spatial resolution leads to external feature infidelity and limits the analysis accuracy. In this study, the fusion of HSI and RGB images and improved ShuffleNet were combined to develop an identification method for soybean kernel damages. First, the HSI-RGB fusion network (HRFN) was designed based on super-resolution and spectral modification modules to process the registered HSI and RGB image pairs and generate super-resolution HSI (SR-HSI) images. ShuffleNet improved with convolution optimization and cross-stage partial architecture (ShuffleNet_COCSP) was used to build classification models with the optimal image set of effective wavelengths (OISEW) of SR-HSI images obtained by support vector machine and ShuffleNet. High-quality fusion of HSI and RGB with the obvious spatial promotion and satisfactory spectral conservation was gained by HRFN. ShuffleNet_COCSP and OISEW obtained the optimal recognition performance of ACCp=98.36%, Params=0.805 M, and FLOPs=0.097 G, outperforming other classification methods and other types of images. Overall, the proposed method provides an accurate and reliable identification of soybean kernel damages and would be extended to analysis of other quality indicators of various crop kernels. Copyright © 2023 Zheng, Zhao, Zhu, Huang, Zhao, Liang and Zhang.","hyperspectral imaging; image fusion; lightweight deep learning; soybean damages; super resolution",
"Zheng Y., Xu Z., Xiao A.","Deep learning in economics: a systematic and critical review","10.1007/s10462-022-10272-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147389352&doi=10.1007%2fs10462-022-10272-8&partnerID=40&md5=2eccdf5b28aa94251a51ace629431911","From the perspective of historical review, the methodology of economics develops from qualitative to quantitative, from a small sampling of data to a vast amount of data. Because of the superiority in learning inherent law and representative level, deep learning models assist in realizing intelligent decision-making in economics. After presenting some statistical results of relevant researches, this paper systematically investigates deep learning in economics, including a survey of frequently-used deep learning models in economics, several applications of deep learning models used in economics. Then, some critical reviews of deep learning in economics are provided, including models and applications, why and how to implement deep learning in economics, research gap and future challenges, respectively. It is obvious that several deep learning models and their variants have been widely applied in different subfields of economics, e.g., financial economics, macroeconomics and monetary economics, agricultural and natural resource economics, industrial organization, urban, rural, regional, real estate and transportation economics, health, education and welfare, business administration and microeconomics, etc. We are very confident that decision-making in economics will be more intelligent with the development of deep learning, because the research of deep learning in economics has become a hot and important topic recently. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.","Critical review; Deep learning; Economics; Intelligent decision-making","Decision making; Deep learning; Learning systems; Urban transportation; Critical review; Deep learning; Economic research; Future challenges; Historical review; Intelligent decision-making; Learning models; Research gaps; Small sampling; Systematic Review; Economics"
"Zhogolev A., Savin I.","Soil mapping based on globally optimal decision trees and digital imitations of traditional approaches","10.3390/ijgi9110664","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112438635&doi=10.3390%2fijgi9110664&partnerID=40&md5=1db13aedaae212ad2833bdcdc337474b","Most digital soil mapping (DSM) approaches aim at complete statistical model extraction. The value of the explicit rules of soil delineation formulated by soil-mapping experts is often underestimated. These rules can be used for expert testing of the notional consistency of soil maps, soil trend prediction, soil geography investigations, and other applications. We propose an approach that imitates traditional soil mapping by constructing compact globally optimal decision trees (EVTREE) for the covariates of traditionally used soil formation factor maps. We evaluated our approach by regional-scale soil mapping at a test site in the Belgorod region of Russia. The notional consistency and compactness of the decision trees created by EVTREE were found to be suitable for expert-based analysis and improvement. With a large sample set, the accuracy of the predictions was slightly lower for EVTREE (59%) than for CART (67%) and much lower than for Random Forest (87%). With smaller sample sets of 1785 and 1000 points, EVTREE produced comparable or more accurate predictions and much more accurate models of soil geography than CART or Random Forest. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Belgorod region; Digital soil mapping; EVTREE; Machine learning; Traditional soil mapping",
"Zhou J., Li Y., Lei Q., Feng Q., Luo J., Lindsey S.","Asynchrony between urban expansion and water environmental protection reshapes the spatial patterns of nitrogen and phosphorus concentrations and N:P stoichiometry in inland small water bodies in Changsha, China","10.3389/fenvs.2022.1018408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143295853&doi=10.3389%2ffenvs.2022.1018408&partnerID=40&md5=194cd78b8cee9576b7a1116140f77961","The asynchrony of urban expansion and urban water environmental protection is a common problem in the process of urbanization. Although urban expansion results in population agglomeration and dramatic changes of land use, it also brings municipal water infrastructures to enhance the water quality of urban water bodies. In order to understand the relationship between water quality and urban expansion and water environmental management, total nitrogen (TN) and total phosphorus (TP) concentrations were measured, which were taken from 68 small urban water bodies in three distance bands (<5 km, 5–10 km and >10 km away from the city center of Changsha City, China) and four main water management types of protection, recovery, degradation and fisheries. The results showed that: 1) with increase in distance away from the city center, TN and TP concentrations in small water bodies and the percentage of polluted samples (IV ∼ inferior V) showed an increasing trend. 2) The degree of protection of small urban water bodies in the study area has not been synchronistic with urban expansion. The protected water bodies (long-term protected and recovering) are mainly distributed in the <5 km distance band, and anthropogenic disturbances (degraded water bodies and small water bodies used for fish farming) were mainly distributed in the 5–10 km and >10 km distance bands. Also, degraded and fish-managed water bodies had higher TN and TP contents than protected and recovering water bodies, but their TN:TP ratios were significantly lower. 3) Overall, urban expansion and water body management contributed 55.8% of the variance of TN and TP concentrations and TN:TP ratios in the study area. Water body management alone contributed 22.2%, which was higher than the contribution of urban expansion (7.6%). This shows that the insufficient application of water environmental protection measures has significantly changed the spatial distribution patterns of N and P concentrations and TN:TP ratios in urban small water bodies as the Changsha urban area has expanded. In the process of urban expansion, the simultaneous development of urban water ecological management is essential to ensure the health protection of the urban water environment. Copyright © 2022 Zhou, Li, Lei, Feng, Luo and Lindsey.","nitrogen and phosphorus; small water bodies; spatial pattern; TN:TP ratios; urban expansion; water environmental protection",
"Zhou J., Zhang Y., Sha Y., Zhou J., Ren H., Shen X., Xu H.","The Effect of the “Triple-Layer Medical Security” Policy on the Vulnerability as Expected Poverty of Rural Households: Evidence from Yunnan Province, China","10.3390/ijerph191912936","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139919290&doi=10.3390%2fijerph191912936&partnerID=40&md5=eb3b8eb8d3c61cf9ea53950b87dae86f","China launched the “critical battle against poverty” nationwide in 2012. As its main battlefield, Yunnan province promulgated the “triple medical security” (TMS) policy in 2017. This study, based on the pooled cross-section database of 2015–2020 of registered poor households in Yunnan province, employed the logit model to examine the effect of TMS on the vulnerability as expected poverty (VEP) of these households. It found that increasing the reimbursement rates for overall medical expenses and inpatient expenses and decreasing the proportion of out-of-pocket medical payment to income reduced the VEP; increases in the number of sick people in the family increased its VEP, and although the increase in the reimbursement rate for overall medical expenses or for inpatient expenses partially offset the VEP caused by the increase in the number of chronically ill people in the family, the VEP caused by the increase in the number of critically ill people would increase in the short term with the increase in the reimbursement rate for overall medical expenses or for inpatient expenses. The findings help improve policies concerning the medical security and health of the rural poor population, providing theoretical reference and practical guidance for future research. © 2022 by the authors.","China; registered poor households; triple-layer medical security (TMS); vulnerability as expected poverty (VEP); Yunnan province","health expenditure; household income; poverty alleviation; rural area; rural policy; security; vulnerability; adult; article; China; chronic patient; critically ill patient; hospital patient; household; human; poverty; reimbursement; security; theoretical study; vulnerability; China; epidemiology; family size; health care cost; policy; poverty; rural population; China; Yunnan; China; Family Characteristics; Health Expenditures; Humans; Policy; Poverty; Rural Population"
"Zhou P., Enders T.A., Myers Z.A., Magnusson E., Crisp P.A., Noshay J.M., Gomez-Cano F., Liang Z., Grotewold E., Greenham K., Springer N.M.","Prediction of conserved and variable heat and cold stress response in maize using cis-regulatory information","10.1093/plcell/koab267","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123347504&doi=10.1093%2fplcell%2fkoab267&partnerID=40&md5=b60f017bf2b026f92b0c2bc9f8c42b41","Changes in gene expression are important for responses to abiotic stress. Transcriptome profiling of heat- or cold-stressed maize genotypes identifies many changes in transcript abundance. We used comparisons of expression responses in multiple genotypes to identify alleles with variable responses to heat or cold stress and to distinguish examples of cis- or trans-regulatory variation for stress-responsive expression changes. We used motifs enriched near the transcription start sites (TSSs) for thermal stress-responsive genes to develop predictive models of gene expression responses. Prediction accuracies can be improved by focusing only on motifs within unmethylated regions near the TSS and vary for genes with different dynamic responses to stress. Models trained on expression responses in a single genotype and promoter sequences provided lower performance when applied to other genotypes but this could be improved by using models trained on data from all three genotypes tested. The analysis of genes with cis-regulatory variation provides evidence for structural variants that result in presence/absence of transcription factor binding sites in creating variable responses. This study provides insights into cis-regulatory motifs for heat- and cold-responsive gene expression and defines a framework for developing models to predict expression responses across multiple genotypes. © The Author(s) 2021. Published by Oxford University Press on behalf of American Society of Plant Biologists.",,"transcriptome; cold shock response; gene expression profiling; gene expression regulation; genetics; heat shock response; maize; physiology; plant gene; Cold-Shock Response; Gene Expression Profiling; Gene Expression Regulation, Plant; Genes, Plant; Heat-Shock Response; Transcriptome; Zea mays"
"Zhou R., Abbasi K.R., Salem S., Almulhim A.I., Alvarado R.","Do natural resources, economic growth, human capital, and urbanization affect the ecological footprint? A modified dynamic ARDL and KRLS approach","10.1016/j.resourpol.2022.102782","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131217131&doi=10.1016%2fj.resourpol.2022.102782&partnerID=40&md5=539e976a9ef6d735a574344092e2b6a1","The interaction between the abundance of natural resources and environmental depletion has significant ecological consequences. Nonetheless, this area is not adequately studied, and numerous results are apparent throughout the literature. For massive economic development, it is vital to recognize the role of human capital, urbanization, and natural resources. Hence it is important to consider various factors that can play a constructive role in environmental sustainability. Therefore, this study investigates the relationship between total natural resources (TNR), gross domestic product (GDP), human capital index (HCI) and urbanization (URB) with ecological footprint (EFP) in Pakistan from 1980 to 2018. The research uses the latest versions of dynamic Autoregressive Distributed Lag (ARDL) simulations model. The key benefit of dynamic ARDL is to estimate positive and negative shifts between the selected variables with an immediate visual illustration over the short and long period. In addition, the Kernel-based Regularized Least Squares (KRLS) machine learning method is used to test robustness. The results show that the rise in TNR has a long-term detrimental influence on EFP. However, upsurge in GDP and HCI increases EFP in the long-term. Lastly, URB observed an important and detrimental long-term impact on the EFP. The KRLS also support the hypothesis. This study suggest a policies to the planners and government officials for managing rapid urbanization and minimizing its urban, environmental and economic challenges. © 2022 Elsevier Ltd","DARDL; Ecological footprint; GDP; Human capital; Natural resources; Urbanization","Ecology; Economic and social effects; Economics; Learning systems; Least squares approximations; Personnel; Auto-regressive; DARDL; Ecological footprint; Economic growths; Gross domestic products; Human capital indices; Human capitals; Natural resource economics; Regularized least squares; Urbanization; Sustainable development; ecological footprint; economic development; economic growth; environmental economics; Gross Domestic Product; human capital; least squares method; machine learning; natural resource; regression analysis; urbanization"
"Zhou T., Wen X., Feng Q., Yu H., Xi H.","Bayesian Model Averaging Ensemble Approach for Multi-Time-Ahead Groundwater Level Prediction Combining the GRACE, GLEAM, and GLDAS Data in Arid Areas","10.3390/rs15010188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145879360&doi=10.3390%2frs15010188&partnerID=40&md5=ab4a727765b5f9aa27c4e5a60096ac88","Accurate groundwater level (GWL) prediction is essential for the sustainable management of groundwater resources. However, the prediction of GWLs remains a challenge due to insufficient data and the complicated hydrogeological system. In this study, we investigated the ability of the Gravity Recovery and Climate Experiment (GRACE) satellite data, the Global Land Evaporation Amsterdam Model (GLEAM) data, the Global Land Data Assimilation System (GLDAS) data, and the publicly available meteorological data in 1-, 2-, and 3-month-ahead GWL prediction using three traditional machine learning models (extreme learning machine, ELM; support vector machine, SVR; and random forest, RF). Meanwhile, we further developed the Bayesian model averaging (BMA) by combining the ELM, SVR, and RF models to avoid the uncertainty of the single models and to improve the predicting accuracy. The validity of the forcing data and the BMA model were assessed for three GWL monitoring wells in the Zhangye Basin in Northwest China. The results indicated that the applied forcing data could be treated as validated inputs to predict the GWL up to 3 months ahead due to the achieved high accuracy of the machine learning models (NS > 0.55). The BMA model could significantly improve the performance of the single machine learning models. Overall, the BMA model reduced the RMSE of the ELM, SVR, and RF models in the testing period by about 13.75%, 24.01%, and 17.69%, respectively; while it improved the NS by about 8.32%, 16.13%, and 9.67% for 1-, 2-, and 3-month-ahead GWL prediction, respectively. The uncertainty analysis results also verified the reliability of the BMA model in multi-time-ahead GWL predicting. This highlighted the efficiency of the satellite data, satellite-based data, and publicly available data as substitute inputs in machine-learning-based GWL prediction, particularly for areas with insufficient or missing data. Meanwhile, the BMA ensemble strategy can serve as a powerful and reliable approach in multi-time-ahead GWL prediction when risk-based decision making is needed or a lack of relevant hydrogeological data impedes the application of the physical models. © 2022 by the authors.","Bayesian model averaging; GLDAS; GLEAM; GRACE; groundwater level","Climate models; Decision making; Forestry; Geodetic satellites; Groundwater; Groundwater resources; Learning systems; Reliability analysis; Support vector machines; Uncertainty analysis; Amsterdam; Bayesian model averaging; Global land data assimilation system; Global land evaporation amsterdam model; Gravity recovery and climate experiments; Ground water level; Hydrogeological; Land data assimilation systems; Land evaporation; Machine learning models; Forecasting"
"Zhou W., Liu M., Xu Z., Herrera-Viedma E.","Global fusion of multiple order relations and hesitant fuzzy decision analysis","10.1007/s10489-021-02689-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115053958&doi=10.1007%2fs10489-021-02689-5&partnerID=40&md5=ad80461482e858dff629a67c07abd6b0","Generally, when making decisions, decision makers always have their subjective opinions regarding attributes, alternatives or even themselves based on their experience and knowledge. Although some methods, such as weighted aggregation, preference analysis, and fuzzy decision-making, can be used to describe and fuse these opinions, these methods involve two limitations, specifically, inaccurate numerical presentation and stepwise aggregation method. To address these issues, in this paper, we define multiple order relations expressed as several inequalities to describe these subjective opinions, and then propose hesitant fuzzy global fusion models to simultaneously fuse the multiple order relations and make a decision. To this end, we first introduce the hesitant fuzzy envelopment rate and develop partial fusion models for single order relations; subsequently, multiple order relations and global fusion model are proposed. Moreover, to ensure computability, we further derive the linear forms of these models and summarize the improvement schedules for the nonoptimal alternatives. According to these calculations and results, a hesitant fuzzy decision analysis including subjective opinion fusion, evaluation presentation, decision-making calculation, alternative ranking and selection, and nonoptimal improvement, can be performed. Finally, an illustrative example based on a real background is considered to show the effectiveness of the models and decision analysis processes. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Alternative optimization; Decision analysis; Global fusion; Hesitant fuzzy set; Multiple order relations","Numerical methods; Aggregation methods; Alternative ranking; Analysis process; Decision makers; Fuzzy decision analysis; Fuzzy Decision making; Making decision; Preference analysis; Decision making"
"Zhou Y., Lentz E., Michelson H., Kim C., Baylis K.","Machine learning for food security: Principles for transparency and usability","10.1002/aepp.13214","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120341889&doi=10.1002%2faepp.13214&partnerID=40&md5=57d2b60033250a377a6583d7a549f543","Machine learning (ML) holds potential to predict hunger crises before they occur. Yet, ML models embed crucial choices that affect their utility. We develop a prototype model to predict food insecurity across three countries in sub-Saharan Africa. Readily available data on prices, assets, and weather all influence our model predictions. Our model obtains 55%–84% accuracy, substantially outperforming both a logit and ML models using only time and location. We highlight key principles for transparency and demonstrate how modeling choices between recall and accuracy can be tailored to policy-maker needs. Our work provides a path for future modeling efforts in this area. © 2021 Agricultural & Applied Economics Association.","food policy; food security; machine learning; remote-sensing; sub-Saharan Africa",
"Zhou Y., Wu W., Wang H., Zhang X., Yang C., Liu H.","Identification of Soil Texture Classes Under Vegetation Cover Based on Sentinel-2 Data With SVM and SHAP Techniques","10.1109/JSTARS.2022.3164140","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127514348&doi=10.1109%2fJSTARS.2022.3164140&partnerID=40&md5=1eb782578ca77ce719f9c474bffacb10","Understanding the spatial variability of soil texture classes is essential for agricultural management and environment sustainability. Sentinel-2 data offer valuable vegetation information as proxies for soil properties inference. However, the applications of them in soil texture classification are still limited. This study investigated the usefulness of Sentinel-2 data for predicting soil texture class using an interpretable machine learning (ML) strategy. Specifically, multitemporal Sentinel-2 images were used to get exhaustive vegetation cover information. Basic digital elevation map (DEM) derivatives and stratum were extracted. Three support vector machines with different input parameters (purely DEM derivatives and stratum, purely Sentinel-2, and Sentinel-2 plus DEM derivatives and stratum) were developed. Moreover, in order to improve the transparency in black box ML models, the novel SHapley Additive exPlanations (SHAP) method was applied to interpret the outputs and analyze the importance of individual variables. Results showed that the model with all variables provided desirable performance with overall accuracy of 0.8435, F1-score of 0.835, kappa statistic of 0.7642, precision of 0.8388, recall of 0.8355, and area under the curve of 0.9451. The model with purely Sentinel-2 data performed much better than that with solely DEM derivatives and stratum. The contributions of Sentinel-2 data to explain soil texture class variability were about 17%, 41%, and 28% for sandy, loamy and clayey soils, respectively. The SHAP method visualized the decision process of ML and indicated that elevation, stratum, and red-edge factors were critical variables for predicting soil texture classes. This study offered much-needed insights into the applications of Sentinel-2 data in digital soil mapping and ML-assisted tasks. © 2008-2012 IEEE.","Machine learning (ML); sentinel-2; shapley additive explanations (SHAP); soil texture classes","Mapping; Remote sensing; Soil surveys; Soils; Vegetation; Index; Remote-sensing; Sentinel-2; Shapley; Shapley additive explanation; Soil texture class; Soil textures; Spatial resolution; Support vectors machine; Vegetation mapping; Support vector machines; numerical model; remote sensing; satellite data; satellite imagery; Sentinel; soil property; soil texture; support vector machine"
"Zhou Y., Liu Y., Wang D., Liu X., Wang Y.","A review on global solar radiation prediction with machine learning models in a comprehensive perspective","10.1016/j.enconman.2021.113960","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102358454&doi=10.1016%2fj.enconman.2021.113960&partnerID=40&md5=c1de4beb8d33c6e6ee0efeeb826bf6b4","Global solar radiation information is the basis for many solar energy utilizations as well as for economic and environmental considerations. However, because solar-radiation changes, and measurements are sometimes not available, accurate global solar-radiation data are often difficult or impossible to obtain. Machine-learning models, on the other hand, are capable of conducting highly nonlinear problems. They have many potential applications and are of high interest to researchers worldwide. Based on 232 paper regarding to the machine-learning models for global solar radiation prediction, this paper provides a comprehensive and systematic review of all important aspects surrounding machine-learning models, including input parameters, feature selection and model development. The pros and cons of three input-parameter sources (observation data from a surface meteorological observation station, satellite-based data, numerical weather-predicting re-analyzed data) and three feature selection methods (filter, wrapped, embedded) are reviewed and analyzed in this paper. Using data pre-processing algorithms, output ensemble methods, and model purposes, seven classes of machine-learning models are identified and reviewed. Finally, the state of current and future research on machine-learning models to forecast the global solar radiation are discussed. This paper provides a compact guide of existing model modification and novel model development regarding predicting global solar radiation. © 2021 Elsevier Ltd","Feature selection; Global solar radiation; Input parameters; Machine-learning model; Predictive modelling","Data handling; Machine learning; Numerical methods; Solar energy; Solar radiation; Weather forecasting; Economic considerations; Environmental considerations; Features selection; Input parameter; Machine learning models; Model development; Predictive models; Radiation information; Solar energy utilization; Solar radiation predictions; Feature extraction"
"Zhou Y., Rao B., Wang W.","UAV swarm intelligence: Recent advances and future trends","10.1109/ACCESS.2020.3028865","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102844003&doi=10.1109%2fACCESS.2020.3028865&partnerID=40&md5=84a17bc2601939cb32f4a994a50359b4","The dynamic uncertain environment and complex tasks determine that the unmanned aerial vehicle (UAV) system is bound to develop towards clustering, autonomy, and intelligence. In this article, we present a comprehensive survey of UAV swarm intelligence from the hierarchical framework perspective. Firstly, we review the basics and advances of UAV swarm intelligent technology. Then we look inside to investigate the research work by classifying UAV swarm intelligence research into five layers, i.e., decisionmaking layer, path planning layer, control layer, communication layer, and application layer. Furthermore, the relationship between each level is explicitly illustrated, and the research trends of each layer are given. Finally, limitations and possible technology trends of swarm intelligence are also covered to enable further research interests. Through this in-depth literature review, we intend to provide novel insights into the latest technologies in UAV swarm intelligence. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.","Hierarchical control framework; Swarm intelligence; Trend; UAV","Antennas; Swarm intelligence; Communication layers; Dynamic uncertain environments; Latest technology; Literature reviews; Research interests; Swarm intelligent; Technology trends; Unmanned aerial vehicle systems; Unmanned aerial vehicles (UAV)"
"Zhu P., Abramoff R., Makowski D., Ciais P.","Uncovering the Past and Future Climate Drivers of Wheat Yield Shocks in Europe With Machine Learning","10.1029/2020EF001815","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106952155&doi=10.1029%2f2020EF001815&partnerID=40&md5=927a287907f3a0e9c69cc4ea1c1ed400","Recently, yield shocks due to extreme weather events and their consequences for food security have become a major concern. Although long yield time series are available in Europe, few studies have been conducted to analyze them in order to investigate the impact of adverse climate events on yield shocks under current and future climate conditions. Here we designated the lowest 10th percentile of the relative yield anomaly as yield shock and analyzed subnational wheat yield shocks across Europe during the last four decades. We applied a data-driven attribution framework to quantify primary climate drivers of wheat yield shock probability based on machine learning and game theory, and used this framework to infer the most critical climate variables that will contribute to yield shocks in the future, under two climate change scenarios. During the period 1980–2018, our attribution analysis showed that 32% of the observed wheat yield shocks were primarily driven by water limitation, making it the leading climate driver. Projection to future climate scenarios RCP4.5 and RCP8.5 suggested an increased risk of yield shock and a paradigm shift from water limitation dominated yield shock to extreme warming induced shocks over 2070–2099: 46% and 54% of areas were primarily driven by extreme warming under RCP4.5 and RCP8.5, respectively. A similar analysis conducted on yields simulated by an ensemble of crop models showed that models can capture the negative impact of low water supply but missed the impact of excess water. These discrepancies between observed and simulated yield data call for improvement in crop models. © 2021. The Authors. Earth's Future published by Wiley Periodicals LLC on behalf of American Geophysical Union.","attribution analysis; extreme climate; extreme warming; random forest; winter wheat; yield shock","climate change; crop yield; environmental factor; food security; machine learning; paradigm shift; time series analysis; water supply; wheat; Europe"
"Zhu W., Benkwitz F., Kilmartin P.A.","Alternative Perspective on Rapid Wine Oxidation through Changes in Gas-Phase Volatile Concentrations, Highlighted by Matrix Component Effects","10.1021/acs.jafc.2c00437","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131018877&doi=10.1021%2facs.jafc.2c00437&partnerID=40&md5=5cdc95a608f84a22031c648ba0bbbd12","A new perspective is presented to investigate the sensorially relevant gas-phase concentrations of volatile compounds in wine. This is achieved by measuring the partition coefficients and matrix-phase concentrations of volatiles using static headspace-gas chromatography-ion mobility spectrometry. Physicochemical properties that can contribute to the partition behaviors of 10 volatile esters, such as hydrophobicity and matrix temperature, are also discussed. Partition coefficients are then linked to quantitative measurements to obtain partial pressures, which describe the availability of volatile compounds in the gas phase. The concept of partition coefficients and partial pressure has then been applied to a time series of aroma changes due to oxidation in commercial wines. As a follow-up study, a full factorial design was devised to inspect the impact of three common wine matrix components, namely, copper, polyphenols, and ascorbic acid, on the partial pressure changes after 30-day oxidation treatment in either full-alcohol or low-alcohol simulated wine matrices. Interesting interactive effects between antioxidant behaviors and alcohol levels were elucidated, especially around the controversial use of ascorbic acid in winemaking. These results can guide winemakers who wish to minimize oxidative damage to wine aroma during wine storage or bulk transport, where ullage may be present or continual oxygen ingress may be occurring. © 2022 American Chemical Society. All rights reserved.","oxidation; partial pressure; partition coefficient; static headspace-gas chromatography-ion mobility spectrometry (SHS-GC-IMS); wine; wine matrix components","Ascorbic acid; Gas chromatography; Gases; Ion mobility spectrometers; Odors; Partial pressure; Spectrometry; Volatile organic compounds; Wine; Gas-phases; Headspace gas chromatography; Ion mobility spectrometry; Matrix components; Partition coefficient; Static headspace; Static headspace-gas chromatography-ion mobility spectrometry; Volatile compounds; Wine matrix; Wine matrix component; Oxidation; ascorbic acid; fragrance; volatile organic compound; chemistry; follow up; mass fragmentography; wine; Ascorbic Acid; Follow-Up Studies; Gas Chromatography-Mass Spectrometry; Odorants; Volatile Organic Compounds; Wine"
"Zhu W., Benkwitz F., Sarmadi B., Kilmartin P.A.","Validation Study on the Simultaneous Quantitation of Multiple Wine Aroma Compounds with Static Headspace-Gas Chromatography-Ion Mobility Spectrometry","10.1021/acs.jafc.1c06411","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121025538&doi=10.1021%2facs.jafc.1c06411&partnerID=40&md5=ca8d549c74669a0a0aa68e07a70200aa","A new quantitative method based on static headspace-gas chromatography-ion mobility spectrometry (SHS-GC-IMS) is proposed, which enables the simultaneous quantitation of multiple aroma compounds in wine. The method was first evaluated for its stability and the necessity of using internal standards as a quality control measure. The two major hurdles in applying GC-IMS in quantitation studies, namely, nonlinearity and multiple ion species, were also investigated using the Boltzmann function and generalized additive model (GAM) as potential solutions. Metrics characterizing the model performance, including root mean squared error, bias, limit of detection, limit of quantitation, repeatability, reproducibility, and recovery, were investigated. Both nonlinear fitting methods, Boltzmann function and GAM, were able to return desirable analytical outcomes with an acceptable range of error. Potential pitfalls that would cause inaccurate quantitation, that is, effects of ethanol content and competitive ionization, were also discussed. The performance of the SHS-GC-IMS method was subsequently compared against that of a currently established method, namely, GC-MS, using commercial wine samples. These findings provide an initial validation of a GC-IMS-based quantitation method, as well as a starting point for further enhancing the analytical scope of GC-IMS. ©","method comparison; method development and validation; quantitative analysis; static headspace-gas chromatography-ion mobility spectrometry (SHS-GC-IMS); wine","Electronic nose; Gas chromatography; Ionization of gases; Ions; Mean square error; Odors; Quality control; Spectrometry; Wine; Aroma compounds; Boltzmann function; Generalized additive model; Headspace gas chromatography; Ion mobility spectrometry; Method comparison; Method development; Method validations; Static headspace; Static headspace-gas chromatography-ion mobility spectrometry; Ion mobility spectrometers; fragrance; volatile organic compound; ion mobility spectrometry; mass fragmentography; reproducibility; wine; Gas Chromatography-Mass Spectrometry; Ion Mobility Spectrometry; Odorants; Reproducibility of Results; Volatile Organic Compounds; Wine"
"Zhu X., Hu J., Xiao T., Huang S., Wen Y., Shang D.","An interpretable stacking ensemble learning framework based on multi-dimensional data for real-time prediction of drug concentration: The example of olanzapine","10.3389/fphar.2022.975855","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139569053&doi=10.3389%2ffphar.2022.975855&partnerID=40&md5=4fe908a4687451acc6b39ad889218f30","Background and Aim: Therapeutic drug monitoring (TDM) has evolved over the years as an important tool for personalized medicine. Nevertheless, some limitations are associated with traditional TDM. Emerging data-driven model forecasting [e.g., through machine learning (ML)-based approaches] has been used for individualized therapy. This study proposes an interpretable stacking-based ML framework to predict concentrations in real time after olanzapine (OLZ) treatment. Methods: The TDM-OLZ dataset, consisting of 2,142 OLZ measurements and 472 features, was formed by collecting electronic health records during the TDM of 927 patients who had received OLZ treatment. We compared the performance of ML algorithms by using 10-fold cross-validation and the mean absolute error (MAE). The optimal subset of features was analyzed by a random forest-based sequential forward feature selection method in the context of the top five heterogeneous regressors as base models to develop a stacked ensemble regressor, which was then optimized via the grid search method. Its predictions were explained by using local interpretable model-agnostic explanations (LIME) and partial dependence plots (PDPs). Results: A state-of-the-art stacking ensemble learning framework that integrates optimized extra trees, XGBoost, random forest, bagging, and gradient-boosting regressors was developed for nine selected features [i.e., daily dose (OLZ), gender_male, age, valproic acid_yes, ALT, K, BW, MONO#, and time of blood sampling after first administration]. It outperformed other base regressors that were considered, with an MAE of 0.064, R-square value of 0.5355, mean squared error of 0.0089, mean relative error of 13%, and ideal rate (the percentages of predicted TDM within ± 30% of actual TDM) of 63.40%. Predictions at the individual level were illustrated by LIME plots, whereas the global interpretation of associations between features and outcomes was illustrated by PDPs. Conclusion: This study highlights the feasibility of the real-time estimation of drug concentrations by using stacking-based ML strategies without losing interpretability, thus facilitating model-informed precision dosing. Copyright © 2022 Zhu, Hu, Xiao, Huang, Wen and Shang.","drug concentration; electronic health record; interpretability; machine learning; model-informed precision dosing; olanzapine; stacking; therapeutic drug monitoring","alanine aminotransferase; olanzapine; potassium; valproic acid; adolescent; adult; age; aged; Article; blood sampling; body weight; child; cohort analysis; conceptual framework; controlled study; cross validation; data analysis; drug blood level; drug concentration; drug database; drug monitoring; electronic health record; feasibility study; female; gender; human; information processing; interpretable stacking based machine learning framework; local interpretable model agnostic explanations; machine learning; major clinical study; male; mean absolute error; mean relative error; mean squared error; measurement accuracy; partial dependence plots; personalized medicine; prediction; process optimization; random forest; school child; statistical error; statistical model; statistical parameters; very elderly"
"Zhu Z., Du Q., Wang Z., Li G.","A Survey of Multi-Agent Cross Domain Cooperative Perception","10.3390/electronics11071091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127452469&doi=10.3390%2felectronics11071091&partnerID=40&md5=ffdaeda1c8841e1bd5f8b7c3972a67c1","Intelligent unmanned systems for ground, sea, aviation, and aerospace application are important research directions for the new generation of artificial intelligence in China. Intelligent unmanned systems are also important carriers of interactive mapping between physical space and cyberspace in the process of the digitization of human society. Based on the current domestic and overseas development status of unmanned systems for ground, sea, aviation, and aerospace application, this paper reviewed the theoretical problems and research trends of multi-agent cross-domain cooperative perception. The scenarios of multi-agent cooperative perception tasks in different areas were deeply investigated and analyzed, the scientific problems of cooperative perception were analyzed, and the development direction of multi-agent cooperative perception theory research for solving the challenges of the complex environment, interactive communication, and cross-domain tasks was expounded. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.","artificial intelligence; Cooperative method; cross domain; multi-agent; perception mechanism",
"Zinonos Z., Gkelios S., Khalifeh A.F., Hadjimitsis D.G., Boutalis Y.S., Chatzichristofis S.A.","Grape Leaf Diseases Identification System Using Convolutional Neural Networks and LoRa Technology","10.1109/ACCESS.2021.3138050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122088675&doi=10.1109%2fACCESS.2021.3138050&partnerID=40&md5=672af8dbe4db33c7f32d8328f80a781b","Image transmission over Low-Power Wide Area Networks (LP-WAN) protocols has always been a difficult task since it necessitates high data rates and high energy consumption. Long Range (LoRa) is one such protocol, which is excellent for transferring data over long distances but has generated severe doubts regarding the viability of image transmission due to its low data rate. This paper demonstrates the application results of an integrated LoRa and Deep Learning-based computer vision system that can efficiently identify grape leaf diseases using low-resolution images. In particular, the focus in this paper is to combine the two technologies, LoRa and Deep Learning, to make the transmission of the images and the identification of the diseases possible. To achieve this objective, the framework utilizes a combination of on-site and simulation experiments along with different LoRa parameters and Convolutional Neural Model (CNN) model fine-tuning. Based on the evaluation, the proposed framework proved that the transmission of images using LoRa is possible within the protocol limitations (such as limited bandwidth and low duty cycle). Our fine-tuned model can efficiently identify grape leaves diseases. The technique is both efficient and adaptive to the specifics of each leaf disease, while it does not need any training data to adjust parameters. It is worth noting that today, end-user trust in Machine and Deep Learning models has increased significantly because of novel solutions in the field of Explainable Artificial Intelligence (XAI). In this study, we use the Grad-CAM method to visualize the output layer judgments of the CNN. The disease's spot region is highly activated, according to the visualization findings. This is how the network distinguishes between different grape leaf diseases. © 2013 IEEE.","CBIR; CNN; deep convolutional features; deep learning; global features; image retrieval; local features; LoRaWAN","Convolution; Deep learning; Energy utilization; Image retrieval; Imaging systems; Internet protocols; Low power electronics; Neural networks; Search engines; Wide area networks; CBIR; Convolutional neural model; Deep convolutional feature; Deep learning; Global feature; Grape leaves; Leaf disease; Local feature; LoRaWAN; Neural modelling; Temperature measurement"
"Zirar A.","Can artificial intelligence’s limitations drive innovative work behaviour?","10.1007/s11846-023-00621-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147740211&doi=10.1007%2fs11846-023-00621-4&partnerID=40&md5=0b568926aeb1684bab3774d30e3905c7","Artificial intelligence (AI) is deemed to increase workers’ productivity by enhancing their creative abilities and acting as a general-purpose tool for innovation. While much is known about AI’s ability to create value through innovation, less is known about how AI’s limitations drive innovative work behaviour (IWB). With AI’s limits in perspective, innovative work behaviour might serve as workarounds to compensate for AI limitations. Therefore, the guiding research question is: How will AI limitations, rather than its apparent transformational strengths, drive workers’ innovative work behaviour in a workplace? A search protocol was employed to identify 65 articles based on relevant keywords and article selection criteria using the Scopus database. The thematic analysis suggests several themes: (i) Robots make mistakes, and such mistakes stimulate workers’ IWB, (ii) AI triggers ‘fear’ in workers, and this ‘fear’ stimulates workers’ IWB, (iii) Workers are reskilled and upskilled to compensate for AI limitations, (iv) AI interface stimulates worker engagement, (v) Algorithmic bias requires IWB, and (vi) AI works as a general-purpose tool for IWB. In contrast to prior reviews, which generally focus on the apparent transformational strengths of AI in the workplace, this review primarily identifies AI limitations before suggesting that the limitations could also drive innovative work behaviour. Propositions are included after each theme to encourage future research. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","AI limitation; Artificial intelligence; Creativity; Innovative work behaviour; Intelligent robot; Reskilling",
"Zroug S., Remadna I., Kahloul L., Terrissa S.L., Benharzallah S.","Towards performance evaluation prediction in WSNs using artificial neural network multi-perceptron","10.1007/s10586-022-03753-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139419688&doi=10.1007%2fs10586-022-03753-6&partnerID=40&md5=39559006e49bba0a067aea70b1e564c2","The use of formal methods in specifying and verifying WSNs protocols attracts several researchers. However, based practically on state-space exploration, these formal methods face scalability problems when the specified system is complicated, which is often the case with WSNs protocols. To overcome this last problem, this paper proposes exploiting a machine learning approach to make predictions when the specified system becomes highly complex due to the increasing number of nodes. The main contribution of this paper is the application of a Multi-Layer Perceptron (MLP) to predict a set of crucial performance metrics of the CSMA/CA MAC protocol based on the historical data generated from formal models representing the whole behaviour of the WSN, including waiting time (WT), delay performance (DP), waiting time for an acknowledgement (WTA), and the throughput (TH). The empirical results demonstrate the effectiveness of the proposed MLP architecture compared to other ML techniques (SVR and LR) using various evaluation criteria (MAE, MSE, RMSE). MLP gives the best, and minimum criteria values on all performance metrics datasets in terms of MSE values are around 4.90, 3.11, 8.88, and 4 × 10 - 5 for metrics WT, WTA, DP, and TH, respectively. The obtained results in this paper proved the efficiency of the combination between formal models (i.e. Hierarchical Timed Coloured Petri Nets) and machine learning approaches that use artificial neural networks. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Formal verification; Hierarchical timed coloured petri nets; Machine learning; Multi-layer perceptron; Performance evaluation; Petri nets","Carrier sense multiple access; Forecasting; Formal verification; Machine learning; Medium access control; Multilayer neural networks; Space research; Delay performance; Formal modeling; Hierarchical timed colored Petri net; Machine learning approaches; Machine-learning; Multilayers perceptrons; On state; Performance metrices; Performances evaluation; Waiting time; Petri nets"
"Committee on Long-Term Environmental Trends in the Gulf of Mexico, Gulf Research Program, National Academies of Sciences, Engineering, and Medicine","An approach for assessing U.S. gulf coast ecosystem restoration","10.17226/26335","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145343586&doi=10.17226%2f26335&partnerID=40&md5=59fac36b18ac4dff26f5f98215e66496","Valued for its ecological richness and economic value, the U.S. Gulf of Mexico is under substantial pressure from human activities. The Deepwater Horizon platform explosion and oil spill significantly damaged Gulf ecosystems and led to the largest ecological restoration investment in history. The unprecedented number and diversity of restoration activities provide valuable information for future restoration efforts, but assessment efforts are hampered by many factors, including the need to evaluate the interaction of multiple stressors and consider long-term environmental trends such as sea level rise, increasing hurricane intensity, and rising water temperatures. This report offers a comprehensive approach to assess restoration activities beyond the project scale in the face of a changing environment. A main component of this approach is using different types of scientific evidence to develop ""multiple lines of evidence"" to evaluate restoration efforts at regional scales and beyond, especially for projects that may be mutually reinforcing (synergistic) or in conflict (antagonistic). Because Gulf of Mexico ecosystems cross political boundaries, increased coordination and collaboration is needed, especially to develop standardized data collection, analysis, synthesis, and reporting. With these improvements, program-level adaptive management approaches can be used more effectively to assess restoration strategies against the backdrop of long-term environmental trends. © 2022 by the National Academy of Sciences. All rights reserved.",,
[No author name available],"42nd SGAI International Conference on Innovative Techniques and Applications of Artificial Intelligence, AI 2022",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144960095&partnerID=40&md5=99a9788b74e59f7562d1a9e06137dc49","The proceedings contain 31 papers. The special focus in this conference is on Innovative Techniques and Applications of Artificial Intelligence. The topics include: Competitive Learning with Spiking Nets and Spike Timing Dependent Plasticity; an Evolutionary Game Theory Model of the Decision to Confront; hidden Markov Models for Surprising Pattern Detection in Discrete Symbol Sequence Data; The ODeLIndA Dataset for Field-of-View Obstruction Detection Using Transfer Learning for Real-Time Industrial Applications; automated Quality Inspection of High Voltage Equipment Supported by Machine Learning and Computer Vision; on Predicting the Work Load for Service Contractors; OAK4XAI: Model Towards Out-of-Box eXplainable Artificial Intelligence for Digital Agriculture; deep Learning for Detecting Tilt Angle and Orientation of Photovoltaic Panels on Satellite Imagery; recurrent Neural Networks for Music Genre Classification; job Assignment Problem and Traveling Salesman Problem: A Linked Optimisation Problem; explainable Boosting Machines for Network Intrusion Detection with Features Reduction; accelerating Cyber-Breach Investigations Through Novel Use of Artificial Immune System Algorithms; Comparing ML Models for Food Production Forecasting; comparing Peircean Algorithm with Various Bio-inspired Techniques for Multi-dimensional Function Optimization; Medical Recommendation System Based on Daily Clinical Reports: A Proposed NLP Approach for Emergency Departments; mentaLex: A Mental Processes Lexicon Based on the Essay Dataset; credit Card Fraud Using Adversarial Attacks; anomaly Detection and Root Cause Analysis on Log Data; Developing Testing Frameworks for AI Cameras; time is Budget: A Heuristic for Reducing the Risk of Ruin in Multi-armed Gambler Bandits; twitter Flu Trend: A Hybrid Deep Neural Network for Tweet Analysis; two-Phase Open-Domain Question Answering System; Have a Break from Making Decisions, Have a MARS: The Multi-valued Action Reasoning System; Data Augmentation for Pathology Prioritisation: An Improved LSTM-Based Approach.",,
[No author name available],"15th Multi-disciplinary International Conference on Artificial Intelligence, MIWAI 2022",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142769307&partnerID=40&md5=ed05cf08dd5e6d5699ef05ece9cf3a09","The proceedings contain 19 papers. The special focus in this conference is on Artificial Intelligence. The topics include: News Feed: A Multiagent-Based Push Notification System; Optimizing the Social Force Model Using New Hybrid WOABAT-IFDO in Crowd Evacuation in Panic Situation; recognizing Driver Activities Using Deep Learning Approaches Based on Smartphone Sensors; sentence-Level Sentiment Analysis for Student Feedback Relevant to Teaching Process Assessment; Sentiment Analysis of Local Tourism in Thailand from YouTube Comments Using BiLSTM; stable Coalitions of Buyers in Real World Agriculture Domain; The Analysis of Explainable AI via Notion of Congruence; Using Ensemble Machine Learning Methods to Forecast Particulate Matter (PM2.5) in Bangkok, Thailand; wearable Fall Detection Based on Motion Signals Using Hybrid Deep Residual Neural Network; evolutionary Feature Weighting Optimization and Majority Voting Ensemble Learning for Curriculum Recommendation in the Higher Education; fuzzy Soft Relations-Based Rough Soft Sets Classified by Overlaps of Successor Classes with Measurement Issues; Helmet Detection System for Motorcycle Riders with Explainable Artificial Intelligence Using Convolutional Neural Network and Grad-CAM; hierarchical Human Activity Recognition Based on Smartwatch Sensors Using Branch Convolutional Neural Networks; improving Predictive Model to Prevent Students’ Dropout in Higher Education Using Majority Voting and Data Mining Techniques; LCIM: Mining Low Cost High Utility Itemsets; MaxFEM: Mining Maximal Frequent Episodes in Complex Event Sequences; method for Image-Based Preliminary Assessment of Car Park for the Disabled and the Elderly Using Convolutional Neural Networks and Transfer Learning.",,
[No author name available],"ACI 2022 - Proceedings of the Workshop on Advances in Computational Intelligence, its Concepts and Applications, co-located with International Semantic Intelligence Conference, ISIC 2022",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143223775&partnerID=40&md5=d85445207b0d4ca7e25b2e6843c17772","The proceedings contain 38 papers. The topics discussed include: web benefit utilizations with K-means clustering approach for efficient clustering; explainable AI framework for multi-label classification using supervised machine learning models; measuring of similarity between pair of words using word net; microcontroller based electronic queue control system; intelligent recognition of characters from ancient manuscripts-a review; corn leaf disease identification with improved accuracy; a survey on soybean seed varieties and defects identification using neural network; student attendance system based on face recognition and machine learning; forecasting of fruits stock life using CNN-based deep learning techniques: a comprehensive study; digital image processing application in agriculture (pest detection) – a review; evolution of smart home energy management system using Internet of things and machine learning algorithms; and stock market prediction using machine learning techniques.",,
[No author name available],"1st International Conference on Smart and Sustainable Agriculture, SSA 2021",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119820741&partnerID=40&md5=8fb06d68c4a664002207b52d5472596a","The proceedings contain 12 papers. The special focus in this conference is on Smart and Sustainable Agriculture. The topics include: Development of Soil Nitrogen Estimation System in Oil Palm Land with Sentinel-1 Image Analysis Approach; new Monitoring Framework Intelligent Irrigation System; ensuring Smart Agriculture System Communication Confidentiality Using a New Network Steganography Method; deploying Deep Neural Networks on Edge Devices for Grape Segmentation; abnormal Behavior Detection in Farming Stream Data; eWeightSmart - A Smart Approach to Beef Production Management; Gaia-AgStream: An Explainable AI Platform for Mining Complex Data Streams in Agriculture; comparison of Machine Learning and Deep Learning Methods for Grape Cluster Segmentation; smart and Sustainable Agriculture: Machine Learning Behind This (R)evolution; a Methodology for Early Detection of Plant Diseases Using Real Time Object Detection Algorithm.",,
[No author name available],"16th IFIP WG 12.5 International Conference on Artificial Intelligence Applications and Innovations, AIAI 2020",,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086249791&partnerID=40&md5=0ce64000136ee465cbbdb18fa6afb21d","The proceedings contain 75 papers. The special focus in this conference is on Artificial Intelligence Applications and Innovations. The topics include: Using Multimodal Contextual Process Information for the Supervised Detection of Connector Lock Events; a Machine Learning Model to Detect Speech and Reading Pathologies; Forecasting Hazard Level of Air Pollutants Using LSTM’s; hypotheses Tests Using Non-asymptotic Fuzzy Estimators and Fuzzy Critical Values; preservation of the Exchange Principle via Lattice Operations on (S,N)– Implications; Versatile Internet of Things for Agriculture: An eXplainable AI Approach; Acoustic Resonance Testing of Glass IV Bottles; AI Based Real-Time Signal Reconstruction for Wind Farm with SCADA Sensor Failure; Autonomous Navigation for Drone Swarms in GPS-Denied Environments Using Structured Learning; Trustworthy AI Needs Unbiased Dictators!; chemical Laboratories 4.0: A Two-Stage Machine Learning System for Predicting the Arrival of Samples; predicting Physical Properties of Woven Fabrics via Automated Machine Learning and Textile Design and Finishing Features; real-Time Surf Manoeuvres’ Detection Using Smartphones’ Inertial Sensors; SDN-Enabled IoT Anomaly Detection Using Ensemble Learning; harnessing Social Interactions on Twitter for Smart Transportation Using Machine Learning; an Intelligent Cloud-Based Platform for Effective Monitoring of Patients with Psychotic Disorders; applying Deep Learning to Predicting Dementia and Mild Cognitive Impairment; Bridging the Gap Between AI and Healthcare Sides: Towards Developing Clinically Relevant AI-Powered Diagnosis Systems; know Yourself: An Adaptive Causal Network Model for Therapeutic Intervention for Regaining Cognitive Control; multi-omics Data and Analytics Integration in Ovarian Cancer; An Introduction of FD-Complete Constraints; overlap-Based Undersampling Method for Classification of Imbalanced Medical Datasets; greek Lyrics Generation.",,
